cognition: 
    model: gemma # Mistral/gemma/codellama_Q (Remember to set True in "load_models" section)
    model_name: 'google/gemma-7b'
    access_token_file: 'access_tokens/viper.key'
    is_setted: True
load_models:
    gemma: True
    mistral: False