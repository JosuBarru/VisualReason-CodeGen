codex:
    model: codellama
    model_name: 'codellama/CodeLlama-7b-Instruct-hf' 
    prompt: ./prompts/benchmarks/gqa.prompt
    temperature: 0.6
    adapter: 
load_models:
    codellama: True