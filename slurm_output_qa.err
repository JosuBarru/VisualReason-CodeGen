Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
[Memory(location=cache/joblib)]: Flushing completely the cache
  0%|          | 0/1049 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
/sorgin1/users/jbarrutia006/viper/main_project.py:277: UserWarning: Not executing code! This is only generating the code. We set the flag 'execute_code' to False by default, because executing code generated by a language model can be dangerous. Set the flag 'execute_code' to True if you want to execute it.
  warnings.warn("Not executing code! This is only generating the code. We set the flag "
  0%|          | 1/1049 [00:37<10:47:01, 37.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|          | 2/1049 [01:13<10:41:51, 36.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|          | 3/1049 [01:50<10:40:27, 36.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|          | 3/1049 [02:26<14:13:30, 48.96s/it]
Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/main_project.py", line 330, in <module>
    main()
  File "/sorgin1/users/jbarrutia006/viper/main_project.py", line 321, in main
    save_results(all_data, dataset)
  File "/sorgin1/users/jbarrutia006/viper/main_project.py", line 140, in save_results
    all_splits = [config.dataset.split for _ in range(config.dataset.max_samples)]
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object cannot be interpreted as an integer
srun: error: localhost: task 0: Exited with exit code 1
