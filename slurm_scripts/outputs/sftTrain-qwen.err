wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbarrutia006 (jbarrutia006-upv-ehu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /sorgin1/users/jbarrutia006/viper/wandb/run-20250530_082754-z0yvwi5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run qwen
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jbarrutia006-upv-ehu/viperSFT
wandb: üöÄ View run at https://wandb.ai/jbarrutia006-upv-ehu/viperSFT/runs/z0yvwi5x
2025-05-30 08:27:56,660 - INFO - Results will be saved to: ./sft_trained_models/05-30_08-27-56
2025-05-30 08:27:56,660 - INFO - Loading model and tokenizer...
Unsloth: unsloth/Qwen2.5-Math-7B-Instruct can only handle sequence lengths of at most 4096.
But with kaiokendev's RoPE scaling of 1.709, it can be magically be extended to 7000!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [01:07<03:21, 67.05s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [02:11<02:10, 65.34s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [03:02<00:58, 58.92s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [03:33<00:00, 48.04s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [03:33<00:00, 53.46s/it]
Unsloth 2025.3.14 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.
2025-05-30 08:31:42,419 - INFO - Loading SFT train and dev datasets...
/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Unsloth: Tokenizing ["text"] (num_proc=128):   0%|          | 0/7824 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   1%|          | 62/7824 [00:00<01:32, 83.71 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   2%|‚ñè         | 124/7824 [00:00<00:49, 156.94 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   3%|‚ñé         | 248/7824 [00:01<00:24, 307.16 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   5%|‚ñç         | 372/7824 [00:01<00:16, 439.76 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   6%|‚ñã         | 496/7824 [00:01<00:13, 549.25 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   8%|‚ñä         | 620/7824 [00:01<00:12, 596.68 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  10%|‚ñâ         | 744/7824 [00:01<00:10, 660.06 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  11%|‚ñà         | 868/7824 [00:01<00:11, 614.43 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  13%|‚ñà‚ñé        | 992/7824 [00:02<00:09, 727.99 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  14%|‚ñà‚ñç        | 1114/7824 [00:02<00:08, 795.86 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  16%|‚ñà‚ñå        | 1236/7824 [00:02<00:07, 873.10 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  17%|‚ñà‚ñã        | 1358/7824 [00:02<00:08, 765.04 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  20%|‚ñà‚ñà        | 1602/7824 [00:02<00:05, 1045.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  22%|‚ñà‚ñà‚ñè       | 1724/7824 [00:02<00:06, 917.04 examples/s] Unsloth: Tokenizing ["text"] (num_proc=128):  24%|‚ñà‚ñà‚ñé       | 1846/7824 [00:02<00:06, 958.43 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  26%|‚ñà‚ñà‚ñå       | 2029/7824 [00:03<00:05, 1019.70 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  27%|‚ñà‚ñà‚ñã       | 2151/7824 [00:03<00:05, 969.78 examples/s] Unsloth: Tokenizing ["text"] (num_proc=128):  29%|‚ñà‚ñà‚ñâ       | 2273/7824 [00:03<00:05, 966.25 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  31%|‚ñà‚ñà‚ñà       | 2395/7824 [00:03<00:05, 915.64 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  32%|‚ñà‚ñà‚ñà‚ñè      | 2517/7824 [00:03<00:06, 823.46 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  34%|‚ñà‚ñà‚ñà‚ñé      | 2639/7824 [00:03<00:05, 873.10 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  35%|‚ñà‚ñà‚ñà‚ñå      | 2761/7824 [00:03<00:06, 820.17 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  37%|‚ñà‚ñà‚ñà‚ñã      | 2883/7824 [00:04<00:05, 883.32 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  38%|‚ñà‚ñà‚ñà‚ñä      | 3005/7824 [00:04<00:05, 922.78 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  40%|‚ñà‚ñà‚ñà‚ñâ      | 3127/7824 [00:04<00:04, 970.56 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3249/7824 [00:04<00:05, 792.43 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3371/7824 [00:04<00:05, 866.58 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 3554/7824 [00:04<00:03, 1080.69 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3676/7824 [00:04<00:04, 965.61 examples/s] Unsloth: Tokenizing ["text"] (num_proc=128):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3859/7824 [00:04<00:03, 1143.51 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4042/7824 [00:05<00:03, 1018.70 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4164/7824 [00:05<00:03, 1039.09 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4286/7824 [00:05<00:03, 1061.86 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4408/7824 [00:05<00:03, 1080.92 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4530/7824 [00:05<00:03, 1093.58 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4652/7824 [00:05<00:02, 1107.31 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4774/7824 [00:05<00:02, 1121.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4896/7824 [00:05<00:02, 1124.76 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5079/7824 [00:06<00:02, 1004.80 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5201/7824 [00:06<00:02, 1042.83 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5323/7824 [00:06<00:02, 1063.74 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5506/7824 [00:06<00:01, 1238.96 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 5689/7824 [00:06<00:01, 1069.05 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5872/7824 [00:06<00:01, 1215.80 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6055/7824 [00:06<00:01, 1347.28 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 6238/7824 [00:07<00:01, 1116.57 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 6421/7824 [00:07<00:01, 1124.32 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 6543/7824 [00:07<00:01, 1131.01 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6665/7824 [00:07<00:01, 1128.25 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 6787/7824 [00:07<00:01, 982.98 examples/s] Unsloth: Tokenizing ["text"] (num_proc=128):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 6909/7824 [00:07<00:00, 1019.13 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 7153/7824 [00:07<00:00, 1154.96 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 7336/7824 [00:08<00:00, 1260.71 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 7519/7824 [00:08<00:00, 1256.10 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 7702/7824 [00:08<00:00, 1189.53 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7824/7824 [00:08<00:00, 910.26 examples/s] 
Unsloth: Tokenizing ["text"] (num_proc=128):   0%|          | 0/1000 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   1%|          | 8/1000 [00:00<00:59, 16.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   2%|‚ñè         | 24/1000 [00:00<00:22, 43.30 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   4%|‚ñç         | 40/1000 [00:00<00:14, 68.17 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   6%|‚ñã         | 64/1000 [00:00<00:09, 95.81 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   9%|‚ñâ         | 88/1000 [00:01<00:07, 126.90 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  10%|‚ñà         | 104/1000 [00:01<00:06, 131.83 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  12%|‚ñà‚ñè        | 120/1000 [00:01<00:06, 134.88 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  14%|‚ñà‚ñé        | 136/1000 [00:01<00:06, 138.70 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  15%|‚ñà‚ñå        | 152/1000 [00:01<00:06, 124.04 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  18%|‚ñà‚ñä        | 176/1000 [00:01<00:05, 147.85 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  19%|‚ñà‚ñâ        | 192/1000 [00:01<00:05, 148.52 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  21%|‚ñà‚ñà        | 208/1000 [00:01<00:06, 130.37 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  23%|‚ñà‚ñà‚ñé       | 232/1000 [00:01<00:04, 155.35 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  26%|‚ñà‚ñà‚ñå       | 256/1000 [00:02<00:04, 152.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  28%|‚ñà‚ñà‚ñä       | 280/1000 [00:02<00:04, 150.28 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  30%|‚ñà‚ñà‚ñâ       | 296/1000 [00:02<00:04, 149.62 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  31%|‚ñà‚ñà‚ñà       | 312/1000 [00:02<00:04, 149.68 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  33%|‚ñà‚ñà‚ñà‚ñé      | 328/1000 [00:02<00:04, 150.98 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  34%|‚ñà‚ñà‚ñà‚ñç      | 344/1000 [00:02<00:04, 149.29 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  36%|‚ñà‚ñà‚ñà‚ñå      | 360/1000 [00:02<00:04, 149.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  38%|‚ñà‚ñà‚ñà‚ñä      | 376/1000 [00:02<00:04, 149.98 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  39%|‚ñà‚ñà‚ñà‚ñâ      | 392/1000 [00:03<00:04, 149.01 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  41%|‚ñà‚ñà‚ñà‚ñà      | 408/1000 [00:03<00:03, 150.24 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 424/1000 [00:03<00:04, 128.67 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 448/1000 [00:03<00:03, 154.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 472/1000 [00:03<00:03, 152.04 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 488/1000 [00:03<00:03, 152.03 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 504/1000 [00:03<00:03, 132.90 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 520/1000 [00:03<00:03, 137.18 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 544/1000 [00:04<00:02, 161.18 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 568/1000 [00:04<00:02, 155.59 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 592/1000 [00:04<00:02, 153.42 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 608/1000 [00:04<00:02, 152.20 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 624/1000 [00:04<00:02, 151.86 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 640/1000 [00:04<00:02, 150.38 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 656/1000 [00:04<00:02, 149.34 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 672/1000 [00:04<00:02, 149.79 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 688/1000 [00:05<00:02, 150.19 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 704/1000 [00:05<00:01, 149.94 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 720/1000 [00:05<00:01, 149.73 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 736/1000 [00:05<00:01, 149.84 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 752/1000 [00:05<00:01, 147.71 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 768/1000 [00:05<00:01, 146.99 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 784/1000 [00:05<00:01, 145.24 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 800/1000 [00:05<00:01, 145.71 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 816/1000 [00:05<00:01, 146.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 832/1000 [00:06<00:01, 147.29 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 853/1000 [00:06<00:01, 140.68 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 874/1000 [00:06<00:00, 137.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 888/1000 [00:06<00:00, 134.75 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 902/1000 [00:06<00:00, 132.80 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 916/1000 [00:06<00:00, 132.71 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 930/1000 [00:06<00:00, 131.19 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 944/1000 [00:06<00:00, 130.92 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 965/1000 [00:07<00:00, 144.15 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 986/1000 [00:07<00:00, 139.69 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:07<00:00, 134.33 examples/s]
2025-05-30 08:32:12,231 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-05-30 08:32:12,237 - INFO - Performing an initial evaluation on the dev_sft dataset...
  0%|          | 0/250 [00:00<?, ?it/s]  1%|          | 2/250 [00:02<05:19,  1.29s/it]  1%|          | 3/250 [00:05<08:14,  2.00s/it]  2%|‚ñè         | 4/250 [00:08<09:15,  2.26s/it]  2%|‚ñè         | 5/250 [00:11<10:11,  2.50s/it]  2%|‚ñè         | 6/250 [00:13<10:14,  2.52s/it]  3%|‚ñé         | 7/250 [00:16<10:47,  2.67s/it]  3%|‚ñé         | 8/250 [00:19<10:52,  2.70s/it]  4%|‚ñé         | 9/250 [00:22<11:08,  2.78s/it]  4%|‚ñç         | 10/250 [00:25<11:07,  2.78s/it]  4%|‚ñç         | 11/250 [00:28<11:21,  2.85s/it]  5%|‚ñç         | 12/250 [00:30<10:51,  2.74s/it]  5%|‚ñå         | 13/250 [00:33<11:14,  2.85s/it]  6%|‚ñå         | 14/250 [00:36<10:50,  2.76s/it]  6%|‚ñå         | 15/250 [00:39<11:04,  2.83s/it]  6%|‚ñã         | 16/250 [00:41<10:42,  2.75s/it]  7%|‚ñã         | 17/250 [00:44<10:53,  2.80s/it]  7%|‚ñã         | 18/250 [00:47<10:50,  2.80s/it]  8%|‚ñä         | 19/250 [00:50<11:00,  2.86s/it]  8%|‚ñä         | 20/250 [00:53<10:36,  2.77s/it]  8%|‚ñä         | 21/250 [00:56<10:41,  2.80s/it]  9%|‚ñâ         | 22/250 [00:58<10:31,  2.77s/it]  9%|‚ñâ         | 23/250 [01:01<10:47,  2.85s/it] 10%|‚ñâ         | 24/250 [01:04<10:26,  2.77s/it] 10%|‚ñà         | 25/250 [01:07<10:33,  2.81s/it] 10%|‚ñà         | 26/250 [01:09<10:14,  2.74s/it] 11%|‚ñà         | 27/250 [01:12<10:30,  2.83s/it] 11%|‚ñà         | 28/250 [01:15<10:10,  2.75s/it] 12%|‚ñà‚ñè        | 29/250 [01:18<10:31,  2.86s/it] 12%|‚ñà‚ñè        | 30/250 [01:21<10:09,  2.77s/it] 12%|‚ñà‚ñè        | 31/250 [01:24<10:19,  2.83s/it] 13%|‚ñà‚ñé        | 32/250 [01:26<10:00,  2.76s/it] 13%|‚ñà‚ñé        | 33/250 [01:29<10:08,  2.81s/it] 14%|‚ñà‚ñé        | 34/250 [01:32<09:48,  2.73s/it] 14%|‚ñà‚ñç        | 35/250 [01:35<10:13,  2.86s/it] 14%|‚ñà‚ñç        | 36/250 [01:37<09:47,  2.74s/it] 15%|‚ñà‚ñç        | 37/250 [01:40<09:55,  2.80s/it] 15%|‚ñà‚ñå        | 38/250 [01:43<09:38,  2.73s/it] 16%|‚ñà‚ñå        | 39/250 [01:46<09:55,  2.82s/it] 16%|‚ñà‚ñå        | 40/250 [01:48<09:38,  2.75s/it] 16%|‚ñà‚ñã        | 41/250 [01:52<09:55,  2.85s/it] 17%|‚ñà‚ñã        | 42/250 [01:54<09:46,  2.82s/it] 17%|‚ñà‚ñã        | 43/250 [01:57<09:56,  2.88s/it] 18%|‚ñà‚ñä        | 44/250 [02:00<09:28,  2.76s/it] 18%|‚ñà‚ñä        | 45/250 [02:03<09:35,  2.81s/it] 18%|‚ñà‚ñä        | 46/250 [02:05<09:27,  2.78s/it] 19%|‚ñà‚ñâ        | 47/250 [02:08<09:37,  2.84s/it] 19%|‚ñà‚ñâ        | 48/250 [02:11<09:25,  2.80s/it] 20%|‚ñà‚ñâ        | 49/250 [02:14<09:35,  2.86s/it] 20%|‚ñà‚ñà        | 50/250 [02:17<09:14,  2.77s/it] 20%|‚ñà‚ñà        | 51/250 [02:20<09:34,  2.89s/it] 21%|‚ñà‚ñà        | 52/250 [02:22<09:05,  2.76s/it] 21%|‚ñà‚ñà        | 53/250 [02:25<09:19,  2.84s/it] 22%|‚ñà‚ñà‚ñè       | 54/250 [02:28<09:00,  2.76s/it] 22%|‚ñà‚ñà‚ñè       | 55/250 [02:31<09:05,  2.80s/it] 22%|‚ñà‚ñà‚ñè       | 56/250 [02:33<08:57,  2.77s/it] 23%|‚ñà‚ñà‚ñé       | 57/250 [02:37<09:10,  2.85s/it] 23%|‚ñà‚ñà‚ñé       | 58/250 [02:39<08:51,  2.77s/it] 24%|‚ñà‚ñà‚ñé       | 59/250 [02:42<09:01,  2.84s/it] 24%|‚ñà‚ñà‚ñç       | 60/250 [02:45<08:43,  2.76s/it] 24%|‚ñà‚ñà‚ñç       | 61/250 [02:48<09:06,  2.89s/it] 25%|‚ñà‚ñà‚ñç       | 62/250 [02:50<08:38,  2.76s/it] 25%|‚ñà‚ñà‚ñå       | 63/250 [02:53<08:59,  2.88s/it] 26%|‚ñà‚ñà‚ñå       | 64/250 [02:56<08:39,  2.79s/it] 26%|‚ñà‚ñà‚ñå       | 65/250 [02:59<08:49,  2.86s/it] 26%|‚ñà‚ñà‚ñã       | 66/250 [03:02<08:30,  2.77s/it] 27%|‚ñà‚ñà‚ñã       | 67/250 [03:05<08:35,  2.82s/it] 27%|‚ñà‚ñà‚ñã       | 68/250 [03:07<08:30,  2.81s/it] 28%|‚ñà‚ñà‚ñä       | 69/250 [03:10<08:40,  2.88s/it] 28%|‚ñà‚ñà‚ñä       | 70/250 [03:13<08:19,  2.78s/it] 28%|‚ñà‚ñà‚ñä       | 71/250 [03:16<08:33,  2.87s/it] 29%|‚ñà‚ñà‚ñâ       | 72/250 [03:19<08:21,  2.82s/it] 29%|‚ñà‚ñà‚ñâ       | 73/250 [03:22<08:44,  2.97s/it] 30%|‚ñà‚ñà‚ñâ       | 74/250 [03:25<08:29,  2.90s/it] 30%|‚ñà‚ñà‚ñà       | 75/250 [03:28<08:39,  2.97s/it] 30%|‚ñà‚ñà‚ñà       | 76/250 [03:31<08:21,  2.88s/it] 31%|‚ñà‚ñà‚ñà       | 77/250 [03:34<08:36,  2.99s/it] 31%|‚ñà‚ñà‚ñà       | 78/250 [03:36<08:13,  2.87s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 79/250 [03:39<08:18,  2.91s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 80/250 [03:42<07:58,  2.82s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 81/250 [03:45<07:59,  2.84s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 82/250 [03:48<07:52,  2.81s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 83/250 [03:51<08:05,  2.90s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 84/250 [03:53<07:42,  2.79s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 85/250 [03:56<07:42,  2.81s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 86/250 [03:59<07:28,  2.74s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 87/250 [04:02<07:45,  2.86s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 88/250 [04:05<07:37,  2.82s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 89/250 [04:08<07:44,  2.89s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 90/250 [04:10<07:20,  2.75s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 91/250 [04:13<07:28,  2.82s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 92/250 [04:16<07:15,  2.76s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 93/250 [04:19<07:23,  2.83s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 94/250 [04:22<07:23,  2.85s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 95/250 [04:25<07:32,  2.92s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 96/250 [04:27<07:23,  2.88s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 97/250 [04:30<07:28,  2.93s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 98/250 [04:33<07:09,  2.83s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 99/250 [04:36<07:16,  2.89s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 100/250 [04:39<06:57,  2.78s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 101/250 [04:42<07:10,  2.89s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 102/250 [04:44<06:58,  2.83s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 103/250 [04:47<07:03,  2.88s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 104/250 [04:50<06:52,  2.82s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 105/250 [04:53<06:58,  2.89s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 106/250 [04:56<06:43,  2.80s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 107/250 [04:59<06:55,  2.91s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 108/250 [05:01<06:37,  2.80s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 109/250 [05:04<06:41,  2.85s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 110/250 [05:07<06:32,  2.81s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 111/250 [05:10<06:33,  2.83s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 112/250 [05:13<06:20,  2.76s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 113/250 [05:16<06:33,  2.87s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 114/250 [05:18<06:18,  2.78s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 115/250 [05:21<06:25,  2.85s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 116/250 [05:24<06:09,  2.76s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 117/250 [05:27<06:15,  2.82s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 118/250 [05:30<06:07,  2.79s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 119/250 [05:33<06:11,  2.83s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 120/250 [05:35<05:56,  2.74s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 121/250 [05:38<06:07,  2.85s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 122/250 [05:41<05:54,  2.77s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 123/250 [05:44<06:00,  2.84s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 124/250 [05:46<05:52,  2.80s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 125/250 [05:50<06:02,  2.90s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 126/250 [05:52<05:44,  2.77s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 127/250 [05:55<05:50,  2.85s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 128/250 [05:58<05:35,  2.75s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 129/250 [06:01<05:47,  2.87s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 130/250 [06:03<05:31,  2.77s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 131/250 [06:06<05:43,  2.88s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 132/250 [06:09<05:29,  2.79s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 133/250 [06:12<05:29,  2.81s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 134/250 [06:14<05:16,  2.73s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 135/250 [06:17<05:24,  2.82s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 136/250 [06:20<05:17,  2.78s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 137/250 [06:23<05:26,  2.89s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 138/250 [06:26<05:12,  2.79s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 139/250 [06:29<05:17,  2.86s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 140/250 [06:32<05:09,  2.81s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 141/250 [06:35<05:12,  2.87s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 142/250 [06:37<05:01,  2.79s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 143/250 [06:40<05:05,  2.86s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 144/250 [06:43<04:54,  2.78s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 145/250 [06:46<04:57,  2.83s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 146/250 [06:48<04:47,  2.76s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 147/250 [06:51<04:56,  2.87s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 148/250 [06:54<04:49,  2.84s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 149/250 [06:57<04:51,  2.89s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 150/250 [07:00<04:44,  2.85s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 151/250 [07:03<04:52,  2.95s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 152/250 [07:06<04:42,  2.88s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 153/250 [07:09<04:43,  2.93s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 154/250 [07:12<04:31,  2.83s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 155/250 [07:14<04:31,  2.86s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 156/250 [07:17<04:21,  2.78s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 157/250 [07:20<04:25,  2.85s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 158/250 [07:23<04:19,  2.82s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 159/250 [07:26<04:19,  2.85s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 160/250 [07:28<04:09,  2.77s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 161/250 [07:31<04:15,  2.87s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 162/250 [07:34<04:03,  2.77s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 163/250 [07:37<04:11,  2.90s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 164/250 [07:40<04:00,  2.80s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 165/250 [07:43<04:04,  2.87s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 166/250 [07:45<03:53,  2.78s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 167/250 [07:48<03:54,  2.82s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 168/250 [07:51<03:44,  2.74s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 169/250 [07:54<03:45,  2.79s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 170/250 [07:56<03:34,  2.69s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 171/250 [07:59<03:44,  2.84s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 172/250 [08:02<03:38,  2.80s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 173/250 [08:05<03:42,  2.89s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 174/250 [08:08<03:31,  2.79s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 175/250 [08:11<03:32,  2.83s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 176/250 [08:13<03:29,  2.82s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 177/250 [08:17<03:35,  2.95s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 178/250 [08:19<03:24,  2.84s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 179/250 [08:22<03:26,  2.91s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 180/250 [08:25<03:19,  2.85s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 181/250 [08:28<03:19,  2.89s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 182/250 [08:31<03:09,  2.79s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 183/250 [08:34<03:14,  2.91s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 184/250 [08:36<03:07,  2.84s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 185/250 [08:39<03:08,  2.89s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 186/250 [08:42<02:57,  2.77s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 187/250 [08:45<03:01,  2.89s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 188/250 [08:48<02:52,  2.78s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 189/250 [08:51<02:52,  2.82s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 190/250 [08:53<02:47,  2.79s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 191/250 [08:56<02:47,  2.83s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 192/250 [08:59<02:39,  2.76s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 193/250 [09:02<02:40,  2.82s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 194/250 [09:04<02:33,  2.75s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 195/250 [09:07<02:34,  2.81s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 196/250 [09:10<02:27,  2.74s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 197/250 [09:13<02:28,  2.80s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 198/250 [09:15<02:21,  2.73s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 199/250 [09:18<02:21,  2.77s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 200/250 [09:21<02:15,  2.72s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 201/250 [09:24<02:18,  2.84s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 202/250 [09:26<02:10,  2.73s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 203/250 [09:30<02:15,  2.87s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 204/250 [09:32<02:07,  2.77s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 205/250 [09:35<02:06,  2.81s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 206/250 [09:38<02:00,  2.74s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 207/250 [09:41<02:03,  2.86s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 208/250 [09:43<01:56,  2.78s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 209/250 [09:47<01:58,  2.90s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 210/250 [09:49<01:50,  2.77s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 211/250 [09:52<01:49,  2.80s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 212/250 [09:54<01:43,  2.73s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 213/250 [09:58<01:44,  2.83s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 214/250 [10:00<01:39,  2.76s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 215/250 [10:03<01:38,  2.83s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 216/250 [10:06<01:33,  2.75s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 217/250 [10:09<01:32,  2.79s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 218/250 [10:11<01:29,  2.79s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 219/250 [10:15<01:30,  2.91s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 220/250 [10:17<01:25,  2.85s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 221/250 [10:20<01:24,  2.90s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 222/250 [10:23<01:19,  2.84s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 223/250 [10:26<01:17,  2.87s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 224/250 [10:28<01:12,  2.77s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 225/250 [10:31<01:10,  2.84s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 226/250 [10:34<01:07,  2.80s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 227/250 [10:37<01:04,  2.82s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 228/250 [10:39<00:59,  2.70s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 229/250 [10:43<00:59,  2.85s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 230/250 [10:45<00:56,  2.84s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 231/250 [10:49<00:56,  2.95s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 232/250 [10:51<00:52,  2.91s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 233/250 [10:55<00:50,  2.99s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 234/250 [10:57<00:45,  2.87s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 235/250 [11:00<00:44,  2.95s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 236/250 [11:03<00:40,  2.88s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 237/250 [11:06<00:37,  2.91s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 238/250 [11:09<00:34,  2.86s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 239/250 [11:12<00:31,  2.87s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 240/250 [11:14<00:27,  2.78s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 241/250 [11:17<00:25,  2.82s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 242/250 [11:20<00:22,  2.79s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 243/250 [11:23<00:19,  2.85s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 244/250 [11:26<00:16,  2.80s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 245/250 [11:29<00:14,  2.86s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 246/250 [11:31<00:11,  2.77s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 247/250 [11:34<00:08,  2.82s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 248/250 [11:37<00:05,  2.73s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 249/250 [11:40<00:02,  2.84s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [11:42<00:00,  2.80s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [11:43<00:00,  2.81s/it]
2025-05-30 08:43:59,287 - INFO - Initial SFT dev set evaluation results: {'eval_loss': nan, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 707.0025, 'eval_samples_per_second': 1.414, 'eval_steps_per_second': 0.354}
2025-05-30 08:43:59,287 - INFO - Starting SFT training...
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,824 | Num Epochs = 4 | Total steps = 980
O^O/ \_/ \    Batch size per device = 32 | Gradient accumulation steps = 1
\        /    Data Parallel GPUs = 1 | Total batch size (32 x 1 x 1) = 32
 "-____-"     Trainable parameters = 161,480,704/7,777,097,216 (2.08% trained)
  0%|          | 0/980 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/scripts/sft/sftrain.py", line 423, in <module>
    main()
  File "/sorgin1/users/jbarrutia006/viper/scripts/sft/sftrain.py", line 392, in main
    trainer.train()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/trainer.py", line 2171, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 359, in _fast_inner_training_loop
  File "<string>", line 68, in _unsloth_training_step
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/accelerate/accelerator.py", line 2246, in backward
    loss.backward(**kwargs)
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/cut_cross_entropy/cce.py", line 94, in backward
    grad_scale = 1 / lse.numel()
                 ~~^~~~~~~~~~~~~
ZeroDivisionError: division by zero
Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/scripts/sft/sftrain.py", line 423, in <module>
    main()
  File "/sorgin1/users/jbarrutia006/viper/scripts/sft/sftrain.py", line 392, in main
    trainer.train()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/trainer.py", line 2171, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 359, in _fast_inner_training_loop
  File "<string>", line 68, in _unsloth_training_step
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/accelerate/accelerator.py", line 2246, in backward
    loss.backward(**kwargs)
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/cut_cross_entropy/cce.py", line 94, in backward
    grad_scale = 1 / lse.numel()
                 ~~^~~~~~~~~~~~~
ZeroDivisionError: division by zero
srun: error: localhost: task 0: Exited with exit code 1
