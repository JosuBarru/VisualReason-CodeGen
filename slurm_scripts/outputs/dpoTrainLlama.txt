ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 05-25 11:12:05 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.325 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
meta-llama/Meta-Llama-3.1-8B-Instruct does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.6933, 'grad_norm': 0.58203125, 'learning_rate': 1.5243902439024391e-06, 'rewards/chosen': -0.001176543883047998, 'rewards/rejected': -0.0008698217570781708, 'rewards/accuracies': 0.3812499940395355, 'rewards/margins': -0.00030672215507365763, 'logps/chosen': -108.9808578491211, 'logps/rejected': -139.85842895507812, 'logits/chosen': 0.18222132325172424, 'logits/rejected': 0.1610420197248459, 'epoch': 0.01}
{'loss': 0.6928, 'grad_norm': 0.7109375, 'learning_rate': 3.0487804878048782e-06, 'rewards/chosen': -0.0026943394914269447, 'rewards/rejected': -0.0035087522119283676, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.0008144128369167447, 'logps/chosen': -102.97966003417969, 'logps/rejected': -143.8399200439453, 'logits/chosen': 0.18727260828018188, 'logits/rejected': 0.13261902332305908, 'epoch': 0.01}
{'loss': 0.6908, 'grad_norm': 0.875, 'learning_rate': 4.573170731707317e-06, 'rewards/chosen': -0.0008638679864816368, 'rewards/rejected': -0.0057131280191242695, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.004849259741604328, 'logps/chosen': -107.2163314819336, 'logps/rejected': -148.40985107421875, 'logits/chosen': 0.20779240131378174, 'logits/rejected': 0.13242578506469727, 'epoch': 0.02}
{'loss': 0.6849, 'grad_norm': 0.6796875, 'learning_rate': 6.0975609756097564e-06, 'rewards/chosen': 0.021829772740602493, 'rewards/rejected': 0.004572121426463127, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.017257653176784515, 'logps/chosen': -96.38249206542969, 'logps/rejected': -143.26622009277344, 'logits/chosen': 0.19559450447559357, 'logits/rejected': 0.1571054905653, 'epoch': 0.02}
{'loss': 0.6688, 'grad_norm': 0.8515625, 'learning_rate': 7.621951219512195e-06, 'rewards/chosen': 0.06788594275712967, 'rewards/rejected': 0.014731149189174175, 'rewards/accuracies': 0.668749988079071, 'rewards/margins': 0.05315478891134262, 'logps/chosen': -96.9906234741211, 'logps/rejected': -138.111328125, 'logits/chosen': 0.20230305194854736, 'logits/rejected': 0.18241889774799347, 'epoch': 0.03}
{'loss': 0.6275, 'grad_norm': 1.265625, 'learning_rate': 9.146341463414634e-06, 'rewards/chosen': -0.02943902648985386, 'rewards/rejected': -0.22268347442150116, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.19324445724487305, 'logps/chosen': -103.6797866821289, 'logps/rejected': -151.6219024658203, 'logits/chosen': 0.16816678643226624, 'logits/rejected': 0.1420787274837494, 'epoch': 0.04}
{'loss': 0.569, 'grad_norm': 1.46875, 'learning_rate': 1.0670731707317074e-05, 'rewards/chosen': -0.2974315285682678, 'rewards/rejected': -0.8826426267623901, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.5852111577987671, 'logps/chosen': -119.14366149902344, 'logps/rejected': -186.90110778808594, 'logits/chosen': -0.056083500385284424, 'logits/rejected': -0.028314899653196335, 'epoch': 0.04}
{'loss': 0.5513, 'grad_norm': 1.5859375, 'learning_rate': 1.2195121951219513e-05, 'rewards/chosen': 0.1574074774980545, 'rewards/rejected': -0.3903729319572449, 'rewards/accuracies': 0.6781250238418579, 'rewards/margins': 0.5477803945541382, 'logps/chosen': -94.50334930419922, 'logps/rejected': -168.49960327148438, 'logits/chosen': 0.0890633687376976, 'logits/rejected': 0.1010059341788292, 'epoch': 0.05}
{'loss': 0.5805, 'grad_norm': 3.78125, 'learning_rate': 1.3719512195121953e-05, 'rewards/chosen': 0.06335829198360443, 'rewards/rejected': -0.60381019115448, 'rewards/accuracies': 0.6968749761581421, 'rewards/margins': 0.667168378829956, 'logps/chosen': -102.30924224853516, 'logps/rejected': -175.11398315429688, 'logits/chosen': -0.04583247750997543, 'logits/rejected': -0.060510437935590744, 'epoch': 0.05}
{'loss': 0.5314, 'grad_norm': 1.5078125, 'learning_rate': 1.524390243902439e-05, 'rewards/chosen': 0.1920965611934662, 'rewards/rejected': -0.5124057531356812, 'rewards/accuracies': 0.7093750238418579, 'rewards/margins': 0.7045023441314697, 'logps/chosen': -91.34224700927734, 'logps/rejected': -171.63844299316406, 'logits/chosen': 0.05273814871907234, 'logits/rejected': 0.059535373002290726, 'epoch': 0.06}
{'loss': 0.5317, 'grad_norm': 2.03125, 'learning_rate': 1.676829268292683e-05, 'rewards/chosen': 0.15518155694007874, 'rewards/rejected': -0.5729304552078247, 'rewards/accuracies': 0.746874988079071, 'rewards/margins': 0.728111982345581, 'logps/chosen': -95.44379425048828, 'logps/rejected': -172.30169677734375, 'logits/chosen': 0.13377347588539124, 'logits/rejected': 0.1455519199371338, 'epoch': 0.07}
{'loss': 0.553, 'grad_norm': 1.4765625, 'learning_rate': 1.8292682926829268e-05, 'rewards/chosen': 0.1455274075269699, 'rewards/rejected': -0.5151970386505127, 'rewards/accuracies': 0.7093750238418579, 'rewards/margins': 0.6607244610786438, 'logps/chosen': -94.80924987792969, 'logps/rejected': -161.29933166503906, 'logits/chosen': 0.2015305757522583, 'logits/rejected': 0.19360658526420593, 'epoch': 0.07}
{'loss': 0.5446, 'grad_norm': 2.0625, 'learning_rate': 1.9817073170731708e-05, 'rewards/chosen': 0.46119260787963867, 'rewards/rejected': -0.1135769858956337, 'rewards/accuracies': 0.715624988079071, 'rewards/margins': 0.5747696161270142, 'logps/chosen': -79.37333679199219, 'logps/rejected': -144.5281982421875, 'logits/chosen': 0.27287840843200684, 'logits/rejected': 0.26959696412086487, 'epoch': 0.08}
{'loss': 0.5307, 'grad_norm': 1.4765625, 'learning_rate': 2.134146341463415e-05, 'rewards/chosen': 0.29060667753219604, 'rewards/rejected': -0.4566308856010437, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.7472375631332397, 'logps/chosen': -89.14900970458984, 'logps/rejected': -163.95364379882812, 'logits/chosen': 0.1739126443862915, 'logits/rejected': 0.18141672015190125, 'epoch': 0.09}
{'loss': 0.4839, 'grad_norm': 2.140625, 'learning_rate': 2.286585365853659e-05, 'rewards/chosen': 0.22790034115314484, 'rewards/rejected': -0.6597710847854614, 'rewards/accuracies': 0.746874988079071, 'rewards/margins': 0.8876713514328003, 'logps/chosen': -92.0192642211914, 'logps/rejected': -179.6904754638672, 'logits/chosen': 0.2001154124736786, 'logits/rejected': 0.2095317840576172, 'epoch': 0.09}
