ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 03-15 11:43:36 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.739 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 7.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.6929, 'grad_norm': 3.391605854034424, 'learning_rate': 6.097560975609757e-07, 'rewards/chosen': 0.0022364973556250334, 'rewards/rejected': 0.001664341427385807, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.0005721559864468873, 'logps/chosen': -177.65548706054688, 'logps/rejected': -206.1190948486328, 'logits/chosen': -0.7199829816818237, 'logits/rejected': -0.6635946035385132, 'epoch': 0.01}
{'loss': 0.6836, 'grad_norm': 3.6158502101898193, 'learning_rate': 1.2195121951219514e-06, 'rewards/chosen': 0.04849628731608391, 'rewards/rejected': 0.028299223631620407, 'rewards/accuracies': 0.667187511920929, 'rewards/margins': 0.0201970674097538, 'logps/chosen': -178.89598083496094, 'logps/rejected': -203.7002716064453, 'logits/chosen': -0.7163625955581665, 'logits/rejected': -0.6509118676185608, 'epoch': 0.02}
{'loss': 0.6587, 'grad_norm': 3.580310821533203, 'learning_rate': 1.8292682926829268e-06, 'rewards/chosen': 0.21932455897331238, 'rewards/rejected': 0.13737313449382782, 'rewards/accuracies': 0.659375011920929, 'rewards/margins': 0.08195141702890396, 'logps/chosen': -174.45193481445312, 'logps/rejected': -204.62464904785156, 'logits/chosen': -0.6945949792861938, 'logits/rejected': -0.6689110398292542, 'epoch': 0.04}
{'loss': 0.6092, 'grad_norm': 4.389981746673584, 'learning_rate': 2.4390243902439027e-06, 'rewards/chosen': 0.49442586302757263, 'rewards/rejected': 0.26878780126571655, 'rewards/accuracies': 0.7109375, 'rewards/margins': 0.22563810646533966, 'logps/chosen': -175.7182159423828, 'logps/rejected': -201.84396362304688, 'logits/chosen': -0.701661229133606, 'logits/rejected': -0.6488624811172485, 'epoch': 0.05}
{'loss': 0.5816, 'grad_norm': 3.018848180770874, 'learning_rate': 3.0487804878048782e-06, 'rewards/chosen': 0.8085446357727051, 'rewards/rejected': 0.4642234742641449, 'rewards/accuracies': 0.7109375, 'rewards/margins': 0.3443211019039154, 'logps/chosen': -173.84605407714844, 'logps/rejected': -208.5723114013672, 'logits/chosen': -0.6730026602745056, 'logits/rejected': -0.6376549601554871, 'epoch': 0.06}
{'loss': 0.5692, 'grad_norm': 4.738694667816162, 'learning_rate': 3.6585365853658537e-06, 'rewards/chosen': 0.9316715002059937, 'rewards/rejected': 0.49033117294311523, 'rewards/accuracies': 0.7109375, 'rewards/margins': 0.4413403570652008, 'logps/chosen': -171.9330291748047, 'logps/rejected': -202.648193359375, 'logits/chosen': -0.6079527735710144, 'logits/rejected': -0.5768862962722778, 'epoch': 0.07}
{'loss': 0.522, 'grad_norm': 4.341312885284424, 'learning_rate': 4.268292682926829e-06, 'rewards/chosen': 1.460193157196045, 'rewards/rejected': 0.8513327836990356, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.608860433101654, 'logps/chosen': -168.58062744140625, 'logps/rejected': -209.3934326171875, 'logits/chosen': -0.5031949281692505, 'logits/rejected': -0.5081003308296204, 'epoch': 0.09}
{'eval_loss': 0.4748474657535553, 'eval_model_preparation_time': 0.008, 'eval_runtime': 273.3883, 'eval_samples_per_second': 3.658, 'eval_steps_per_second': 0.457, 'eval_rewards/chosen': 1.4887131452560425, 'eval_rewards/rejected': 0.6382417678833008, 'eval_rewards/accuracies': 0.7720000147819519, 'eval_rewards/margins': 0.8504714369773865, 'eval_logps/chosen': -162.82049560546875, 'eval_logps/rejected': -193.6608123779297, 'eval_logits/chosen': -0.4411861300468445, 'eval_logits/rejected': -0.3690548837184906, 'epoch': 0.09}
{'loss': 0.5173, 'grad_norm': 4.654880523681641, 'learning_rate': 4.8780487804878055e-06, 'rewards/chosen': 1.5904364585876465, 'rewards/rejected': 0.872784435749054, 'rewards/accuracies': 0.746874988079071, 'rewards/margins': 0.7176520228385925, 'logps/chosen': -164.2074737548828, 'logps/rejected': -198.2205352783203, 'logits/chosen': -0.4490046501159668, 'logits/rejected': -0.42449674010276794, 'epoch': 0.1}
{'loss': 0.4897, 'grad_norm': 3.9653878211975098, 'learning_rate': 5.487804878048781e-06, 'rewards/chosen': 1.8795688152313232, 'rewards/rejected': 0.9373424649238586, 'rewards/accuracies': 0.7734375, 'rewards/margins': 0.9422262907028198, 'logps/chosen': -159.941162109375, 'logps/rejected': -198.63119506835938, 'logits/chosen': -0.32857680320739746, 'logits/rejected': -0.3164500594139099, 'epoch': 0.11}
{'loss': 0.502, 'grad_norm': 6.724809169769287, 'learning_rate': 6.0975609756097564e-06, 'rewards/chosen': 2.169569492340088, 'rewards/rejected': 1.2691562175750732, 'rewards/accuracies': 0.745312511920929, 'rewards/margins': 0.9004133939743042, 'logps/chosen': -158.16665649414062, 'logps/rejected': -193.94960021972656, 'logits/chosen': -0.30130699276924133, 'logits/rejected': -0.2715438902378082, 'epoch': 0.12}
{'loss': 0.4858, 'grad_norm': 4.485454082489014, 'learning_rate': 6.707317073170733e-06, 'rewards/chosen': 2.3075060844421387, 'rewards/rejected': 1.2936193943023682, 'rewards/accuracies': 0.754687488079071, 'rewards/margins': 1.0138869285583496, 'logps/chosen': -157.36447143554688, 'logps/rejected': -195.9698028564453, 'logits/chosen': -0.22348205745220184, 'logits/rejected': -0.24339619278907776, 'epoch': 0.13}
{'loss': 0.5286, 'grad_norm': 3.656928777694702, 'learning_rate': 7.317073170731707e-06, 'rewards/chosen': 2.207164764404297, 'rewards/rejected': 1.3035527467727661, 'rewards/accuracies': 0.721875011920929, 'rewards/margins': 0.9036123156547546, 'logps/chosen': -160.56423950195312, 'logps/rejected': -189.8618621826172, 'logits/chosen': -0.19086620211601257, 'logits/rejected': -0.14641983807086945, 'epoch': 0.15}
{'loss': 0.4843, 'grad_norm': 4.506543159484863, 'learning_rate': 7.926829268292685e-06, 'rewards/chosen': 2.3361828327178955, 'rewards/rejected': 1.2424638271331787, 'rewards/accuracies': 0.7671874761581421, 'rewards/margins': 1.0937191247940063, 'logps/chosen': -154.63319396972656, 'logps/rejected': -191.24819946289062, 'logits/chosen': -0.13642266392707825, 'logits/rejected': -0.10093426704406738, 'epoch': 0.16}
{'loss': 0.4577, 'grad_norm': 6.975582122802734, 'learning_rate': 8.536585365853658e-06, 'rewards/chosen': 2.2537829875946045, 'rewards/rejected': 1.0253868103027344, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.2283962965011597, 'logps/chosen': -151.99179077148438, 'logps/rejected': -193.7216339111328, 'logits/chosen': -0.0883980542421341, 'logits/rejected': -0.026080314069986343, 'epoch': 0.17}
{'loss': 0.473, 'grad_norm': 3.9526565074920654, 'learning_rate': 9.131097560975611e-06, 'rewards/chosen': 2.4588286876678467, 'rewards/rejected': 1.1951658725738525, 'rewards/accuracies': 0.7718750238418579, 'rewards/margins': 1.2636626958847046, 'logps/chosen': -155.57485961914062, 'logps/rejected': -194.9725341796875, 'logits/chosen': -0.11093876510858536, 'logits/rejected': -0.08519954234361649, 'epoch': 0.18}
{'eval_loss': 0.4110424816608429, 'eval_model_preparation_time': 0.008, 'eval_runtime': 273.3591, 'eval_samples_per_second': 3.658, 'eval_steps_per_second': 0.457, 'eval_rewards/chosen': 2.4469382762908936, 'eval_rewards/rejected': 0.8672720193862915, 'eval_rewards/accuracies': 0.8080000281333923, 'eval_rewards/margins': 1.579666256904602, 'eval_logps/chosen': -153.23825073242188, 'eval_logps/rejected': -191.37049865722656, 'eval_logits/chosen': -0.14067110419273376, 'eval_logits/rejected': -0.05874574929475784, 'epoch': 0.18}
{'loss': 0.4687, 'grad_norm': 6.195958137512207, 'learning_rate': 9.740853658536586e-06, 'rewards/chosen': 2.4143624305725098, 'rewards/rejected': 0.9797753095626831, 'rewards/accuracies': 0.765625, 'rewards/margins': 1.4345872402191162, 'logps/chosen': -152.35523986816406, 'logps/rejected': -194.7137451171875, 'logits/chosen': -0.10686460882425308, 'logits/rejected': -0.047158677130937576, 'epoch': 0.2}
{'loss': 0.437, 'grad_norm': 4.103343963623047, 'learning_rate': 9.999625547005812e-06, 'rewards/chosen': 2.5333359241485596, 'rewards/rejected': 1.199810266494751, 'rewards/accuracies': 0.7828124761581421, 'rewards/margins': 1.333525538444519, 'logps/chosen': -154.81588745117188, 'logps/rejected': -198.68130493164062, 'logits/chosen': -0.046666789799928665, 'logits/rejected': -0.02394154854118824, 'epoch': 0.21}
{'loss': 0.4336, 'grad_norm': 4.833155632019043, 'learning_rate': 9.997190768798639e-06, 'rewards/chosen': 2.5389113426208496, 'rewards/rejected': 0.9962693452835083, 'rewards/accuracies': 0.7984374761581421, 'rewards/margins': 1.5426422357559204, 'logps/chosen': -152.5806121826172, 'logps/rejected': -198.23513793945312, 'logits/chosen': 0.04359947890043259, 'logits/rejected': 0.051537103950977325, 'epoch': 0.22}
{'loss': 0.4478, 'grad_norm': 3.615841865539551, 'learning_rate': 9.9924921983681e-06, 'rewards/chosen': 2.6105661392211914, 'rewards/rejected': 1.1657648086547852, 'rewards/accuracies': 0.792187511920929, 'rewards/margins': 1.4448013305664062, 'logps/chosen': -150.2440643310547, 'logps/rejected': -196.2646942138672, 'logits/chosen': -0.009037956595420837, 'logits/rejected': 0.01878305897116661, 'epoch': 0.23}
{'loss': 0.4043, 'grad_norm': 4.943539142608643, 'learning_rate': 9.985531964227529e-06, 'rewards/chosen': 2.7738523483276367, 'rewards/rejected': 0.9913204908370972, 'rewards/accuracies': 0.809374988079071, 'rewards/margins': 1.782531976699829, 'logps/chosen': -151.65589904785156, 'logps/rejected': -202.42977905273438, 'logits/chosen': 0.03941834717988968, 'logits/rejected': 0.07719022780656815, 'epoch': 0.24}
{'loss': 0.4158, 'grad_norm': 4.247549057006836, 'learning_rate': 9.976313219453255e-06, 'rewards/chosen': 2.5815868377685547, 'rewards/rejected': 0.8745464086532593, 'rewards/accuracies': 0.7906249761581421, 'rewards/margins': 1.7070401906967163, 'logps/chosen': -153.8496856689453, 'logps/rejected': -191.4007110595703, 'logits/chosen': 0.07720883935689926, 'logits/rejected': 0.12744197249412537, 'epoch': 0.26}
{'loss': 0.3873, 'grad_norm': 3.1701607704162598, 'learning_rate': 9.964840140256214e-06, 'rewards/chosen': 3.1133499145507812, 'rewards/rejected': 1.169364333152771, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.9439857006072998, 'logps/chosen': -142.703369140625, 'logps/rejected': -196.09884643554688, 'logits/chosen': 0.11486859619617462, 'logits/rejected': 0.17416514456272125, 'epoch': 0.27}
{'eval_loss': 0.40546637773513794, 'eval_model_preparation_time': 0.008, 'eval_runtime': 272.9163, 'eval_samples_per_second': 3.664, 'eval_steps_per_second': 0.458, 'eval_rewards/chosen': 2.4559457302093506, 'eval_rewards/rejected': 0.46627476811408997, 'eval_rewards/accuracies': 0.8029999732971191, 'eval_rewards/margins': 1.989670991897583, 'eval_logps/chosen': -153.14816284179688, 'eval_logps/rejected': -195.38047790527344, 'eval_logits/chosen': 0.13626404106616974, 'eval_logits/rejected': 0.22889825701713562, 'epoch': 0.27}
{'loss': 0.4055, 'grad_norm': 6.145461559295654, 'learning_rate': 9.951117924090066e-06, 'rewards/chosen': 2.4860599040985107, 'rewards/rejected': 0.5830013155937195, 'rewards/accuracies': 0.8109375238418579, 'rewards/margins': 1.903058648109436, 'logps/chosen': -156.55844116210938, 'logps/rejected': -207.71231079101562, 'logits/chosen': 0.14202401041984558, 'logits/rejected': 0.15464545786380768, 'epoch': 0.28}
{'loss': 0.3982, 'grad_norm': 4.564024448394775, 'learning_rate': 9.935152787296689e-06, 'rewards/chosen': 2.1499969959259033, 'rewards/rejected': 0.1574544906616211, 'rewards/accuracies': 0.801562488079071, 'rewards/margins': 1.9925426244735718, 'logps/chosen': -158.6891632080078, 'logps/rejected': -215.166259765625, 'logits/chosen': 0.19870978593826294, 'logits/rejected': 0.23151198029518127, 'epoch': 0.29}
{'loss': 0.374, 'grad_norm': 3.9244704246520996, 'learning_rate': 9.916951962290094e-06, 'rewards/chosen': 2.712742805480957, 'rewards/rejected': 0.8265493512153625, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.8861935138702393, 'logps/chosen': -151.05618286132812, 'logps/rejected': -199.8861083984375, 'logits/chosen': 0.21652574837207794, 'logits/rejected': 0.20852573215961456, 'epoch': 0.3}
{'loss': 0.4128, 'grad_norm': 6.603164196014404, 'learning_rate': 9.896523694280037e-06, 'rewards/chosen': 2.865539073944092, 'rewards/rejected': 0.975638210773468, 'rewards/accuracies': 0.792187511920929, 'rewards/margins': 1.8899011611938477, 'logps/chosen': -152.085205078125, 'logps/rejected': -194.5582275390625, 'logits/chosen': 0.21709302067756653, 'logits/rejected': 0.2529063820838928, 'epoch': 0.32}
{'loss': 0.3558, 'grad_norm': 4.325310230255127, 'learning_rate': 9.873877237536854e-06, 'rewards/chosen': 2.993744373321533, 'rewards/rejected': 0.8586940765380859, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.135050058364868, 'logps/chosen': -151.56813049316406, 'logps/rejected': -192.7662811279297, 'logits/chosen': 0.1935463398694992, 'logits/rejected': 0.24273213744163513, 'epoch': 0.33}
{'loss': 0.3758, 'grad_norm': 4.167506217956543, 'learning_rate': 9.849022851199128e-06, 'rewards/chosen': 2.9970099925994873, 'rewards/rejected': 0.8838770985603333, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.113132953643799, 'logps/chosen': -148.13412475585938, 'logps/rejected': -194.33291625976562, 'logits/chosen': 0.16213029623031616, 'logits/rejected': 0.20689444243907928, 'epoch': 0.34}
{'loss': 0.3766, 'grad_norm': 4.918790817260742, 'learning_rate': 9.821971794626196e-06, 'rewards/chosen': 2.704428195953369, 'rewards/rejected': 0.5654728412628174, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.1389553546905518, 'logps/chosen': -152.3673553466797, 'logps/rejected': -194.7655029296875, 'logits/chosen': 0.2106485366821289, 'logits/rejected': 0.23813319206237793, 'epoch': 0.35}
{'loss': 0.3595, 'grad_norm': 3.1114320755004883, 'learning_rate': 9.793493727437343e-06, 'rewards/chosen': 2.750405788421631, 'rewards/rejected': 0.4931541979312897, 'rewards/accuracies': 0.839062511920929, 'rewards/margins': 2.257251501083374, 'logps/chosen': -152.1969757080078, 'logps/rejected': -204.53842163085938, 'logits/chosen': 0.23075170814990997, 'logits/rejected': 0.24256233870983124, 'epoch': 0.37}
{'eval_loss': 0.35476842522621155, 'eval_model_preparation_time': 0.008, 'eval_runtime': 272.7181, 'eval_samples_per_second': 3.667, 'eval_steps_per_second': 0.458, 'eval_rewards/chosen': 2.7096633911132812, 'eval_rewards/rejected': 0.2745884358882904, 'eval_rewards/accuracies': 0.8420000076293945, 'eval_rewards/margins': 2.4350745677948, 'eval_logps/chosen': -150.61099243164062, 'eval_logps/rejected': -197.29734802246094, 'eval_logits/chosen': 0.2766765058040619, 'eval_logits/rejected': 0.3732287585735321, 'epoch': 0.37}
{'loss': 0.3692, 'grad_norm': 2.5387799739837646, 'learning_rate': 9.762141193377329e-06, 'rewards/chosen': 2.8282101154327393, 'rewards/rejected': 0.6595805883407593, 'rewards/accuracies': 0.823437511920929, 'rewards/margins': 2.1686294078826904, 'logps/chosen': -148.55825805664062, 'logps/rejected': -190.76406860351562, 'logits/chosen': 0.22321827709674835, 'logits/rejected': 0.23855090141296387, 'epoch': 0.38}
{'loss': 0.3896, 'grad_norm': 8.10246467590332, 'learning_rate': 9.72863134759981e-06, 'rewards/chosen': 2.122135639190674, 'rewards/rejected': -0.26819461584091187, 'rewards/accuracies': 0.832812488079071, 'rewards/margins': 2.3903305530548096, 'logps/chosen': -156.9713897705078, 'logps/rejected': -208.245361328125, 'logits/chosen': 0.21119356155395508, 'logits/rejected': 0.25754377245903015, 'epoch': 0.39}
{'loss': 0.3544, 'grad_norm': 8.604955673217773, 'learning_rate': 9.692979370499485e-06, 'rewards/chosen': 2.0745043754577637, 'rewards/rejected': -0.32806268334388733, 'rewards/accuracies': 0.8296874761581421, 'rewards/margins': 2.4025673866271973, 'logps/chosen': -156.25794982910156, 'logps/rejected': -208.8203582763672, 'logits/chosen': 0.23192830383777618, 'logits/rejected': 0.2737761437892914, 'epoch': 0.4}
{'loss': 0.3886, 'grad_norm': 5.2092366218566895, 'learning_rate': 9.655201412884328e-06, 'rewards/chosen': 2.2760021686553955, 'rewards/rejected': -0.16621163487434387, 'rewards/accuracies': 0.8359375, 'rewards/margins': 2.442213773727417, 'logps/chosen': -156.5153350830078, 'logps/rejected': -203.75820922851562, 'logits/chosen': 0.2360161989927292, 'logits/rejected': 0.2813534438610077, 'epoch': 0.41}
{'loss': 0.3267, 'grad_norm': 4.915922164916992, 'learning_rate': 9.615314588659054e-06, 'rewards/chosen': 2.3515894412994385, 'rewards/rejected': -0.17559882998466492, 'rewards/accuracies': 0.8515625, 'rewards/margins': 2.5271880626678467, 'logps/chosen': -157.3750762939453, 'logps/rejected': -214.0307159423828, 'logits/chosen': 0.2726261019706726, 'logits/rejected': 0.30242645740509033, 'epoch': 0.43}
{'loss': 0.3727, 'grad_norm': 4.804167747497559, 'learning_rate': 9.573336967072304e-06, 'rewards/chosen': 2.7035412788391113, 'rewards/rejected': 0.41173768043518066, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.2918035984039307, 'logps/chosen': -154.44544982910156, 'logps/rejected': -198.12545776367188, 'logits/chosen': 0.20994892716407776, 'logits/rejected': 0.22237654030323029, 'epoch': 0.44}
{'loss': 0.3569, 'grad_norm': 6.127157211303711, 'learning_rate': 9.529287564531034e-06, 'rewards/chosen': 3.0619068145751953, 'rewards/rejected': 0.6816622018814087, 'rewards/accuracies': 0.815625011920929, 'rewards/margins': 2.380244731903076, 'logps/chosen': -150.73165893554688, 'logps/rejected': -203.25685119628906, 'logits/chosen': 0.1926114559173584, 'logits/rejected': 0.23086127638816833, 'epoch': 0.45}
