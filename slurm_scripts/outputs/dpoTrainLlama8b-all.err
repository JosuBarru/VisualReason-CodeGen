wandb: Currently logged in as: jbarrutia006 (jbarrutia006-upv-ehu). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /sorgin1/users/jbarrutia006/viper/wandb/run-20250314_122309-65s8brqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Primera en dataset all. 
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jbarrutia006-upv-ehu/viperDPO
wandb: üöÄ View run at https://wandb.ai/jbarrutia006-upv-ehu/viperDPO/runs/65s8brqr
2025-03-14 12:23:10,558 - INFO - Loading model and tokenizer...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:05,  1.92s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:04<00:04,  2.16s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:06<00:02,  2.14s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:07<00:00,  1.71s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:07<00:00,  1.85s/it]
Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2025-03-14 12:23:41,993 - INFO - Loading dataset from /sorgin1/users/jbarrutia006/viper/PrefDatasets/dpo_dataset_all_train.arrow as train and /sorgin1/users/jbarrutia006/viper/PrefDatasets/dpo_dataset_single_dev.arrow as dev
Map:   0%|          | 0/52487 [00:00<?, ? examples/s]2025-03-14 12:23:42,556 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are there men to the left of the guy that is wearing sneakers?
def execute_command(image)->str:
2025-03-14 12:23:42,559 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    guy_patches = image_patch.find("guy")
    if len(guy_patches) == 0:
        return image_patch.simple_query("Are there men to the left of the guy that is wearing sneakers?")
    guy_patch = guy_patches[0]
    if not guy_patch.verify_property("guy", "wearing sneakers"):
        return "no"
    man_patches = image_patch.find("man")
    if len(man_patches) == 0:
        return "no"
    man_patch = man_patches[0]
    if man_patch.horizontal_center < guy_patch.horizontal_center:
        return "yes"
    return "no"

2025-03-14 12:23:42,561 - INFO - Rejected response: 
    # asks for the predicate of a relational verb (to the left), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Are there men to the left of the guy that is wearing sneakers?")
Map:   2%|‚ñè         | 1000/52487 [00:00<00:07, 7173.61 examples/s]2025-03-14 12:23:42,646 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Which side of the image is the yellow fruit on?
def execute_command(image)->str:
2025-03-14 12:23:42,648 - INFO - Chosen response:  #transitive verb
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Which side of the image is the yellow fruit on?")
2025-03-14 12:23:42,650 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    fruits = image_patch.find("yellow fruit")
    if not fruits:
        return image_patch.simple_query("Which side of the image is the yellow fruit on?")
    center = image_patch.horizontal_center
    for fruit in fruits:
        if fruit.horizontal_center < center:
            return "left"
        elif fruit.hours_center > center:
            return "right"
    return "left"
2025-03-14 12:23:42,682 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are the toys to the left of a pig?
def execute_command(image)->str:
2025-03-14 12:23:42,684 - INFO - Chosen response:  # spelling is meant to confuse you, first try answering with pig, then with pet, then with pig
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("Are the toys to the left of a pig?")
    for toy_patch in toy_patches:
        prize_pig_patches = image_patch.find("prize pig")
        for prize_pig_patch in prize_pig_patches:
            if toy_patch.left > prize_pig_patch.left: # left, not horizontal_center
                return "yes"
    return "no"
2025-03-14 12:23:42,685 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    try:
        pig_patch = image_patch.find("pig")[0]
    except:
        # If no pig is found, query the image directly
        return image_patch.simple_query("Are the toys to the left of a pig?")
    toys_patches = image_patch.find("toy")
    for toy_patch in toys_patches:
        if toy_patch.horizontal_center < pig_patch.horizontal_center:
            return "yes"
    return "no"
2025-03-14 12:23:42,716 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the sky above an airplane?
def execute_command(image)->str:
2025-03-14 12:23:42,718 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # Question has a conjunction (and)
    if (image_patch.verify_property("sky", "visible is-above")) or (image_patch.verify_property("airplane", "visible is-above")):
        return "yes"
    else:
        return "no"
2025-03-14 12:23:42,719 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    sky_patches = image_patch.find("sky")
    # Question assumes only one sky patch
    if len(sky_patches) == 0:
        # If no sky is found, query the image directly
        return image_patch.simple_query("Is the sky above an airplane?")
    sky_patch = sky_patches[0]
    sky_width = sky_patch.right - sky_patch.left
    airplane_patches = image_patch.find("airplane")
    for airplane_patch in airplane_patches:
        airplane_width = airplane_patch.right - airplane_patch.left
        if airplane_width < sky_width:
            return "no"
    return "yes"
2025-03-14 12:23:42,749 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the hydrant to the left or to the right of the car in the middle of the photo?
def execute_command(image)->str:
2025-03-14 12:23:42,751 - INFO - Chosen response:  # car in the middle of the photo
    image_patch = ImagePatch(image)
    hydrant_patches = image_patch.find("hydrant")
    # Question assumes only one hydrant patch
    if len(hydrant_patches) == 0:
        # If no hydrant is found, query the image directly
        return image_patch.simple_query("Is the hydrant to the left or to the right of the car in the middle of the photo?")
    hydrant_patch = hydrant_patches[0]
    car_patches = image_patch.find("car")
    # Question assumes only one car patch
    if len(car_patches) == 0:
        # If no car is found, query the image directly
        return image_patch.simple_query("Is the hydrant to the left or to the right of the car in the middle of the photo?")
    car_patch = car_patches[0]
    if hydrant_patch.horizontal_center < car_patch.horizontal_center:
        return "left"
    else:
        return "right"
2025-03-14 12:23:42,753 - INFO - Rejected response: 
    """
    Determines whether the hydrant is to the left or right of the car in the middle of the photograph.
Map:  10%|‚ñâ         | 5000/52487 [00:00<00:02, 19982.16 examples/s]2025-03-14 12:23:42,783 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the clock to the right of a shelf?
def execute_command(image)->str:
2025-03-14 12:23:42,785 - INFO - Chosen response:  # shelf or bookshelf
    image_patch = ImagePatch(image)
    clock_patches = image_patch.find("clock")
    # Question assumes only one clock patch
    if len(clock_patches) == 0:
        # If no clock is found, query the image directly
        return image_patch.simple_query("Is the clock to the right of a shelf?")
    for clock_patch in clock_patches:
        shelf_patches = image_patch.find("shelf")
        for shelf_patch in shelf_patches:
            if shelf_patch.horizontal_center > clock_patch.horizontal_center:
                return "yes"
    return "no"
2025-03-14 12:23:42,787 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    clock_patches = image_patch.find("clock")
    # Question assumes only one clock patch
    if len(clock_patches) == 0:
        # If no coffee patches are found, query the image directly
        return image_patch.simple_query("Is the clock in front of the shelf?")
    for clock_patch in clock_patches:
        shelf_patches = image_patch.find("shelf")
        for shelf_patch in shelf_patches:
            if clock_patch.vertical_center > shelf_patch.vertical_center:
                return "yes"
    return "no"
2025-03-14 12:23:42,816 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the color of the shirt the same as the wetsuit?
def execute_command(image)->str:
2025-03-14 12:23:42,818 - INFO - Chosen response:  # shirt not found, remove shirt
    image_patch = ImagePatch(image)
    # find the shirt
    shirt_patches = image_patch.find("shirt")
    # Question assumes one shirt patch
    if len(shirt_patches) == 0:
        # If no shirt is found, query the image directly
        return image_patch.simple_query("Is the color of the shirt the same as the wetsuit?")
    if shirt_patches[0].verify_property("shirt", "color") == image_patch.verify_property("suit", "color"):
        return "yes"
    return "no"
2025-03-14 12:23:42,819 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    shirts = image_patch.find("shirt")
    wetsuits = image_patch.find("wetsuit")
    
    # Check if both exist
    if not shirts or not wetsuits:
        return image_patch.simple_query("Is the color of the shirt the same as the wetsuit?")
    
    # Check if all shirt colors match wetsuit colors
    for shirt in shirts:
        for wetsuit in wetsuits:
            # Example color comparison (you might need a better method)
            if (shirt.red == wetsuit.red and
                shirt.green == wetsuit.green and
                shirt.blue == wetsuit.blue):
                # Colors match, break and return yes
                return "yes"
    
    return "no"

2025-03-14 12:23:42,849 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What is the window made of?
def execute_command(image)->str:
2025-03-14 12:23:42,851 - INFO - Chosen response:  # window is not in the database
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What is the window made of?")
2025-03-14 12:23:42,853 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    window_patches = image_patch.find("window")
    # Question assumes only one window patch
    if len(window_patches) == 0:
        # If no window is found, query the image directly
        return image_patch.simple_query("What is the window made of?")
    if window_patches[0].verify_property("window", "glass"):
        return "The window is made of glass."
    if window_patches[0].verify_property("window", "metal"):
        return "The window is made of metal."
    if window_patches[0].verify_property("window", "wood"):
        return "The window is made of wood."
    if window_patches[0].verify_property("window", "other"):
        return "The window is made of other materials."
    return "The window's material is unknown."

2025-03-14 12:23:42,883 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What color is the kettle in the top of the photo?
def execute_command(image)->str:
2025-03-14 12:23:42,885 - INFO - Chosen response:  # top is a predicate of a relational verb (on top of), so ask directly
    image_patch = ImagePatch(image)
    kettle_patches = image_patch.find("kettle")
    # Question assumes only one kettle patch
    if len(kettle_patches) == 0:
        # If no kettle is found, query the image directly
        return image_patch.simple_query("What color is the kettle in the top of the photo?")
    return kettle_patches[0].simple_query("What color is the kettle?") # crop would include the kettle so keep it in the query
2025-03-14 12:23:42,887 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    top = image_patch's top (maybe the entire image)
    kettle_patches = image_patch.find('kettle')
    # but if top is the entire image, then top is the same as image_patch
    # then, maybe it's sufficient to just find 'kettle' and then check its color.
    # So, for each kettle patch, check if the color is blue, for example.
    # But the user's question is general, so perhaps the function can get the color directly.
    # But the query is about the color in the top, which is the same as the entire image.
Map:  17%|‚ñà‚ñã        | 9000/52487 [00:00<00:01, 24334.29 examples/s]2025-03-14 12:23:42,917 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What is the animal that the woman sits on?
def execute_command(image)->str:
2025-03-14 12:23:42,919 - INFO - Chosen response: 
    # asks for the predicate of a relational verb (sits on), so ask directly
    image_patch = ImagePatch(image)
    woman_patches = image_patch.find("woman")
    # Question assumes only one woman patch
    if len(woman_patches) == 0:
        # If no woman is found, query the image directly
        return image_patch.simple_query("What is the animal that the woman sits on?")
    return woman_patches[0].simple_query("What is the animal that the woman sits on?")
2025-03-14 12:23:42,921 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    woman_patches = image_patch.find("woman")
    # Question assumes only one woman patch
    if len(woman_patches) == 0:
        # If no woman is found, query the image directly
        return image_patch.simple_query("What is the animal that the woman sits on?")
    woman_patch = woman_patches[0]
    animal_patches = image_patch.find("animal")
    # Question assumes only one animal patch
    if len(animal_patches) == 0:
        return image_patch.simple_query("What is the animal that the woman sits on?")
    animal_patch = animal_patches[0]
    if animal_patch.horizontal_center > woman_patch.horizontal_center:
        return "yes"
    else:
        return "no"

2025-03-14 12:23:42,951 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What animal is in the water?
def execute_command(image)->str:
2025-03-14 12:23:42,953 - INFO - Chosen response:  
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What animal is in the water?")
2025-03-14 12:23:42,955 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    animal_patches = image_patch.find("animal")
    # Question assumes only one animal patch
    if len(animal_patches) == 0:
        # If no animal is found, query the image directly
        return image_patch.simple_query("What animal is in the water?")
    for animal_patch in animal_patches:
        if animal_patch.verify_property("animal", "in water"):
            return animal_patch.simple_query("What animal is in the water?") # crop would include water so keep it in the query
    # If no animal is in the water, pick the first animal
    return animal_patches[0].simple_query("what animal is in the water?")
2025-03-14 12:23:42,984 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What is the animal to the right of the person in the middle?
def execute_command(image)->str:
2025-03-14 12:23:42,986 - INFO - Chosen response:  # could implement it by taking the average horizontal and vertical coordinates of the center person
    image_patch = ImagePatch(image)
    people_patches = image_patch.find("person")
    top_most_person_patch = people_patches[0]
    #Áâ©‰∏ö ph√°p
    return top_most_person_patch.simple_query("What animal do you see to the right?")
2025-03-14 12:23:42,988 - INFO - Rejected response: 
    image patched = ImagePatch(image)
    person_patches = image_patch.find("person")
    if not person_patches:
        return "no"  # or handle accordingly
    # compute image center
    image_width = image.shape[2]
    image_height = image.shape[1]
    image_center_x = image_width / 2
    image_center_y = image_height / 2
    # find the middle_person
    middle_person = None
    min_distance = float('inf')
    for person in person_patches:
        person_x = (person.left + person.right) / 2
        person_y = (person.lower + person.upper) / 2
        dx = person_x - image_center_x
        dy = person_y - image_center_y
        distance = (dx ** 2 + dy **2) ** 0.5
        if distance < min_distance:
            min_distance = distance
            middle_person = person
    if middle_person is None:
        return "no"
    # Now find animals to the right
    animal_patches = image_patch.find("animal")
    for animal in animal_patches:
        animal_x = (animal.left + animal.right) / 2
        if animal_x > middle_person.left + middle_person.right / 2:
            # Wait, no: middle_person's horizontal_center is (left + right)/2
            if animal.horizontal_center > middle_person.horizontal_center:
                # find best match for this animal
                return best_text_match(animal.cropped_image, ["animal"])
    # If no animals found to the right
    return "no"
    
Wait, but perhaps we should find the closest animal to the middle_person's right side, not just the first one. Maybe the animal whose left boundary is closest to the middle_person's right boundary.
2025-03-14 12:23:43,019 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Do you see either any bikes or umbrellas?
def execute_command(image)->str:
2025-03-14 12:23:43,021 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    bikes = image_patch.find("bikes")
    umbrellas = image_patch.find("umbrellas")
    if len(bikes) > 0 or len(umbrellas) > 0:
        return "yes"
    else:
        return image_patch.simple_query("Do you see either any bikes or umbrellas?")

2025-03-14 12:23:43,022 - INFO - Rejected response:  # Uses OR
    image_patch = ImagePatch(image)
    bikes_patches = image_patch.find("bike")
    umbrellas_patches = image_patch.find("umbrella")
    # Question assumes only one bike and one umbrella patch
    if len(bikes_patches) == 0 and len(umbrellas_patches) == 0:
        # If no bikes or umbrellas found, ask directly
        return image_patch.simple_query("Do you see either a bike or an umbrella?")
    if bool_to_yesno(len(bikes_patches) == 0) and bool_to_yesno(len(umbrellas_patches) == 0):
        answer = image_patch.simple_query("Do you see either a bike or an umbrella?")
    else:
        return "yes"
    return answer
Map:  25%|‚ñà‚ñà‚ñç       | 13000/52487 [00:00<00:01, 26335.46 examples/s]2025-03-14 12:23:43,054 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the helmet on the right side or on the left of the image?
def execute_command(image)->str:
2025-03-14 12:23:43,055 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    helmet_patches = image_patch.find("helmet")
    if not helmet_patches:
        # If no helmets are found, query directly (though unlikely given the question)
        return image_patch.simple_query("Is the helmet on the right side or left side of the image?")
    
    image_width = image_patch.width
    image_center = image_width / 2
    for helmet_patch in helmet_patches:
        if helmet_patch.horizontal_center > image_center:
            return "right"
    return "left"

2025-03-14 12:23:43,057 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    helmet_patches = image_patch.find("helmet")
    if len(helmet_patches) == 0:
        return "no"
    helmet_patch = helmet_patches[0]
    return helmet_patch_crop.horizontal_center > image_patch.vertical_center

2025-03-14 12:23:43,087 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the blue blanket to the left or to the right of the animal that is sitting down?
def execute_command(image)->str:
2025-03-14 12:23:43,089 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blue blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is the blue blanket to the left or to the right of the animal that is sitting down?")
    blanket_patch = blanket_patches[0]
    seated_animal_patches = image_patch.find("animal sitting")
    for seated_animal_patch in seated_animal_patches:
        if seated_animal_patch.horizontal_center < blanket_patch.horizontal_center:
            return "right"
        else:
            return "left"
2025-03-14 12:23:43,092 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    animal_patch = image_patch.find("animal")
    # Question assumes only one animal patch
    if len(animal_patch) == 0:
        # If no animal is found, query the image directly
        return image_patch.simple_query("Is the blue blanket to the left or to the right of the animal that is sitting down?")
    for animal_patch in animal_patch:
        if animal_patch.simple_query("is sitting down?") == "yes":
            is_to_the_left = animal_patch.simple_query("Is the blue blanket to the left or to the right of the animal that is sitting down?")
2025-03-14 12:23:43,122 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are the carrots to the left of a spoon?
def execute_command(image)->str:
2025-03-14 12:23:43,123 - INFO - Chosen response:  # assumes a spoon
    image_patch = ImagePatch(image)
    carrot_patches = image_patch.find("carrot")
    # Question assumes only one carrot patch
    if len(carrot_patches) == 0:
        # If no carrot is found, query the image directly
        return image_patch.simple_query("Are the carrots to the left of a spoon?")
    for carrot_patch in carrot_patches:
        spoon_patches = image_patch.find("spoon")
        # Question assumes only one spoon patch
        if len(spoon_patches) == 0:
            return "no"
        for spoon_patch in spoon_patches:
            if spoon_patch.horizontal_center > carrot_patch.horizontal_center:
                return "yes"
    return "no"
2025-03-14 12:23:43,125 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    carrots_patches = image_patch.find("carrot")
    # Question assumes only one carrot patch
    if len(carrots_patches) == 0:
        # If no carrots are found, query the image directly
        return image_patch.simple_query("Are the carrots to the left of a spoon?")
    for carrots_patch in carrots_patches:
        spoon_patches = image_patch.find("spoon")
        for spoon_patch in spoon_patches:
            if spoon_patch.horizontal_center < carrots_patch.horizontal_center:
                return "yes"
    return "no"
2025-03-14 12:23:43,154 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What vehicle is in front of the tree?
def execute_command(image)->str:
2025-03-14 12:23:43,156 - INFO - Chosen response:  # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What vehicle is in front of the tree?")
2025-03-14 12:23:43,158 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    tree_patches = image_patch.find("tree")
    
    for tree_patch in tree_patches:
        # Create a crop centered around the tree
        cropped_image = image_patch.cropped_image[tree_patch.upper:tree_patch.upper+tree_patch.shape[0],
                                                  tree_patch.left:tree_patch.left+tree_patch.shape[1]]
        # Find vehicles in the cropped area
        vehicle_found = cropped_image.find("vehicle")
        if vehicle_found:
            return vehicle_found[0].simple_query("What vehicle is in front of the tree?")
    return "No vehicle in front of the tree."

Map:  32%|‚ñà‚ñà‚ñà‚ñè      | 17000/52487 [00:00<00:01, 27572.02 examples/s]2025-03-14 12:23:43,188 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# On which side of the image is the mirror, the right or the left?
def execute_command(image)->str:
2025-03-14 12:23:43,190 - INFO - Chosen response:  # mirror
    image_patch = ImagePatch(image)
    mirror_patches = image_patch.find("mirror")
    # Question assumes only one mirror patch
    if len(mirror_patches) == 0:
        # If no mirror is found, query the image directly
        return image_patch.simple_query("On which side of the image is the mirror, the right or the left?")
    if mirror_patches[0].horizontal_center < image_patch.horizontal_center:
        return "left"
    else:
        return "right"
2025-03-14 12:23:43,191 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    mirror_patch = image_patch.find("mirror")
    if not mirror_patch:
        return image_patch.simple_query("Where is the mirror in the image?")
    if mirror_patch.horizontal_center < image_patch horizontal_center:
        return "The mirror is on the left."
    else:
        return "The mirror is on the right."

2025-03-14 12:23:43,221 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is there a pot to the left of the utensil on the stove?
def execute_command(image)->str:
2025-03-14 12:23:43,223 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # Find all utensil patches
    utensil_patches = image_patch.find("utensil")
    # If no utensil, query directly
    if not utensil_patches:
        return image_patch.simple_query("Is there a utensil on the stove?")
    # Find all pot patches
    pot_patches = image_patch.find("pot")
    if not pot_patches:
        return image_patch.simple_query("Is there a pot on the stove?")
    # Check each utensil relative to each pot
    for utensil in utensil_patches:
        for pot in pot_patches:
            if utensil.horizontal_center > pot.horizontal_center:
                return "yes"
    return "no"

2025-03-14 12:23:43,225 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    stove_patches = image_patch.find("stove")
    # Iterate through each stove patch
    for stove_patch in stove_patches:
        # Find utensils within the vicinity of the stove (example region)
        utensil_patches = image_patch.find("utensil", 
                left=stove_patch.left,
                right=stove_patch.right,
                upper=stove_patch.upper,
                lower=stove_patch.lower)
        # Check each utensil to see if a pot is to the left
        for utensil_patch in utensil_patches:
            pot_patches = image_patch.find("pot",
                left=utensil_patch.left,
                right=utensil_patch.right,
                upper=utensil_patch.upper,
                lower=utensil_patch.lower)
            if len(pot_patches) > 0:
                return "yes"
    return "no"

2025-03-14 12:23:43,255 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Which side of the photo is the clock on?
def execute_command(image)->str:
2025-03-14 12:23:43,257 - INFO - Chosen response:  # left or right
    image_patch = ImagePatch(image)
    clock_patches = image_patch.find("clock")
    # Question assumes only one clock patch
    if len(clock_patches) == 0:
        # If no clock is found, query the image directly
        return image_patch.simple_query("Which side of the photo is the clock on?")
    clock_patch = clock_patches[0]
    if clock_patch.horizontal_center < image_patch.horizontal_center:
        return "left"
    else:
        return "right"
2025-03-14 12:23:43,259 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    clock_patches = image_patch.find("clock")
    
    if not clock_patches:
        return "The clock is not present in the image."
    
    # Calculate the center of the entire photo
    vertical_center = (image_patch.upper + image_patch.lower) / 2
    horizontal_center = (image_patch.left + image_patch.right) / 2
    
    for clock in clock_patches:
        clock_vertical_center = (clock.upper + clock.lower) / 2
        clock_horizontal_center = (clock.left + clock.right) / 2
        
        # Check if the clock is to the left or right
        if clock_horizontal_center < horizontal_center:
            return "The clock is on the left side of the photo."
        else:
            return "The clock is on the right side of the photo."

2025-03-14 12:23:43,288 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the man to the left of the woman wearing shorts?
def execute_command(image)->str:
2025-03-14 12:23:43,290 - INFO - Chosen response:  # assumes one man and one woman
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    woman_patches = image_patch.find("woman")
    # Question assumes one man and one woman patch
    if len(man_patches) == 0 or len(woman_patches) == 0:
        return "no"
    man_patch = man_patches[0]
    woman_patch = woman_patches[0]
    if man_patch.horizontal_center < woman_patch.horizontal_center:
        return image_patch.simple_query("Is the man wearing shorts?") # crop would include the shorts so keep it in the query
    else:
        return "no"
2025-03-14 12:23:43,292 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes only one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is the man to the left of the woman wearing shorts?")
    for man_patch in man_patches:
        woman_patches = image_patch.find("man")
        # Question assumes one woman patch
        if len(woman_patches) != 1:
            return image_patch.simple_query("Is the man to the left of the woman wearing shorts?")
        for woman_patch in woman_patches:
            if woman_patch.hole_and_v < man_patch.hole_and_v:
                return "yes"
    return "no"
Map:  40%|‚ñà‚ñà‚ñà‚ñà      | 21000/52487 [00:00<00:01, 28299.32 examples/s]2025-03-14 12:23:43,322 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the large pot on the right or on the left side of the picture?
def execute_command(image)->str:
2025-03-14 12:23:43,324 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    pot_patches = image_patch.find("pot")
    # Question assumes only one pot patch
    if len(pot_patches) == 0:
        # If no pot is found, query the image directly
        return image_patch.simple_query("Where is the large pot in the picture?")
    if pot_patches[0].horizontal_center > image_patch.horizontal_center:
        return "right"
    else:
        return "left"
2025-03-14 12:23:43,326 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    pot_patch = image_patch.find("large pot")
    if not pot_patch:
        return image_patch.simple_query("Is the large pot on the right or on the left side of the picture?")
    if pot_patch.horizontal_center > image_patch.horizontal_center / 2:
        return "right"
    else:
        return "left"

2025-03-14 12:23:43,356 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the white refrigerator to the left of the man that is wearing a jacket?
def execute_command(image)->str:
2025-03-14 12:23:43,358 - INFO - Chosen response:  # assumes a refrigerator is white
    image_patch = ImagePatch(image)
    refrigerator_patches = image_patch.find("refrigerator")
    # Question assumes only one refrigerator patch
    if len(refrigerator_patches) == 0:
        # If no refrigerator is found, query the image directly
        return image_patch.simple_query("Is the white refrigerator to the left of the man that is wearing a jacket?")
    refrigerator_patch = refrigerator_patches[0]
    man_patches = image_patch.find("man")
    # Question assumes only one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is the white refrigerator to the left of the man that is wearing a jacket?")
    man_patch = man_patches[0]
    jacket_patches = image_patch.find("jacket")
    # Question assumes only one jacket patch
    if len(jacket_patches) == 0:
        return "no"
    jacket_patch = jacket_patches[0]
    if refrigerator_patch.horizontal_center < man_patch.horizontal_center and man_patch.horizontal_center < jacket_patch.horizontal_center:
        return "yes"
    return "no"
2025-03-14 12:23:43,360 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    white_refrigerator_patches = image_patch.find("white refrigerator")
    # Question assumes only one white_refrigerator patch
    if len(white_refrigerator_patches) == 0:
        # If no white refrigerator is found, query the image directly
        return image_patch.simple_query("Is the white refrigerator to the left of the man that is wearing a jacket?")
    white_refrigerator = white_refrigerator_patches[0]
    making_man_patches = image_patch.find("making_man")
    # Question assumes only one making_man patch
    if len(making_man_patches) == 0:
        # If no making_man is found, query the image directly
        return image_patch.simple_query("Is the white refrigerator to the left of the man that is wearing a jacket?")
    making_man = making_man_patches[0]
    for making_man_patch in making_man_patches:
        if making_man_patch.horizontal_center > white_refrigerator.horizontal_center:
            return "no"
    return "yes"
2025-03-14 12:23:43,389 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Do the shower and the faucet have the same material?
def execute_command(image)->str:
2025-03-14 12:23:43,391 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    is_shower = image_patch.verify_property("shower", "shower")
    is_faucet = image_patch.verify_property("faucet", "faucet")
2025-03-14 12:23:43,393 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    shower_patches = image_patch.find("shower")
    # Question assumes only one shower patch
    if len(shower_patches) == 0:
        # If no shower is found, query the image directly
        return image_patch.simple_query("Do the shower and the faucet have the same material?")
    shower = shower_patches[0]
    faucet_patches = image_patch.find("faucet")
    # Question assumes no faucet patches
    if len(faucet_patches) == 0:
        # If no faucet is found, query the image directly
        return image_patch.simple_query("Do the shower and the faucet have the same material?")
    # Question assumes only one faucet patch
    if len(faucet_patches) == 0:
        return "yes"
    return bool_to_yesno(shower.verify_property("shower", "material", faucet_patches[0].verify_property("faucet", "material")))
2025-03-14 12:23:43,423 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is there either a fence or a surfboard in the photograph?
def execute_command(image)->str:
2025-03-14 12:23:43,425 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    fence_exists = image_patch.exists("fence")
    surfboard_exists = image_patch.exists("surfboard")
    return bool_to_yesno(fence_exists or surfboard_exists)
2025-03-14 12:23:43,427 - INFO - Rejected response:   # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ.photoÎ£®_hid, photoname
    return "or"
Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 25000/52487 [00:00<00:00, 28789.51 examples/s]2025-03-14 12:23:43,457 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are there both women and men in the photo?
def execute_command(image)->str:
2025-03-14 12:23:43,459 - INFO - Chosen response:  # assumes one image
    image_patch = ImagePatch(image)
    is_woman = image_patch.exists("woman")
    is_man = image_patch.exists("man")
    return bool_to_yesno(is_woman and is_man)
2025-03-14 12:23:43,460 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    if len(man_patches) == 0:
        return bool_to_yesno(False)
    man_present = bool_to_yesno(True)
    woman_patches = image_patch.find("woman")
    if len(woman_patches) == 0:
        return bool_to_yesno(False)
    woman_present = bool_to_yesno(verify_property(man_patches[0].cropped_image, "man", "gender") and 
                                  verify_property(woman_patches[0].cropped_image, "woman", "gender"))
    return bool_to_yesno(man_present and woman_present)

2025-03-14 12:23:43,492 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the bicycle on the right or on the left?
def execute_command(image)->str:
2025-03-14 12:23:43,494 - INFO - Chosen response:  # asks for the predicate of a relational verb (on), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Is the bicycle on the right or on the left?")
2025-03-14 12:23:43,496 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    bicycle_patches = image_patch.find("bicycle")
    if len(bicycle_patches) == 0:
        return image_patch.simple_query("Is the bicycle on the right or on the left?")
    has_right = any(p.horizontal_center > image_patch.horizontal_center
2025-03-14 12:23:43,528 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What piece of furniture is covered?
def execute_command(image)->str:
2025-03-14 12:23:43,530 - INFO - Chosen response:     
    image_patch = ImagePatch(image)
    # Identify the object
    object_patches = image_patch.find("furniture")
    # Question assumes the only one piece of furniture is covered
    if len(object_patches) == 0:
        # If no object with a word similar to "furniture" is found, query the image directly
        return image_patch.simple_query("What piece of furniture is covered?")
    for object_patch in object_patches:
        is_covered = (object_patch.simple_query("Is the furniture covered?") == "yes")
        if is_covered:
            return object_patch.simple_query("What piece of furniture is covered?")
    return "No furniture is covered."
2025-03-14 12:23:43,531 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    furniture_patches = image_patch.find("furniture")
    # Question assumes at least one furniture patch
    if len(furniture_patches) == 0:
        return image_patch.simple_query("Are there any pieces of furniture in the image?")
    furniture_centers = [furniture_patch.vertical_center for furniture_patch in furniture_patches]
    vertical_center = image_patch.vertical_center
    # Find a covered object under the furniture
    covered patched = image_patch.find("covered") if "covered" in vision_functions.__dict__ else image_patch.find("object")  # Assuming "covered" refers to objects that might be over furniture
    if len(covered patched) > 0:
        for patch in covered patched:
            if patch.vertical_center > min(furniture_centers):
                return patch_best_match("What piece of furniture is covered?")
    # If no covered furniture found, check if any furniture is covered
    if any(covered patched):
        return best_text_match(["furniture"])
    return "no"

2025-03-14 12:23:43,563 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# How large is the horse to the right of the other horse?
def execute_command(image)->str:
2025-03-14 12:23:43,565 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    horse_patches = image_patch.find("horse")
    
    if len(horse_patches) == 0:
        return image_patch.simple_query("How large is the horse to the right of the other horse?")
    elif len(horse_patches) == 1:
        return horse_patches[0].simple_query("What is the size of this horse?")
    else:
        # Find the horse with the largest horizontal center (rightmost horse)
        right_horse = max(horse_patches, key=lambda hp: hp.horizontal_center)
        return right_horse.simple_query("What is the size of this horse?")
2025-03-14 12:23:43,566 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    horse_patches = image_patch.find("horse")
    
    if len(horse_patches) < 2:
        return "There are not enough horses to determine their size."
    
    for right_horse in horse_patches:
        for left_horse in horse_patches:
            if right_horse.horizontal_center > left_horse.horizontal_center:
                size = right_horse.cropped_image.size
                if size < (100, 100):
                    return "very small"
                elif size < (200, 200):
                    return "small"
                elif size < (300, 300):
                    return "medium"
                else:
                    return "large"
    
    return "Unable to determine the size of the horses."

Map:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 29000/52487 [00:01<00:00, 28710.63 examples/s]2025-03-14 12:23:43,597 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Does the shirt look purple?
def execute_command(image)->str:
2025-03-14 12:23:43,599 - INFO - Chosen response:  # the shirt is assumed to be found
    image_patch = ImagePatch(image)
    return bool_to_yesno(image_patch.verify_property("shirt", "purple"))
2025-03-14 12:23:43,601 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    purple_color_patches = image_patch.find("purple")
    # Question assumes only one purple color patch
    if len(purple_color_patches) == 0:
        # If no purple is found, query the image directly
        return image_patch.simple_query("Does the shirt look purple?")
    return "yes"
2025-03-14 12:23:43,631 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are there either pink gloves or hats?
def execute_command(image)->str:
2025-03-14 12:23:43,633 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    gloves = image_patch.find("gloves")
    hats = image_patch.find("hats")
    return "yes" if gloves or hats else "no"

2025-03-14 12:23:43,635 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    # 'either ... or' means one is acceptable, so if it finds pink gloves, return yes.
    gloves_patches = image_patch.find("gloves")
    hats_patches = image_patch.find("hat")
    # Question assumes only one gloves patch and one hat patch
    has_gloves = len(gloves_patches) == 1
    has_hats = len(hats_patches) == 1
    if has_gloves and gloves_patches[0].belongs_to(["pink", "light pink"]):
        return "yes"
    elif has_hats and hats_patches[0].belongs_to(["pink", "light pink"]):
        return "yes"
    else:
        return "no"
2025-03-14 12:23:43,665 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Which color is that shirt?
def execute_command(image)->str:
2025-03-14 12:23:43,667 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    shirt_patches = image_patch.find("shirt")
    # Question assumes only one shirt patch
    if len(shirt_patches) == 0:
        # If no shirt is found, query the image directly
        return image_patch.simple_query("Which color is that shirt?")
    return shirt_patches[0].simple_query("What color is that shirt?")
2025-03-14 12:23:43,668 - INFO - Rejected response:  # Query the image directly if no shirt is found
    image_patch = ImagePatch(image)
    is_shirt = image_patch.exists("shirt")
    if is_shirt:
        return execute_command_with_shirt(image, image_patch) # first query is the real Command as in other examples
    else:
        return image_patch.simple_query("Which color is that shirt?")
2025-03-14 12:23:43,698 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What is the church made of?
def execute_command(image)->str:
2025-03-14 12:23:43,700 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is the church made of?")
2025-03-14 12:23:43,702 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    church_patches = image_patch.find("church")
    if len(church_patches) == 0:
        # If no church found, query the entire image
        return image_patch.simple_query("What is the church made of?")
    # Ask for the material of the first church patch found
    material = church_patches[0].simple_query("What is the material of this church?")
    return bool_to_yesno(material == "wood") or bool_to_yesno(material == "brick")

Map:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33000/52487 [00:01<00:00, 28958.89 examples/s]2025-03-14 12:23:43,733 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What vegetable is to the right of the croissant?
def execute_command(image)->str:
2025-03-14 12:23:43,734 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # Find all croissants
    croissant_pairs = image_patch.find("croissant")
    if len(croissant_pairs) == 0:
        return "no"  # Because the query is about a croissant not being found
    # For each croissant, find vegetables that are to the right
    for croissant in croissant_pairs:
        # Create a new ImagePatch for each croissant, but wait, the ImagePatch's crop is relative to the original image. So, when we find vegetables, they are relative to the original image.
        # So, for each croissant's position, find vegetables and check if their left is greater than the croissant's right.
        for vegetable in image_patch.find("vegetable"):
            # Get the left and right of the vegetable
            if vegetable.left > croissant.right:
                # Check if the vegetable is entirely to the right
                # Wait, but ImagePatch's left and right are in the original image. So, the veg is to the right if veg's left > croissant's right.
                # But what if the veg spans beyond? Maybe just check the left boundaries.
                # For simplicity, I'll assume that if the left of the vegetable is greater than the right of the croissant, it's to the right.
                return vegetable.simple_query("What vegetable is to the right of the croissant?")
    # If no vegetable found to the right of any croissant
    return "no"
2025-03-14 12:23:43,737 - INFO - Rejected response:   # why pictured vegetables vs actual vegetables
    image_patch = ImagePatch(image)
    vegetable_patches = image_patch.find("vegetable")
    # Question assumes only one vegetable patch
    if len(vegetable_patches) == 0:
        # If no vegetable is found, query the image directly
        return image_patch.simple_query("What vegetable is to the right of the croissant?")
    for vegetable_patch in vegetable_patches:
        if vegetable_patch.horizontal_center > image_patch.get_center_h():
            return vegetable_patch.simple_query("What vegetable is to the right of the croissant?")
2025-03-14 12:23:43,767 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Who is in the water?
def execute_command(image)->str:
2025-03-14 12:23:43,769 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    person_patches = image_patch.find("person")
    # Question assumes only one person
    if len(person_patches) == 0:
        # If no person is found, query the image directly
        return image_patch.simple_query("Who is in the water?")
    person_patch = person_patches[0]
    is_in_water = person_patch.verify_property("bodypart", "in water")
    if is_in_water:
        return person_patch.simple_query("Who is in the water?") # crop would include the person so keep it in the query
    return image_patch.simple_query("Who is in the water?") # would not include the person
2025-03-14 12:23:43,771 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    people = image_patch.find("person")
    for person in people:
        if person.verify_property("person", "in water"):
            return "yes"
    return "no"

2025-03-14 12:23:43,799 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# On which side is the white animal?
def execute_command(image)->str:
2025-03-14 12:23:43,801 - INFO - Chosen response:  
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("On which side is the white animal?")
2025-03-14 12:23:43,803 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    animal_patch = image_patch.find("animal", {"white": True})
    
    if len(animal_patch) == 0:
        return "No white animal is present in the image."
        
    image_width = image_patch.width
    horizontal_center = animal_patch.horizontal_center
    
    if horizontal_center < image_width // 2:
        return "The white animal is on the left side."
    else:
        return "The white animal is on the right side."

2025-03-14 12:23:43,833 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the truck to the right or to the left of the person who is standing beside the plane?
def execute_command(image)->str:
2025-03-14 12:23:43,835 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    truck_patches = image_patch.find("truck")
    person_patches = image_patch.find("person")
    plane_patches = image_patch.find("plane")
    
    if len(person_patches) == 0 or len(plane_patches) == 0 or len(truck_patches) == 0:
        return image_patch.simple_query("Is the truck to the right or to the left of the person who is standing beside the plane?")
    
    truck_center = truck_patches[0].horizontal_center
    person_center = person_patches[0].horizontal_center
    plane_center = plane_patches[0].vertical_center
    
    if plane_center >= person_center:
        return "right" if truck_center > person_center else "left"
    else:
        return "no, the person is not standing beside the plane"

2025-03-14 12:23:43,836 - INFO - Rejected response:  # assumes there are only two planes
    image_patch = ImagePatch(image)
    truck_patches = image_patch.find("truck")
    # Question assumes only one truck patch
    if len(truck_patches) == 0:
        # If no truck is found, query the image directly
        return image_patch.simple_query("Is the truck to the right or to the left of the person who is standing beside the plane?")
    for truck_patch in truck_patches:
        person_patches = image_patch.find("person")
        # Question assumes only one person patch
        if len(person_patches) == 0:
            return image_patch.simple_query("Is the truck to the right or to the left of the person who is standing beside the plane?")
        person_patch = person_patches[0]
        plane_patches = image_patch.find("plane")
        # Question assumes only one plane patch
        if len(plane_patches) == 0:
            return image_patch.simple_query("Is the truck to the right or to the left of the person who is standing beside the plane?")
        plane_patch = plane_patches[0]
        if truck_patch.horizontal_center > person_patch.horizontal_center and truck_patch.horizontal_center > plane_patch.horizontal_center:
            return "right"
        elif truck_patch.horizontal
Map:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 37000/52487 [00:01<00:00, 29159.52 examples/s]2025-03-14 12:23:43,868 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Do you see whisks or spatulas that are made out of metal?
def execute_command(image)->str:
2025-03-14 12:23:43,870 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    simple_query = image_patch.simple_query("Do you see whisks or spatulas that are made out of metal?")
    if simple_query == "yes":
        whisk_patches = image_patch.find("wing")
        for whisk_patch in whisk_patches:
            simple_query =  whisk_patch.simple_query("Are they made of metal?")
            if simple_query == "yes":
                return "yes"
    return "no"
2025-03-14 12:23:43,872 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    object_patches = image_patch.find(["whisks", "spatulas"])
    if len(object_patches) == 0:
        return image_patch.simple_query("Do you see whisks or spatulas made of metal?")
    for patch in object_patches:
        if patch.verify_property("spatulas", "metal") or patch.verify_property("whisks", "metal"):
            return "yes"
    return "no"

2025-03-14 12:23:43,904 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Do you see both speakers and televisions?
def execute_command(image)->str:
2025-03-14 12:23:43,906 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    has_speaker = image_patch.exists("speaker")
    has_television = image_patch.exists("television")
    return bool_to_yesno(has_speaker and has_television)

2025-03-14 12:23:43,907 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    speakersAndTelevisons_patches = image_patch.find("speakers & television")
    return bool_to_yesno(len(speakersAndTelevisons_patches) > 0) # len because 2+0 and 1+1 both are true.

2025-03-14 12:23:43,938 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are there either any old men or women?
def execute_command(image)->str:
2025-03-14 12:23:43,940 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    is_man = image_patch.exists("old man")
    is_woman = image_patch.exists("old woman")
    return bool_to_yesno(is_man or is_woman)
2025-03-14 12:23:43,942 - INFO - Rejected response:  return execute_command1(image) or execute_command2(image)
2025-03-14 12:23:43,972 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is that ground sandy or snowy?
def execute_command(image)->str:
2025-03-14 12:23:43,974 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # not a relational verb so go step by step
    sand_patches = image_patch.find("sand")
    # Question assumes only one sand patch
    if len(sand_patches) == 0:
        # If no sand is found, query the image directly
        return image_patch.simple_query("Is that ground sandy or snowy?")
    snow_patches = image_patch.find("snow")
    # Question assumes only one snow patch
    if len(snow_patches) == 0:
        # If no snow is found, query the image directly
        return image_patch.simple_query("Is that ground sandy or snowy?")
    for sand_patch in sand_patches:
        if image_patch.verify_property("sand", "become"):
            return "snow"
        return "sandy"
    return "snowy"
2025-03-14 12:23:43,976 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    ground_patches = image_patch.find("ground")
    sand_patches = image_patch.find("sand")
    snow_patches = image_patch.find("snow")
    for ground_patch in ground_patches:
        if any((sand_patch.horizontal_center > ground_patch.horizontal_center or sand_patch.horizontal_center < ground_patch.horizontal_center) for sand_patch in sand_patches) or any((snow_patch.horizontal_center > ground_patch.horizontal_center or snow_patch.horizontal_center < ground_patch.horizontal_center) for snow_patch in snow_patches):
            return "yes"
    return "no"
Map:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 41000/52487 [00:01<00:00, 29036.25 examples/s]2025-03-14 12:23:44,007 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What kind of vegetable is on the plate that is on the table?
def execute_command(image)->str:
2025-03-14 12:23:44,009 - INFO - Chosen response:  # crop would include the plate and the table so keep them in the query
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What kind of vegetable is on the plate that is on the table?")
2025-03-14 12:23:44,010 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    plate = image_patch.find("plate")
    if not plate:
        return image_patch.simple_query("What kind of vegetable is on the table?")
    
    vegetables_on_plate = plate.box_aspect("on")
    if vegetables_on_plate:
        return vegetables_on_plate[0].best_text_match(["vegetable"])
    
    vegetables = image_patch.find("vegetable")
    if vegetables:
        return vegetables[0].best_text_match(["vegetable"])
    
    return image_patch.simple_query("What kind of vegetable is on the table?")

2025-03-14 12:23:44,040 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are there any words in this photograph that are red?
def execute_command(image)->str:
2025-03-14 12:23:44,042 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    text_patches = image_patch.find("text")
    for patch in text_patches:
        if patch.verify_property("text", "color") == "red":
            return "yes"
    return "no"

2025-03-14 12:23:44,044 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    word_patches = image_patch.find("word")
    
    # If no word patches are found, query the image directly
    if not word_patches:
        return image_patch.simple_query("Are there any red words in this photograph?")
    
    # Check each word to see if it is red
    has_red = False
    for word_patch in word_patches:
        if word_patch.verify_property("color", "red"):
            has_red = True
            break  # No need to check further once a red word is found
    
    return "yes" if has_red else "no"

2025-03-14 12:23:44,073 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# The horse is in front of what?
def execute_command(image)->str:
2025-03-14 12:23:44,075 - INFO - Chosen response:   # rectangle
    image_patch = ImagePatch(image)
    # not a relational verb so go step by step
    return image_patch.simple_query("The horse is in front of what?")
2025-03-14 12:23:44,077 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    horse_patches = image_patch.find("horse")
    if len(horse_patches) == 0:
        return image_patch.simple_query("The horse is in front of what?")
    for horse_patch in horse_patches:
        found = horse_patch.verify_property("horse", "in_front_of")
        for option in found:
            return image_patch.simple_query(f"The horse is in front of {option}")
    return image_patch.simple_query("The horse is in front of what?")

2025-03-14 12:23:44,106 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Do you see any breads or tomatoes in this photograph?
def execute_command(image)->str:
2025-03-14 12:23:44,108 - INFO - Chosen response:  # foods in top half, people around it
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    tomatoes_patches = image_patch.find("tomato")
    # Question assumes only one of each
    for bread_patch in bread_patches:
        is_bread_in_top_half = (image_patch.upper + bread_patch.lower) / 2 > image_patch.vertical_center
        if is_bread_in_top_half:
            return image_patch.simple_query("Do you see any breads or tomatoes in this photograph?")
    for tomato_patch in tomatoes_patches:
        is_tomato_in_top_half = (image_patch.upper + tomato_patch.lower) / 2 > image_patch.vertical_center
        if is_tomato_in_top_half:
            return image_patch.simple_query("Do you see any breads or tomatoes in this photograph?")
    # If no food or people are found in the top half, query the image directly
    return "no"
2025-03-14 12:23:44,110 - INFO - Rejected response:  # breads is plural
    image_patch = ImagePatch(image)
    is_bread = image_patch.exists("bread")
    is_tomato = image_patch.exists("tomato")
    return bool_to_yesno(is_bread or is_tomato)
Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 45000/52487 [00:01<00:00, 29304.34 examples/s]2025-03-14 12:23:44,140 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Which side of the image is the person on?
def execute_command(image)->str:
2025-03-14 12:23:44,142 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    person_patches = image_patch.find("person")
    
    if not person_patches:
        return "no"  # Or handle accordingly if no person is present
    
    main_center = image_patch.horizontal_center
    person_center = person_patches[0].horizontal_center
    
    if person_center < main_center:
        return "left"
    elif person_center > main_center:
        return "right"
    else:
        # If at the center, could consider position relative to others or default to left/right
        return "left"  # Example default

2025-03-14 12:23:44,143 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    person_patches = image_patch.find("person")
    if not person_patches:
        return image_patch.simple_query("Which side of the image is the person on?")
    image_center_w = image_patch.width // 2
    image_center_h = image_patch.height // 2
    for patch in person_patches:
        person_w_center = patch.right // 2
        person_h_center = patch.upper // 2
        if person_w_center < image_center_w - (image_center_w // 2):
            # Wait, no, that would be left of center.
            return "left"
        elif person_w_center > image_center_w + (image_center_w // 2):
            # Right of center
            return "right"
        elif person_h_center < image_center_h - (image_center_h // 2):
            # Bottom of center
            return "bottom"
        elif person_h_center > image_center_h + (image_center_h // 2):
            # Top of
2025-03-14 12:23:44,173 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is that grass tall?
def execute_command(image)->str:
2025-03-14 12:23:44,175 - INFO - Chosen response:  # image is a PIL image
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("Is that grass tall?")
2025-03-14 12:23:44,177 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    grass_patches = image_patch.find("grass")
    # Question assumes only one grass patch
    if len(grass_patches) == 0:
        # If no grass is found, query the image directly
        return image_patch.simple_query("Is that grass tall?")
    return grass_patches[0].verify_property("grass", "tall")
2025-03-14 12:23:44,206 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What color are the books on the right side?
def execute_command(image)->str:
2025-03-14 12:23:44,208 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # Query directly
    return image_patch.simple_query("What color are the books on the right side?")
2025-03-14 12:23:44,210 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    book_patches = image_patch.find("book")
    # Question assumes only one book patch
    if len(book_patches) == 0:
        # If no book is found, query the image directly
        return image_patch.simple_query("What color are the books on the right side?")
    book_patch = book_patches[0]
    if book_patch.horizontal_center + 0.5*book_patch.width > image_patch.width/2:
        return book_patch.simple_query("What color is the book?")
    else:
        return "none"
2025-03-14 12:23:44,239 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What vehicle is the road behind of, a truck or a bus?
def execute_command(image)->str:
2025-03-14 12:23:44,241 - INFO - Chosen response:   # Whether your command will work depends on the location of the vehicle.
    image_patch = ImagePatch(image)
    vehicle_patches = image_patch.find("vehicle")
    # Question assumes only one vehicle patch
    if len(vehicle_patches) == 0:
        # If no vehicle is found, query the image directly
        return image_patch.simple_query("Is that vehicle in front of a truck or a bus?")
    if vehicle_patches[0].verify_property("vehicle", "your favorite commercial vehicle"):
        return "truck"
    elif vehicle_patches[0].verify_property("vehicle", "your second favorite commercial vehicle"):
        return "bus"
2025-03-14 12:23:44,243 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    road_patches = image_patch.find("road")
    # Question assumes only one road patch
    if len(road_patches) == 0:
        # If no road is found, query the image directly
        return image_patch.simple_query("What vehicle is the road behind of, a truck or a bus?")
    is_behind_truck = image_patch.find("truck").time(road_patch.cropped_image.shape[0], 100) != -1 or image_patch.find("truck").on(road_patch.cropped_image.shape[0], 100) != -1
    is_behind_bus = image_patch.find("bus").time(road_patch.cropped_image.shape[0], 100) != -1 or image_patch.find("bus").on(road_patch.cropped_image.shape[0], 100) != -1
    if is_behind_truck and not is_behind_bus:
        return "truck"
    if not is_behind_truck and is_behind_bus:
        return "bus"
    return best_text_match(road_patches[0].cropped_image, ['truck', 'bus'])
Map:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49000/52487 [00:01<00:00, 29573.35 examples/s]2025-03-14 12:23:44,272 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are there any backpacks to the left of the shelf?
def execute_command(image)->str:
2025-03-14 12:23:44,274 - INFO - Chosen response: 
    # first use find using exist to identify any backpacks; this is faster if there is a large number of backpacks
    image_patch = ImagePatch(image)
    backpack_patches = image_patch.find("backpack")
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center <= image_patch.horizontal_center:
            return "yes"
    # If there is one backpack to the left, ask it
    if len(backpack_patches) > 0:
        return backpack_patches[0].simple_query("Are there any backpacks to the left of the shelf?")
    # If no backpacks are found, ask image
    return image_patch.simple_query("Are there any backpacks to the left of the shelf?")
2025-03-14 12:23:44,276 - INFO - Rejected response:  # image_patch = ImagePatch(image)
    image_patch = ImagePatch(image)
    backpack_patches = image_patch.find("backpack")
    # Question assumes only one shelf patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        shelf_patches = image_patch.find("shelf")
        for shelf_patch in shelf_patches:
            if shelf_patch.horizontal_center > backpack_patch.horizontal_center:
                return "no"
    return "yes"
2025-03-14 12:23:44,305 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Which place is it?
def execute_command(image)->str:
2025-03-14 12:23:44,307 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Which place is it?")
2025-03-14 12:23:44,310 - INFO - Rejected response: 
    """Determines the location based on objects present in the image.
    
    The function uses the ImagePatch class to identify common places like restaurants, parks, or cities.
    If ambiguous, it queries the image directly to confirm the location.
    """
    image_patch = ImagePatch(image)
    
    # Find common place objects
    restaurant_found = image_patch.exists("restaurant")
    park_found = image_patch.exists("park")
    city_found = image_patch.exists("city")
   arket_found = image_patch.exists("market")
    
    # Check for indicators that can help determine the place
    has_sign = any(image_patch.exists("sign") for _ in range(5))
    has_building = any(image_patch.exists("building") for _ in range(5))
    has_parked_car = any(image_patch.exists("parked car") for _ in range(5))
    has_trees = any(image_patch.exists("tree") for _ in range(5))
    
    # Determine based on combinations
    if restaurant_found and has_sign and has_building:
        return "restaurant"
    if park_found and has_trees and has_parked_car:
        return "park"
    if city_found and has_sign and has_building and has_parked_car:
        return "city"
    ifarket_found and has_sign and has_market_items:
        return "market"
    
    # If none or multiple possibilities, query directly
    return image_patch.simple_query("Which place is it?")
2025-03-14 12:23:44,340 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the young man on the left side of the image?
def execute_command(image)->str:
2025-03-14 12:23:44,342 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes only one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is the young man on the left side of the image?")
    man_patch = man_patches[0]
    if man_patch.horizontal_center < image_patch.width / 2:
        return "yes"
    else:
        return "no"
2025-03-14 12:23:44,344 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    young_man_patches = image_patch.find("young man")
    # Question assumes only one young man patch
    if len(young_man_patches) == 0:
        # If no young man is found, query the image directly
        return image_patch.simple_query("Is there a young man on the left?")
    young_man_patch = young_man_patches[0]
    if young_man_patch.horizontal_center < image_patch.left:
        return "yes"
    return "no"
2025-03-14 12:23:44,371 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# What is the watercraft to the right of the elephant in the middle?
def execute_command(image)->str:
2025-03-14 12:23:44,372 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # it's actually fine here, but it may be better to split the command
    # elephant -> watercraft
    #   right
    elephant_patches = image_patch.find("elephant")
    # Query assumes only one elephant patch
    if len(elephant_patches) == 0:
        # If no elephant is found, query the image directly
        return image_patch.simple_query("What is the watercraft to the right of the elephant in the middle?")
    elephant_patch = elephant_patches[0]
    watercraft_patches = image_patch.find("watercraft")
    for watercraft_patch in watercraft_patches:
        if elephant_patch.horizontal_center < watercraft_patch.horizontal_center:
            return watercraft_patch.simple_query("What is the watercraft to the right of the elephant in the middle?")
    # if no watercraft is found to the right of the elephant
    return image_patch.simple_query("What is the watercraft to the right of the elephant in the middle?")
2025-03-14 12:23:44,373 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    # Find watercraft and elephant patches
    watercraft = [wp for wp in image_patch.find("watercraft")]
    elephants = [ep for ep in image_patch.find("elephant")]
    
    # If no watercraft exists, query directly
    if not watercraft:
        return image_patch.simple_query("Is there a watercraft to the right of an elephant.")
    
    # If no elephant exists, assume based on query
    if not elephants:
        return image_patch.simple_query("Is there an elephant in the middle?")
    
    # Iterate through each watercraft
    for wp in watercraft:
        for ep in elephants:
            # Check if watercraft is to the right of elephant
            if wp.horizontal_center > ep.horizontal_center:
                # The watercraft is to the right of the elephant
                return wp.simple_query("What type of watercraft is to the right of an elephant?")
    
    # If no watercraft to the right of elephant
    return "no"

Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52487/52487 [00:01<00:00, 29321.07 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52487/52487 [00:11<00:00, 4694.73 examples/s] 
2025-03-14 12:23:53,680 - INFO - Initializing DPOTrainer...
Extracting prompt in train dataset:   0%|          | 0/52487 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|‚ñè         | 999/52487 [00:00<00:05, 9910.76 examples/s]Extracting prompt in train dataset:   4%|‚ñç         | 2040/52487 [00:00<00:04, 10198.50 examples/s]Extracting prompt in train dataset:   6%|‚ñå         | 3104/52487 [00:00<00:04, 10396.68 examples/s]Extracting prompt in train dataset:   8%|‚ñä         | 4170/52487 [00:00<00:04, 10480.46 examples/s]Extracting prompt in train dataset:  10%|‚ñâ         | 5230/52487 [00:00<00:04, 10500.73 examples/s]Extracting prompt in train dataset:  13%|‚ñà‚ñé        | 6805/52487 [00:00<00:04, 10498.53 examples/s]Extracting prompt in train dataset:  16%|‚ñà‚ñå        | 8350/52487 [00:00<00:04, 10413.49 examples/s]Extracting prompt in train dataset:  18%|‚ñà‚ñä        | 9409/52487 [00:00<00:04, 10459.26 examples/s]Extracting prompt in train dataset:  21%|‚ñà‚ñà        | 10920/52487 [00:01<00:04, 10306.23 examples/s]Extracting prompt in train dataset:  23%|‚ñà‚ñà‚ñé       | 11960/52487 [00:01<00:03, 10327.78 examples/s]Extracting prompt in train dataset:  25%|‚ñà‚ñà‚ñç       | 13010/52487 [00:01<00:03, 10369.28 examples/s]Extracting prompt in train dataset:  27%|‚ñà‚ñà‚ñã       | 14064/52487 [00:01<00:03, 10410.23 examples/s]Extracting prompt in train dataset:  29%|‚ñà‚ñà‚ñâ       | 15111/52487 [00:01<00:03, 10423.52 examples/s]Extracting prompt in train dataset:  31%|‚ñà‚ñà‚ñà       | 16180/52487 [00:01<00:03, 10489.37 examples/s]Extracting prompt in train dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 17231/52487 [00:01<00:03, 10493.17 examples/s]Extracting prompt in train dataset:  36%|‚ñà‚ñà‚ñà‚ñå      | 18770/52487 [00:01<00:03, 10398.53 examples/s]Extracting prompt in train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 19830/52487 [00:01<00:03, 10445.38 examples/s]Extracting prompt in train dataset:  41%|‚ñà‚ñà‚ñà‚ñà      | 21401/52487 [00:02<00:02, 10452.62 examples/s]Extracting prompt in train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22450/52487 [00:02<00:02, 10445.10 examples/s]Extracting prompt in train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 24025/52487 [00:02<00:02, 10462.19 examples/s]Extracting prompt in train dataset:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 25080/52487 [00:02<00:02, 10474.97 examples/s]Extracting prompt in train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 26138/52487 [00:02<00:02, 10502.09 examples/s]Extracting prompt in train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27700/52487 [00:02<00:02, 10453.32 examples/s]Extracting prompt in train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 29263/52487 [00:02<00:02, 10440.23 examples/s]Extracting prompt in train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 30830/52487 [00:02<00:02, 10433.11 examples/s]Extracting prompt in train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 32311/52487 [00:03<00:01, 10253.26 examples/s]Extracting prompt in train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33360/52487 [00:03<00:01, 10292.36 examples/s]Extracting prompt in train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 34420/52487 [00:03<00:01, 10360.60 examples/s]Extracting prompt in train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35480/52487 [00:03<00:01, 10418.33 examples/s]Extracting prompt in train dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 36542/52487 [00:03<00:01, 10471.90 examples/s]Extracting prompt in train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 38120/52487 [00:03<00:01, 10464.82 examples/s]Extracting prompt in train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 39170/52487 [00:03<00:01, 10465.03 examples/s]Extracting prompt in train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40743/52487 [00:03<00:01, 10470.90 examples/s]Extracting prompt in train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 42312/52487 [00:04<00:00, 10463.14 examples/s]Extracting prompt in train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 43870/52487 [00:04<00:00, 10427.31 examples/s]Extracting prompt in train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 44922/52487 [00:04<00:00, 10447.76 examples/s]Extracting prompt in train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45971/52487 [00:04<00:00, 10449.76 examples/s]Extracting prompt in train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 47020/52487 [00:04<00:00, 10447.76 examples/s]Extracting prompt in train dataset:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 48581/52487 [00:04<00:00, 10419.82 examples/s]Extracting prompt in train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 50150/52487 [00:04<00:00, 10423.94 examples/s]Extracting prompt in train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 51210/52487 [00:04<00:00, 10460.84 examples/s]Extracting prompt in train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 52260/52487 [00:05<00:00, 10462.05 examples/s]Extracting prompt in train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52487/52487 [00:07<00:00, 6646.36 examples/s] 
Applying chat template to train dataset:   0%|          | 0/52487 [00:00<?, ? examples/s]Applying chat template to train dataset:   2%|‚ñè         | 1240/52487 [00:00<00:04, 12280.49 examples/s]Applying chat template to train dataset:   5%|‚ñç         | 2519/52487 [00:00<00:03, 12564.36 examples/s]Applying chat template to train dataset:   7%|‚ñã         | 3784/52487 [00:00<00:03, 12600.78 examples/s]Applying chat template to train dataset:  11%|‚ñà         | 5680/52487 [00:00<00:03, 12602.91 examples/s]Applying chat template to train dataset:  14%|‚ñà‚ñç        | 7546/52487 [00:00<00:03, 12533.53 examples/s]Applying chat template to train dataset:  17%|‚ñà‚ñã        | 8803/52487 [00:00<00:03, 12542.33 examples/s]Applying chat template to train dataset:  19%|‚ñà‚ñâ        | 10061/52487 [00:00<00:03, 12549.89 examples/s]Applying chat template to train dataset:  22%|‚ñà‚ñà‚ñè       | 11320/52487 [00:00<00:03, 12549.08 examples/s]Applying chat template to train dataset:  25%|‚ñà‚ñà‚ñå       | 13207/52487 [00:01<00:03, 12550.05 examples/s]Applying chat template to train dataset:  29%|‚ñà‚ñà‚ñâ       | 15100/52487 [00:01<00:02, 12568.39 examples/s]Applying chat template to train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 17000/52487 [00:01<00:02, 12593.12 examples/s]Applying chat template to train dataset:  35%|‚ñà‚ñà‚ñà‚ñç      | 18263/52487 [00:01<00:02, 12601.58 examples/s]Applying chat template to train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 20140/52487 [00:01<00:02, 12561.01 examples/s]Applying chat template to train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 22024/52487 [00:01<00:02, 12554.85 examples/s]Applying chat template to train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23894/52487 [00:01<00:02, 12516.80 examples/s]Applying chat template to train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25769/52487 [00:02<00:02, 12505.53 examples/s]Applying chat template to train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27650/52487 [00:02<00:01, 12509.49 examples/s]Applying chat template to train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29537/52487 [00:02<00:01, 12525.01 examples/s]Applying chat template to train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 31404/52487 [00:02<00:01, 12495.51 examples/s]Applying chat template to train dataset:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33270/52487 [00:02<00:01, 12475.95 examples/s]Applying chat template to train dataset:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 35141/52487 [00:02<00:01, 12472.74 examples/s]Applying chat template to train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 37020/52487 [00:02<00:01, 12479.90 examples/s]Applying chat template to train dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38896/52487 [00:03<00:01, 12482.30 examples/s]Applying chat template to train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 40159/52487 [00:03<00:00, 12513.01 examples/s]Applying chat template to train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 41418/52487 [00:03<00:00, 12529.89 examples/s]Applying chat template to train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42687/52487 [00:03<00:00, 12568.83 examples/s]Applying chat template to train dataset:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 44565/52487 [00:03<00:00, 12541.66 examples/s]Applying chat template to train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 46459/52487 [00:03<00:00, 12561.85 examples/s]Applying chat template to train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 48337/52487 [00:03<00:00, 12547.23 examples/s]Applying chat template to train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 50162/52487 [00:04<00:00, 12424.96 examples/s]Applying chat template to train dataset:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 52028/52487 [00:04<00:00, 12421.79 examples/s]Applying chat template to train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52487/52487 [00:07<00:00, 7234.32 examples/s] 
Tokenizing train dataset:   0%|          | 0/52487 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 77/52487 [00:00<01:09, 758.99 examples/s]Tokenizing train dataset:   0%|          | 162/52487 [00:00<01:04, 805.62 examples/s]Tokenizing train dataset:   1%|          | 272/52487 [00:00<00:55, 935.47 examples/s]Tokenizing train dataset:   1%|          | 378/52487 [00:00<00:53, 976.11 examples/s]Tokenizing train dataset:   1%|          | 480/52487 [00:00<00:52, 987.19 examples/s]Tokenizing train dataset:   1%|          | 627/52487 [00:00<00:52, 979.76 examples/s]Tokenizing train dataset:   1%|‚ñè         | 737/52487 [00:00<00:51, 1013.17 examples/s]Tokenizing train dataset:   2%|‚ñè         | 840/52487 [00:00<00:51, 1011.11 examples/s]Tokenizing train dataset:   2%|‚ñè         | 993/52487 [00:01<00:51, 1006.75 examples/s]Tokenizing train dataset:   2%|‚ñè         | 1138/52487 [00:01<00:51, 988.92 examples/s]Tokenizing train dataset:   2%|‚ñè         | 1268/52487 [00:01<00:54, 945.04 examples/s]Tokenizing train dataset:   3%|‚ñé         | 1366/52487 [00:01<00:53, 950.09 examples/s]Tokenizing train dataset:   3%|‚ñé         | 1466/52487 [00:01<00:53, 957.56 examples/s]Tokenizing train dataset:   3%|‚ñé         | 1563/52487 [00:01<00:53, 957.01 examples/s]Tokenizing train dataset:   3%|‚ñé         | 1706/52487 [00:01<00:53, 949.37 examples/s]Tokenizing train dataset:   3%|‚ñé         | 1807/52487 [00:01<00:52, 963.54 examples/s]Tokenizing train dataset:   4%|‚ñé         | 1951/52487 [00:02<00:52, 958.96 examples/s]Tokenizing train dataset:   4%|‚ñç         | 2050/52487 [00:02<00:52, 964.71 examples/s]Tokenizing train dataset:   4%|‚ñç         | 2159/52487 [00:02<00:50, 997.08 examples/s]Tokenizing train dataset:   4%|‚ñç         | 2261/52487 [00:02<00:50, 999.26 examples/s]Tokenizing train dataset:   5%|‚ñç         | 2365/52487 [00:02<00:49, 1007.83 examples/s]Tokenizing train dataset:   5%|‚ñç         | 2520/52487 [00:02<00:49, 1010.86 examples/s]Tokenizing train dataset:   5%|‚ñç         | 2624/52487 [00:02<00:49, 1015.43 examples/s]Tokenizing train dataset:   5%|‚ñå         | 2777/52487 [00:02<00:49, 1009.56 examples/s]Tokenizing train dataset:   6%|‚ñå         | 2925/52487 [00:02<00:49, 998.58 examples/s] Tokenizing train dataset:   6%|‚ñå         | 3083/52487 [00:03<00:48, 1012.91 examples/s]Tokenizing train dataset:   6%|‚ñå         | 3228/52487 [00:03<00:49, 994.69 examples/s] Tokenizing train dataset:   6%|‚ñã         | 3333/52487 [00:03<00:48, 1005.99 examples/s]Tokenizing train dataset:   7%|‚ñã         | 3470/52487 [00:03<00:50, 970.30 examples/s] Tokenizing train dataset:   7%|‚ñã         | 3618/52487 [00:03<00:50, 971.05 examples/s]Tokenizing train dataset:   7%|‚ñã         | 3758/52487 [00:03<00:51, 955.06 examples/s]Tokenizing train dataset:   7%|‚ñã         | 3912/52487 [00:04<00:49, 974.12 examples/s]Tokenizing train dataset:   8%|‚ñä         | 4010/52487 [00:04<00:49, 974.31 examples/s]Tokenizing train dataset:   8%|‚ñä         | 4111/52487 [00:04<00:49, 980.51 examples/s]Tokenizing train dataset:   8%|‚ñä         | 4223/52487 [00:04<00:47, 1012.81 examples/s]Tokenizing train dataset:   8%|‚ñä         | 4370/52487 [00:04<00:48, 996.09 examples/s] Tokenizing train dataset:   9%|‚ñä         | 4474/52487 [00:04<00:47, 1005.45 examples/s]Tokenizing train dataset:   9%|‚ñâ         | 4624/52487 [00:04<00:47, 1000.22 examples/s]Tokenizing train dataset:   9%|‚ñâ         | 4762/52487 [00:04<00:49, 968.57 examples/s] Tokenizing train dataset:   9%|‚ñâ         | 4870/52487 [00:04<00:48, 991.45 examples/s]Tokenizing train dataset:   9%|‚ñâ         | 4971/52487 [00:05<00:47, 994.36 examples/s]Tokenizing train dataset:  10%|‚ñâ         | 5074/52487 [00:05<00:47, 1001.03 examples/s]Tokenizing train dataset:  10%|‚ñâ         | 5219/52487 [00:05<00:48, 980.35 examples/s] Tokenizing train dataset:  10%|‚ñà         | 5322/52487 [00:05<00:47, 990.55 examples/s]Tokenizing train dataset:  10%|‚ñà         | 5472/52487 [00:05<00:47, 984.85 examples/s]Tokenizing train dataset:  11%|‚ñà         | 5617/52487 [00:05<00:48, 974.16 examples/s]Tokenizing train dataset:  11%|‚ñà         | 5755/52487 [00:05<00:49, 952.08 examples/s]Tokenizing train dataset:  11%|‚ñà         | 5852/52487 [00:05<00:48, 954.94 examples/s]Tokenizing train dataset:  11%|‚ñà‚ñè        | 5961/52487 [00:06<00:47, 986.17 examples/s]Tokenizing train dataset:  12%|‚ñà‚ñè        | 6068/52487 [00:06<00:46, 1004.77 examples/s]Tokenizing train dataset:  12%|‚ñà‚ñè        | 6172/52487 [00:06<00:45, 1010.85 examples/s]Tokenizing train dataset:  12%|‚ñà‚ñè        | 6317/52487 [00:06<00:46, 991.45 examples/s] Tokenizing train dataset:  12%|‚ñà‚ñè        | 6418/52487 [00:06<00:46, 994.30 examples/s]Tokenizing train dataset:  13%|‚ñà‚ñé        | 6563/52487 [00:06<00:46, 978.24 examples/s]Tokenizing train dataset:  13%|‚ñà‚ñé        | 6662/52487 [00:06<00:46, 977.47 examples/s]Tokenizing train dataset:  13%|‚ñà‚ñé        | 6763/52487 [00:06<00:46, 983.61 examples/s]Tokenizing train dataset:  13%|‚ñà‚ñé        | 6898/52487 [00:07<00:47, 950.81 examples/s]Tokenizing train dataset:  13%|‚ñà‚ñé        | 6995/52487 [00:07<00:47, 953.51 examples/s]Tokenizing train dataset:  14%|‚ñà‚ñé        | 7122/52487 [00:07<00:49, 913.54 examples/s]Tokenizing train dataset:  14%|‚ñà‚ñç        | 7252/52487 [00:07<00:50, 895.74 examples/s]Tokenizing train dataset:  14%|‚ñà‚ñç        | 7344/52487 [00:07<00:50, 899.74 examples/s]Tokenizing train dataset:  14%|‚ñà‚ñç        | 7438/52487 [00:07<00:49, 908.17 examples/s]Tokenizing train dataset:  14%|‚ñà‚ñç        | 7558/52487 [00:07<00:51, 864.63 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñç        | 7669/52487 [00:07<00:54, 818.08 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñç        | 7780/52487 [00:08<00:56, 790.84 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñå        | 7891/52487 [00:08<00:57, 773.53 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñå        | 7970/52487 [00:08<00:57, 772.05 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñå        | 8083/52487 [00:08<00:58, 763.96 examples/s]Tokenizing train dataset:  16%|‚ñà‚ñå        | 8170/52487 [00:08<00:56, 786.68 examples/s]Tokenizing train dataset:  16%|‚ñà‚ñå        | 8293/52487 [00:08<00:55, 795.96 examples/s]Tokenizing train dataset:  16%|‚ñà‚ñå        | 8396/52487 [00:08<00:51, 849.18 examples/s]Tokenizing train dataset:  16%|‚ñà‚ñå        | 8498/52487 [00:08<00:49, 891.00 examples/s]Tokenizing train dataset:  16%|‚ñà‚ñã        | 8621/52487 [00:09<00:50, 863.01 examples/s]Tokenizing train dataset:  17%|‚ñà‚ñã        | 8753/52487 [00:09<00:50, 863.85 examples/s]Tokenizing train dataset:  17%|‚ñà‚ñã        | 8878/52487 [00:09<00:51, 850.15 examples/s]Tokenizing train dataset:  17%|‚ñà‚ñã        | 8968/52487 [00:09<00:50, 860.08 examples/s]Tokenizing train dataset:  17%|‚ñà‚ñã        | 9059/52487 [00:09<00:49, 870.61 examples/s]Tokenizing train dataset:  17%|‚ñà‚ñã        | 9183/52487 [00:09<00:50, 850.06 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 9310/52487 [00:09<00:51, 841.78 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 9402/52487 [00:10<00:50, 858.05 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 9495/52487 [00:10<00:49, 875.50 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 9584/52487 [00:10<00:48, 877.66 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 9680/52487 [00:10<00:47, 895.71 examples/s]Tokenizing train dataset:  19%|‚ñà‚ñä        | 9778/52487 [00:10<00:46, 914.84 examples/s]Tokenizing train dataset:  19%|‚ñà‚ñâ        | 9874/52487 [00:10<00:46, 924.48 examples/s]Tokenizing train dataset:  19%|‚ñà‚ñâ        | 10020/52487 [00:10<00:45, 939.58 examples/s]Tokenizing train dataset:  19%|‚ñà‚ñâ        | 10116/52487 [00:10<00:44, 943.77 examples/s]Tokenizing train dataset:  20%|‚ñà‚ñâ        | 10259/52487 [00:10<00:44, 942.31 examples/s]Tokenizing train dataset:  20%|‚ñà‚ñâ        | 10393/52487 [00:11<00:45, 922.85 examples/s]Tokenizing train dataset:  20%|‚ñà‚ñà        | 10531/52487 [00:11<00:45, 918.41 examples/s]Tokenizing train dataset:  20%|‚ñà‚ñà        | 10626/52487 [00:11<00:45, 924.20 examples/s]Tokenizing train dataset:  20%|‚ñà‚ñà        | 10749/52487 [00:11<00:47, 884.20 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà        | 10850/52487 [00:11<00:45, 912.03 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà        | 10943/52487 [00:11<00:45, 914.77 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà        | 11038/52487 [00:11<00:44, 921.63 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà        | 11134/52487 [00:11<00:44, 931.33 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà‚ñè       | 11281/52487 [00:12<00:43, 947.39 examples/s]Tokenizing train dataset:  22%|‚ñà‚ñà‚ñè       | 11414/52487 [00:12<00:44, 925.04 examples/s]Tokenizing train dataset:  22%|‚ñà‚ñà‚ñè       | 11542/52487 [00:12<00:45, 896.31 examples/s]Tokenizing train dataset:  22%|‚ñà‚ñà‚ñè       | 11633/52487 [00:12<00:45, 896.33 examples/s]Tokenizing train dataset:  22%|‚ñà‚ñà‚ñè       | 11773/52487 [00:12<00:45, 901.71 examples/s]Tokenizing train dataset:  23%|‚ñà‚ñà‚ñé       | 11868/52487 [00:12<00:44, 910.06 examples/s]Tokenizing train dataset:  23%|‚ñà‚ñà‚ñé       | 11960/52487 [00:12<00:44, 906.14 examples/s]Tokenizing train dataset:  23%|‚ñà‚ñà‚ñé       | 12058/52487 [00:12<00:43, 924.96 examples/s]Tokenizing train dataset:  23%|‚ñà‚ñà‚ñé       | 12191/52487 [00:13<00:44, 903.80 examples/s]Tokenizing train dataset:  23%|‚ñà‚ñà‚ñé       | 12285/52487 [00:13<00:44, 910.80 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñé       | 12390/52487 [00:13<00:42, 947.67 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñç       | 12488/52487 [00:13<00:41, 955.58 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñç       | 12633/52487 [00:13<00:41, 954.48 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñç       | 12730/52487 [00:13<00:41, 954.26 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñç       | 12843/52487 [00:13<00:39, 997.59 examples/s]Tokenizing train dataset:  25%|‚ñà‚ñà‚ñç       | 12983/52487 [00:13<00:40, 964.93 examples/s]Tokenizing train dataset:  25%|‚ñà‚ñà‚ñå       | 13122/52487 [00:14<00:41, 947.91 examples/s]Tokenizing train dataset:  25%|‚ñà‚ñà‚ñå       | 13226/52487 [00:14<00:40, 968.64 examples/s]Tokenizing train dataset:  25%|‚ñà‚ñà‚ñå       | 13331/52487 [00:14<00:39, 986.74 examples/s]Tokenizing train dataset:  26%|‚ñà‚ñà‚ñå       | 13477/52487 [00:14<00:39, 976.49 examples/s]Tokenizing train dataset:  26%|‚ñà‚ñà‚ñå       | 13628/52487 [00:14<00:39, 983.14 examples/s]Tokenizing train dataset:  26%|‚ñà‚ñà‚ñã       | 13779/52487 [00:14<00:39, 984.22 examples/s]Tokenizing train dataset:  26%|‚ñà‚ñà‚ñã       | 13880/52487 [00:14<00:39, 985.53 examples/s]Tokenizing train dataset:  27%|‚ñà‚ñà‚ñã       | 13982/52487 [00:14<00:38, 990.84 examples/s]Tokenizing train dataset:  27%|‚ñà‚ñà‚ñã       | 14123/52487 [00:15<00:39, 969.37 examples/s]Tokenizing train dataset:  27%|‚ñà‚ñà‚ñã       | 14230/52487 [00:15<00:38, 992.24 examples/s]Tokenizing train dataset:  27%|‚ñà‚ñà‚ñã       | 14380/52487 [00:15<00:38, 990.82 examples/s]Tokenizing train dataset:  28%|‚ñà‚ñà‚ñä       | 14518/52487 [00:15<00:39, 963.86 examples/s]Tokenizing train dataset:  28%|‚ñà‚ñà‚ñä       | 14654/52487 [00:15<00:40, 944.21 examples/s]Tokenizing train dataset:  28%|‚ñà‚ñà‚ñä       | 14755/52487 [00:15<00:39, 954.75 examples/s]Tokenizing train dataset:  28%|‚ñà‚ñà‚ñä       | 14881/52487 [00:15<00:41, 910.90 examples/s]Tokenizing train dataset:  29%|‚ñà‚ñà‚ñä       | 14980/52487 [00:15<00:40, 927.01 examples/s]Tokenizing train dataset:  29%|‚ñà‚ñà‚ñâ       | 15120/52487 [00:16<00:40, 926.16 examples/s]Tokenizing train dataset:  29%|‚ñà‚ñà‚ñâ       | 15264/52487 [00:16<00:39, 933.92 examples/s]Tokenizing train dataset:  29%|‚ñà‚ñà‚ñâ       | 15362/52487 [00:16<00:39, 941.54 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñâ       | 15506/52487 [00:16<00:39, 941.70 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñâ       | 15609/52487 [00:16<00:38, 959.69 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñâ       | 15710/52487 [00:16<00:37, 971.15 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñà       | 15814/52487 [00:16<00:37, 988.43 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñà       | 15965/52487 [00:16<00:36, 990.10 examples/s]Tokenizing train dataset:  31%|‚ñà‚ñà‚ñà       | 16069/52487 [00:17<00:36, 998.39 examples/s]Tokenizing train dataset:  31%|‚ñà‚ñà‚ñà       | 16176/52487 [00:17<00:35, 1014.20 examples/s]Tokenizing train dataset:  31%|‚ñà‚ñà‚ñà       | 16280/52487 [00:17<00:35, 1017.28 examples/s]Tokenizing train dataset:  31%|‚ñà‚ñà‚ñà       | 16388/52487 [00:17<00:34, 1032.84 examples/s]Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 16536/52487 [00:17<00:35, 1013.01 examples/s]Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 16665/52487 [00:17<00:37, 957.74 examples/s] Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 16795/52487 [00:17<00:38, 922.06 examples/s]Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 16896/52487 [00:17<00:37, 939.75 examples/s]Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 17035/52487 [00:18<00:37, 933.54 examples/s]Tokenizing train dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 17168/52487 [00:18<00:38, 914.25 examples/s]Tokenizing train dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 17310/52487 [00:18<00:38, 919.24 examples/s]Tokenizing train dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 17408/52487 [00:18<00:37, 931.75 examples/s]Tokenizing train dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 17520/52487 [00:18<00:35, 974.70 examples/s]Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñé      | 17624/52487 [00:18<00:35, 989.34 examples/s]Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñç      | 17730/52487 [00:18<00:34, 1007.13 examples/s]Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñç      | 17869/52487 [00:18<00:35, 974.53 examples/s] Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñç      | 17969/52487 [00:19<00:35, 976.04 examples/s]Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñç      | 18103/52487 [00:19<00:36, 943.82 examples/s]Tokenizing train dataset:  35%|‚ñà‚ñà‚ñà‚ñç      | 18240/52487 [00:19<00:36, 929.12 examples/s]Tokenizing train dataset:  35%|‚ñà‚ñà‚ñà‚ñç      | 18350/52487 [00:19<00:35, 966.65 examples/s]Tokenizing train dataset:  35%|‚ñà‚ñà‚ñà‚ñå      | 18488/52487 [00:19<00:35, 948.36 examples/s]Tokenizing train dataset:  35%|‚ñà‚ñà‚ñà‚ñå      | 18625/52487 [00:19<00:36, 930.79 examples/s]Tokenizing train dataset:  36%|‚ñà‚ñà‚ñà‚ñå      | 18763/52487 [00:19<00:36, 923.30 examples/s]Tokenizing train dataset:  36%|‚ñà‚ñà‚ñà‚ñå      | 18895/52487 [00:20<00:36, 907.96 examples/s]Tokenizing train dataset:  36%|‚ñà‚ñà‚ñà‚ñå      | 18995/52487 [00:20<00:36, 926.69 examples/s]Tokenizing train dataset:  36%|‚ñà‚ñà‚ñà‚ñã      | 19095/52487 [00:20<00:35, 940.79 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 19220/52487 [00:20<00:36, 899.18 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 19320/52487 [00:20<00:35, 921.43 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 19430/52487 [00:20<00:34, 963.99 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 19528/52487 [00:20<00:34, 964.12 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 19629/52487 [00:20<00:33, 975.50 examples/s]Tokenizing train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 19782/52487 [00:20<00:33, 988.64 examples/s]Tokenizing train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 19926/52487 [00:21<00:33, 976.38 examples/s]Tokenizing train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 20060/52487 [00:21<00:34, 944.16 examples/s]Tokenizing train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 20157/52487 [00:21<00:34, 948.96 examples/s]Tokenizing train dataset:  39%|‚ñà‚ñà‚ñà‚ñä      | 20289/52487 [00:21<00:34, 922.60 examples/s]Tokenizing train dataset:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20383/52487 [00:21<00:34, 924.55 examples/s]Tokenizing train dataset:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20529/52487 [00:21<00:34, 937.75 examples/s]Tokenizing train dataset:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20633/52487 [00:21<00:33, 961.55 examples/s]Tokenizing train dataset:  40%|‚ñà‚ñà‚ñà‚ñâ      | 20733/52487 [00:21<00:32, 968.83 examples/s]Tokenizing train dataset:  40%|‚ñà‚ñà‚ñà‚ñâ      | 20835/52487 [00:22<00:32, 977.40 examples/s]Tokenizing train dataset:  40%|‚ñà‚ñà‚ñà‚ñâ      | 20935/52487 [00:22<00:32, 981.76 examples/s]Tokenizing train dataset:  40%|‚ñà‚ñà‚ñà‚ñà      | 21080/52487 [00:22<00:32, 970.60 examples/s]Tokenizing train dataset:  40%|‚ñà‚ñà‚ñà‚ñà      | 21181/52487 [00:22<00:31, 979.61 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà      | 21323/52487 [00:22<00:32, 964.35 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà      | 21471/52487 [00:22<00:31, 969.73 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà      | 21610/52487 [00:23<00:46, 664.49 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21691/52487 [00:23<00:44, 687.73 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21776/52487 [00:23<00:42, 719.22 examples/s]Tokenizing train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21864/52487 [00:23<00:40, 754.99 examples/s]Tokenizing train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21958/52487 [00:23<00:38, 796.47 examples/s]Tokenizing train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 22050/52487 [00:23<00:37, 821.93 examples/s]Tokenizing train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 22151/52487 [00:23<00:34, 868.51 examples/s]Tokenizing train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 22251/52487 [00:23<00:33, 903.08 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22360/52487 [00:23<00:31, 954.69 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22494/52487 [00:24<00:32, 926.32 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22590/52487 [00:24<00:32, 932.53 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22696/52487 [00:24<00:30, 965.18 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22809/52487 [00:24<00:29, 1008.39 examples/s]Tokenizing train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22945/52487 [00:24<00:30, 967.42 examples/s] Tokenizing train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 23090/52487 [00:24<00:30, 963.60 examples/s]Tokenizing train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 23225/52487 [00:24<00:31, 937.90 examples/s]Tokenizing train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 23322/52487 [00:24<00:30, 944.13 examples/s]Tokenizing train dataset:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 23468/52487 [00:25<00:30, 951.13 examples/s]Tokenizing train dataset:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 23564/52487 [00:25<00:30, 952.86 examples/s]Tokenizing train dataset:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23688/52487 [00:25<00:31, 906.00 examples/s]Tokenizing train dataset:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23829/52487 [00:25<00:31, 914.38 examples/s]Tokenizing train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23924/52487 [00:25<00:31, 921.11 examples/s]Tokenizing train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 24034/52487 [00:25<00:29, 963.93 examples/s]Tokenizing train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 24136/52487 [00:25<00:29, 975.51 examples/s]Tokenizing train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24285/52487 [00:25<00:28, 975.00 examples/s]Tokenizing train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24390/52487 [00:26<00:28, 987.16 examples/s]Tokenizing train dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24498/52487 [00:26<00:27, 1010.01 examples/s]Tokenizing train dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24637/52487 [00:26<00:28, 973.84 examples/s] Tokenizing train dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24768/52487 [00:26<00:29, 934.77 examples/s]Tokenizing train dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24867/52487 [00:26<00:29, 945.97 examples/s]Tokenizing train dataset:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24965/52487 [00:26<00:28, 952.45 examples/s]Tokenizing train dataset:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 25107/52487 [00:26<00:28, 946.86 examples/s]Tokenizing train dataset:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 25214/52487 [00:26<00:27, 974.35 examples/s]Tokenizing train dataset:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 25358/52487 [00:27<00:28, 963.47 examples/s]Tokenizing train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 25465/52487 [00:27<00:27, 987.28 examples/s]Tokenizing train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25604/52487 [00:27<00:27, 962.24 examples/s]Tokenizing train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25750/52487 [00:27<00:27, 961.19 examples/s]Tokenizing train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25898/52487 [00:27<00:27, 967.77 examples/s]Tokenizing train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 26001/52487 [00:27<00:27, 979.51 examples/s]Tokenizing train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 26105/52487 [00:27<00:26, 993.08 examples/s]Tokenizing train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 26210/52487 [00:27<00:26, 1003.82 examples/s]Tokenizing train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26318/52487 [00:27<00:25, 1023.67 examples/s]Tokenizing train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26464/52487 [00:28<00:25, 1002.41 examples/s]Tokenizing train dataset:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26607/52487 [00:28<00:26, 983.05 examples/s] Tokenizing train dataset:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26742/52487 [00:28<00:27, 953.26 examples/s]Tokenizing train dataset:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26850/52487 [00:28<00:26, 976.20 examples/s]Tokenizing train dataset:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26950/52487 [00:28<00:26, 974.07 examples/s]Tokenizing train dataset:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 27052/52487 [00:28<00:25, 982.06 examples/s]Tokenizing train dataset:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 27195/52487 [00:28<00:26, 967.87 examples/s]Tokenizing train dataset:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 27300/52487 [00:29<00:25, 984.78 examples/s]Tokenizing train dataset:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 27400/52487 [00:29<00:25, 984.03 examples/s]Tokenizing train dataset:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 27543/52487 [00:29<00:25, 970.48 examples/s]Tokenizing train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27644/52487 [00:29<00:25, 980.38 examples/s]Tokenizing train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27780/52487 [00:29<00:25, 950.29 examples/s]Tokenizing train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27921/52487 [00:29<00:26, 944.67 examples/s]Tokenizing train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 28063/52487 [00:29<00:25, 942.99 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 28159/52487 [00:29<00:25, 943.55 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28256/52487 [00:30<00:25, 948.90 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28353/52487 [00:30<00:25, 952.23 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28454/52487 [00:30<00:24, 965.03 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28557/52487 [00:30<00:24, 981.37 examples/s]Tokenizing train dataset:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28657/52487 [00:30<00:24, 984.11 examples/s]Tokenizing train dataset:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28773/52487 [00:30<00:23, 1031.04 examples/s]Tokenizing train dataset:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28936/52487 [00:30<00:22, 1050.76 examples/s]Tokenizing train dataset:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 29045/52487 [00:30<00:22, 1057.40 examples/s]Tokenizing train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 29201/52487 [00:30<00:22, 1047.32 examples/s]Tokenizing train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 29346/52487 [00:31<00:22, 1015.31 examples/s]Tokenizing train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 29488/52487 [00:31<00:23, 989.71 examples/s] Tokenizing train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29642/52487 [00:31<00:22, 998.89 examples/s]Tokenizing train dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29784/52487 [00:31<00:23, 977.55 examples/s]Tokenizing train dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29884/52487 [00:31<00:23, 979.68 examples/s]Tokenizing train dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 30023/52487 [00:31<00:23, 960.86 examples/s]Tokenizing train dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 30120/52487 [00:31<00:23, 961.11 examples/s]Tokenizing train dataset:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 30262/52487 [00:32<00:23, 953.91 examples/s]Tokenizing train dataset:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 30371/52487 [00:32<00:22, 984.99 examples/s]Tokenizing train dataset:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 30472/52487 [00:32<00:22, 988.54 examples/s]Tokenizing train dataset:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 30577/52487 [00:32<00:21, 1003.28 examples/s]Tokenizing train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 30729/52487 [00:32<00:21, 1003.29 examples/s]Tokenizing train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30870/52487 [00:32<00:22, 977.09 examples/s] Tokenizing train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 31014/52487 [00:32<00:22, 969.65 examples/s]Tokenizing train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 31151/52487 [00:32<00:22, 949.34 examples/s]Tokenizing train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 31248/52487 [00:33<00:22, 950.08 examples/s]Tokenizing train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 31357/52487 [00:33<00:21, 983.21 examples/s]Tokenizing train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 31492/52487 [00:33<00:22, 951.05 examples/s]Tokenizing train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31590/52487 [00:33<00:21, 953.84 examples/s]Tokenizing train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31726/52487 [00:33<00:22, 932.49 examples/s]Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31834/52487 [00:33<00:21, 965.97 examples/s]Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31941/52487 [00:33<00:20, 990.10 examples/s]Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 32045/52487 [00:33<00:20, 1001.38 examples/s]Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 32196/52487 [00:34<00:20, 996.84 examples/s] Tokenizing train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 32332/52487 [00:34<00:20, 964.15 examples/s]Tokenizing train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 32474/52487 [00:34<00:20, 953.08 examples/s]Tokenizing train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 32620/52487 [00:34<00:20, 952.57 examples/s]Tokenizing train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 32719/52487 [00:34<00:20, 959.41 examples/s]Tokenizing train dataset:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32877/52487 [00:34<00:19, 987.59 examples/s]Tokenizing train dataset:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33019/52487 [00:34<00:20, 971.36 examples/s]Tokenizing train dataset:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33162/52487 [00:35<00:20, 962.42 examples/s]Tokenizing train dataset:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33263/52487 [00:35<00:19, 970.61 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33362/52487 [00:35<00:19, 971.00 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 33460/52487 [00:35<00:19, 968.18 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33602/52487 [00:35<00:19, 958.64 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33710/52487 [00:35<00:19, 984.12 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33847/52487 [00:35<00:19, 952.90 examples/s]Tokenizing train dataset:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33977/52487 [00:35<00:20, 921.57 examples/s]Tokenizing train dataset:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 34079/52487 [00:35<00:19, 942.42 examples/s]Tokenizing train dataset:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 34224/52487 [00:36<00:19, 946.02 examples/s]Tokenizing train dataset:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 34365/52487 [00:36<00:19, 942.02 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 34473/52487 [00:36<00:18, 972.67 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 34572/52487 [00:36<00:18, 973.67 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 34678/52487 [00:36<00:17, 992.60 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34785/52487 [00:36<00:17, 1010.43 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34890/52487 [00:36<00:17, 1014.54 examples/s]Tokenizing train dataset:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 35006/52487 [00:36<00:16, 1053.25 examples/s]Tokenizing train dataset:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 35168/52487 [00:37<00:16, 1057.44 examples/s]Tokenizing train dataset:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 35275/52487 [00:37<00:16, 1057.42 examples/s]Tokenizing train dataset:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 35388/52487 [00:37<00:15, 1073.87 examples/s]Tokenizing train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35502/52487 [00:37<00:15, 1090.68 examples/s]Tokenizing train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35657/52487 [00:37<00:15, 1065.06 examples/s]Tokenizing train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35799/52487 [00:37<00:16, 1021.12 examples/s]Tokenizing train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35940/52487 [00:37<00:16, 986.96 examples/s] Tokenizing train dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 36082/52487 [00:37<00:16, 971.92 examples/s]Tokenizing train dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 36218/52487 [00:38<00:17, 947.82 examples/s]Tokenizing train dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 36352/52487 [00:38<00:17, 928.71 examples/s]Tokenizing train dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 36455/52487 [00:38<00:16, 949.14 examples/s]Tokenizing train dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 36552/52487 [00:38<00:16, 950.71 examples/s]Tokenizing train dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 36649/52487 [00:38<00:16, 953.93 examples/s]Tokenizing train dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36758/52487 [00:38<00:15, 986.17 examples/s]Tokenizing train dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36907/52487 [00:38<00:15, 986.68 examples/s]Tokenizing train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 37060/52487 [00:38<00:15, 994.46 examples/s]Tokenizing train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 37202/52487 [00:39<00:15, 973.12 examples/s]Tokenizing train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 37341/52487 [00:39<00:15, 954.38 examples/s]Tokenizing train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 37439/52487 [00:39<00:15, 956.58 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 37578/52487 [00:39<00:15, 943.30 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 37676/52487 [00:39<00:15, 948.33 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 37777/52487 [00:39<00:15, 961.70 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 37877/52487 [00:39<00:15, 966.96 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 37975/52487 [00:39<00:14, 968.77 examples/s]Tokenizing train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 38075/52487 [00:40<00:14, 974.65 examples/s]Tokenizing train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 38221/52487 [00:40<00:14, 969.77 examples/s]Tokenizing train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 38320/52487 [00:40<00:14, 969.71 examples/s]Tokenizing train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 38426/52487 [00:40<00:14, 992.04 examples/s]Tokenizing train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 38570/52487 [00:40<00:14, 978.01 examples/s]Tokenizing train dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38719/52487 [00:40<00:14, 982.51 examples/s]Tokenizing train dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38824/52487 [00:40<00:13, 997.13 examples/s]Tokenizing train dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38930/52487 [00:40<00:13, 1006.44 examples/s]Tokenizing train dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 39040/52487 [00:40<00:13, 1026.94 examples/s]Tokenizing train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 39183/52487 [00:41<00:13, 994.33 examples/s] Tokenizing train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 39328/52487 [00:41<00:13, 980.33 examples/s]Tokenizing train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 39427/52487 [00:41<00:13, 979.52 examples/s]Tokenizing train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 39530/52487 [00:41<00:13, 987.51 examples/s]Tokenizing train dataset:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 39674/52487 [00:41<00:13, 975.74 examples/s]Tokenizing train dataset:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 39820/52487 [00:41<00:13, 969.10 examples/s]Tokenizing train dataset:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 39970/52487 [00:41<00:12, 974.13 examples/s]Tokenizing train dataset:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 40069/52487 [00:42<00:12, 975.52 examples/s]Tokenizing train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 40167/52487 [00:42<00:12, 972.21 examples/s]Tokenizing train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 40305/52487 [00:42<00:12, 952.24 examples/s]Tokenizing train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 40401/52487 [00:42<00:12, 953.47 examples/s]Tokenizing train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 40508/52487 [00:42<00:12, 983.62 examples/s]Tokenizing train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 40651/52487 [00:42<00:12, 969.13 examples/s]Tokenizing train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40796/52487 [00:42<00:12, 964.06 examples/s]Tokenizing train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40898/52487 [00:42<00:11, 975.46 examples/s]Tokenizing train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 41030/52487 [00:43<00:12, 939.83 examples/s]Tokenizing train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 41151/52487 [00:43<00:12, 891.14 examples/s]Tokenizing train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 41292/52487 [00:43<00:12, 904.95 examples/s]Tokenizing train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 41419/52487 [00:43<00:16, 679.33 examples/s]Tokenizing train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 41520/52487 [00:43<00:14, 738.04 examples/s]Tokenizing train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 41618/52487 [00:43<00:13, 786.98 examples/s]Tokenizing train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 41719/52487 [00:43<00:12, 836.30 examples/s]Tokenizing train dataset:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 41818/52487 [00:44<00:12, 872.63 examples/s]Tokenizing train dataset:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 41962/52487 [00:44<00:11, 897.78 examples/s]Tokenizing train dataset:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 42060/52487 [00:44<00:11, 914.77 examples/s]Tokenizing train dataset:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 42155/52487 [00:44<00:11, 922.04 examples/s]Tokenizing train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 42264/52487 [00:44<00:10, 963.51 examples/s]Tokenizing train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 42412/52487 [00:44<00:10, 966.44 examples/s]Tokenizing train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 42510/52487 [00:44<00:10, 965.87 examples/s]Tokenizing train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42652/52487 [00:44<00:10, 956.97 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42783/52487 [00:45<00:10, 927.35 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42884/52487 [00:45<00:10, 943.56 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42981/52487 [00:45<00:10, 947.29 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 43080/52487 [00:45<00:09, 956.07 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 43215/52487 [00:45<00:09, 932.45 examples/s]Tokenizing train dataset:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 43313/52487 [00:45<00:09, 943.23 examples/s]Tokenizing train dataset:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 43416/52487 [00:45<00:09, 962.58 examples/s]Tokenizing train dataset:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 43561/52487 [00:45<00:09, 962.16 examples/s]Tokenizing train dataset:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 43700/52487 [00:46<00:09, 945.71 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 43844/52487 [00:46<00:09, 946.26 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 43951/52487 [00:46<00:08, 973.56 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 44080/52487 [00:46<00:09, 933.19 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 44220/52487 [00:46<00:08, 928.41 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 44321/52487 [00:46<00:08, 945.75 examples/s]Tokenizing train dataset:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 44468/52487 [00:46<00:08, 953.95 examples/s]Tokenizing train dataset:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 44571/52487 [00:46<00:08, 970.29 examples/s]Tokenizing train dataset:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 44711/52487 [00:47<00:08, 952.08 examples/s]Tokenizing train dataset:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 44840/52487 [00:47<00:08, 917.13 examples/s]Tokenizing train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 44938/52487 [00:47<00:08, 931.12 examples/s]Tokenizing train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 45077/52487 [00:47<00:07, 927.99 examples/s]Tokenizing train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 45179/52487 [00:47<00:07, 948.06 examples/s]Tokenizing train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 45279/52487 [00:47<00:07, 958.70 examples/s]Tokenizing train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 45378/52487 [00:47<00:07, 964.74 examples/s]Tokenizing train dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 45520/52487 [00:47<00:07, 955.75 examples/s]Tokenizing train dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 45623/52487 [00:48<00:07, 972.24 examples/s]Tokenizing train dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 45721/52487 [00:48<00:06, 970.11 examples/s]Tokenizing train dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 45856/52487 [00:48<00:07, 941.45 examples/s]Tokenizing train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45990/52487 [00:48<00:07, 918.23 examples/s]Tokenizing train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 46100/52487 [00:48<00:06, 958.97 examples/s]Tokenizing train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 46208/52487 [00:48<00:06, 989.57 examples/s]Tokenizing train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 46361/52487 [00:48<00:06, 999.34 examples/s]Tokenizing train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 46465/52487 [00:48<00:05, 1005.79 examples/s]Tokenizing train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 46580/52487 [00:49<00:05, 1039.06 examples/s]Tokenizing train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 46730/52487 [00:49<00:05, 1016.16 examples/s]Tokenizing train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 46868/52487 [00:49<00:05, 980.87 examples/s] Tokenizing train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 47020/52487 [00:49<00:05, 983.52 examples/s]Tokenizing train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 47161/52487 [00:49<00:05, 966.60 examples/s]Tokenizing train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 47303/52487 [00:49<00:05, 956.67 examples/s]Tokenizing train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 47409/52487 [00:49<00:05, 976.62 examples/s]Tokenizing train dataset:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 47511/52487 [00:49<00:05, 985.10 examples/s]Tokenizing train dataset:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 47645/52487 [00:50<00:05, 948.36 examples/s]Tokenizing train dataset:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 47788/52487 [00:50<00:04, 942.43 examples/s]Tokenizing train dataset:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 47888/52487 [00:50<00:04, 954.20 examples/s]Tokenizing train dataset:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47995/52487 [00:50<00:04, 981.49 examples/s]Tokenizing train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 48132/52487 [00:50<00:04, 952.08 examples/s]Tokenizing train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 48234/52487 [00:50<00:04, 965.19 examples/s]Tokenizing train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 48343/52487 [00:50<00:04, 995.86 examples/s]Tokenizing train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 48481/52487 [00:50<00:04, 965.57 examples/s]Tokenizing train dataset:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 48620/52487 [00:51<00:04, 949.04 examples/s]Tokenizing train dataset:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 48761/52487 [00:51<00:03, 942.95 examples/s]Tokenizing train dataset:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 48901/52487 [00:51<00:03, 936.13 examples/s]Tokenizing train dataset:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49037/52487 [00:51<00:03, 922.23 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 49133/52487 [00:51<00:03, 927.47 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 49268/52487 [00:51<00:03, 914.90 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 49407/52487 [00:52<00:03, 916.44 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 49506/52487 [00:52<00:03, 931.93 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 49600/52487 [00:52<00:03, 929.77 examples/s]Tokenizing train dataset:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 49709/52487 [00:52<00:02, 968.35 examples/s]Tokenizing train dataset:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 49817/52487 [00:52<00:02, 994.32 examples/s]Tokenizing train dataset:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49958/52487 [00:52<00:02, 968.85 examples/s]Tokenizing train dataset:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 50090/52487 [00:52<00:02, 931.34 examples/s]Tokenizing train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 50218/52487 [00:52<00:02, 899.50 examples/s]Tokenizing train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 50339/52487 [00:53<00:02, 867.55 examples/s]Tokenizing train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 50431/52487 [00:53<00:02, 878.47 examples/s]Tokenizing train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 50521/52487 [00:53<00:02, 881.49 examples/s]Tokenizing train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 50620/52487 [00:53<00:02, 904.66 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 50717/52487 [00:53<00:01, 920.49 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 50817/52487 [00:53<00:01, 941.23 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 50914/52487 [00:53<00:01, 946.55 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 51053/52487 [00:53<00:01, 936.88 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 51155/52487 [00:53<00:01, 955.62 examples/s]Tokenizing train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 51259/52487 [00:53<00:01, 974.30 examples/s]Tokenizing train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 51402/52487 [00:54<00:01, 964.30 examples/s]Tokenizing train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 51501/52487 [00:54<00:01, 967.96 examples/s]Tokenizing train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 51642/52487 [00:54<00:00, 955.70 examples/s]Tokenizing train dataset:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 51795/52487 [00:54<00:00, 973.08 examples/s]Tokenizing train dataset:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 51902/52487 [00:54<00:00, 993.98 examples/s]Tokenizing train dataset:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 52043/52487 [00:54<00:00, 972.27 examples/s]Tokenizing train dataset:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 52187/52487 [00:54<00:00, 963.36 examples/s]Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 52333/52487 [00:55<00:00, 963.81 examples/s]Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 52436/52487 [00:55<00:00, 976.94 examples/s]Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52487/52487 [00:58<00:00, 904.35 examples/s]
2025-03-14 12:25:07,855 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-03-14 12:25:07,873 - INFO - Performing pre-training evaluation on the dev dataset...
  0%|          | 0/125 [00:00<?, ?it/s]  2%|‚ñè         | 2/125 [00:03<03:59,  1.94s/it]  2%|‚ñè         | 3/125 [00:07<05:26,  2.67s/it]  3%|‚ñé         | 4/125 [00:10<05:24,  2.68s/it]  4%|‚ñç         | 5/125 [00:12<05:11,  2.60s/it]  5%|‚ñç         | 6/125 [00:14<04:55,  2.48s/it]  6%|‚ñå         | 7/125 [00:17<04:51,  2.47s/it]  6%|‚ñã         | 8/125 [00:19<04:44,  2.43s/it]  7%|‚ñã         | 9/125 [00:21<04:06,  2.13s/it]  8%|‚ñä         | 10/125 [00:23<03:55,  2.05s/it]  9%|‚ñâ         | 11/125 [00:25<03:51,  2.03s/it] 10%|‚ñâ         | 12/125 [00:27<03:55,  2.08s/it] 10%|‚ñà         | 13/125 [00:29<04:01,  2.16s/it] 11%|‚ñà         | 14/125 [00:31<03:44,  2.02s/it] 12%|‚ñà‚ñè        | 15/125 [00:32<03:30,  1.92s/it] 13%|‚ñà‚ñé        | 16/125 [00:34<03:24,  1.88s/it] 14%|‚ñà‚ñé        | 17/125 [00:36<03:12,  1.78s/it] 14%|‚ñà‚ñç        | 18/125 [00:38<03:19,  1.86s/it] 15%|‚ñà‚ñå        | 19/125 [00:39<02:56,  1.67s/it] 16%|‚ñà‚ñå        | 20/125 [00:41<02:58,  1.70s/it] 17%|‚ñà‚ñã        | 21/125 [00:42<02:49,  1.63s/it] 18%|‚ñà‚ñä        | 22/125 [00:45<03:10,  1.85s/it] 18%|‚ñà‚ñä        | 23/125 [00:46<02:56,  1.73s/it] 19%|‚ñà‚ñâ        | 24/125 [00:48<02:50,  1.69s/it] 20%|‚ñà‚ñà        | 25/125 [00:50<03:15,  1.95s/it] 21%|‚ñà‚ñà        | 26/125 [00:53<03:35,  2.18s/it] 22%|‚ñà‚ñà‚ñè       | 27/125 [00:55<03:38,  2.23s/it] 22%|‚ñà‚ñà‚ñè       | 28/125 [00:58<03:55,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 29/125 [01:01<03:48,  2.38s/it] 24%|‚ñà‚ñà‚ñç       | 30/125 [01:02<03:21,  2.12s/it] 25%|‚ñà‚ñà‚ñç       | 31/125 [01:04<03:12,  2.05s/it] 26%|‚ñà‚ñà‚ñå       | 32/125 [01:06<03:05,  1.99s/it] 26%|‚ñà‚ñà‚ñã       | 33/125 [01:08<03:09,  2.06s/it] 27%|‚ñà‚ñà‚ñã       | 34/125 [01:10<03:15,  2.15s/it] 28%|‚ñà‚ñà‚ñä       | 35/125 [01:13<03:32,  2.36s/it] 29%|‚ñà‚ñà‚ñâ       | 36/125 [01:15<03:22,  2.27s/it] 30%|‚ñà‚ñà‚ñâ       | 37/125 [01:18<03:32,  2.41s/it] 30%|‚ñà‚ñà‚ñà       | 38/125 [01:21<03:34,  2.47s/it] 31%|‚ñà‚ñà‚ñà       | 39/125 [01:24<03:43,  2.60s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 40/125 [01:25<03:15,  2.30s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 41/125 [01:27<03:05,  2.21s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 42/125 [01:29<02:46,  2.00s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [01:31<02:40,  1.96s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 44/125 [01:33<02:57,  2.19s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 45/125 [01:35<02:40,  2.01s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 46/125 [01:38<03:17,  2.50s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 47/125 [01:41<03:12,  2.47s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 48/125 [01:43<03:13,  2.51s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 49/125 [01:47<03:32,  2.80s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 50/125 [01:49<03:02,  2.44s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 51/125 [01:51<02:54,  2.36s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 52/125 [01:53<02:42,  2.22s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 53/125 [01:56<02:54,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [01:57<02:30,  2.12s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 55/125 [01:59<02:24,  2.06s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 56/125 [02:01<02:19,  2.02s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 57/125 [02:05<02:57,  2.61s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 58/125 [02:07<02:40,  2.39s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 59/125 [02:08<02:22,  2.15s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60/125 [02:10<02:14,  2.08s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 61/125 [02:13<02:22,  2.23s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 62/125 [02:14<02:06,  2.01s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 63/125 [02:16<02:09,  2.09s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 64/125 [02:18<02:03,  2.02s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [02:21<02:07,  2.13s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 66/125 [02:24<02:19,  2.37s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 67/125 [02:25<02:04,  2.14s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 68/125 [02:28<02:13,  2.35s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 69/125 [02:30<02:02,  2.18s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 70/125 [02:33<02:10,  2.38s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 71/125 [02:34<01:57,  2.18s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 72/125 [02:36<01:51,  2.09s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 73/125 [02:38<01:45,  2.03s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 74/125 [02:40<01:36,  1.90s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75/125 [02:42<01:42,  2.06s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [02:45<01:50,  2.27s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 77/125 [02:47<01:38,  2.04s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 78/125 [02:49<01:47,  2.29s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 79/125 [02:52<01:52,  2.46s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 80/125 [02:54<01:42,  2.28s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 81/125 [02:56<01:40,  2.28s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 82/125 [03:00<01:58,  2.76s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 83/125 [03:02<01:42,  2.45s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 84/125 [03:05<01:44,  2.54s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [03:07<01:37,  2.44s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 86/125 [03:09<01:34,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [03:12<01:39,  2.62s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 88/125 [03:15<01:32,  2.49s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 89/125 [03:17<01:33,  2.59s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90/125 [03:19<01:24,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 91/125 [03:21<01:18,  2.30s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 92/125 [03:24<01:13,  2.24s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 93/125 [03:26<01:12,  2.26s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 94/125 [03:28<01:08,  2.21s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 95/125 [03:29<00:59,  1.99s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 96/125 [03:31<00:55,  1.93s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 97/125 [03:33<00:49,  1.78s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [03:35<00:49,  1.81s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 99/125 [03:36<00:47,  1.84s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 100/125 [03:39<00:50,  2.02s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 101/125 [03:41<00:51,  2.15s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 102/125 [03:44<00:49,  2.16s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 103/125 [03:45<00:44,  2.03s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 104/125 [03:47<00:41,  1.98s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105/125 [03:51<00:53,  2.70s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 106/125 [03:55<00:54,  2.89s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 107/125 [03:57<00:50,  2.80s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 108/125 [04:00<00:47,  2.81s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [04:02<00:38,  2.41s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 110/125 [04:04<00:36,  2.43s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 111/125 [04:06<00:30,  2.16s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [04:08<00:28,  2.17s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 113/125 [04:10<00:24,  2.06s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 114/125 [04:11<00:20,  1.90s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 115/125 [04:14<00:21,  2.16s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 116/125 [04:17<00:20,  2.28s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 117/125 [04:19<00:17,  2.22s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 118/125 [04:20<00:14,  2.09s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 119/125 [04:23<00:13,  2.25s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [04:25<00:10,  2.13s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 121/125 [04:28<00:09,  2.33s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 122/125 [04:32<00:08,  2.85s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 123/125 [04:33<00:04,  2.37s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 124/125 [04:36<00:02,  2.48s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.40s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.23s/it]
2025-03-14 12:29:50,802 - INFO - Initial evaluation results: {'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0274, 'eval_runtime': 282.8767, 'eval_samples_per_second': 3.535, 'eval_steps_per_second': 0.442, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015}
2025-03-14 12:29:50,802 - INFO - Starting training...
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 52,487 | Num Epochs = 2
O^O/ \_/ \    Batch size per device = 4 | Gradient Accumulation steps = 4
\        /    Total batch size = 16 | Total steps = 6,560
 "-____-"     Number of trainable parameters = 167,772,160
  0%|          | 0/6560 [00:00<?, ?it/s]  0%|          | 1/6560 [00:09<17:21:52,  9.53s/it]  0%|          | 2/6560 [00:20<18:51:42, 10.35s/it]  0%|          | 3/6560 [00:27<16:06:13,  8.84s/it]  0%|          | 4/6560 [00:36<15:58:46,  8.77s/it]  0%|          | 5/6560 [00:44<15:39:42,  8.60s/it]  0%|          | 6/6560 [00:53<15:50:41,  8.70s/it]  0%|          | 7/6560 [01:02<15:50:42,  8.70s/it]  0%|          | 8/6560 [01:11<16:13:20,  8.91s/it]  0%|          | 9/6560 [01:18<15:12:48,  8.36s/it]  0%|          | 10/6560 [01:25<14:11:57,  7.80s/it]  0%|          | 11/6560 [01:32<13:49:19,  7.60s/it]  0%|          | 12/6560 [01:40<13:57:02,  7.67s/it]  0%|          | 13/6560 [01:47<13:39:37,  7.51s/it]  0%|          | 14/6560 [01:54<13:36:31,  7.48s/it]  0%|          | 15/6560 [02:02<13:36:15,  7.48s/it]  0%|          | 16/6560 [02:10<14:05:50,  7.76s/it]  0%|          | 17/6560 [02:18<14:23:33,  7.92s/it]  0%|          | 18/6560 [02:26<14:09:50,  7.79s/it]  0%|          | 19/6560 [02:35<14:39:01,  8.06s/it]  0%|          | 20/6560 [02:43<14:40:17,  8.08s/it]  0%|          | 21/6560 [02:51<14:48:40,  8.15s/it]  0%|          | 22/6560 [02:59<14:36:51,  8.05s/it]  0%|          | 23/6560 [03:07<14:37:53,  8.06s/it]  0%|          | 24/6560 [03:14<14:04:23,  7.75s/it]  0%|          | 25/6560 [03:21<13:52:37,  7.64s/it]  0%|          | 26/6560 [03:27<12:56:56,  7.13s/it]  0%|          | 27/6560 [03:36<13:34:34,  7.48s/it]  0%|          | 28/6560 [03:42<12:46:11,  7.04s/it]  0%|          | 29/6560 [03:49<13:06:37,  7.23s/it]  0%|          | 30/6560 [03:57<13:39:49,  7.53s/it]  0%|          | 31/6560 [04:04<13:11:51,  7.28s/it]  0%|          | 32/6560 [04:12<13:35:41,  7.50s/it]  1%|          | 33/6560 [04:20<13:40:07,  7.54s/it]  1%|          | 34/6560 [04:27<13:40:13,  7.54s/it]  1%|          | 35/6560 [04:34<13:01:25,  7.19s/it]  1%|          | 36/6560 [04:42<13:28:06,  7.43s/it]  1%|          | 37/6560 [04:50<14:04:13,  7.77s/it]  1%|          | 38/6560 [04:58<14:05:55,  7.78s/it]  1%|          | 39/6560 [05:06<14:16:01,  7.88s/it]  1%|          | 40/6560 [05:13<13:50:31,  7.64s/it]                                                      1%|          | 40/6560 [05:13<13:50:31,  7.64s/it]  1%|          | 41/6560 [05:21<13:39:26,  7.54s/it]  1%|          | 42/6560 [05:29<14:03:16,  7.76s/it]  1%|          | 43/6560 [05:34<12:50:15,  7.09s/it]  1%|          | 44/6560 [05:44<14:15:20,  7.88s/it]  1%|          | 45/6560 [05:54<15:07:16,  8.36s/it]  1%|          | 46/6560 [06:02<15:22:59,  8.50s/it]  1%|          | 47/6560 [06:12<15:45:11,  8.71s/it]  1%|          | 48/6560 [06:20<15:31:05,  8.58s/it]  1%|          | 49/6560 [06:26<14:25:56,  7.98s/it]  1%|          | 50/6560 [06:33<13:47:37,  7.63s/it]  1%|          | 51/6560 [06:40<13:05:58,  7.25s/it]  1%|          | 52/6560 [06:47<13:02:39,  7.22s/it]  1%|          | 53/6560 [06:55<13:37:30,  7.54s/it]  1%|          | 54/6560 [07:02<13:18:52,  7.37s/it]  1%|          | 55/6560 [07:08<12:27:33,  6.90s/it]  1%|          | 56/6560 [07:15<12:26:23,  6.89s/it]  1%|          | 57/6560 [07:23<12:59:20,  7.19s/it]  1%|          | 58/6560 [07:31<13:34:58,  7.52s/it]  1%|          | 59/6560 [07:38<13:28:55,  7.47s/it]  1%|          | 60/6560 [07:47<14:24:13,  7.98s/it]  1%|          | 61/6560 [07:54<13:55:05,  7.71s/it]  1%|          | 62/6560 [08:01<13:19:02,  7.38s/it]  1%|          | 63/6560 [08:11<14:55:52,  8.27s/it]  1%|          | 64/6560 [08:19<14:45:22,  8.18s/it]  1%|          | 65/6560 [08:27<14:38:27,  8.12s/it]  1%|          | 66/6560 [08:34<13:46:58,  7.64s/it]  1%|          | 67/6560 [08:44<15:10:32,  8.41s/it]  1%|          | 68/6560 [08:52<15:07:56,  8.39s/it]  1%|          | 69/6560 [09:00<14:29:49,  8.04s/it]  1%|          | 70/6560 [09:06<13:39:06,  7.57s/it]  1%|          | 71/6560 [09:14<13:37:57,  7.56s/it]  1%|          | 72/6560 [09:21<13:16:08,  7.36s/it]  1%|          | 73/6560 [09:29<14:00:08,  7.77s/it]  1%|          | 74/6560 [09:38<14:24:10,  7.99s/it]  1%|          | 75/6560 [09:45<14:01:32,  7.79s/it]  1%|          | 76/6560 [09:54<14:23:52,  7.99s/it]  1%|          | 77/6560 [10:01<14:19:01,  7.95s/it]  1%|          | 78/6560 [10:09<14:17:57,  7.94s/it]  1%|          | 79/6560 [10:17<14:16:22,  7.93s/it]  1%|          | 80/6560 [10:26<14:28:30,  8.04s/it]                                                      1%|          | 80/6560 [10:26<14:28:30,  8.04s/it]  1%|          | 81/6560 [10:33<13:54:17,  7.73s/it]  1%|‚ñè         | 82/6560 [10:39<13:24:12,  7.45s/it]  1%|‚ñè         | 83/6560 [10:46<12:51:23,  7.15s/it]  1%|‚ñè         | 84/6560 [10:54<13:19:25,  7.41s/it]  1%|‚ñè         | 85/6560 [11:02<13:50:36,  7.70s/it]  1%|‚ñè         | 86/6560 [11:09<13:26:41,  7.48s/it]  1%|‚ñè         | 87/6560 [11:15<12:35:52,  7.01s/it]  1%|‚ñè         | 88/6560 [11:21<11:57:05,  6.65s/it]  1%|‚ñè         | 89/6560 [11:29<12:49:22,  7.13s/it]  1%|‚ñè         | 90/6560 [11:37<13:16:10,  7.38s/it]  1%|‚ñè         | 91/6560 [11:45<13:38:07,  7.59s/it]  1%|‚ñè         | 92/6560 [11:54<14:28:14,  8.05s/it]  1%|‚ñè         | 93/6560 [12:01<13:57:55,  7.77s/it]  1%|‚ñè         | 94/6560 [12:10<14:35:42,  8.13s/it]  1%|‚ñè         | 95/6560 [12:18<14:20:56,  7.99s/it]  1%|‚ñè         | 96/6560 [12:26<14:32:51,  8.10s/it]  1%|‚ñè         | 97/6560 [12:37<15:55:06,  8.87s/it]  1%|‚ñè         | 98/6560 [12:45<15:19:58,  8.54s/it]  2%|‚ñè         | 99/6560 [12:52<14:35:26,  8.13s/it]  2%|‚ñè         | 100/6560 [13:00<14:28:30,  8.07s/it]  2%|‚ñè         | 101/6560 [13:08<14:33:14,  8.11s/it]  2%|‚ñè         | 102/6560 [13:16<14:35:04,  8.13s/it]  2%|‚ñè         | 103/6560 [13:25<14:42:16,  8.20s/it]  2%|‚ñè         | 104/6560 [13:31<13:56:03,  7.77s/it]  2%|‚ñè         | 105/6560 [13:39<13:48:41,  7.70s/it]  2%|‚ñè         | 106/6560 [13:45<13:08:11,  7.33s/it]  2%|‚ñè         | 107/6560 [13:53<13:15:22,  7.40s/it]  2%|‚ñè         | 108/6560 [14:01<13:41:17,  7.64s/it]  2%|‚ñè         | 109/6560 [14:08<13:15:22,  7.40s/it]  2%|‚ñè         | 110/6560 [14:16<13:19:58,  7.44s/it]  2%|‚ñè         | 111/6560 [14:21<12:30:34,  6.98s/it]  2%|‚ñè         | 112/6560 [14:28<12:18:59,  6.88s/it]  2%|‚ñè         | 113/6560 [14:35<12:29:16,  6.97s/it]  2%|‚ñè         | 114/6560 [14:42<12:27:31,  6.96s/it]  2%|‚ñè         | 115/6560 [14:51<13:23:28,  7.48s/it]  2%|‚ñè         | 116/6560 [14:58<13:22:06,  7.47s/it]  2%|‚ñè         | 117/6560 [15:08<14:33:43,  8.14s/it]  2%|‚ñè         | 118/6560 [15:19<16:16:00,  9.09s/it]  2%|‚ñè         | 119/6560 [15:27<15:31:21,  8.68s/it]  2%|‚ñè         | 120/6560 [15:35<15:21:49,  8.59s/it]                                                       2%|‚ñè         | 120/6560 [15:35<15:21:49,  8.59s/it]  2%|‚ñè         | 121/6560 [15:42<14:09:03,  7.91s/it]  2%|‚ñè         | 122/6560 [15:49<13:51:14,  7.75s/it]  2%|‚ñè         | 123/6560 [15:57<14:08:37,  7.91s/it]  2%|‚ñè         | 124/6560 [16:04<13:17:38,  7.44s/it]  2%|‚ñè         | 125/6560 [16:11<13:23:38,  7.49s/it]  2%|‚ñè         | 126/6560 [16:17<12:34:30,  7.04s/it]  2%|‚ñè         | 127/6560 [16:25<13:08:44,  7.36s/it]  2%|‚ñè         | 128/6560 [16:35<14:02:23,  7.86s/it]  2%|‚ñè         | 129/6560 [16:42<13:59:51,  7.84s/it]  2%|‚ñè         | 130/6560 [16:50<13:41:59,  7.67s/it]  2%|‚ñè         | 131/6560 [16:57<13:31:47,  7.58s/it]  2%|‚ñè         | 132/6560 [17:04<13:28:01,  7.54s/it]  2%|‚ñè         | 133/6560 [17:12<13:33:22,  7.59s/it]  2%|‚ñè         | 134/6560 [17:20<13:32:36,  7.59s/it]  2%|‚ñè         | 135/6560 [17:28<13:56:52,  7.82s/it]  2%|‚ñè         | 136/6560 [17:35<13:21:21,  7.48s/it]  2%|‚ñè         | 137/6560 [17:44<14:08:09,  7.92s/it]  2%|‚ñè         | 138/6560 [17:51<13:51:26,  7.77s/it]  2%|‚ñè         | 139/6560 [17:57<12:57:59,  7.27s/it]  2%|‚ñè         | 140/6560 [18:05<13:08:06,  7.37s/it]  2%|‚ñè         | 141/6560 [18:13<13:43:50,  7.70s/it]  2%|‚ñè         | 142/6560 [18:20<12:58:25,  7.28s/it]  2%|‚ñè         | 143/6560 [18:27<13:14:43,  7.43s/it]  2%|‚ñè         | 144/6560 [18:35<13:30:37,  7.58s/it]  2%|‚ñè         | 145/6560 [18:43<13:43:51,  7.71s/it]  2%|‚ñè         | 146/6560 [18:51<13:47:35,  7.74s/it]  2%|‚ñè         | 147/6560 [18:59<13:59:58,  7.86s/it]  2%|‚ñè         | 148/6560 [19:07<14:09:47,  7.95s/it]  2%|‚ñè         | 149/6560 [19:15<14:04:49,  7.91s/it]  2%|‚ñè         | 150/6560 [19:22<13:38:58,  7.67s/it]  2%|‚ñè         | 151/6560 [19:32<14:28:01,  8.13s/it]  2%|‚ñè         | 152/6560 [19:39<14:11:58,  7.98s/it]  2%|‚ñè         | 153/6560 [19:47<13:56:49,  7.84s/it]  2%|‚ñè         | 154/6560 [19:55<14:05:00,  7.91s/it]  2%|‚ñè         | 155/6560 [20:02<13:35:00,  7.63s/it]  2%|‚ñè         | 156/6560 [20:11<14:34:18,  8.19s/it]  2%|‚ñè         | 157/6560 [20:18<14:02:43,  7.90s/it]  2%|‚ñè         | 158/6560 [20:27<14:38:24,  8.23s/it]  2%|‚ñè         | 159/6560 [20:34<13:39:38,  7.68s/it]  2%|‚ñè         | 160/6560 [20:42<13:46:14,  7.75s/it]                                                       2%|‚ñè         | 160/6560 [20:42<13:46:14,  7.75s/it]  2%|‚ñè         | 161/6560 [20:49<13:33:30,  7.63s/it]  2%|‚ñè         | 162/6560 [20:55<12:48:42,  7.21s/it]  2%|‚ñè         | 163/6560 [21:05<14:10:23,  7.98s/it]  2%|‚ñé         | 164/6560 [21:13<14:20:53,  8.08s/it]  3%|‚ñé         | 165/6560 [21:20<13:49:27,  7.78s/it]  3%|‚ñé         | 166/6560 [21:29<14:11:58,  7.99s/it]  3%|‚ñé         | 167/6560 [21:37<14:27:44,  8.14s/it]  3%|‚ñé         | 168/6560 [21:46<14:28:46,  8.15s/it]  3%|‚ñé         | 169/6560 [21:54<14:48:20,  8.34s/it]  3%|‚ñé         | 170/6560 [22:02<14:28:59,  8.16s/it]  3%|‚ñé         | 171/6560 [22:09<13:58:25,  7.87s/it]  3%|‚ñé         | 172/6560 [22:18<14:21:46,  8.09s/it]  3%|‚ñé         | 173/6560 [22:25<13:48:51,  7.79s/it]  3%|‚ñé         | 174/6560 [22:33<13:41:15,  7.72s/it]  3%|‚ñé         | 175/6560 [22:41<14:14:56,  8.03s/it]  3%|‚ñé         | 176/6560 [22:49<13:53:27,  7.83s/it]  3%|‚ñé         | 177/6560 [22:57<14:19:36,  8.08s/it]  3%|‚ñé         | 178/6560 [23:04<13:37:18,  7.68s/it]  3%|‚ñé         | 179/6560 [23:12<13:49:10,  7.80s/it]  3%|‚ñé         | 180/6560 [23:21<14:16:27,  8.05s/it]  3%|‚ñé         | 181/6560 [23:30<14:59:25,  8.46s/it]  3%|‚ñé         | 182/6560 [23:39<14:53:36,  8.41s/it]  3%|‚ñé         | 183/6560 [23:49<16:13:45,  9.16s/it]  3%|‚ñé         | 184/6560 [23:58<15:50:21,  8.94s/it]  3%|‚ñé         | 185/6560 [24:05<15:02:42,  8.50s/it]  3%|‚ñé         | 186/6560 [24:14<15:03:41,  8.51s/it]  3%|‚ñé         | 187/6560 [24:22<14:44:52,  8.33s/it]  3%|‚ñé         | 188/6560 [24:29<13:59:22,  7.90s/it]  3%|‚ñé         | 189/6560 [24:39<15:07:50,  8.55s/it]  3%|‚ñé         | 190/6560 [24:45<13:42:25,  7.75s/it]  3%|‚ñé         | 191/6560 [24:51<12:43:09,  7.19s/it]  3%|‚ñé         | 192/6560 [24:58<12:45:55,  7.22s/it]  3%|‚ñé         | 193/6560 [25:05<12:59:43,  7.35s/it]  3%|‚ñé         | 194/6560 [25:12<12:41:56,  7.18s/it]  3%|‚ñé         | 195/6560 [25:20<12:44:34,  7.21s/it]  3%|‚ñé         | 196/6560 [25:28<13:13:02,  7.48s/it]  3%|‚ñé         | 197/6560 [25:37<13:58:13,  7.90s/it]  3%|‚ñé         | 198/6560 [25:47<15:13:35,  8.62s/it]  3%|‚ñé         | 199/6560 [25:54<14:18:29,  8.10s/it]  3%|‚ñé         | 200/6560 [26:02<14:16:51,  8.08s/it]                                                       3%|‚ñé         | 200/6560 [26:02<14:16:51,  8.08s/it]  3%|‚ñé         | 201/6560 [26:10<14:15:51,  8.08s/it]  3%|‚ñé         | 202/6560 [26:20<15:12:00,  8.61s/it]  3%|‚ñé         | 203/6560 [26:28<15:18:44,  8.67s/it]  3%|‚ñé         | 204/6560 [26:35<14:01:13,  7.94s/it]  3%|‚ñé         | 205/6560 [26:44<14:57:17,  8.47s/it]  3%|‚ñé         | 206/6560 [26:55<15:55:51,  9.03s/it]  3%|‚ñé         | 207/6560 [27:04<15:54:12,  9.01s/it]  3%|‚ñé         | 208/6560 [27:13<15:50:06,  8.97s/it]  3%|‚ñé         | 209/6560 [27:22<16:10:09,  9.17s/it]  3%|‚ñé         | 210/6560 [27:31<15:59:56,  9.07s/it]  3%|‚ñé         | 211/6560 [27:39<15:13:36,  8.63s/it]  3%|‚ñé         | 212/6560 [27:48<15:33:30,  8.82s/it]  3%|‚ñé         | 213/6560 [27:55<14:49:01,  8.40s/it]  3%|‚ñé         | 214/6560 [28:04<15:08:06,  8.59s/it]  3%|‚ñé         | 215/6560 [28:13<15:14:39,  8.65s/it]  3%|‚ñé         | 216/6560 [28:21<14:46:23,  8.38s/it]  3%|‚ñé         | 217/6560 [28:29<14:34:44,  8.27s/it]  3%|‚ñé         | 218/6560 [28:36<14:02:50,  7.97s/it]  3%|‚ñé         | 219/6560 [28:44<14:08:47,  8.03s/it]  3%|‚ñé         | 220/6560 [28:52<13:38:46,  7.75s/it]  3%|‚ñé         | 221/6560 [29:00<13:51:02,  7.87s/it]  3%|‚ñé         | 222/6560 [29:09<14:22:23,  8.16s/it]  3%|‚ñé         | 223/6560 [29:16<14:12:32,  8.07s/it]  3%|‚ñé         | 224/6560 [29:22<12:57:49,  7.37s/it]  3%|‚ñé         | 225/6560 [29:29<12:33:03,  7.13s/it]  3%|‚ñé         | 226/6560 [29:36<12:52:41,  7.32s/it]  3%|‚ñé         | 227/6560 [29:43<12:18:58,  7.00s/it]  3%|‚ñé         | 228/6560 [29:49<12:01:59,  6.84s/it]  3%|‚ñé         | 229/6560 [29:56<11:47:57,  6.71s/it]  4%|‚ñé         | 230/6560 [30:02<11:47:37,  6.71s/it]  4%|‚ñé         | 231/6560 [30:11<12:51:37,  7.32s/it]  4%|‚ñé         | 232/6560 [30:18<12:33:23,  7.14s/it]  4%|‚ñé         | 233/6560 [30:26<13:05:49,  7.45s/it]  4%|‚ñé         | 234/6560 [30:33<12:47:34,  7.28s/it]  4%|‚ñé         | 235/6560 [30:40<12:49:16,  7.30s/it]  4%|‚ñé         | 236/6560 [30:49<13:29:35,  7.68s/it]  4%|‚ñé         | 237/6560 [30:56<13:21:37,  7.61s/it]  4%|‚ñé         | 238/6560 [31:04<13:43:46,  7.82s/it]  4%|‚ñé         | 239/6560 [31:12<13:25:46,  7.65s/it]  4%|‚ñé         | 240/6560 [31:20<13:46:17,  7.84s/it]                                                       4%|‚ñé         | 240/6560 [31:20<13:46:17,  7.84s/it]  4%|‚ñé         | 241/6560 [31:27<13:27:03,  7.66s/it]  4%|‚ñé         | 242/6560 [31:35<13:43:47,  7.82s/it]  4%|‚ñé         | 243/6560 [31:43<13:31:43,  7.71s/it]  4%|‚ñé         | 244/6560 [31:52<14:26:00,  8.23s/it]  4%|‚ñé         | 245/6560 [32:01<14:29:19,  8.26s/it]  4%|‚ñç         | 246/6560 [32:11<15:34:22,  8.88s/it]  4%|‚ñç         | 247/6560 [32:18<14:46:31,  8.43s/it]  4%|‚ñç         | 248/6560 [32:26<14:11:26,  8.09s/it]  4%|‚ñç         | 249/6560 [32:33<13:54:59,  7.94s/it]  4%|‚ñç         | 250/6560 [32:42<14:18:03,  8.16s/it]  4%|‚ñç         | 251/6560 [32:49<13:36:49,  7.77s/it]  4%|‚ñç         | 252/6560 [32:57<13:52:47,  7.92s/it]  4%|‚ñç         | 253/6560 [33:04<13:24:25,  7.65s/it]  4%|‚ñç         | 254/6560 [33:11<13:13:38,  7.55s/it]  4%|‚ñç         | 255/6560 [33:20<13:38:27,  7.79s/it]  4%|‚ñç         | 256/6560 [33:29<14:28:41,  8.27s/it]  4%|‚ñç         | 257/6560 [33:39<15:24:06,  8.80s/it]  4%|‚ñç         | 258/6560 [33:50<16:26:03,  9.39s/it]  4%|‚ñç         | 259/6560 [33:56<14:47:33,  8.45s/it]  4%|‚ñç         | 260/6560 [34:03<13:53:11,  7.94s/it]  4%|‚ñç         | 261/6560 [34:13<15:12:09,  8.69s/it]  4%|‚ñç         | 262/6560 [34:23<15:39:05,  8.95s/it]  4%|‚ñç         | 263/6560 [34:32<15:29:00,  8.85s/it]  4%|‚ñç         | 264/6560 [34:39<14:42:51,  8.41s/it]  4%|‚ñç         | 265/6560 [34:47<14:30:16,  8.29s/it]  4%|‚ñç         | 266/6560 [34:53<13:31:18,  7.73s/it]  4%|‚ñç         | 267/6560 [35:01<13:18:26,  7.61s/it]  4%|‚ñç         | 268/6560 [35:08<12:57:17,  7.41s/it]  4%|‚ñç         | 269/6560 [35:16<13:30:37,  7.73s/it]  4%|‚ñç         | 270/6560 [35:24<13:29:42,  7.72s/it]  4%|‚ñç         | 271/6560 [35:33<14:04:24,  8.06s/it]  4%|‚ñç         | 272/6560 [35:40<13:53:10,  7.95s/it]  4%|‚ñç         | 273/6560 [35:48<13:31:17,  7.74s/it]  4%|‚ñç         | 274/6560 [35:54<13:00:55,  7.45s/it]  4%|‚ñç         | 275/6560 [36:01<12:42:36,  7.28s/it]  4%|‚ñç         | 276/6560 [36:09<13:01:18,  7.46s/it]  4%|‚ñç         | 277/6560 [36:17<13:12:03,  7.56s/it]  4%|‚ñç         | 278/6560 [36:25<13:20:15,  7.64s/it]  4%|‚ñç         | 279/6560 [36:33<13:45:28,  7.89s/it]  4%|‚ñç         | 280/6560 [36:41<13:39:01,  7.83s/it]                                                       4%|‚ñç         | 280/6560 [36:41<13:39:01,  7.83s/it]  4%|‚ñç         | 281/6560 [36:48<13:13:46,  7.58s/it]  4%|‚ñç         | 282/6560 [36:56<13:14:09,  7.59s/it]  4%|‚ñç         | 283/6560 [37:03<13:09:16,  7.54s/it]  4%|‚ñç         | 284/6560 [37:10<12:47:15,  7.34s/it]  4%|‚ñç         | 285/6560 [37:15<11:46:06,  6.75s/it]  4%|‚ñç         | 286/6560 [37:23<12:03:10,  6.92s/it]  4%|‚ñç         | 287/6560 [37:31<12:56:21,  7.43s/it]  4%|‚ñç         | 288/6560 [37:39<13:09:18,  7.55s/it]  4%|‚ñç         | 289/6560 [37:49<14:40:44,  8.43s/it]  4%|‚ñç         | 290/6560 [37:58<14:31:39,  8.34s/it]  4%|‚ñç         | 291/6560 [38:06<14:39:37,  8.42s/it]  4%|‚ñç         | 292/6560 [38:15<14:36:18,  8.39s/it]  4%|‚ñç         | 293/6560 [38:21<13:40:08,  7.85s/it]  4%|‚ñç         | 294/6560 [38:31<14:29:20,  8.32s/it]  4%|‚ñç         | 295/6560 [38:41<15:34:15,  8.95s/it]  5%|‚ñç         | 296/6560 [38:50<15:27:40,  8.89s/it]  5%|‚ñç         | 297/6560 [38:58<15:13:05,  8.75s/it]  5%|‚ñç         | 298/6560 [39:05<14:22:32,  8.26s/it]  5%|‚ñç         | 299/6560 [39:13<14:16:01,  8.20s/it]  5%|‚ñç         | 300/6560 [39:21<13:53:40,  7.99s/it]
  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|‚ñè         | 2/125 [00:03<04:02,  1.97s/it][A
  2%|‚ñè         | 3/125 [00:07<05:30,  2.71s/it][A
  3%|‚ñé         | 4/125 [00:10<05:28,  2.72s/it][A
  4%|‚ñç         | 5/125 [00:12<05:16,  2.64s/it][A
  5%|‚ñç         | 6/125 [00:15<04:59,  2.52s/it][A
  6%|‚ñå         | 7/125 [00:17<04:56,  2.51s/it][A
  6%|‚ñã         | 8/125 [00:20<04:48,  2.46s/it][A
  7%|‚ñã         | 9/125 [00:21<04:10,  2.16s/it][A
  8%|‚ñä         | 10/125 [00:23<03:58,  2.08s/it][A
  9%|‚ñâ         | 11/125 [00:25<03:54,  2.06s/it][A
 10%|‚ñâ         | 12/125 [00:27<03:57,  2.11s/it][A
 10%|‚ñà         | 13/125 [00:30<04:04,  2.19s/it][A
 11%|‚ñà         | 14/125 [00:31<03:47,  2.05s/it][A
 12%|‚ñà‚ñè        | 15/125 [00:33<03:33,  1.94s/it][A
 13%|‚ñà‚ñé        | 16/125 [00:35<03:27,  1.90s/it][A
 14%|‚ñà‚ñé        | 17/125 [00:36<03:14,  1.80s/it][A
 14%|‚ñà‚ñç        | 18/125 [00:38<03:21,  1.88s/it][A
 15%|‚ñà‚ñå        | 19/125 [00:40<02:58,  1.68s/it][A
 16%|‚ñà‚ñå        | 20/125 [00:41<03:00,  1.72s/it][A
 17%|‚ñà‚ñã        | 21/125 [00:43<02:50,  1.64s/it][A
 18%|‚ñà‚ñä        | 22/125 [00:45<03:11,  1.86s/it][A
 18%|‚ñà‚ñä        | 23/125 [00:47<02:57,  1.74s/it][A
 19%|‚ñà‚ñâ        | 24/125 [00:48<02:51,  1.70s/it][A
 20%|‚ñà‚ñà        | 25/125 [00:51<03:16,  1.96s/it][A
 21%|‚ñà‚ñà        | 26/125 [00:54<03:37,  2.19s/it][A
 22%|‚ñà‚ñà‚ñè       | 27/125 [00:56<03:40,  2.25s/it][A
 22%|‚ñà‚ñà‚ñè       | 28/125 [00:59<03:56,  2.44s/it][A
 23%|‚ñà‚ñà‚ñé       | 29/125 [01:01<03:49,  2.39s/it][A
 24%|‚ñà‚ñà‚ñç       | 30/125 [01:03<03:22,  2.13s/it][A
 25%|‚ñà‚ñà‚ñç       | 31/125 [01:05<03:13,  2.06s/it][A
 26%|‚ñà‚ñà‚ñå       | 32/125 [01:06<03:05,  2.00s/it][A
 26%|‚ñà‚ñà‚ñã       | 33/125 [01:09<03:10,  2.07s/it][A
 27%|‚ñà‚ñà‚ñã       | 34/125 [01:11<03:16,  2.15s/it][A
 28%|‚ñà‚ñà‚ñä       | 35/125 [01:14<03:32,  2.37s/it][A
 29%|‚ñà‚ñà‚ñâ       | 36/125 [01:16<03:22,  2.28s/it][A
 30%|‚ñà‚ñà‚ñâ       | 37/125 [01:19<03:32,  2.42s/it][A
 30%|‚ñà‚ñà‚ñà       | 38/125 [01:21<03:35,  2.47s/it][A
 31%|‚ñà‚ñà‚ñà       | 39/125 [01:24<03:44,  2.61s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 40/125 [01:26<03:15,  2.30s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 41/125 [01:28<03:06,  2.22s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 42/125 [01:29<02:46,  2.01s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [01:31<02:41,  1.96s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 44/125 [01:34<02:57,  2.19s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 45/125 [01:35<02:40,  2.01s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 46/125 [01:39<03:17,  2.50s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 47/125 [01:42<03:12,  2.47s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 48/125 [01:44<03:13,  2.51s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 49/125 [01:48<03:32,  2.80s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 50/125 [01:49<03:02,  2.44s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 51/125 [01:51<02:54,  2.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 52/125 [01:53<02:42,  2.22s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 53/125 [01:56<02:54,  2.42s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [01:58<02:30,  2.11s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 55/125 [01:59<02:23,  2.05s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 56/125 [02:01<02:18,  2.01s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 57/125 [02:05<02:57,  2.61s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 58/125 [02:07<02:39,  2.38s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 59/125 [02:09<02:21,  2.15s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60/125 [02:11<02:14,  2.07s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 61/125 [02:13<02:22,  2.23s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 62/125 [02:15<02:06,  2.00s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 63/125 [02:17<02:09,  2.09s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 64/125 [02:19<02:03,  2.02s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [02:21<02:07,  2.12s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 66/125 [02:24<02:19,  2.37s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 67/125 [02:26<02:03,  2.14s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 68/125 [02:29<02:13,  2.34s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 69/125 [02:30<02:01,  2.17s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 70/125 [02:33<02:10,  2.37s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 71/125 [02:35<01:57,  2.18s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 72/125 [02:37<01:50,  2.09s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 73/125 [02:39<01:45,  2.02s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 74/125 [02:40<01:36,  1.90s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75/125 [02:43<01:42,  2.05s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [02:46<01:50,  2.26s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 77/125 [02:47<01:38,  2.04s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 78/125 [02:50<01:47,  2.29s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 79/125 [02:53<01:52,  2.45s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 80/125 [02:55<01:42,  2.27s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 81/125 [02:57<01:40,  2.28s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 82/125 [03:01<01:58,  2.75s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 83/125 [03:02<01:42,  2.44s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 84/125 [03:05<01:43,  2.53s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [03:07<01:37,  2.44s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 86/125 [03:10<01:34,  2.41s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [03:13<01:39,  2.61s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 88/125 [03:15<01:31,  2.48s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 89/125 [03:18<01:32,  2.58s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90/125 [03:20<01:24,  2.41s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 91/125 [03:22<01:17,  2.29s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 92/125 [03:24<01:13,  2.23s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 93/125 [03:26<01:11,  2.25s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 94/125 [03:28<01:08,  2.20s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 95/125 [03:30<00:59,  1.98s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 96/125 [03:32<00:55,  1.93s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 97/125 [03:33<00:49,  1.77s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [03:35<00:48,  1.81s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 99/125 [03:37<00:47,  1.84s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 100/125 [03:39<00:50,  2.01s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 101/125 [03:42<00:51,  2.15s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 102/125 [03:44<00:49,  2.16s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 103/125 [03:46<00:44,  2.03s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 104/125 [03:47<00:41,  1.98s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105/125 [03:52<00:53,  2.69s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 106/125 [03:55<00:54,  2.88s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 107/125 [03:58<00:50,  2.79s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 108/125 [04:01<00:47,  2.80s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [04:02<00:38,  2.40s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 110/125 [04:05<00:36,  2.43s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 111/125 [04:06<00:30,  2.15s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [04:08<00:28,  2.17s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 113/125 [04:10<00:24,  2.06s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 114/125 [04:12<00:20,  1.90s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 115/125 [04:14<00:21,  2.16s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 116/125 [04:17<00:20,  2.28s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 117/125 [04:19<00:17,  2.22s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 118/125 [04:21<00:14,  2.09s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 119/125 [04:23<00:13,  2.24s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [04:25<00:10,  2.13s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 121/125 [04:28<00:09,  2.33s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 122/125 [04:32<00:08,  2.86s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 123/125 [04:33<00:04,  2.37s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 124/125 [04:36<00:02,  2.48s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.40s/it][A                                                     
                                                 [A  5%|‚ñç         | 300/6560 [44:02<13:53:40,  7.99s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.40s/it][A
                                                 [A  5%|‚ñç         | 301/6560 [44:38<175:11:27, 100.76s/it]  5%|‚ñç         | 302/6560 [44:47<127:20:06, 73.25s/it]   5%|‚ñç         | 303/6560 [44:57<94:07:22, 54.15s/it]   5%|‚ñç         | 304/6560 [45:05<70:02:51, 40.31s/it]  5%|‚ñç         | 305/6560 [45:13<53:21:20, 30.71s/it]  5%|‚ñç         | 306/6560 [45:22<41:48:33, 24.07s/it]  5%|‚ñç         | 307/6560 [45:28<32:31:17, 18.72s/it]  5%|‚ñç         | 308/6560 [45:35<26:43:45, 15.39s/it]  5%|‚ñç         | 309/6560 [45:44<22:55:47, 13.21s/it]  5%|‚ñç         | 310/6560 [45:50<19:16:55, 11.11s/it]  5%|‚ñç         | 311/6560 [45:57<17:23:17, 10.02s/it]  5%|‚ñç         | 312/6560 [46:04<15:32:14,  8.95s/it]  5%|‚ñç         | 313/6560 [46:11<14:29:46,  8.35s/it]  5%|‚ñç         | 314/6560 [46:19<14:23:28,  8.29s/it]  5%|‚ñç         | 315/6560 [46:26<14:01:34,  8.09s/it]  5%|‚ñç         | 316/6560 [46:34<13:50:45,  7.98s/it]  5%|‚ñç         | 317/6560 [46:41<13:30:10,  7.79s/it]  5%|‚ñç         | 318/6560 [46:49<13:35:18,  7.84s/it]  5%|‚ñç         | 319/6560 [46:57<13:15:35,  7.65s/it]  5%|‚ñç         | 320/6560 [47:04<12:57:06,  7.47s/it]                                                       5%|‚ñç         | 320/6560 [47:04<12:57:06,  7.47s/it]  5%|‚ñç         | 321/6560 [47:11<12:51:00,  7.41s/it]  5%|‚ñç         | 322/6560 [47:19<13:05:27,  7.55s/it]  5%|‚ñç         | 323/6560 [47:25<12:31:40,  7.23s/it]  5%|‚ñç         | 324/6560 [47:34<13:05:17,  7.56s/it]  5%|‚ñç         | 325/6560 [47:41<13:13:22,  7.63s/it]  5%|‚ñç         | 326/6560 [47:48<12:49:43,  7.41s/it]  5%|‚ñç         | 327/6560 [47:55<12:17:35,  7.10s/it]  5%|‚ñå         | 328/6560 [48:03<12:43:23,  7.35s/it]  5%|‚ñå         | 329/6560 [48:10<12:45:33,  7.37s/it]  5%|‚ñå         | 330/6560 [48:18<12:55:09,  7.47s/it]  5%|‚ñå         | 331/6560 [48:25<12:50:43,  7.42s/it]  5%|‚ñå         | 332/6560 [48:34<13:44:45,  7.95s/it]  5%|‚ñå         | 333/6560 [48:43<14:22:34,  8.31s/it]  5%|‚ñå         | 334/6560 [48:52<14:43:09,  8.51s/it]  5%|‚ñå         | 335/6560 [48:59<13:49:14,  7.99s/it]  5%|‚ñå         | 336/6560 [49:07<13:57:25,  8.07s/it]  5%|‚ñå         | 337/6560 [49:16<14:08:52,  8.18s/it]  5%|‚ñå         | 338/6560 [49:25<14:22:42,  8.32s/it]  5%|‚ñå         | 339/6560 [49:32<13:59:03,  8.09s/it]  5%|‚ñå         | 340/6560 [49:38<12:59:04,  7.52s/it]  5%|‚ñå         | 341/6560 [49:44<12:08:37,  7.03s/it]  5%|‚ñå         | 342/6560 [49:52<12:45:27,  7.39s/it]  5%|‚ñå         | 343/6560 [50:02<13:58:41,  8.09s/it]  5%|‚ñå         | 344/6560 [50:10<13:49:27,  8.01s/it]  5%|‚ñå         | 345/6560 [50:16<12:51:16,  7.45s/it]  5%|‚ñå         | 346/6560 [50:24<12:58:49,  7.52s/it]  5%|‚ñå         | 347/6560 [50:29<12:01:58,  6.97s/it]  5%|‚ñå         | 348/6560 [50:39<13:30:08,  7.83s/it]  5%|‚ñå         | 349/6560 [50:48<13:54:10,  8.06s/it]  5%|‚ñå         | 350/6560 [50:59<15:25:14,  8.94s/it]  5%|‚ñå         | 351/6560 [51:07<14:54:02,  8.64s/it]  5%|‚ñå         | 352/6560 [51:13<13:42:20,  7.95s/it]  5%|‚ñå         | 353/6560 [51:21<13:43:39,  7.96s/it]  5%|‚ñå         | 354/6560 [51:30<14:14:27,  8.26s/it]  5%|‚ñå         | 355/6560 [51:39<14:30:59,  8.42s/it]  5%|‚ñå         | 356/6560 [51:47<14:11:03,  8.23s/it]  5%|‚ñå         | 357/6560 [51:55<14:02:21,  8.15s/it]  5%|‚ñå         | 358/6560 [52:02<13:43:03,  7.96s/it]  5%|‚ñå         | 359/6560 [52:10<13:54:25,  8.07s/it]  5%|‚ñå         | 360/6560 [52:17<13:08:57,  7.64s/it]                                                       5%|‚ñå         | 360/6560 [52:17<13:08:57,  7.64s/it]  6%|‚ñå         | 361/6560 [52:24<12:45:53,  7.41s/it]  6%|‚ñå         | 362/6560 [52:31<12:35:26,  7.31s/it]  6%|‚ñå         | 363/6560 [52:38<12:23:20,  7.20s/it]  6%|‚ñå         | 364/6560 [52:46<12:46:02,  7.42s/it]  6%|‚ñå         | 365/6560 [52:54<13:01:51,  7.57s/it]  6%|‚ñå         | 366/6560 [53:01<12:44:32,  7.41s/it]  6%|‚ñå         | 367/6560 [53:09<13:01:03,  7.57s/it]  6%|‚ñå         | 368/6560 [53:16<13:01:08,  7.57s/it]  6%|‚ñå         | 369/6560 [53:26<13:48:15,  8.03s/it]  6%|‚ñå         | 370/6560 [53:31<12:39:19,  7.36s/it]  6%|‚ñå         | 371/6560 [53:38<12:05:26,  7.03s/it]  6%|‚ñå         | 372/6560 [53:45<12:02:00,  7.00s/it]  6%|‚ñå         | 373/6560 [53:52<12:08:31,  7.07s/it]  6%|‚ñå         | 374/6560 [53:58<11:56:39,  6.95s/it]  6%|‚ñå         | 375/6560 [54:07<12:41:49,  7.39s/it]  6%|‚ñå         | 376/6560 [54:14<12:22:38,  7.21s/it]  6%|‚ñå         | 377/6560 [54:20<12:00:01,  6.99s/it]  6%|‚ñå         | 378/6560 [54:28<12:40:48,  7.38s/it]  6%|‚ñå         | 379/6560 [54:37<13:12:03,  7.69s/it]  6%|‚ñå         | 380/6560 [54:44<12:46:48,  7.44s/it]  6%|‚ñå         | 381/6560 [54:54<14:05:27,  8.21s/it]  6%|‚ñå         | 382/6560 [55:02<13:57:11,  8.13s/it]  6%|‚ñå         | 383/6560 [55:09<13:44:20,  8.01s/it]  6%|‚ñå         | 384/6560 [55:17<13:24:30,  7.82s/it]  6%|‚ñå         | 385/6560 [55:23<12:39:17,  7.38s/it]  6%|‚ñå         | 386/6560 [55:30<12:41:19,  7.40s/it]  6%|‚ñå         | 387/6560 [55:39<13:15:54,  7.74s/it]  6%|‚ñå         | 388/6560 [55:47<13:39:01,  7.96s/it]  6%|‚ñå         | 389/6560 [55:56<13:41:57,  7.99s/it]  6%|‚ñå         | 390/6560 [56:04<13:40:16,  7.98s/it]  6%|‚ñå         | 391/6560 [56:12<14:01:24,  8.18s/it]  6%|‚ñå         | 392/6560 [56:20<13:54:29,  8.12s/it]  6%|‚ñå         | 393/6560 [56:31<15:31:18,  9.06s/it]  6%|‚ñå         | 394/6560 [56:40<15:15:01,  8.90s/it]  6%|‚ñå         | 395/6560 [56:49<15:10:34,  8.86s/it]  6%|‚ñå         | 396/6560 [56:55<13:49:20,  8.07s/it]  6%|‚ñå         | 397/6560 [57:05<14:43:32,  8.60s/it]  6%|‚ñå         | 398/6560 [57:12<13:53:34,  8.12s/it]  6%|‚ñå         | 399/6560 [57:20<14:02:25,  8.20s/it]  6%|‚ñå         | 400/6560 [57:28<13:43:59,  8.03s/it]                                                       6%|‚ñå         | 400/6560 [57:28<13:43:59,  8.03s/it]  6%|‚ñå         | 401/6560 [57:34<12:57:58,  7.58s/it]  6%|‚ñå         | 402/6560 [57:42<13:08:38,  7.68s/it]  6%|‚ñå         | 403/6560 [57:50<12:59:22,  7.60s/it]  6%|‚ñå         | 404/6560 [57:56<12:33:01,  7.34s/it]  6%|‚ñå         | 405/6560 [58:03<12:26:42,  7.28s/it]  6%|‚ñå         | 406/6560 [58:10<12:14:17,  7.16s/it]  6%|‚ñå         | 407/6560 [58:17<12:09:24,  7.11s/it]  6%|‚ñå         | 408/6560 [58:26<12:53:41,  7.55s/it]  6%|‚ñå         | 409/6560 [58:34<13:01:04,  7.62s/it]  6%|‚ñã         | 410/6560 [58:40<12:28:06,  7.30s/it]  6%|‚ñã         | 411/6560 [58:48<12:31:46,  7.34s/it]  6%|‚ñã         | 412/6560 [58:54<12:14:36,  7.17s/it]  6%|‚ñã         | 413/6560 [59:03<12:43:21,  7.45s/it]  6%|‚ñã         | 414/6560 [59:11<13:07:39,  7.69s/it]  6%|‚ñã         | 415/6560 [59:19<13:06:58,  7.68s/it]  6%|‚ñã         | 416/6560 [59:27<13:22:31,  7.84s/it]  6%|‚ñã         | 417/6560 [59:34<12:59:46,  7.62s/it]  6%|‚ñã         | 418/6560 [59:41<12:43:01,  7.45s/it]  6%|‚ñã         | 419/6560 [59:49<13:01:08,  7.63s/it]  6%|‚ñã         | 420/6560 [59:57<13:25:17,  7.87s/it]  6%|‚ñã         | 421/6560 [1:00:05<13:28:38,  7.90s/it]  6%|‚ñã         | 422/6560 [1:00:15<14:13:44,  8.35s/it]  6%|‚ñã         | 423/6560 [1:00:24<14:35:36,  8.56s/it]  6%|‚ñã         | 424/6560 [1:00:31<14:00:10,  8.22s/it]  6%|‚ñã         | 425/6560 [1:00:40<14:20:51,  8.42s/it]  6%|‚ñã         | 426/6560 [1:00:46<13:18:27,  7.81s/it]  7%|‚ñã         | 427/6560 [1:00:55<13:53:59,  8.16s/it]  7%|‚ñã         | 428/6560 [1:01:04<13:51:56,  8.14s/it]  7%|‚ñã         | 429/6560 [1:01:13<14:39:39,  8.61s/it]  7%|‚ñã         | 430/6560 [1:01:21<14:13:35,  8.35s/it]  7%|‚ñã         | 431/6560 [1:01:30<14:24:07,  8.46s/it]  7%|‚ñã         | 432/6560 [1:01:37<13:56:11,  8.19s/it]  7%|‚ñã         | 433/6560 [1:01:47<14:39:04,  8.61s/it]  7%|‚ñã         | 434/6560 [1:01:55<14:22:10,  8.44s/it]  7%|‚ñã         | 435/6560 [1:02:02<13:33:04,  7.96s/it]  7%|‚ñã         | 436/6560 [1:02:11<14:16:35,  8.39s/it]  7%|‚ñã         | 437/6560 [1:02:20<14:15:55,  8.39s/it]  7%|‚ñã         | 438/6560 [1:02:28<14:04:40,  8.28s/it]  7%|‚ñã         | 439/6560 [1:02:34<12:59:25,  7.64s/it]  7%|‚ñã         | 440/6560 [1:02:42<13:22:52,  7.87s/it]                                                         7%|‚ñã         | 440/6560 [1:02:42<13:22:52,  7.87s/it]  7%|‚ñã         | 441/6560 [1:02:52<14:14:05,  8.37s/it]  7%|‚ñã         | 442/6560 [1:02:58<13:26:32,  7.91s/it]  7%|‚ñã         | 443/6560 [1:03:04<12:20:11,  7.26s/it]  7%|‚ñã         | 444/6560 [1:03:11<12:06:07,  7.12s/it]  7%|‚ñã         | 445/6560 [1:03:18<12:11:10,  7.17s/it]  7%|‚ñã         | 446/6560 [1:03:28<13:34:12,  7.99s/it]  7%|‚ñã         | 447/6560 [1:03:37<14:05:57,  8.30s/it]  7%|‚ñã         | 448/6560 [1:03:44<13:26:17,  7.92s/it]  7%|‚ñã         | 449/6560 [1:03:53<13:50:30,  8.15s/it]  7%|‚ñã         | 450/6560 [1:04:02<14:30:33,  8.55s/it]  7%|‚ñã         | 451/6560 [1:04:10<14:14:38,  8.39s/it]  7%|‚ñã         | 452/6560 [1:04:17<13:25:10,  7.91s/it]  7%|‚ñã         | 453/6560 [1:04:26<13:45:50,  8.11s/it]  7%|‚ñã         | 454/6560 [1:04:33<13:12:54,  7.79s/it]  7%|‚ñã         | 455/6560 [1:04:41<13:11:06,  7.78s/it]  7%|‚ñã         | 456/6560 [1:04:49<13:43:34,  8.10s/it]  7%|‚ñã         | 457/6560 [1:05:00<14:45:35,  8.71s/it]  7%|‚ñã         | 458/6560 [1:05:06<13:37:17,  8.04s/it]  7%|‚ñã         | 459/6560 [1:05:16<14:26:05,  8.52s/it]  7%|‚ñã         | 460/6560 [1:05:24<14:05:04,  8.31s/it]  7%|‚ñã         | 461/6560 [1:05:31<13:35:38,  8.02s/it]  7%|‚ñã         | 462/6560 [1:05:41<14:35:26,  8.61s/it]  7%|‚ñã         | 463/6560 [1:05:48<13:38:35,  8.06s/it]  7%|‚ñã         | 464/6560 [1:05:55<13:16:38,  7.84s/it]  7%|‚ñã         | 465/6560 [1:06:04<13:58:11,  8.25s/it]  7%|‚ñã         | 466/6560 [1:06:12<13:37:59,  8.05s/it]  7%|‚ñã         | 467/6560 [1:06:19<13:00:15,  7.68s/it]  7%|‚ñã         | 468/6560 [1:06:25<12:24:22,  7.33s/it]  7%|‚ñã         | 469/6560 [1:06:31<11:43:45,  6.93s/it]  7%|‚ñã         | 470/6560 [1:06:38<11:56:16,  7.06s/it]  7%|‚ñã         | 471/6560 [1:06:45<11:38:37,  6.88s/it]  7%|‚ñã         | 472/6560 [1:06:53<12:02:05,  7.12s/it]  7%|‚ñã         | 473/6560 [1:07:01<12:30:08,  7.39s/it]  7%|‚ñã         | 474/6560 [1:07:10<13:16:17,  7.85s/it]  7%|‚ñã         | 475/6560 [1:07:19<13:56:30,  8.25s/it]  7%|‚ñã         | 476/6560 [1:07:28<14:14:45,  8.43s/it]  7%|‚ñã         | 477/6560 [1:07:35<13:48:34,  8.17s/it]  7%|‚ñã         | 478/6560 [1:07:42<13:18:28,  7.88s/it]  7%|‚ñã         | 479/6560 [1:07:51<13:45:51,  8.15s/it]  7%|‚ñã         | 480/6560 [1:07:57<12:49:25,  7.59s/it]                                                         7%|‚ñã         | 480/6560 [1:07:57<12:49:25,  7.59s/it]  7%|‚ñã         | 481/6560 [1:08:04<12:15:00,  7.25s/it]  7%|‚ñã         | 482/6560 [1:08:12<12:29:35,  7.40s/it]  7%|‚ñã         | 483/6560 [1:08:19<12:35:49,  7.46s/it]  7%|‚ñã         | 484/6560 [1:08:27<12:49:37,  7.60s/it]  7%|‚ñã         | 485/6560 [1:08:34<12:18:44,  7.30s/it]  7%|‚ñã         | 486/6560 [1:08:41<12:11:16,  7.22s/it]  7%|‚ñã         | 487/6560 [1:08:49<12:38:29,  7.49s/it]  7%|‚ñã         | 488/6560 [1:08:55<12:04:25,  7.16s/it]  7%|‚ñã         | 489/6560 [1:09:03<12:32:33,  7.44s/it]  7%|‚ñã         | 490/6560 [1:09:10<12:15:45,  7.27s/it]  7%|‚ñã         | 491/6560 [1:09:19<12:49:22,  7.61s/it]  8%|‚ñä         | 492/6560 [1:09:26<12:37:58,  7.49s/it]  8%|‚ñä         | 493/6560 [1:09:35<13:15:32,  7.87s/it]  8%|‚ñä         | 494/6560 [1:09:43<13:38:59,  8.10s/it]  8%|‚ñä         | 495/6560 [1:09:52<14:01:08,  8.32s/it]  8%|‚ñä         | 496/6560 [1:10:01<14:28:21,  8.59s/it]  8%|‚ñä         | 497/6560 [1:10:08<13:37:02,  8.09s/it]  8%|‚ñä         | 498/6560 [1:10:15<13:08:55,  7.81s/it]  8%|‚ñä         | 499/6560 [1:10:24<13:22:43,  7.95s/it]  8%|‚ñä         | 500/6560 [1:10:30<12:32:32,  7.45s/it]  8%|‚ñä         | 501/6560 [1:10:40<13:55:11,  8.27s/it]  8%|‚ñä         | 502/6560 [1:10:49<14:23:01,  8.55s/it]  8%|‚ñä         | 503/6560 [1:10:58<14:11:59,  8.44s/it]  8%|‚ñä         | 504/6560 [1:11:05<13:56:30,  8.29s/it]  8%|‚ñä         | 505/6560 [1:11:11<12:47:13,  7.60s/it]  8%|‚ñä         | 506/6560 [1:11:19<12:49:57,  7.63s/it]  8%|‚ñä         | 507/6560 [1:11:26<12:38:45,  7.52s/it]  8%|‚ñä         | 508/6560 [1:11:35<13:19:54,  7.93s/it]  8%|‚ñä         | 509/6560 [1:11:44<13:41:43,  8.15s/it]  8%|‚ñä         | 510/6560 [1:11:51<12:56:25,  7.70s/it]  8%|‚ñä         | 511/6560 [1:11:59<13:17:17,  7.91s/it]  8%|‚ñä         | 512/6560 [1:12:06<13:02:23,  7.76s/it]  8%|‚ñä         | 513/6560 [1:12:15<13:37:25,  8.11s/it]  8%|‚ñä         | 514/6560 [1:12:23<13:26:53,  8.01s/it]  8%|‚ñä         | 515/6560 [1:12:31<13:19:58,  7.94s/it]  8%|‚ñä         | 516/6560 [1:12:41<14:28:19,  8.62s/it]  8%|‚ñä         | 517/6560 [1:12:49<14:00:43,  8.35s/it]  8%|‚ñä         | 518/6560 [1:12:55<13:05:45,  7.80s/it]  8%|‚ñä         | 519/6560 [1:13:02<12:38:14,  7.53s/it]  8%|‚ñä         | 520/6560 [1:13:09<12:11:25,  7.27s/it]                                                         8%|‚ñä         | 520/6560 [1:13:09<12:11:25,  7.27s/it]  8%|‚ñä         | 521/6560 [1:13:18<13:02:08,  7.77s/it]  8%|‚ñä         | 522/6560 [1:13:26<12:59:08,  7.74s/it]  8%|‚ñä         | 523/6560 [1:13:34<13:15:57,  7.91s/it]  8%|‚ñä         | 524/6560 [1:13:42<13:36:54,  8.12s/it]  8%|‚ñä         | 525/6560 [1:13:52<14:20:25,  8.55s/it]  8%|‚ñä         | 526/6560 [1:14:00<14:18:13,  8.53s/it]  8%|‚ñä         | 527/6560 [1:14:07<13:22:26,  7.98s/it]  8%|‚ñä         | 528/6560 [1:14:16<13:40:22,  8.16s/it]  8%|‚ñä         | 529/6560 [1:14:23<13:14:18,  7.90s/it]  8%|‚ñä         | 530/6560 [1:14:31<13:08:54,  7.85s/it]  8%|‚ñä         | 531/6560 [1:14:39<13:07:07,  7.83s/it]  8%|‚ñä         | 532/6560 [1:14:46<12:42:16,  7.59s/it]  8%|‚ñä         | 533/6560 [1:14:53<12:46:38,  7.63s/it]  8%|‚ñä         | 534/6560 [1:15:01<12:54:50,  7.71s/it]  8%|‚ñä         | 535/6560 [1:15:10<13:17:42,  7.94s/it]  8%|‚ñä         | 536/6560 [1:15:17<12:50:00,  7.67s/it]  8%|‚ñä         | 537/6560 [1:15:26<13:26:01,  8.03s/it]  8%|‚ñä         | 538/6560 [1:15:32<12:40:06,  7.57s/it]  8%|‚ñä         | 539/6560 [1:15:39<12:13:49,  7.31s/it]  8%|‚ñä         | 540/6560 [1:15:45<11:52:30,  7.10s/it]  8%|‚ñä         | 541/6560 [1:15:53<11:56:49,  7.15s/it]  8%|‚ñä         | 542/6560 [1:16:00<11:57:57,  7.16s/it]  8%|‚ñä         | 543/6560 [1:16:06<11:28:34,  6.87s/it]  8%|‚ñä         | 544/6560 [1:16:13<11:22:30,  6.81s/it]  8%|‚ñä         | 545/6560 [1:16:21<12:02:23,  7.21s/it]  8%|‚ñä         | 546/6560 [1:16:27<11:43:18,  7.02s/it]  8%|‚ñä         | 547/6560 [1:16:36<12:34:35,  7.53s/it]  8%|‚ñä         | 548/6560 [1:16:44<12:50:15,  7.69s/it]  8%|‚ñä         | 549/6560 [1:16:52<12:49:36,  7.68s/it]  8%|‚ñä         | 550/6560 [1:16:59<12:38:58,  7.58s/it]  8%|‚ñä         | 551/6560 [1:17:07<12:38:34,  7.57s/it]  8%|‚ñä         | 552/6560 [1:17:14<12:39:12,  7.58s/it]  8%|‚ñä         | 553/6560 [1:17:23<13:23:46,  8.03s/it]  8%|‚ñä         | 554/6560 [1:17:32<13:49:00,  8.28s/it]  8%|‚ñä         | 555/6560 [1:17:40<13:31:58,  8.11s/it]  8%|‚ñä         | 556/6560 [1:17:47<13:04:52,  7.84s/it]  8%|‚ñä         | 557/6560 [1:17:56<13:22:44,  8.02s/it]  9%|‚ñä         | 558/6560 [1:18:03<12:56:11,  7.76s/it]  9%|‚ñä         | 559/6560 [1:18:10<12:26:01,  7.46s/it]  9%|‚ñä         | 560/6560 [1:18:16<12:05:57,  7.26s/it]                                                         9%|‚ñä         | 560/6560 [1:18:16<12:05:57,  7.26s/it]  9%|‚ñä         | 561/6560 [1:18:23<11:42:37,  7.03s/it]  9%|‚ñä         | 562/6560 [1:18:32<12:32:34,  7.53s/it]  9%|‚ñä         | 563/6560 [1:18:41<13:17:38,  7.98s/it]  9%|‚ñä         | 564/6560 [1:18:49<13:19:24,  8.00s/it]  9%|‚ñä         | 565/6560 [1:18:57<13:22:45,  8.03s/it]  9%|‚ñä         | 566/6560 [1:19:06<14:10:40,  8.52s/it]  9%|‚ñä         | 567/6560 [1:19:13<13:13:17,  7.94s/it]  9%|‚ñä         | 568/6560 [1:19:20<12:46:51,  7.68s/it]  9%|‚ñä         | 569/6560 [1:19:28<12:58:33,  7.80s/it]  9%|‚ñä         | 570/6560 [1:19:35<12:29:28,  7.51s/it]  9%|‚ñä         | 571/6560 [1:19:42<12:09:00,  7.30s/it]  9%|‚ñä         | 572/6560 [1:19:48<11:22:39,  6.84s/it]  9%|‚ñä         | 573/6560 [1:19:55<11:53:18,  7.15s/it]  9%|‚ñâ         | 574/6560 [1:20:03<12:02:27,  7.24s/it]  9%|‚ñâ         | 575/6560 [1:20:11<12:34:17,  7.56s/it]  9%|‚ñâ         | 576/6560 [1:20:20<13:01:40,  7.84s/it]  9%|‚ñâ         | 577/6560 [1:20:27<12:41:01,  7.63s/it]  9%|‚ñâ         | 578/6560 [1:20:34<12:22:38,  7.45s/it]  9%|‚ñâ         | 579/6560 [1:20:41<12:22:06,  7.44s/it]  9%|‚ñâ         | 580/6560 [1:20:49<12:19:33,  7.42s/it]  9%|‚ñâ         | 581/6560 [1:20:58<13:06:07,  7.89s/it]  9%|‚ñâ         | 582/6560 [1:21:05<12:48:08,  7.71s/it]  9%|‚ñâ         | 583/6560 [1:21:11<12:05:55,  7.29s/it]  9%|‚ñâ         | 584/6560 [1:21:19<12:31:56,  7.55s/it]  9%|‚ñâ         | 585/6560 [1:21:29<13:36:50,  8.20s/it]  9%|‚ñâ         | 586/6560 [1:21:35<12:37:33,  7.61s/it]  9%|‚ñâ         | 587/6560 [1:21:42<11:57:10,  7.20s/it]  9%|‚ñâ         | 588/6560 [1:21:49<11:56:24,  7.20s/it]  9%|‚ñâ         | 589/6560 [1:21:57<12:21:48,  7.45s/it]  9%|‚ñâ         | 590/6560 [1:22:05<12:33:50,  7.58s/it]  9%|‚ñâ         | 591/6560 [1:22:12<12:18:06,  7.42s/it]  9%|‚ñâ         | 592/6560 [1:22:22<13:47:06,  8.32s/it]  9%|‚ñâ         | 593/6560 [1:22:29<13:10:57,  7.95s/it]  9%|‚ñâ         | 594/6560 [1:22:35<12:12:53,  7.37s/it]  9%|‚ñâ         | 595/6560 [1:22:43<12:20:33,  7.45s/it]  9%|‚ñâ         | 596/6560 [1:22:50<12:08:50,  7.33s/it]  9%|‚ñâ         | 597/6560 [1:22:57<12:06:06,  7.31s/it]  9%|‚ñâ         | 598/6560 [1:23:05<12:24:21,  7.49s/it]  9%|‚ñâ         | 599/6560 [1:23:13<12:29:51,  7.55s/it]  9%|‚ñâ         | 600/6560 [1:23:20<12:31:46,  7.57s/it]                                                         9%|‚ñâ         | 600/6560 [1:23:20<12:31:46,  7.57s/it]
  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|‚ñè         | 2/125 [00:03<04:03,  1.98s/it][A
  2%|‚ñè         | 3/125 [00:07<05:31,  2.72s/it][A
  3%|‚ñé         | 4/125 [00:10<05:29,  2.73s/it][A
  4%|‚ñç         | 5/125 [00:12<05:17,  2.64s/it][A
  5%|‚ñç         | 6/125 [00:15<05:00,  2.52s/it][A
  6%|‚ñå         | 7/125 [00:17<04:56,  2.51s/it][A
  6%|‚ñã         | 8/125 [00:20<04:48,  2.46s/it][A
  7%|‚ñã         | 9/125 [00:21<04:10,  2.16s/it][A
  8%|‚ñä         | 10/125 [00:23<03:58,  2.08s/it][A
  9%|‚ñâ         | 11/125 [00:25<03:54,  2.06s/it][A
 10%|‚ñâ         | 12/125 [00:27<03:57,  2.10s/it][A
 10%|‚ñà         | 13/125 [00:30<04:04,  2.18s/it][A
 11%|‚ñà         | 14/125 [00:31<03:46,  2.04s/it][A
 12%|‚ñà‚ñè        | 15/125 [00:33<03:33,  1.94s/it][A
 13%|‚ñà‚ñé        | 16/125 [00:35<03:26,  1.90s/it][A
 14%|‚ñà‚ñé        | 17/125 [00:36<03:14,  1.80s/it][A
 14%|‚ñà‚ñç        | 18/125 [00:38<03:21,  1.88s/it][A
 15%|‚ñà‚ñå        | 19/125 [00:40<02:58,  1.68s/it][A
 16%|‚ñà‚ñå        | 20/125 [00:41<03:00,  1.72s/it][A
 17%|‚ñà‚ñã        | 21/125 [00:43<02:51,  1.64s/it][A
 18%|‚ñà‚ñä        | 22/125 [00:45<03:11,  1.86s/it][A
 18%|‚ñà‚ñä        | 23/125 [00:47<02:57,  1.74s/it][A
 19%|‚ñà‚ñâ        | 24/125 [00:48<02:51,  1.70s/it][A
 20%|‚ñà‚ñà        | 25/125 [00:51<03:16,  1.97s/it][A
 21%|‚ñà‚ñà        | 26/125 [00:54<03:37,  2.20s/it][A
 22%|‚ñà‚ñà‚ñè       | 27/125 [00:56<03:40,  2.25s/it][A
 22%|‚ñà‚ñà‚ñè       | 28/125 [00:59<03:56,  2.43s/it][A
 23%|‚ñà‚ñà‚ñé       | 29/125 [01:01<03:48,  2.38s/it][A
 24%|‚ñà‚ñà‚ñç       | 30/125 [01:03<03:21,  2.12s/it][A
 25%|‚ñà‚ñà‚ñç       | 31/125 [01:05<03:13,  2.06s/it][A
 26%|‚ñà‚ñà‚ñå       | 32/125 [01:06<03:05,  2.00s/it][A
 26%|‚ñà‚ñà‚ñã       | 33/125 [01:09<03:09,  2.07s/it][A
 27%|‚ñà‚ñà‚ñã       | 34/125 [01:11<03:15,  2.15s/it][A
 28%|‚ñà‚ñà‚ñä       | 35/125 [01:14<03:32,  2.37s/it][A
 29%|‚ñà‚ñà‚ñâ       | 36/125 [01:16<03:22,  2.28s/it][A
 30%|‚ñà‚ñà‚ñâ       | 37/125 [01:19<03:32,  2.42s/it][A
 30%|‚ñà‚ñà‚ñà       | 38/125 [01:21<03:35,  2.47s/it][A
 31%|‚ñà‚ñà‚ñà       | 39/125 [01:24<03:44,  2.61s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 40/125 [01:26<03:15,  2.30s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 41/125 [01:28<03:05,  2.21s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 42/125 [01:30<02:59,  2.17s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [01:32<02:50,  2.08s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 44/125 [01:34<03:03,  2.27s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 45/125 [01:36<02:45,  2.06s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 46/125 [01:40<03:20,  2.53s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 47/125 [01:42<03:14,  2.50s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 48/125 [01:45<03:14,  2.53s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 49/125 [01:48<03:33,  2.81s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 50/125 [01:50<03:03,  2.45s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 51/125 [01:52<02:54,  2.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 52/125 [01:54<02:42,  2.23s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 53/125 [01:57<02:54,  2.42s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [01:58<02:30,  2.12s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 55/125 [02:00<02:23,  2.06s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 56/125 [02:02<02:18,  2.01s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 57/125 [02:06<02:57,  2.61s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 58/125 [02:08<02:39,  2.38s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 59/125 [02:09<02:21,  2.15s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60/125 [02:11<02:14,  2.07s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 61/125 [02:14<02:22,  2.23s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 62/125 [02:15<02:06,  2.00s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 63/125 [02:18<02:09,  2.09s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 64/125 [02:19<02:03,  2.02s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [02:22<02:07,  2.12s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 66/125 [02:25<02:19,  2.37s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 67/125 [02:26<02:03,  2.14s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 68/125 [02:29<02:13,  2.34s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 69/125 [02:31<02:02,  2.18s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 70/125 [02:34<02:10,  2.38s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 71/125 [02:36<01:58,  2.19s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 72/125 [02:37<01:51,  2.10s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 73/125 [02:39<01:45,  2.03s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 74/125 [02:41<01:36,  1.90s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75/125 [02:43<01:42,  2.06s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [02:46<01:51,  2.27s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 77/125 [02:48<01:38,  2.05s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 78/125 [02:51<01:47,  2.29s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 79/125 [02:53<01:53,  2.46s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 80/125 [02:55<01:42,  2.29s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 81/125 [02:58<01:40,  2.29s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 82/125 [03:01<01:58,  2.76s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 83/125 [03:03<01:42,  2.45s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 84/125 [03:06<01:43,  2.54s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [03:08<01:37,  2.44s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 86/125 [03:10<01:34,  2.42s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [03:14<01:39,  2.61s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 88/125 [03:16<01:31,  2.48s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 89/125 [03:18<01:33,  2.58s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90/125 [03:21<01:24,  2.41s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 91/125 [03:23<01:18,  2.30s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 92/125 [03:25<01:13,  2.23s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 93/125 [03:27<01:12,  2.25s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 94/125 [03:29<01:08,  2.21s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 95/125 [03:31<00:59,  1.99s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 96/125 [03:32<00:56,  1.93s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 97/125 [03:34<00:49,  1.78s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [03:36<00:49,  1.82s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 99/125 [03:38<00:47,  1.84s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 100/125 [03:40<00:50,  2.01s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 101/125 [03:42<00:51,  2.15s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 102/125 [03:45<00:49,  2.16s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 103/125 [03:46<00:44,  2.03s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 104/125 [03:48<00:41,  1.98s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105/125 [03:53<00:53,  2.70s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 106/125 [03:56<00:54,  2.88s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 107/125 [03:58<00:50,  2.80s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 108/125 [04:01<00:47,  2.80s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [04:03<00:38,  2.40s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 110/125 [04:05<00:36,  2.43s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 111/125 [04:07<00:30,  2.15s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [04:09<00:28,  2.17s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 113/125 [04:11<00:24,  2.05s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 114/125 [04:12<00:20,  1.89s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 115/125 [04:15<00:21,  2.15s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 116/125 [04:18<00:20,  2.28s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 117/125 [04:20<00:17,  2.22s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 118/125 [04:21<00:14,  2.10s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 119/125 [04:24<00:13,  2.25s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [04:26<00:10,  2.14s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 121/125 [04:29<00:09,  2.34s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 122/125 [04:33<00:08,  2.86s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 123/125 [04:34<00:04,  2.38s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 124/125 [04:37<00:02,  2.49s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:39<00:00,  2.41s/it][A                                                       
                                                 [A  9%|‚ñâ         | 600/6560 [1:28:02<12:31:46,  7.57s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:39<00:00,  2.41s/it][A
                                                 [A  9%|‚ñâ         | 601/6560 [1:28:35<164:57:30, 99.66s/it]  9%|‚ñâ         | 602/6560 [1:28:42<119:00:09, 71.90s/it]  9%|‚ñâ         | 603/6560 [1:28:50<87:20:58, 52.79s/it]   9%|‚ñâ         | 604/6560 [1:28:58<64:58:25, 39.27s/it]  9%|‚ñâ         | 605/6560 [1:29:06<49:22:30, 29.85s/it]  9%|‚ñâ         | 606/6560 [1:29:13<37:59:17, 22.97s/it]  9%|‚ñâ         | 607/6560 [1:29:20<30:03:45, 18.18s/it]  9%|‚ñâ         | 608/6560 [1:29:30<25:50:14, 15.63s/it]  9%|‚ñâ         | 609/6560 [1:29:38<22:06:41, 13.38s/it]  9%|‚ñâ         | 610/6560 [1:29:45<19:08:54, 11.59s/it]  9%|‚ñâ         | 611/6560 [1:29:51<16:30:07,  9.99s/it]  9%|‚ñâ         | 612/6560 [1:30:00<15:39:11,  9.47s/it]  9%|‚ñâ         | 613/6560 [1:30:07<14:52:41,  9.01s/it]  9%|‚ñâ         | 614/6560 [1:30:15<14:01:18,  8.49s/it]  9%|‚ñâ         | 615/6560 [1:30:22<13:17:43,  8.05s/it]  9%|‚ñâ         | 616/6560 [1:30:29<12:41:15,  7.68s/it]  9%|‚ñâ         | 617/6560 [1:30:39<13:49:43,  8.38s/it]  9%|‚ñâ         | 618/6560 [1:30:46<13:34:20,  8.22s/it]  9%|‚ñâ         | 619/6560 [1:30:54<13:20:25,  8.08s/it]  9%|‚ñâ         | 620/6560 [1:31:00<12:25:30,  7.53s/it]  9%|‚ñâ         | 621/6560 [1:31:09<12:44:42,  7.73s/it]  9%|‚ñâ         | 622/6560 [1:31:17<12:50:19,  7.78s/it]  9%|‚ñâ         | 623/6560 [1:31:24<12:30:39,  7.59s/it] 10%|‚ñâ         | 624/6560 [1:31:31<12:28:43,  7.57s/it] 10%|‚ñâ         | 625/6560 [1:31:40<13:15:02,  8.04s/it] 10%|‚ñâ         | 626/6560 [1:31:50<13:50:09,  8.39s/it] 10%|‚ñâ         | 627/6560 [1:31:58<14:02:26,  8.52s/it] 10%|‚ñâ         | 628/6560 [1:32:08<14:26:37,  8.77s/it] 10%|‚ñâ         | 629/6560 [1:32:15<13:40:50,  8.30s/it] 10%|‚ñâ         | 630/6560 [1:32:22<12:56:38,  7.86s/it] 10%|‚ñâ         | 631/6560 [1:32:29<12:38:55,  7.68s/it] 10%|‚ñâ         | 632/6560 [1:32:37<12:42:40,  7.72s/it] 10%|‚ñâ         | 633/6560 [1:32:45<12:52:43,  7.82s/it] 10%|‚ñâ         | 634/6560 [1:32:52<12:45:04,  7.75s/it] 10%|‚ñâ         | 635/6560 [1:33:00<12:28:16,  7.58s/it] 10%|‚ñâ         | 636/6560 [1:33:08<12:37:10,  7.67s/it] 10%|‚ñâ         | 637/6560 [1:33:14<12:02:59,  7.32s/it] 10%|‚ñâ         | 638/6560 [1:33:23<12:37:43,  7.68s/it] 10%|‚ñâ         | 639/6560 [1:33:30<12:32:20,  7.62s/it] 10%|‚ñâ         | 640/6560 [1:33:38<12:32:08,  7.62s/it]                                                        10%|‚ñâ         | 640/6560 [1:33:38<12:32:08,  7.62s/it] 10%|‚ñâ         | 641/6560 [1:33:47<13:33:57,  8.25s/it] 10%|‚ñâ         | 642/6560 [1:33:54<12:43:24,  7.74s/it] 10%|‚ñâ         | 643/6560 [1:34:01<12:24:14,  7.55s/it] 10%|‚ñâ         | 644/6560 [1:34:09<12:42:44,  7.74s/it] 10%|‚ñâ         | 645/6560 [1:34:17<12:43:47,  7.75s/it] 10%|‚ñâ         | 646/6560 [1:34:25<12:55:53,  7.87s/it] 10%|‚ñâ         | 647/6560 [1:34:33<12:53:24,  7.85s/it] 10%|‚ñâ         | 648/6560 [1:34:43<13:44:14,  8.37s/it] 10%|‚ñâ         | 649/6560 [1:34:52<14:16:39,  8.70s/it] 10%|‚ñâ         | 650/6560 [1:35:01<14:32:59,  8.86s/it] 10%|‚ñâ         | 651/6560 [1:35:10<14:32:38,  8.86s/it] 10%|‚ñâ         | 652/6560 [1:35:19<14:36:38,  8.90s/it] 10%|‚ñâ         | 653/6560 [1:35:27<13:59:35,  8.53s/it] 10%|‚ñâ         | 654/6560 [1:35:35<14:03:45,  8.57s/it] 10%|‚ñâ         | 655/6560 [1:35:43<13:29:37,  8.23s/it] 10%|‚ñà         | 656/6560 [1:35:50<13:01:33,  7.94s/it] 10%|‚ñà         | 657/6560 [1:35:58<13:12:15,  8.05s/it] 10%|‚ñà         | 658/6560 [1:36:06<13:03:56,  7.97s/it] 10%|‚ñà         | 659/6560 [1:36:12<12:06:27,  7.39s/it] 10%|‚ñà         | 660/6560 [1:36:19<11:59:00,  7.31s/it] 10%|‚ñà         | 661/6560 [1:36:28<12:23:59,  7.57s/it] 10%|‚ñà         | 662/6560 [1:36:36<12:37:24,  7.71s/it] 10%|‚ñà         | 663/6560 [1:36:43<12:16:57,  7.50s/it] 10%|‚ñà         | 664/6560 [1:36:50<12:10:15,  7.43s/it] 10%|‚ñà         | 665/6560 [1:36:58<12:20:47,  7.54s/it] 10%|‚ñà         | 666/6560 [1:37:06<12:46:58,  7.81s/it] 10%|‚ñà         | 667/6560 [1:37:14<12:48:34,  7.83s/it] 10%|‚ñà         | 668/6560 [1:37:20<12:00:04,  7.33s/it] 10%|‚ñà         | 669/6560 [1:37:32<14:21:42,  8.78s/it] 10%|‚ñà         | 670/6560 [1:37:43<15:09:57,  9.27s/it] 10%|‚ñà         | 671/6560 [1:37:50<13:59:38,  8.55s/it] 10%|‚ñà         | 672/6560 [1:37:58<13:50:23,  8.46s/it] 10%|‚ñà         | 673/6560 [1:38:04<12:32:43,  7.67s/it] 10%|‚ñà         | 674/6560 [1:38:13<13:07:07,  8.02s/it] 10%|‚ñà         | 675/6560 [1:38:20<12:50:05,  7.85s/it] 10%|‚ñà         | 676/6560 [1:38:29<13:19:38,  8.15s/it] 10%|‚ñà         | 677/6560 [1:38:36<12:53:59,  7.89s/it] 10%|‚ñà         | 678/6560 [1:38:45<13:08:33,  8.04s/it] 10%|‚ñà         | 679/6560 [1:38:54<13:43:25,  8.40s/it] 10%|‚ñà         | 680/6560 [1:39:01<13:20:50,  8.17s/it]                                                        10%|‚ñà         | 680/6560 [1:39:01<13:20:50,  8.17s/it] 10%|‚ñà         | 681/6560 [1:39:09<12:58:55,  7.95s/it] 10%|‚ñà         | 682/6560 [1:39:17<13:13:15,  8.10s/it] 10%|‚ñà         | 683/6560 [1:39:25<13:01:04,  7.97s/it] 10%|‚ñà         | 684/6560 [1:39:33<13:04:40,  8.01s/it] 10%|‚ñà         | 685/6560 [1:39:42<13:18:59,  8.16s/it] 10%|‚ñà         | 686/6560 [1:39:49<12:51:30,  7.88s/it] 10%|‚ñà         | 687/6560 [1:39:55<12:12:41,  7.49s/it] 10%|‚ñà         | 688/6560 [1:40:05<13:08:51,  8.06s/it] 11%|‚ñà         | 689/6560 [1:40:12<12:59:20,  7.96s/it] 11%|‚ñà         | 690/6560 [1:40:19<12:26:10,  7.63s/it] 11%|‚ñà         | 691/6560 [1:40:27<12:26:46,  7.63s/it] 11%|‚ñà         | 692/6560 [1:40:34<12:03:15,  7.40s/it] 11%|‚ñà         | 693/6560 [1:40:43<13:08:04,  8.06s/it] 11%|‚ñà         | 694/6560 [1:40:54<14:10:25,  8.70s/it] 11%|‚ñà         | 695/6560 [1:41:03<14:22:11,  8.82s/it] 11%|‚ñà         | 696/6560 [1:41:11<14:20:40,  8.81s/it] 11%|‚ñà         | 697/6560 [1:41:19<13:47:36,  8.47s/it] 11%|‚ñà         | 698/6560 [1:41:28<13:46:03,  8.46s/it] 11%|‚ñà         | 699/6560 [1:41:37<14:15:25,  8.76s/it] 11%|‚ñà         | 700/6560 [1:41:45<13:54:12,  8.54s/it] 11%|‚ñà         | 701/6560 [1:41:52<12:57:43,  7.96s/it] 11%|‚ñà         | 702/6560 [1:42:00<12:53:49,  7.93s/it] 11%|‚ñà         | 703/6560 [1:42:07<12:27:35,  7.66s/it] 11%|‚ñà         | 704/6560 [1:42:14<12:06:14,  7.44s/it] 11%|‚ñà         | 705/6560 [1:42:21<12:03:02,  7.41s/it] 11%|‚ñà         | 706/6560 [1:42:27<11:29:22,  7.07s/it] 11%|‚ñà         | 707/6560 [1:42:35<11:47:43,  7.26s/it] 11%|‚ñà         | 708/6560 [1:42:44<12:48:10,  7.88s/it] 11%|‚ñà         | 709/6560 [1:42:52<12:48:45,  7.88s/it] 11%|‚ñà         | 710/6560 [1:42:58<12:03:37,  7.42s/it] 11%|‚ñà         | 711/6560 [1:43:07<12:49:03,  7.89s/it] 11%|‚ñà         | 712/6560 [1:43:14<12:14:34,  7.54s/it] 11%|‚ñà         | 713/6560 [1:43:22<12:30:26,  7.70s/it] 11%|‚ñà         | 714/6560 [1:43:29<12:06:35,  7.46s/it] 11%|‚ñà         | 715/6560 [1:43:37<12:18:12,  7.58s/it] 11%|‚ñà         | 716/6560 [1:43:44<12:03:51,  7.43s/it] 11%|‚ñà         | 717/6560 [1:43:52<12:34:45,  7.75s/it] 11%|‚ñà         | 718/6560 [1:44:03<13:41:44,  8.44s/it] 11%|‚ñà         | 719/6560 [1:44:10<13:12:55,  8.15s/it] 11%|‚ñà         | 720/6560 [1:44:18<13:10:19,  8.12s/it]                                                        11%|‚ñà         | 720/6560 [1:44:18<13:10:19,  8.12s/it] 11%|‚ñà         | 721/6560 [1:44:26<13:06:59,  8.09s/it] 11%|‚ñà         | 722/6560 [1:44:34<12:54:03,  7.96s/it] 11%|‚ñà         | 723/6560 [1:44:42<13:04:16,  8.06s/it] 11%|‚ñà         | 724/6560 [1:44:50<12:49:12,  7.91s/it] 11%|‚ñà         | 725/6560 [1:44:58<12:57:57,  8.00s/it] 11%|‚ñà         | 726/6560 [1:45:06<13:04:01,  8.06s/it] 11%|‚ñà         | 727/6560 [1:45:15<13:20:56,  8.24s/it] 11%|‚ñà         | 728/6560 [1:45:23<13:29:33,  8.33s/it] 11%|‚ñà         | 729/6560 [1:45:31<13:24:45,  8.28s/it] 11%|‚ñà         | 730/6560 [1:45:40<13:21:30,  8.25s/it] 11%|‚ñà         | 731/6560 [1:45:46<12:35:11,  7.77s/it] 11%|‚ñà         | 732/6560 [1:45:53<12:21:09,  7.63s/it] 11%|‚ñà         | 733/6560 [1:46:00<11:56:21,  7.38s/it] 11%|‚ñà         | 734/6560 [1:46:07<11:41:23,  7.22s/it] 11%|‚ñà         | 735/6560 [1:46:15<12:08:36,  7.50s/it] 11%|‚ñà         | 736/6560 [1:46:24<12:47:39,  7.91s/it] 11%|‚ñà         | 737/6560 [1:46:31<12:15:33,  7.58s/it] 11%|‚ñà‚ñè        | 738/6560 [1:46:38<11:54:37,  7.36s/it] 11%|‚ñà‚ñè        | 739/6560 [1:46:45<11:50:41,  7.33s/it] 11%|‚ñà‚ñè        | 740/6560 [1:46:51<11:22:03,  7.03s/it] 11%|‚ñà‚ñè        | 741/6560 [1:46:59<11:51:15,  7.33s/it] 11%|‚ñà‚ñè        | 742/6560 [1:47:07<12:00:59,  7.44s/it] 11%|‚ñà‚ñè        | 743/6560 [1:47:15<12:01:26,  7.44s/it] 11%|‚ñà‚ñè        | 744/6560 [1:47:23<12:37:09,  7.81s/it] 11%|‚ñà‚ñè        | 745/6560 [1:47:33<13:24:14,  8.30s/it] 11%|‚ñà‚ñè        | 746/6560 [1:47:41<13:34:28,  8.41s/it] 11%|‚ñà‚ñè        | 747/6560 [1:47:49<13:14:25,  8.20s/it] 11%|‚ñà‚ñè        | 748/6560 [1:47:58<13:30:41,  8.37s/it] 11%|‚ñà‚ñè        | 749/6560 [1:48:05<12:43:11,  7.88s/it] 11%|‚ñà‚ñè        | 750/6560 [1:48:12<12:43:50,  7.89s/it] 11%|‚ñà‚ñè        | 751/6560 [1:48:19<12:03:00,  7.47s/it] 11%|‚ñà‚ñè        | 752/6560 [1:48:26<11:44:00,  7.27s/it] 11%|‚ñà‚ñè        | 753/6560 [1:48:32<11:20:04,  7.03s/it] 11%|‚ñà‚ñè        | 754/6560 [1:48:39<11:03:39,  6.86s/it] 12%|‚ñà‚ñè        | 755/6560 [1:48:46<11:09:47,  6.92s/it] 12%|‚ñà‚ñè        | 756/6560 [1:48:54<11:45:07,  7.29s/it] 12%|‚ñà‚ñè        | 757/6560 [1:49:01<11:53:22,  7.38s/it] 12%|‚ñà‚ñè        | 758/6560 [1:49:11<12:44:03,  7.90s/it] 12%|‚ñà‚ñè        | 759/6560 [1:49:18<12:31:05,  7.77s/it] 12%|‚ñà‚ñè        | 760/6560 [1:49:25<12:00:19,  7.45s/it]                                                        12%|‚ñà‚ñè        | 760/6560 [1:49:25<12:00:19,  7.45s/it] 12%|‚ñà‚ñè        | 761/6560 [1:49:31<11:37:53,  7.22s/it] 12%|‚ñà‚ñè        | 762/6560 [1:49:40<12:20:55,  7.67s/it] 12%|‚ñà‚ñè        | 763/6560 [1:49:48<12:13:51,  7.60s/it] 12%|‚ñà‚ñè        | 764/6560 [1:49:56<12:40:54,  7.88s/it] 12%|‚ñà‚ñè        | 765/6560 [1:50:04<12:48:27,  7.96s/it] 12%|‚ñà‚ñè        | 766/6560 [1:50:12<12:36:19,  7.83s/it] 12%|‚ñà‚ñè        | 767/6560 [1:50:19<12:24:39,  7.71s/it] 12%|‚ñà‚ñè        | 768/6560 [1:50:27<12:39:35,  7.87s/it] 12%|‚ñà‚ñè        | 769/6560 [1:50:37<13:13:52,  8.23s/it] 12%|‚ñà‚ñè        | 770/6560 [1:50:44<12:58:18,  8.07s/it] 12%|‚ñà‚ñè        | 771/6560 [1:50:52<12:55:50,  8.04s/it] 12%|‚ñà‚ñè        | 772/6560 [1:51:03<14:13:52,  8.85s/it] 12%|‚ñà‚ñè        | 773/6560 [1:51:10<13:34:49,  8.45s/it] 12%|‚ñà‚ñè        | 774/6560 [1:51:19<13:29:33,  8.40s/it] 12%|‚ñà‚ñè        | 775/6560 [1:51:26<13:07:47,  8.17s/it] 12%|‚ñà‚ñè        | 776/6560 [1:51:36<13:52:42,  8.64s/it] 12%|‚ñà‚ñè        | 777/6560 [1:51:46<14:31:50,  9.05s/it] 12%|‚ñà‚ñè        | 778/6560 [1:51:54<13:52:42,  8.64s/it] 12%|‚ñà‚ñè        | 779/6560 [1:52:02<13:36:34,  8.48s/it] 12%|‚ñà‚ñè        | 780/6560 [1:52:10<13:17:10,  8.28s/it] 12%|‚ñà‚ñè        | 781/6560 [1:52:17<12:40:46,  7.90s/it] 12%|‚ñà‚ñè        | 782/6560 [1:52:24<12:36:35,  7.86s/it] 12%|‚ñà‚ñè        | 783/6560 [1:52:34<13:16:43,  8.27s/it] 12%|‚ñà‚ñè        | 784/6560 [1:52:42<13:03:21,  8.14s/it] 12%|‚ñà‚ñè        | 785/6560 [1:52:49<12:55:24,  8.06s/it] 12%|‚ñà‚ñè        | 786/6560 [1:52:57<12:29:47,  7.79s/it] 12%|‚ñà‚ñè        | 787/6560 [1:53:05<13:00:56,  8.12s/it] 12%|‚ñà‚ñè        | 788/6560 [1:53:14<12:58:33,  8.09s/it] 12%|‚ñà‚ñè        | 789/6560 [1:53:21<12:44:52,  7.95s/it] 12%|‚ñà‚ñè        | 790/6560 [1:53:30<12:57:37,  8.09s/it] 12%|‚ñà‚ñè        | 791/6560 [1:53:37<12:26:44,  7.77s/it] 12%|‚ñà‚ñè        | 792/6560 [1:53:44<12:24:33,  7.75s/it] 12%|‚ñà‚ñè        | 793/6560 [1:53:52<12:31:29,  7.82s/it] 12%|‚ñà‚ñè        | 794/6560 [1:53:58<11:33:30,  7.22s/it] 12%|‚ñà‚ñè        | 795/6560 [1:54:04<11:10:24,  6.98s/it] 12%|‚ñà‚ñè        | 796/6560 [1:54:13<11:42:06,  7.31s/it] 12%|‚ñà‚ñè        | 797/6560 [1:54:23<12:59:27,  8.12s/it] 12%|‚ñà‚ñè        | 798/6560 [1:54:29<12:08:14,  7.58s/it] 12%|‚ñà‚ñè        | 799/6560 [1:54:37<12:14:51,  7.65s/it] 12%|‚ñà‚ñè        | 800/6560 [1:54:43<11:36:29,  7.26s/it]                                                        12%|‚ñà‚ñè        | 800/6560 [1:54:43<11:36:29,  7.26s/it] 12%|‚ñà‚ñè        | 801/6560 [1:54:51<12:00:53,  7.51s/it] 12%|‚ñà‚ñè        | 802/6560 [1:54:59<12:06:09,  7.57s/it] 12%|‚ñà‚ñè        | 803/6560 [1:55:07<12:31:26,  7.83s/it] 12%|‚ñà‚ñè        | 804/6560 [1:55:14<12:11:12,  7.62s/it] 12%|‚ñà‚ñè        | 805/6560 [1:55:21<11:51:14,  7.42s/it] 12%|‚ñà‚ñè        | 806/6560 [1:55:27<11:07:43,  6.96s/it] 12%|‚ñà‚ñè        | 807/6560 [1:55:35<11:28:40,  7.18s/it] 12%|‚ñà‚ñè        | 808/6560 [1:55:41<11:00:06,  6.89s/it] 12%|‚ñà‚ñè        | 809/6560 [1:55:50<12:07:47,  7.59s/it] 12%|‚ñà‚ñè        | 810/6560 [1:55:59<12:36:58,  7.90s/it] 12%|‚ñà‚ñè        | 811/6560 [1:56:08<13:22:31,  8.38s/it] 12%|‚ñà‚ñè        | 812/6560 [1:56:19<14:09:35,  8.87s/it] 12%|‚ñà‚ñè        | 813/6560 [1:56:25<12:49:33,  8.03s/it] 12%|‚ñà‚ñè        | 814/6560 [1:56:32<12:33:34,  7.87s/it] 12%|‚ñà‚ñè        | 815/6560 [1:56:40<12:46:30,  8.01s/it] 12%|‚ñà‚ñè        | 816/6560 [1:56:48<12:48:42,  8.03s/it] 12%|‚ñà‚ñè        | 817/6560 [1:56:55<12:11:10,  7.64s/it] 12%|‚ñà‚ñè        | 818/6560 [1:57:03<12:02:52,  7.55s/it] 12%|‚ñà‚ñè        | 819/6560 [1:57:10<12:05:40,  7.58s/it] 12%|‚ñà‚ñé        | 820/6560 [1:57:18<12:14:36,  7.68s/it] 13%|‚ñà‚ñé        | 821/6560 [1:57:25<11:44:32,  7.37s/it] 13%|‚ñà‚ñé        | 822/6560 [1:57:33<11:59:25,  7.52s/it] 13%|‚ñà‚ñé        | 823/6560 [1:57:40<11:55:27,  7.48s/it] 13%|‚ñà‚ñé        | 824/6560 [1:57:50<12:56:50,  8.13s/it] 13%|‚ñà‚ñé        | 825/6560 [1:57:58<12:54:14,  8.10s/it] 13%|‚ñà‚ñé        | 826/6560 [1:58:05<12:42:38,  7.98s/it] 13%|‚ñà‚ñé        | 827/6560 [1:58:12<12:02:29,  7.56s/it] 13%|‚ñà‚ñé        | 828/6560 [1:58:20<12:21:24,  7.76s/it] 13%|‚ñà‚ñé        | 829/6560 [1:58:30<13:12:54,  8.30s/it] 13%|‚ñà‚ñé        | 830/6560 [1:58:39<13:29:41,  8.48s/it] 13%|‚ñà‚ñé        | 831/6560 [1:58:46<12:53:41,  8.10s/it] 13%|‚ñà‚ñé        | 832/6560 [1:58:54<12:52:39,  8.09s/it] 13%|‚ñà‚ñé        | 833/6560 [1:59:02<12:51:40,  8.08s/it] 13%|‚ñà‚ñé        | 834/6560 [1:59:10<12:49:17,  8.06s/it] 13%|‚ñà‚ñé        | 835/6560 [1:59:16<11:47:36,  7.42s/it] 13%|‚ñà‚ñé        | 836/6560 [1:59:24<12:16:39,  7.72s/it] 13%|‚ñà‚ñé        | 837/6560 [1:59:31<11:38:24,  7.32s/it] 13%|‚ñà‚ñé        | 838/6560 [1:59:40<12:27:33,  7.84s/it] 13%|‚ñà‚ñé        | 839/6560 [1:59:47<12:22:06,  7.78s/it] 13%|‚ñà‚ñé        | 840/6560 [1:59:54<11:42:59,  7.37s/it]                                                        13%|‚ñà‚ñé        | 840/6560 [1:59:54<11:42:59,  7.37s/it] 13%|‚ñà‚ñé        | 841/6560 [2:00:02<12:00:53,  7.56s/it] 13%|‚ñà‚ñé        | 842/6560 [2:00:12<13:06:10,  8.25s/it] 13%|‚ñà‚ñé        | 843/6560 [2:00:20<13:06:04,  8.25s/it] 13%|‚ñà‚ñé        | 844/6560 [2:00:28<13:12:29,  8.32s/it] 13%|‚ñà‚ñé        | 845/6560 [2:00:35<12:35:04,  7.93s/it] 13%|‚ñà‚ñé        | 846/6560 [2:00:42<11:58:40,  7.55s/it] 13%|‚ñà‚ñé        | 847/6560 [2:00:53<13:19:28,  8.40s/it] 13%|‚ñà‚ñé        | 848/6560 [2:01:00<13:06:36,  8.26s/it] 13%|‚ñà‚ñé        | 849/6560 [2:01:06<12:00:18,  7.57s/it] 13%|‚ñà‚ñé        | 850/6560 [2:01:15<12:21:29,  7.79s/it] 13%|‚ñà‚ñé        | 851/6560 [2:01:23<12:34:07,  7.93s/it] 13%|‚ñà‚ñé        | 852/6560 [2:01:29<11:49:57,  7.46s/it] 13%|‚ñà‚ñé        | 853/6560 [2:01:36<11:27:53,  7.23s/it] 13%|‚ñà‚ñé        | 854/6560 [2:01:43<11:32:32,  7.28s/it] 13%|‚ñà‚ñé        | 855/6560 [2:01:52<12:13:09,  7.71s/it] 13%|‚ñà‚ñé        | 856/6560 [2:01:59<11:57:51,  7.55s/it] 13%|‚ñà‚ñé        | 857/6560 [2:02:06<11:44:52,  7.42s/it] 13%|‚ñà‚ñé        | 858/6560 [2:02:13<11:33:36,  7.30s/it] 13%|‚ñà‚ñé        | 859/6560 [2:02:21<11:41:27,  7.38s/it] 13%|‚ñà‚ñé        | 860/6560 [2:02:27<11:11:17,  7.07s/it] 13%|‚ñà‚ñé        | 861/6560 [2:02:35<11:30:05,  7.27s/it] 13%|‚ñà‚ñé        | 862/6560 [2:02:43<11:40:23,  7.38s/it] 13%|‚ñà‚ñé        | 863/6560 [2:02:52<12:25:31,  7.85s/it] 13%|‚ñà‚ñé        | 864/6560 [2:03:00<12:24:53,  7.85s/it] 13%|‚ñà‚ñé        | 865/6560 [2:03:07<12:18:26,  7.78s/it] 13%|‚ñà‚ñé        | 866/6560 [2:03:14<11:39:46,  7.37s/it] 13%|‚ñà‚ñé        | 867/6560 [2:03:22<12:08:19,  7.68s/it] 13%|‚ñà‚ñé        | 868/6560 [2:03:31<12:42:07,  8.03s/it] 13%|‚ñà‚ñé        | 869/6560 [2:03:40<13:01:32,  8.24s/it] 13%|‚ñà‚ñé        | 870/6560 [2:03:46<12:16:32,  7.77s/it] 13%|‚ñà‚ñé        | 871/6560 [2:03:54<12:19:41,  7.80s/it] 13%|‚ñà‚ñé        | 872/6560 [2:04:02<12:23:36,  7.84s/it] 13%|‚ñà‚ñé        | 873/6560 [2:04:10<12:38:44,  8.00s/it] 13%|‚ñà‚ñé        | 874/6560 [2:04:17<11:57:48,  7.57s/it] 13%|‚ñà‚ñé        | 875/6560 [2:04:24<11:51:50,  7.51s/it] 13%|‚ñà‚ñé        | 876/6560 [2:04:32<11:43:06,  7.42s/it] 13%|‚ñà‚ñé        | 877/6560 [2:04:40<12:09:44,  7.70s/it] 13%|‚ñà‚ñé        | 878/6560 [2:04:47<12:01:18,  7.62s/it] 13%|‚ñà‚ñé        | 879/6560 [2:04:55<11:55:26,  7.56s/it] 13%|‚ñà‚ñé        | 880/6560 [2:05:03<12:05:03,  7.66s/it]                                                        13%|‚ñà‚ñé        | 880/6560 [2:05:03<12:05:03,  7.66s/it] 13%|‚ñà‚ñé        | 881/6560 [2:05:09<11:24:32,  7.23s/it] 13%|‚ñà‚ñé        | 882/6560 [2:05:16<11:17:19,  7.16s/it] 13%|‚ñà‚ñé        | 883/6560 [2:05:25<12:17:39,  7.80s/it] 13%|‚ñà‚ñé        | 884/6560 [2:05:33<12:14:00,  7.76s/it] 13%|‚ñà‚ñé        | 885/6560 [2:05:40<11:50:10,  7.51s/it] 14%|‚ñà‚ñé        | 886/6560 [2:05:50<13:12:02,  8.38s/it] 14%|‚ñà‚ñé        | 887/6560 [2:06:00<13:53:29,  8.82s/it] 14%|‚ñà‚ñé        | 888/6560 [2:06:09<13:46:11,  8.74s/it] 14%|‚ñà‚ñé        | 889/6560 [2:06:17<13:30:08,  8.57s/it] 14%|‚ñà‚ñé        | 890/6560 [2:06:24<12:50:37,  8.15s/it] 14%|‚ñà‚ñé        | 891/6560 [2:06:33<13:08:41,  8.35s/it] 14%|‚ñà‚ñé        | 892/6560 [2:06:39<12:12:08,  7.75s/it] 14%|‚ñà‚ñé        | 893/6560 [2:06:46<11:50:07,  7.52s/it] 14%|‚ñà‚ñé        | 894/6560 [2:06:53<11:40:12,  7.41s/it] 14%|‚ñà‚ñé        | 895/6560 [2:07:01<11:50:30,  7.53s/it] 14%|‚ñà‚ñé        | 896/6560 [2:07:10<12:33:05,  7.98s/it] 14%|‚ñà‚ñé        | 897/6560 [2:07:17<12:12:14,  7.76s/it] 14%|‚ñà‚ñé        | 898/6560 [2:07:26<12:46:08,  8.12s/it] 14%|‚ñà‚ñé        | 899/6560 [2:07:34<12:23:37,  7.88s/it] 14%|‚ñà‚ñé        | 900/6560 [2:07:41<12:04:32,  7.68s/it]
  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|‚ñè         | 2/125 [00:03<04:02,  1.97s/it][A
  2%|‚ñè         | 3/125 [00:07<05:29,  2.70s/it][A
  3%|‚ñé         | 4/125 [00:10<05:28,  2.71s/it][A
  4%|‚ñç         | 5/125 [00:12<05:15,  2.63s/it][A
  5%|‚ñç         | 6/125 [00:15<04:59,  2.51s/it][A
  6%|‚ñå         | 7/125 [00:17<04:55,  2.50s/it][A
  6%|‚ñã         | 8/125 [00:20<04:47,  2.46s/it][A
  7%|‚ñã         | 9/125 [00:21<04:10,  2.16s/it][A
  8%|‚ñä         | 10/125 [00:23<03:58,  2.07s/it][A
  9%|‚ñâ         | 11/125 [00:25<03:54,  2.06s/it][A
 10%|‚ñâ         | 12/125 [00:27<03:57,  2.10s/it][A
 10%|‚ñà         | 13/125 [00:29<04:04,  2.18s/it][A
 11%|‚ñà         | 14/125 [00:31<03:46,  2.04s/it][A
 12%|‚ñà‚ñè        | 15/125 [00:33<03:32,  1.94s/it][A
 13%|‚ñà‚ñé        | 16/125 [00:35<03:26,  1.90s/it][A
 14%|‚ñà‚ñé        | 17/125 [00:36<03:14,  1.80s/it][A
 14%|‚ñà‚ñç        | 18/125 [00:38<03:21,  1.88s/it][A
 15%|‚ñà‚ñå        | 19/125 [00:40<02:58,  1.68s/it][A
 16%|‚ñà‚ñå        | 20/125 [00:41<03:00,  1.72s/it][A
 17%|‚ñà‚ñã        | 21/125 [00:43<02:51,  1.64s/it][A
 18%|‚ñà‚ñä        | 22/125 [00:45<03:11,  1.86s/it][A
 18%|‚ñà‚ñä        | 23/125 [00:47<02:57,  1.74s/it][A
 19%|‚ñà‚ñâ        | 24/125 [00:48<02:51,  1.70s/it][A
 20%|‚ñà‚ñà        | 25/125 [00:51<03:16,  1.97s/it][A
 21%|‚ñà‚ñà        | 26/125 [00:54<03:37,  2.19s/it][A
 22%|‚ñà‚ñà‚ñè       | 27/125 [00:56<03:40,  2.25s/it][A
 22%|‚ñà‚ñà‚ñè       | 28/125 [00:59<03:55,  2.43s/it][A
 23%|‚ñà‚ñà‚ñé       | 29/125 [01:01<03:48,  2.38s/it][A
 24%|‚ñà‚ñà‚ñç       | 30/125 [01:03<03:21,  2.12s/it][A
 25%|‚ñà‚ñà‚ñç       | 31/125 [01:04<03:13,  2.06s/it][A
 26%|‚ñà‚ñà‚ñå       | 32/125 [01:06<03:05,  2.00s/it][A
 26%|‚ñà‚ñà‚ñã       | 33/125 [01:09<03:09,  2.06s/it][A
 27%|‚ñà‚ñà‚ñã       | 34/125 [01:11<03:15,  2.15s/it][A
 28%|‚ñà‚ñà‚ñä       | 35/125 [01:14<03:32,  2.36s/it][A
 29%|‚ñà‚ñà‚ñâ       | 36/125 [01:16<03:22,  2.28s/it][A
 30%|‚ñà‚ñà‚ñâ       | 37/125 [01:19<03:32,  2.41s/it][A
 30%|‚ñà‚ñà‚ñà       | 38/125 [01:21<03:34,  2.47s/it][A
 31%|‚ñà‚ñà‚ñà       | 39/125 [01:24<03:43,  2.60s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 40/125 [01:26<03:15,  2.30s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 41/125 [01:28<03:05,  2.21s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 42/125 [01:29<02:46,  2.00s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [01:31<02:40,  1.96s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 44/125 [01:34<02:57,  2.19s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 45/125 [01:35<02:40,  2.01s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 46/125 [01:39<03:17,  2.50s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 47/125 [01:41<03:12,  2.47s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 48/125 [01:44<03:13,  2.51s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 49/125 [01:48<03:32,  2.80s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 50/125 [01:49<03:02,  2.44s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 51/125 [01:51<02:54,  2.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 52/125 [01:53<02:42,  2.22s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 53/125 [01:56<02:54,  2.42s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [01:57<02:30,  2.12s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 55/125 [01:59<02:23,  2.06s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 56/125 [02:01<02:18,  2.01s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 57/125 [02:05<02:57,  2.61s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 58/125 [02:07<02:39,  2.39s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 59/125 [02:09<02:21,  2.15s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60/125 [02:11<02:14,  2.07s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 61/125 [02:13<02:22,  2.23s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 62/125 [02:15<02:06,  2.00s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 63/125 [02:17<02:09,  2.09s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 64/125 [02:19<02:03,  2.02s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [02:21<02:07,  2.12s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 66/125 [02:24<02:19,  2.37s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 67/125 [02:26<02:03,  2.13s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 68/125 [02:29<02:13,  2.34s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 69/125 [02:30<02:01,  2.17s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 70/125 [02:33<02:10,  2.37s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 71/125 [02:35<01:57,  2.17s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 72/125 [02:37<01:50,  2.08s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 73/125 [02:39<01:44,  2.02s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 74/125 [02:40<01:36,  1.89s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75/125 [02:43<01:42,  2.05s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [02:45<01:50,  2.26s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 77/125 [02:47<01:37,  2.03s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 78/125 [02:50<01:47,  2.28s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 79/125 [02:53<01:52,  2.44s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 80/125 [02:54<01:42,  2.27s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 81/125 [02:57<01:40,  2.27s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 82/125 [03:01<01:58,  2.75s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 83/125 [03:02<01:42,  2.44s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 84/125 [03:05<01:43,  2.53s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [03:07<01:37,  2.43s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 86/125 [03:10<01:33,  2.41s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [03:13<01:39,  2.61s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 88/125 [03:15<01:31,  2.48s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 89/125 [03:18<01:32,  2.58s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90/125 [03:20<01:24,  2.41s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 91/125 [03:22<01:17,  2.29s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 92/125 [03:24<01:13,  2.23s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 93/125 [03:26<01:11,  2.24s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 94/125 [03:28<01:08,  2.20s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 95/125 [03:30<00:59,  1.98s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 96/125 [03:31<00:55,  1.92s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 97/125 [03:33<00:49,  1.77s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [03:35<00:48,  1.81s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 99/125 [03:37<00:47,  1.83s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 100/125 [03:39<00:50,  2.01s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 101/125 [03:41<00:51,  2.15s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 102/125 [03:44<00:49,  2.15s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 103/125 [03:45<00:44,  2.03s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 104/125 [03:47<00:41,  1.98s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105/125 [03:52<00:53,  2.70s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 106/125 [03:55<00:54,  2.89s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 107/125 [03:58<00:50,  2.80s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 108/125 [04:00<00:47,  2.81s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [04:02<00:38,  2.41s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 110/125 [04:04<00:36,  2.43s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 111/125 [04:06<00:30,  2.16s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [04:08<00:28,  2.17s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 113/125 [04:10<00:24,  2.06s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 114/125 [04:11<00:20,  1.90s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 115/125 [04:14<00:21,  2.16s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 116/125 [04:17<00:20,  2.28s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 117/125 [04:19<00:17,  2.22s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 118/125 [04:21<00:14,  2.10s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 119/125 [04:23<00:13,  2.25s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [04:25<00:10,  2.14s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 121/125 [04:28<00:09,  2.34s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 122/125 [04:32<00:08,  2.86s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 123/125 [04:33<00:04,  2.37s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 124/125 [04:36<00:02,  2.49s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.41s/it][A                                                       
                                                 [A 14%|‚ñà‚ñé        | 900/6560 [2:12:22<12:04:32,  7.68s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.41s/it][A
                                                 [A 14%|‚ñà‚ñé        | 901/6560 [2:12:57<157:39:02, 100.29s/it] 14%|‚ñà‚ñç        | 902/6560 [2:13:04<113:44:16, 72.37s/it]  14%|‚ñà‚ñç        | 903/6560 [2:13:13<83:39:51, 53.24s/it]  14%|‚ñà‚ñç        | 904/6560 [2:13:22<62:35:13, 39.84s/it] 14%|‚ñà‚ñç        | 905/6560 [2:13:29<47:16:54, 30.10s/it] 14%|‚ñà‚ñç        | 906/6560 [2:13:39<37:58:23, 24.18s/it] 14%|‚ñà‚ñç        | 907/6560 [2:13:49<31:09:27, 19.84s/it] 14%|‚ñà‚ñç        | 908/6560 [2:13:57<25:31:05, 16.25s/it] 14%|‚ñà‚ñç        | 909/6560 [2:14:05<21:45:39, 13.86s/it] 14%|‚ñà‚ñç        | 910/6560 [2:14:15<19:44:16, 12.58s/it] 14%|‚ñà‚ñç        | 911/6560 [2:14:22<17:08:18, 10.92s/it] 14%|‚ñà‚ñç        | 912/6560 [2:14:31<16:24:53, 10.46s/it] 14%|‚ñà‚ñç        | 913/6560 [2:14:43<17:15:06, 11.00s/it] 14%|‚ñà‚ñç        | 914/6560 [2:14:53<16:29:08, 10.51s/it] 14%|‚ñà‚ñç        | 915/6560 [2:15:00<14:57:34,  9.54s/it] 14%|‚ñà‚ñç        | 916/6560 [2:15:07<13:31:53,  8.63s/it] 14%|‚ñà‚ñç        | 917/6560 [2:15:15<13:22:13,  8.53s/it] 14%|‚ñà‚ñç        | 918/6560 [2:15:24<13:36:28,  8.68s/it] 14%|‚ñà‚ñç        | 919/6560 [2:15:31<13:01:57,  8.32s/it] 14%|‚ñà‚ñç        | 920/6560 [2:15:39<12:38:04,  8.06s/it]                                                        14%|‚ñà‚ñç        | 920/6560 [2:15:39<12:38:04,  8.06s/it] 14%|‚ñà‚ñç        | 921/6560 [2:15:46<12:19:06,  7.86s/it] 14%|‚ñà‚ñç        | 922/6560 [2:15:53<11:47:42,  7.53s/it] 14%|‚ñà‚ñç        | 923/6560 [2:16:03<12:55:34,  8.26s/it] 14%|‚ñà‚ñç        | 924/6560 [2:16:13<13:35:55,  8.69s/it] 14%|‚ñà‚ñç        | 925/6560 [2:16:21<13:31:27,  8.64s/it] 14%|‚ñà‚ñç        | 926/6560 [2:16:29<13:03:28,  8.34s/it] 14%|‚ñà‚ñç        | 927/6560 [2:16:37<13:08:53,  8.40s/it] 14%|‚ñà‚ñç        | 928/6560 [2:16:46<13:26:13,  8.59s/it] 14%|‚ñà‚ñç        | 929/6560 [2:16:55<13:16:05,  8.48s/it] 14%|‚ñà‚ñç        | 930/6560 [2:17:02<12:47:53,  8.18s/it] 14%|‚ñà‚ñç        | 931/6560 [2:17:14<14:20:03,  9.17s/it] 14%|‚ñà‚ñç        | 932/6560 [2:17:21<13:36:00,  8.70s/it] 14%|‚ñà‚ñç        | 933/6560 [2:17:30<13:34:36,  8.69s/it] 14%|‚ñà‚ñç        | 934/6560 [2:17:39<13:37:55,  8.72s/it] 14%|‚ñà‚ñç        | 935/6560 [2:17:46<12:49:12,  8.20s/it] 14%|‚ñà‚ñç        | 936/6560 [2:17:53<12:28:05,  7.98s/it] 14%|‚ñà‚ñç        | 937/6560 [2:18:00<12:05:48,  7.74s/it] 14%|‚ñà‚ñç        | 938/6560 [2:18:10<12:48:49,  8.21s/it] 14%|‚ñà‚ñç        | 939/6560 [2:18:18<12:47:11,  8.19s/it] 14%|‚ñà‚ñç        | 940/6560 [2:18:25<12:31:29,  8.02s/it] 14%|‚ñà‚ñç        | 941/6560 [2:18:34<12:42:18,  8.14s/it] 14%|‚ñà‚ñç        | 942/6560 [2:18:41<12:20:14,  7.91s/it] 14%|‚ñà‚ñç        | 943/6560 [2:18:50<12:50:04,  8.23s/it] 14%|‚ñà‚ñç        | 944/6560 [2:18:57<12:00:01,  7.69s/it] 14%|‚ñà‚ñç        | 945/6560 [2:19:04<11:54:32,  7.64s/it] 14%|‚ñà‚ñç        | 946/6560 [2:19:13<12:24:17,  7.95s/it] 14%|‚ñà‚ñç        | 947/6560 [2:19:20<12:07:44,  7.78s/it] 14%|‚ñà‚ñç        | 948/6560 [2:19:28<12:10:52,  7.81s/it] 14%|‚ñà‚ñç        | 949/6560 [2:19:38<13:05:06,  8.40s/it] 14%|‚ñà‚ñç        | 950/6560 [2:19:46<12:46:10,  8.19s/it] 14%|‚ñà‚ñç        | 951/6560 [2:19:53<12:15:06,  7.86s/it] 15%|‚ñà‚ñç        | 952/6560 [2:20:00<11:54:33,  7.65s/it] 15%|‚ñà‚ñç        | 953/6560 [2:20:08<12:14:49,  7.86s/it] 15%|‚ñà‚ñç        | 954/6560 [2:20:16<12:26:34,  7.99s/it] 15%|‚ñà‚ñç        | 955/6560 [2:20:26<12:57:13,  8.32s/it] 15%|‚ñà‚ñç        | 956/6560 [2:20:36<13:57:13,  8.96s/it] 15%|‚ñà‚ñç        | 957/6560 [2:20:43<12:58:54,  8.34s/it] 15%|‚ñà‚ñç        | 958/6560 [2:20:52<13:15:27,  8.52s/it] 15%|‚ñà‚ñç        | 959/6560 [2:20:58<12:04:14,  7.76s/it] 15%|‚ñà‚ñç        | 960/6560 [2:21:04<11:23:51,  7.33s/it]                                                        15%|‚ñà‚ñç        | 960/6560 [2:21:04<11:23:51,  7.33s/it] 15%|‚ñà‚ñç        | 961/6560 [2:21:13<12:13:51,  7.86s/it] 15%|‚ñà‚ñç        | 962/6560 [2:21:22<12:30:10,  8.04s/it] 15%|‚ñà‚ñç        | 963/6560 [2:21:28<11:33:44,  7.44s/it] 15%|‚ñà‚ñç        | 964/6560 [2:21:35<11:35:28,  7.46s/it] 15%|‚ñà‚ñç        | 965/6560 [2:21:43<11:41:46,  7.53s/it] 15%|‚ñà‚ñç        | 966/6560 [2:21:52<12:29:17,  8.04s/it] 15%|‚ñà‚ñç        | 967/6560 [2:22:00<12:22:29,  7.97s/it] 15%|‚ñà‚ñç        | 968/6560 [2:22:07<11:44:57,  7.56s/it] 15%|‚ñà‚ñç        | 969/6560 [2:22:16<12:35:29,  8.11s/it] 15%|‚ñà‚ñç        | 970/6560 [2:22:26<13:42:22,  8.83s/it] 15%|‚ñà‚ñç        | 971/6560 [2:22:34<13:04:05,  8.42s/it] 15%|‚ñà‚ñç        | 972/6560 [2:22:42<12:41:43,  8.18s/it] 15%|‚ñà‚ñç        | 973/6560 [2:22:51<13:24:08,  8.64s/it] 15%|‚ñà‚ñç        | 974/6560 [2:22:58<12:27:45,  8.03s/it] 15%|‚ñà‚ñç        | 975/6560 [2:23:06<12:24:41,  8.00s/it] 15%|‚ñà‚ñç        | 976/6560 [2:23:13<11:52:55,  7.66s/it] 15%|‚ñà‚ñç        | 977/6560 [2:23:21<12:12:22,  7.87s/it] 15%|‚ñà‚ñç        | 978/6560 [2:23:30<12:46:59,  8.24s/it] 15%|‚ñà‚ñç        | 979/6560 [2:23:39<13:05:53,  8.45s/it] 15%|‚ñà‚ñç        | 980/6560 [2:23:46<12:30:40,  8.07s/it] 15%|‚ñà‚ñç        | 981/6560 [2:23:53<12:03:27,  7.78s/it] 15%|‚ñà‚ñç        | 982/6560 [2:24:00<11:29:20,  7.41s/it] 15%|‚ñà‚ñç        | 983/6560 [2:24:07<11:23:37,  7.35s/it] 15%|‚ñà‚ñå        | 984/6560 [2:24:16<11:59:14,  7.74s/it] 15%|‚ñà‚ñå        | 985/6560 [2:24:24<12:10:13,  7.86s/it] 15%|‚ñà‚ñå        | 986/6560 [2:24:30<11:32:12,  7.45s/it] 15%|‚ñà‚ñå        | 987/6560 [2:24:39<12:08:18,  7.84s/it] 15%|‚ñà‚ñå        | 988/6560 [2:24:47<12:17:58,  7.95s/it] 15%|‚ñà‚ñå        | 989/6560 [2:24:54<11:34:57,  7.48s/it] 15%|‚ñà‚ñå        | 990/6560 [2:25:01<11:29:34,  7.43s/it] 15%|‚ñà‚ñå        | 991/6560 [2:25:07<10:49:49,  7.00s/it] 15%|‚ñà‚ñå        | 992/6560 [2:25:14<10:42:49,  6.93s/it] 15%|‚ñà‚ñå        | 993/6560 [2:25:22<11:11:19,  7.24s/it] 15%|‚ñà‚ñå        | 994/6560 [2:25:30<11:25:39,  7.39s/it] 15%|‚ñà‚ñå        | 995/6560 [2:25:36<10:49:14,  7.00s/it] 15%|‚ñà‚ñå        | 996/6560 [2:25:43<11:12:07,  7.25s/it] 15%|‚ñà‚ñå        | 997/6560 [2:25:52<11:57:44,  7.74s/it] 15%|‚ñà‚ñå        | 998/6560 [2:25:59<11:25:21,  7.39s/it] 15%|‚ñà‚ñå        | 999/6560 [2:26:07<11:38:19,  7.53s/it] 15%|‚ñà‚ñå        | 1000/6560 [2:26:13<11:13:17,  7.27s/it]                                                         15%|‚ñà‚ñå        | 1000/6560 [2:26:13<11:13:17,  7.27s/it] 15%|‚ñà‚ñå        | 1001/6560 [2:26:22<11:40:10,  7.56s/it] 15%|‚ñà‚ñå        | 1002/6560 [2:26:29<11:37:40,  7.53s/it] 15%|‚ñà‚ñå        | 1003/6560 [2:26:37<11:48:00,  7.64s/it] 15%|‚ñà‚ñå        | 1004/6560 [2:26:44<11:27:58,  7.43s/it] 15%|‚ñà‚ñå        | 1005/6560 [2:26:51<11:26:31,  7.42s/it] 15%|‚ñà‚ñå        | 1006/6560 [2:26:59<11:26:21,  7.41s/it] 15%|‚ñà‚ñå        | 1007/6560 [2:27:06<11:22:55,  7.38s/it] 15%|‚ñà‚ñå        | 1008/6560 [2:27:14<11:43:41,  7.60s/it] 15%|‚ñà‚ñå        | 1009/6560 [2:27:22<11:54:58,  7.73s/it] 15%|‚ñà‚ñå        | 1010/6560 [2:27:30<11:51:26,  7.69s/it] 15%|‚ñà‚ñå        | 1011/6560 [2:27:36<11:10:45,  7.25s/it] 15%|‚ñà‚ñå        | 1012/6560 [2:27:44<11:30:31,  7.47s/it] 15%|‚ñà‚ñå        | 1013/6560 [2:27:51<11:18:43,  7.34s/it] 15%|‚ñà‚ñå        | 1014/6560 [2:27:59<11:29:58,  7.46s/it] 15%|‚ñà‚ñå        | 1015/6560 [2:28:07<11:37:37,  7.55s/it] 15%|‚ñà‚ñå        | 1016/6560 [2:28:15<12:11:13,  7.91s/it] 16%|‚ñà‚ñå        | 1017/6560 [2:28:23<12:16:00,  7.97s/it] 16%|‚ñà‚ñå        | 1018/6560 [2:28:30<11:42:05,  7.60s/it] 16%|‚ñà‚ñå        | 1019/6560 [2:28:39<12:30:46,  8.13s/it] 16%|‚ñà‚ñå        | 1020/6560 [2:28:45<11:22:37,  7.39s/it] 16%|‚ñà‚ñå        | 1021/6560 [2:28:54<12:03:59,  7.84s/it] 16%|‚ñà‚ñå        | 1022/6560 [2:29:03<12:30:19,  8.13s/it] 16%|‚ñà‚ñå        | 1023/6560 [2:29:11<12:28:48,  8.11s/it] 16%|‚ñà‚ñå        | 1024/6560 [2:29:20<12:45:47,  8.30s/it] 16%|‚ñà‚ñå        | 1025/6560 [2:29:28<12:57:42,  8.43s/it] 16%|‚ñà‚ñå        | 1026/6560 [2:29:35<12:19:13,  8.01s/it] 16%|‚ñà‚ñå        | 1027/6560 [2:29:44<12:40:22,  8.25s/it] 16%|‚ñà‚ñå        | 1028/6560 [2:29:52<12:15:41,  7.98s/it] 16%|‚ñà‚ñå        | 1029/6560 [2:30:00<12:29:50,  8.13s/it] 16%|‚ñà‚ñå        | 1030/6560 [2:30:07<11:47:02,  7.67s/it] 16%|‚ñà‚ñå        | 1031/6560 [2:30:16<12:26:13,  8.10s/it] 16%|‚ñà‚ñå        | 1032/6560 [2:30:23<12:08:36,  7.91s/it] 16%|‚ñà‚ñå        | 1033/6560 [2:30:30<11:33:26,  7.53s/it] 16%|‚ñà‚ñå        | 1034/6560 [2:30:36<11:06:06,  7.23s/it] 16%|‚ñà‚ñå        | 1035/6560 [2:30:46<11:58:02,  7.80s/it] 16%|‚ñà‚ñå        | 1036/6560 [2:30:53<11:58:41,  7.81s/it] 16%|‚ñà‚ñå        | 1037/6560 [2:31:02<12:13:02,  7.96s/it] 16%|‚ñà‚ñå        | 1038/6560 [2:31:10<12:14:00,  7.98s/it] 16%|‚ñà‚ñå        | 1039/6560 [2:31:18<12:27:13,  8.12s/it] 16%|‚ñà‚ñå        | 1040/6560 [2:31:25<11:50:01,  7.72s/it]                                                         16%|‚ñà‚ñå        | 1040/6560 [2:31:25<11:50:01,  7.72s/it] 16%|‚ñà‚ñå        | 1041/6560 [2:31:33<11:52:03,  7.74s/it] 16%|‚ñà‚ñå        | 1042/6560 [2:31:42<12:32:17,  8.18s/it] 16%|‚ñà‚ñå        | 1043/6560 [2:31:50<12:17:55,  8.03s/it] 16%|‚ñà‚ñå        | 1044/6560 [2:31:57<12:00:43,  7.84s/it] 16%|‚ñà‚ñå        | 1045/6560 [2:32:05<11:58:49,  7.82s/it] 16%|‚ñà‚ñå        | 1046/6560 [2:32:13<11:58:56,  7.82s/it] 16%|‚ñà‚ñå        | 1047/6560 [2:32:19<11:23:05,  7.43s/it] 16%|‚ñà‚ñå        | 1048/6560 [2:32:25<10:48:47,  7.06s/it] 16%|‚ñà‚ñå        | 1049/6560 [2:32:33<11:14:34,  7.34s/it] 16%|‚ñà‚ñå        | 1050/6560 [2:32:40<10:55:19,  7.14s/it] 16%|‚ñà‚ñå        | 1051/6560 [2:32:49<11:43:41,  7.66s/it] 16%|‚ñà‚ñå        | 1052/6560 [2:32:56<11:27:28,  7.49s/it] 16%|‚ñà‚ñå        | 1053/6560 [2:33:03<11:23:01,  7.44s/it] 16%|‚ñà‚ñå        | 1054/6560 [2:33:11<11:22:45,  7.44s/it] 16%|‚ñà‚ñå        | 1055/6560 [2:33:19<11:36:07,  7.59s/it] 16%|‚ñà‚ñå        | 1056/6560 [2:33:26<11:25:48,  7.48s/it] 16%|‚ñà‚ñå        | 1057/6560 [2:33:32<10:44:06,  7.02s/it] 16%|‚ñà‚ñå        | 1058/6560 [2:33:40<11:24:20,  7.46s/it] 16%|‚ñà‚ñå        | 1059/6560 [2:33:49<11:57:24,  7.82s/it] 16%|‚ñà‚ñå        | 1060/6560 [2:33:57<11:59:50,  7.85s/it] 16%|‚ñà‚ñå        | 1061/6560 [2:34:04<11:26:18,  7.49s/it] 16%|‚ñà‚ñå        | 1062/6560 [2:34:11<11:33:26,  7.57s/it] 16%|‚ñà‚ñå        | 1063/6560 [2:34:18<10:59:49,  7.20s/it] 16%|‚ñà‚ñå        | 1064/6560 [2:34:26<11:18:53,  7.41s/it] 16%|‚ñà‚ñå        | 1065/6560 [2:34:34<11:36:06,  7.60s/it] 16%|‚ñà‚ñã        | 1066/6560 [2:34:41<11:42:07,  7.67s/it] 16%|‚ñà‚ñã        | 1067/6560 [2:34:49<11:39:57,  7.65s/it] 16%|‚ñà‚ñã        | 1068/6560 [2:34:57<11:41:27,  7.66s/it] 16%|‚ñà‚ñã        | 1069/6560 [2:35:04<11:18:07,  7.41s/it] 16%|‚ñà‚ñã        | 1070/6560 [2:35:12<11:35:34,  7.60s/it] 16%|‚ñà‚ñã        | 1071/6560 [2:35:20<11:44:54,  7.71s/it] 16%|‚ñà‚ñã        | 1072/6560 [2:35:26<11:19:41,  7.43s/it] 16%|‚ñà‚ñã        | 1073/6560 [2:35:34<11:26:01,  7.50s/it] 16%|‚ñà‚ñã        | 1074/6560 [2:35:41<11:16:51,  7.40s/it] 16%|‚ñà‚ñã        | 1075/6560 [2:35:51<12:14:40,  8.04s/it] 16%|‚ñà‚ñã        | 1076/6560 [2:35:59<12:16:22,  8.06s/it] 16%|‚ñà‚ñã        | 1077/6560 [2:36:07<12:13:24,  8.03s/it] 16%|‚ñà‚ñã        | 1078/6560 [2:36:14<12:05:08,  7.94s/it] 16%|‚ñà‚ñã        | 1079/6560 [2:36:23<12:10:37,  8.00s/it] 16%|‚ñà‚ñã        | 1080/6560 [2:36:30<11:54:43,  7.83s/it]                                                         16%|‚ñà‚ñã        | 1080/6560 [2:36:30<11:54:43,  7.83s/it] 16%|‚ñà‚ñã        | 1081/6560 [2:36:37<11:41:52,  7.69s/it] 16%|‚ñà‚ñã        | 1082/6560 [2:36:45<11:49:00,  7.77s/it] 17%|‚ñà‚ñã        | 1083/6560 [2:36:53<11:48:25,  7.76s/it] 17%|‚ñà‚ñã        | 1084/6560 [2:37:02<12:11:24,  8.01s/it] 17%|‚ñà‚ñã        | 1085/6560 [2:37:10<12:16:53,  8.08s/it] 17%|‚ñà‚ñã        | 1086/6560 [2:37:17<11:50:54,  7.79s/it] 17%|‚ñà‚ñã        | 1087/6560 [2:37:23<11:09:04,  7.34s/it] 17%|‚ñà‚ñã        | 1088/6560 [2:37:29<10:27:49,  6.88s/it] 17%|‚ñà‚ñã        | 1089/6560 [2:37:37<10:41:52,  7.04s/it] 17%|‚ñà‚ñã        | 1090/6560 [2:37:43<10:36:02,  6.98s/it] 17%|‚ñà‚ñã        | 1091/6560 [2:37:50<10:34:33,  6.96s/it] 17%|‚ñà‚ñã        | 1092/6560 [2:38:00<11:48:29,  7.77s/it] 17%|‚ñà‚ñã        | 1093/6560 [2:38:08<11:59:40,  7.90s/it] 17%|‚ñà‚ñã        | 1094/6560 [2:38:16<11:51:29,  7.81s/it] 17%|‚ñà‚ñã        | 1095/6560 [2:38:24<11:58:29,  7.89s/it] 17%|‚ñà‚ñã        | 1096/6560 [2:38:31<11:42:01,  7.71s/it] 17%|‚ñà‚ñã        | 1097/6560 [2:38:38<11:24:48,  7.52s/it] 17%|‚ñà‚ñã        | 1098/6560 [2:38:47<11:50:33,  7.81s/it] 17%|‚ñà‚ñã        | 1099/6560 [2:38:55<12:12:16,  8.05s/it] 17%|‚ñà‚ñã        | 1100/6560 [2:39:05<12:46:41,  8.43s/it] 17%|‚ñà‚ñã        | 1101/6560 [2:39:12<12:29:22,  8.24s/it] 17%|‚ñà‚ñã        | 1102/6560 [2:39:19<11:53:46,  7.85s/it] 17%|‚ñà‚ñã        | 1103/6560 [2:39:28<12:09:37,  8.02s/it] 17%|‚ñà‚ñã        | 1104/6560 [2:39:34<11:33:51,  7.63s/it] 17%|‚ñà‚ñã        | 1105/6560 [2:39:46<13:06:45,  8.65s/it] 17%|‚ñà‚ñã        | 1106/6560 [2:39:52<12:17:45,  8.12s/it] 17%|‚ñà‚ñã        | 1107/6560 [2:40:02<13:02:34,  8.61s/it] 17%|‚ñà‚ñã        | 1108/6560 [2:40:10<12:37:06,  8.33s/it] 17%|‚ñà‚ñã        | 1109/6560 [2:40:16<11:30:54,  7.61s/it] 17%|‚ñà‚ñã        | 1110/6560 [2:40:27<13:07:52,  8.67s/it] 17%|‚ñà‚ñã        | 1111/6560 [2:40:35<13:00:56,  8.60s/it] 17%|‚ñà‚ñã        | 1112/6560 [2:40:42<12:18:27,  8.13s/it] 17%|‚ñà‚ñã        | 1113/6560 [2:40:48<11:18:30,  7.47s/it] 17%|‚ñà‚ñã        | 1114/6560 [2:40:56<11:21:17,  7.51s/it] 17%|‚ñà‚ñã        | 1115/6560 [2:41:02<10:47:06,  7.13s/it] 17%|‚ñà‚ñã        | 1116/6560 [2:41:10<10:56:52,  7.24s/it] 17%|‚ñà‚ñã        | 1117/6560 [2:41:17<11:10:12,  7.39s/it] 17%|‚ñà‚ñã        | 1118/6560 [2:41:23<10:33:11,  6.98s/it] 17%|‚ñà‚ñã        | 1119/6560 [2:41:32<11:12:17,  7.41s/it] 17%|‚ñà‚ñã        | 1120/6560 [2:41:40<11:26:35,  7.57s/it]                                                         17%|‚ñà‚ñã        | 1120/6560 [2:41:40<11:26:35,  7.57s/it] 17%|‚ñà‚ñã        | 1121/6560 [2:41:48<11:39:51,  7.72s/it] 17%|‚ñà‚ñã        | 1122/6560 [2:41:56<11:56:55,  7.91s/it] 17%|‚ñà‚ñã        | 1123/6560 [2:42:03<11:39:49,  7.72s/it] 17%|‚ñà‚ñã        | 1124/6560 [2:42:11<11:31:37,  7.63s/it] 17%|‚ñà‚ñã        | 1125/6560 [2:42:18<11:11:58,  7.42s/it] 17%|‚ñà‚ñã        | 1126/6560 [2:42:26<11:36:29,  7.69s/it] 17%|‚ñà‚ñã        | 1127/6560 [2:42:34<11:41:48,  7.75s/it] 17%|‚ñà‚ñã        | 1128/6560 [2:42:44<12:29:43,  8.28s/it] 17%|‚ñà‚ñã        | 1129/6560 [2:42:52<12:42:03,  8.42s/it] 17%|‚ñà‚ñã        | 1130/6560 [2:43:00<12:10:10,  8.07s/it] 17%|‚ñà‚ñã        | 1131/6560 [2:43:07<11:39:55,  7.74s/it] 17%|‚ñà‚ñã        | 1132/6560 [2:43:18<13:20:05,  8.84s/it] 17%|‚ñà‚ñã        | 1133/6560 [2:43:24<12:10:28,  8.08s/it] 17%|‚ñà‚ñã        | 1134/6560 [2:43:32<12:01:51,  7.98s/it] 17%|‚ñà‚ñã        | 1135/6560 [2:43:40<12:12:49,  8.10s/it] 17%|‚ñà‚ñã        | 1136/6560 [2:43:48<11:47:12,  7.82s/it] 17%|‚ñà‚ñã        | 1137/6560 [2:43:57<12:39:50,  8.41s/it] 17%|‚ñà‚ñã        | 1138/6560 [2:44:04<11:40:19,  7.75s/it] 17%|‚ñà‚ñã        | 1139/6560 [2:44:12<12:01:49,  7.99s/it] 17%|‚ñà‚ñã        | 1140/6560 [2:44:20<12:12:39,  8.11s/it] 17%|‚ñà‚ñã        | 1141/6560 [2:44:28<11:56:38,  7.93s/it] 17%|‚ñà‚ñã        | 1142/6560 [2:44:35<11:26:52,  7.61s/it] 17%|‚ñà‚ñã        | 1143/6560 [2:44:42<11:26:46,  7.61s/it] 17%|‚ñà‚ñã        | 1144/6560 [2:44:49<11:08:15,  7.40s/it] 17%|‚ñà‚ñã        | 1145/6560 [2:44:57<11:03:06,  7.35s/it] 17%|‚ñà‚ñã        | 1146/6560 [2:45:04<10:56:03,  7.27s/it] 17%|‚ñà‚ñã        | 1147/6560 [2:45:11<11:08:45,  7.41s/it] 18%|‚ñà‚ñä        | 1148/6560 [2:45:19<11:06:44,  7.39s/it] 18%|‚ñà‚ñä        | 1149/6560 [2:45:27<11:24:03,  7.59s/it] 18%|‚ñà‚ñä        | 1150/6560 [2:45:34<11:09:58,  7.43s/it] 18%|‚ñà‚ñä        | 1151/6560 [2:45:40<10:46:32,  7.17s/it] 18%|‚ñà‚ñä        | 1152/6560 [2:45:48<11:07:48,  7.41s/it] 18%|‚ñà‚ñä        | 1153/6560 [2:45:55<10:48:59,  7.20s/it] 18%|‚ñà‚ñä        | 1154/6560 [2:46:03<11:03:36,  7.37s/it] 18%|‚ñà‚ñä        | 1155/6560 [2:46:11<11:18:31,  7.53s/it] 18%|‚ñà‚ñä        | 1156/6560 [2:46:20<11:53:40,  7.92s/it] 18%|‚ñà‚ñä        | 1157/6560 [2:46:26<11:18:44,  7.54s/it] 18%|‚ñà‚ñä        | 1158/6560 [2:46:34<11:16:07,  7.51s/it] 18%|‚ñà‚ñä        | 1159/6560 [2:46:41<11:19:39,  7.55s/it] 18%|‚ñà‚ñä        | 1160/6560 [2:46:50<11:38:26,  7.76s/it]                                                         18%|‚ñà‚ñä        | 1160/6560 [2:46:50<11:38:26,  7.76s/it] 18%|‚ñà‚ñä        | 1161/6560 [2:46:57<11:18:21,  7.54s/it] 18%|‚ñà‚ñä        | 1162/6560 [2:47:05<11:28:47,  7.66s/it] 18%|‚ñà‚ñä        | 1163/6560 [2:47:11<11:08:59,  7.44s/it] 18%|‚ñà‚ñä        | 1164/6560 [2:47:19<11:16:34,  7.52s/it] 18%|‚ñà‚ñä        | 1165/6560 [2:47:27<11:14:24,  7.50s/it] 18%|‚ñà‚ñä        | 1166/6560 [2:47:33<10:55:19,  7.29s/it] 18%|‚ñà‚ñä        | 1167/6560 [2:47:41<11:07:53,  7.43s/it] 18%|‚ñà‚ñä        | 1168/6560 [2:47:49<11:04:58,  7.40s/it] 18%|‚ñà‚ñä        | 1169/6560 [2:47:57<11:24:54,  7.62s/it] 18%|‚ñà‚ñä        | 1170/6560 [2:48:03<10:49:31,  7.23s/it] 18%|‚ñà‚ñä        | 1171/6560 [2:48:09<10:09:22,  6.78s/it] 18%|‚ñà‚ñä        | 1172/6560 [2:48:18<11:23:37,  7.61s/it] 18%|‚ñà‚ñä        | 1173/6560 [2:48:29<12:44:15,  8.51s/it] 18%|‚ñà‚ñä        | 1174/6560 [2:48:37<12:38:43,  8.45s/it] 18%|‚ñà‚ñä        | 1175/6560 [2:48:44<12:01:26,  8.04s/it] 18%|‚ñà‚ñä        | 1176/6560 [2:48:52<11:43:06,  7.84s/it] 18%|‚ñà‚ñä        | 1177/6560 [2:49:00<11:59:25,  8.02s/it] 18%|‚ñà‚ñä        | 1178/6560 [2:49:07<11:19:52,  7.58s/it] 18%|‚ñà‚ñä        | 1179/6560 [2:49:14<11:14:02,  7.52s/it] 18%|‚ñà‚ñä        | 1180/6560 [2:49:23<11:47:20,  7.89s/it] 18%|‚ñà‚ñä        | 1181/6560 [2:49:33<12:40:41,  8.49s/it] 18%|‚ñà‚ñä        | 1182/6560 [2:49:42<13:00:57,  8.71s/it] 18%|‚ñà‚ñä        | 1183/6560 [2:49:47<11:33:28,  7.74s/it] 18%|‚ñà‚ñä        | 1184/6560 [2:49:57<12:20:45,  8.27s/it] 18%|‚ñà‚ñä        | 1185/6560 [2:50:05<12:29:31,  8.37s/it] 18%|‚ñà‚ñä        | 1186/6560 [2:50:13<12:17:43,  8.24s/it] 18%|‚ñà‚ñä        | 1187/6560 [2:50:23<12:58:48,  8.70s/it] 18%|‚ñà‚ñä        | 1188/6560 [2:50:32<12:55:21,  8.66s/it] 18%|‚ñà‚ñä        | 1189/6560 [2:50:39<12:22:15,  8.29s/it] 18%|‚ñà‚ñä        | 1190/6560 [2:50:45<11:04:58,  7.43s/it] 18%|‚ñà‚ñä        | 1191/6560 [2:50:50<10:18:29,  6.91s/it] 18%|‚ñà‚ñä        | 1192/6560 [2:50:59<11:06:05,  7.45s/it] 18%|‚ñà‚ñä        | 1193/6560 [2:51:05<10:33:40,  7.08s/it] 18%|‚ñà‚ñä        | 1194/6560 [2:51:14<11:11:28,  7.51s/it] 18%|‚ñà‚ñä        | 1195/6560 [2:51:20<10:40:14,  7.16s/it] 18%|‚ñà‚ñä        | 1196/6560 [2:51:29<11:25:31,  7.67s/it] 18%|‚ñà‚ñä        | 1197/6560 [2:51:37<11:33:26,  7.76s/it] 18%|‚ñà‚ñä        | 1198/6560 [2:51:45<11:29:24,  7.71s/it] 18%|‚ñà‚ñä        | 1199/6560 [2:51:53<11:48:40,  7.93s/it] 18%|‚ñà‚ñä        | 1200/6560 [2:52:01<12:02:30,  8.09s/it]                                                         18%|‚ñà‚ñä        | 1200/6560 [2:52:01<12:02:30,  8.09s/it]
  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|‚ñè         | 2/125 [00:03<04:02,  1.97s/it][A
  2%|‚ñè         | 3/125 [00:07<05:30,  2.71s/it][A
  3%|‚ñé         | 4/125 [00:10<05:28,  2.71s/it][A
  4%|‚ñç         | 5/125 [00:12<05:16,  2.63s/it][A
  5%|‚ñç         | 6/125 [00:15<04:59,  2.51s/it][A
  6%|‚ñå         | 7/125 [00:17<04:55,  2.51s/it][A
  6%|‚ñã         | 8/125 [00:20<04:47,  2.46s/it][A
  7%|‚ñã         | 9/125 [00:21<04:10,  2.16s/it][A
  8%|‚ñä         | 10/125 [00:23<03:58,  2.07s/it][A
  9%|‚ñâ         | 11/125 [00:25<03:54,  2.05s/it][A
 10%|‚ñâ         | 12/125 [00:27<03:57,  2.10s/it][A
 10%|‚ñà         | 13/125 [00:29<04:04,  2.18s/it][A
 11%|‚ñà         | 14/125 [00:31<03:46,  2.04s/it][A
 12%|‚ñà‚ñè        | 15/125 [00:33<03:33,  1.94s/it][A
 13%|‚ñà‚ñé        | 16/125 [00:35<03:26,  1.90s/it][A
 14%|‚ñà‚ñé        | 17/125 [00:36<03:14,  1.80s/it][A
 14%|‚ñà‚ñç        | 18/125 [00:38<03:21,  1.88s/it][A
 15%|‚ñà‚ñå        | 19/125 [00:40<02:58,  1.68s/it][A
 16%|‚ñà‚ñå        | 20/125 [00:41<03:00,  1.72s/it][A
 17%|‚ñà‚ñã        | 21/125 [00:43<02:50,  1.64s/it][A
 18%|‚ñà‚ñä        | 22/125 [00:45<03:11,  1.86s/it][A
 18%|‚ñà‚ñä        | 23/125 [00:47<02:57,  1.74s/it][A
 19%|‚ñà‚ñâ        | 24/125 [00:48<02:51,  1.70s/it][A
 20%|‚ñà‚ñà        | 25/125 [00:51<03:16,  1.96s/it][A
 21%|‚ñà‚ñà        | 26/125 [00:54<03:37,  2.19s/it][A
 22%|‚ñà‚ñà‚ñè       | 27/125 [00:56<03:40,  2.25s/it][A
 22%|‚ñà‚ñà‚ñè       | 28/125 [00:59<03:56,  2.43s/it][A
 23%|‚ñà‚ñà‚ñé       | 29/125 [01:01<03:48,  2.38s/it][A
 24%|‚ñà‚ñà‚ñç       | 30/125 [01:03<03:21,  2.12s/it][A
 25%|‚ñà‚ñà‚ñç       | 31/125 [01:04<03:13,  2.06s/it][A
 26%|‚ñà‚ñà‚ñå       | 32/125 [01:06<03:05,  2.00s/it][A
 26%|‚ñà‚ñà‚ñã       | 33/125 [01:09<03:09,  2.06s/it][A
 27%|‚ñà‚ñà‚ñã       | 34/125 [01:11<03:15,  2.15s/it][A
 28%|‚ñà‚ñà‚ñä       | 35/125 [01:14<03:32,  2.36s/it][A
 29%|‚ñà‚ñà‚ñâ       | 36/125 [01:16<03:22,  2.28s/it][A
 30%|‚ñà‚ñà‚ñâ       | 37/125 [01:19<03:32,  2.42s/it][A
 30%|‚ñà‚ñà‚ñà       | 38/125 [01:21<03:34,  2.47s/it][A
 31%|‚ñà‚ñà‚ñà       | 39/125 [01:24<03:44,  2.61s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 40/125 [01:26<03:15,  2.30s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 41/125 [01:28<03:05,  2.21s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 42/125 [01:29<02:46,  2.00s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [01:32<02:56,  2.15s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 44/125 [01:34<03:07,  2.32s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 45/125 [01:36<02:47,  2.10s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 46/125 [01:40<03:22,  2.56s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 47/125 [01:42<03:16,  2.52s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 48/125 [01:45<03:15,  2.54s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 49/125 [01:48<03:34,  2.82s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 50/125 [01:50<03:03,  2.45s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 51/125 [01:52<02:55,  2.37s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 52/125 [01:54<02:42,  2.23s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 53/125 [01:57<02:54,  2.42s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [01:58<02:30,  2.12s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 55/125 [02:00<02:23,  2.06s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 56/125 [02:02<02:18,  2.01s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 57/125 [02:06<02:57,  2.61s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 58/125 [02:08<02:39,  2.38s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 59/125 [02:09<02:21,  2.15s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60/125 [02:11<02:14,  2.07s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 61/125 [02:14<02:22,  2.23s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 62/125 [02:15<02:06,  2.00s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 63/125 [02:18<02:09,  2.09s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 64/125 [02:19<02:03,  2.02s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [02:22<02:07,  2.12s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 66/125 [02:25<02:19,  2.36s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 67/125 [02:26<02:03,  2.13s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 68/125 [02:29<02:13,  2.34s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 69/125 [02:31<02:01,  2.17s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 70/125 [02:34<02:10,  2.37s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 71/125 [02:35<01:57,  2.17s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 72/125 [02:37<01:50,  2.08s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 73/125 [02:39<01:44,  2.01s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 74/125 [02:41<01:36,  1.89s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75/125 [02:43<01:42,  2.05s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [02:46<01:50,  2.25s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 77/125 [02:47<01:37,  2.03s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 78/125 [02:50<01:47,  2.28s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 79/125 [02:53<01:52,  2.44s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 80/125 [02:55<01:42,  2.27s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 81/125 [02:57<01:39,  2.27s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 82/125 [03:01<01:58,  2.74s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 83/125 [03:03<01:42,  2.44s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 84/125 [03:06<01:43,  2.52s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [03:08<01:37,  2.43s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 86/125 [03:10<01:33,  2.41s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [03:13<01:39,  2.61s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 88/125 [03:15<01:31,  2.47s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 89/125 [03:18<01:32,  2.58s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90/125 [03:20<01:24,  2.41s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 91/125 [03:22<01:17,  2.29s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 92/125 [03:24<01:13,  2.23s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 93/125 [03:27<01:11,  2.24s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 94/125 [03:29<01:08,  2.20s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 95/125 [03:30<00:59,  1.98s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 96/125 [03:32<00:55,  1.93s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 97/125 [03:33<00:49,  1.77s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [03:35<00:49,  1.82s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 99/125 [03:37<00:47,  1.84s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 100/125 [03:40<00:50,  2.02s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 101/125 [03:42<00:51,  2.15s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 102/125 [03:44<00:49,  2.16s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 103/125 [03:46<00:44,  2.03s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 104/125 [03:48<00:41,  1.99s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105/125 [03:52<00:54,  2.70s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 106/125 [03:56<00:54,  2.89s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 107/125 [03:58<00:50,  2.80s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 108/125 [04:01<00:47,  2.81s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [04:02<00:38,  2.41s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 110/125 [04:05<00:36,  2.43s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 111/125 [04:06<00:30,  2.16s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [04:09<00:28,  2.18s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 113/125 [04:10<00:24,  2.06s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 114/125 [04:12<00:20,  1.91s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 115/125 [04:15<00:21,  2.16s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 116/125 [04:17<00:20,  2.28s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 117/125 [04:19<00:17,  2.22s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 118/125 [04:21<00:14,  2.10s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 119/125 [04:24<00:13,  2.25s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [04:26<00:10,  2.14s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 121/125 [04:29<00:09,  2.34s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 122/125 [04:33<00:08,  2.85s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 123/125 [04:34<00:04,  2.37s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 124/125 [04:37<00:02,  2.48s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:39<00:00,  2.40s/it][A                                                        
                                                 [A 18%|‚ñà‚ñä        | 1200/6560 [2:56:43<12:02:30,  8.09s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:39<00:00,  2.40s/it][A
                                                 [A 18%|‚ñà‚ñä        | 1201/6560 [2:57:16<149:01:49, 100.11s/it] 18%|‚ñà‚ñä        | 1202/6560 [2:57:23<107:09:55, 72.00s/it]  18%|‚ñà‚ñä        | 1203/6560 [2:57:31<78:46:09, 52.93s/it]  18%|‚ñà‚ñä        | 1204/6560 [2:57:40<58:57:55, 39.63s/it] 18%|‚ñà‚ñä        | 1205/6560 [2:57:46<44:07:18, 29.66s/it] 18%|‚ñà‚ñä        | 1206/6560 [2:57:55<34:41:07, 23.32s/it] 18%|‚ñà‚ñä        | 1207/6560 [2:58:02<27:25:35, 18.44s/it] 18%|‚ñà‚ñä        | 1208/6560 [2:58:09<22:18:14, 15.00s/it] 18%|‚ñà‚ñä        | 1209/6560 [2:58:15<18:23:17, 12.37s/it] 18%|‚ñà‚ñä        | 1210/6560 [2:58:22<15:54:10, 10.70s/it] 18%|‚ñà‚ñä        | 1211/6560 [2:58:30<14:44:20,  9.92s/it] 18%|‚ñà‚ñä        | 1212/6560 [2:58:37<13:19:18,  8.97s/it] 18%|‚ñà‚ñä        | 1213/6560 [2:58:45<13:00:13,  8.76s/it] 19%|‚ñà‚ñä        | 1214/6560 [2:58:52<12:13:52,  8.24s/it] 19%|‚ñà‚ñä        | 1215/6560 [2:59:00<12:04:06,  8.13s/it] 19%|‚ñà‚ñä        | 1216/6560 [2:59:07<11:54:49,  8.03s/it] 19%|‚ñà‚ñä        | 1217/6560 [2:59:15<11:29:54,  7.75s/it] 19%|‚ñà‚ñä        | 1218/6560 [2:59:22<11:15:30,  7.59s/it] 19%|‚ñà‚ñä        | 1219/6560 [2:59:28<10:42:43,  7.22s/it] 19%|‚ñà‚ñä        | 1220/6560 [2:59:36<10:47:55,  7.28s/it] 19%|‚ñà‚ñä        | 1221/6560 [2:59:44<11:27:52,  7.73s/it] 19%|‚ñà‚ñä        | 1222/6560 [2:59:53<11:52:13,  8.01s/it] 19%|‚ñà‚ñä        | 1223/6560 [3:00:00<11:35:35,  7.82s/it] 19%|‚ñà‚ñä        | 1224/6560 [3:00:08<11:22:03,  7.67s/it] 19%|‚ñà‚ñä        | 1225/6560 [3:00:14<10:55:52,  7.38s/it] 19%|‚ñà‚ñä        | 1226/6560 [3:00:21<10:39:06,  7.19s/it] 19%|‚ñà‚ñä        | 1227/6560 [3:00:27<10:15:02,  6.92s/it] 19%|‚ñà‚ñä        | 1228/6560 [3:00:37<11:34:52,  7.82s/it] 19%|‚ñà‚ñä        | 1229/6560 [3:00:43<10:38:28,  7.19s/it] 19%|‚ñà‚ñâ        | 1230/6560 [3:00:50<10:43:22,  7.24s/it] 19%|‚ñà‚ñâ        | 1231/6560 [3:00:58<10:51:54,  7.34s/it] 19%|‚ñà‚ñâ        | 1232/6560 [3:01:05<10:44:01,  7.25s/it] 19%|‚ñà‚ñâ        | 1233/6560 [3:01:12<10:25:26,  7.04s/it] 19%|‚ñà‚ñâ        | 1234/6560 [3:01:19<10:24:10,  7.03s/it] 19%|‚ñà‚ñâ        | 1235/6560 [3:01:27<10:52:59,  7.36s/it] 19%|‚ñà‚ñâ        | 1236/6560 [3:01:36<11:37:48,  7.86s/it] 19%|‚ñà‚ñâ        | 1237/6560 [3:01:42<11:01:58,  7.46s/it] 19%|‚ñà‚ñâ        | 1238/6560 [3:01:52<11:56:59,  8.08s/it] 19%|‚ñà‚ñâ        | 1239/6560 [3:02:00<12:06:49,  8.20s/it] 19%|‚ñà‚ñâ        | 1240/6560 [3:02:07<11:16:48,  7.63s/it]                                                         19%|‚ñà‚ñâ        | 1240/6560 [3:02:07<11:16:48,  7.63s/it] 19%|‚ñà‚ñâ        | 1241/6560 [3:02:13<10:34:12,  7.15s/it] 19%|‚ñà‚ñâ        | 1242/6560 [3:02:23<11:49:59,  8.01s/it] 19%|‚ñà‚ñâ        | 1243/6560 [3:02:30<11:41:03,  7.91s/it] 19%|‚ñà‚ñâ        | 1244/6560 [3:02:38<11:39:13,  7.89s/it] 19%|‚ñà‚ñâ        | 1245/6560 [3:02:45<11:15:48,  7.63s/it] 19%|‚ñà‚ñâ        | 1246/6560 [3:02:53<11:14:26,  7.62s/it] 19%|‚ñà‚ñâ        | 1247/6560 [3:02:59<10:46:48,  7.30s/it] 19%|‚ñà‚ñâ        | 1248/6560 [3:03:08<11:13:20,  7.61s/it] 19%|‚ñà‚ñâ        | 1249/6560 [3:03:16<11:33:18,  7.83s/it] 19%|‚ñà‚ñâ        | 1250/6560 [3:03:23<11:18:01,  7.66s/it] 19%|‚ñà‚ñâ        | 1251/6560 [3:03:30<10:41:52,  7.25s/it] 19%|‚ñà‚ñâ        | 1252/6560 [3:03:39<11:26:39,  7.76s/it] 19%|‚ñà‚ñâ        | 1253/6560 [3:03:47<11:34:52,  7.86s/it] 19%|‚ñà‚ñâ        | 1254/6560 [3:03:55<12:00:49,  8.15s/it] 19%|‚ñà‚ñâ        | 1255/6560 [3:04:04<12:20:25,  8.37s/it] 19%|‚ñà‚ñâ        | 1256/6560 [3:04:12<11:49:12,  8.02s/it] 19%|‚ñà‚ñâ        | 1257/6560 [3:04:20<11:52:19,  8.06s/it] 19%|‚ñà‚ñâ        | 1258/6560 [3:04:28<12:04:02,  8.19s/it] 19%|‚ñà‚ñâ        | 1259/6560 [3:04:37<12:20:19,  8.38s/it] 19%|‚ñà‚ñâ        | 1260/6560 [3:04:46<12:38:40,  8.59s/it] 19%|‚ñà‚ñâ        | 1261/6560 [3:04:53<12:02:18,  8.18s/it] 19%|‚ñà‚ñâ        | 1262/6560 [3:05:01<11:41:48,  7.95s/it] 19%|‚ñà‚ñâ        | 1263/6560 [3:05:12<12:56:43,  8.80s/it] 19%|‚ñà‚ñâ        | 1264/6560 [3:05:18<11:45:28,  7.99s/it] 19%|‚ñà‚ñâ        | 1265/6560 [3:05:24<11:08:22,  7.57s/it] 19%|‚ñà‚ñâ        | 1266/6560 [3:05:31<10:45:55,  7.32s/it] 19%|‚ñà‚ñâ        | 1267/6560 [3:05:39<10:58:12,  7.46s/it] 19%|‚ñà‚ñâ        | 1268/6560 [3:05:46<10:47:32,  7.34s/it] 19%|‚ñà‚ñâ        | 1269/6560 [3:05:52<10:24:41,  7.08s/it] 19%|‚ñà‚ñâ        | 1270/6560 [3:06:00<10:51:03,  7.38s/it] 19%|‚ñà‚ñâ        | 1271/6560 [3:06:06<10:16:17,  6.99s/it] 19%|‚ñà‚ñâ        | 1272/6560 [3:06:15<10:53:26,  7.41s/it] 19%|‚ñà‚ñâ        | 1273/6560 [3:06:25<12:03:12,  8.21s/it] 19%|‚ñà‚ñâ        | 1274/6560 [3:06:34<12:31:36,  8.53s/it] 19%|‚ñà‚ñâ        | 1275/6560 [3:06:41<11:54:30,  8.11s/it] 19%|‚ñà‚ñâ        | 1276/6560 [3:06:48<11:25:19,  7.78s/it] 19%|‚ñà‚ñâ        | 1277/6560 [3:06:57<11:58:22,  8.16s/it] 19%|‚ñà‚ñâ        | 1278/6560 [3:07:06<11:58:37,  8.16s/it] 19%|‚ñà‚ñâ        | 1279/6560 [3:07:14<12:14:24,  8.34s/it] 20%|‚ñà‚ñâ        | 1280/6560 [3:07:22<12:04:39,  8.23s/it]                                                         20%|‚ñà‚ñâ        | 1280/6560 [3:07:22<12:04:39,  8.23s/it] 20%|‚ñà‚ñâ        | 1281/6560 [3:07:31<12:06:32,  8.26s/it] 20%|‚ñà‚ñâ        | 1282/6560 [3:07:38<11:54:00,  8.12s/it] 20%|‚ñà‚ñâ        | 1283/6560 [3:07:47<12:14:28,  8.35s/it] 20%|‚ñà‚ñâ        | 1284/6560 [3:07:55<11:44:59,  8.02s/it] 20%|‚ñà‚ñâ        | 1285/6560 [3:08:02<11:37:12,  7.93s/it] 20%|‚ñà‚ñâ        | 1286/6560 [3:08:11<11:48:29,  8.06s/it] 20%|‚ñà‚ñâ        | 1287/6560 [3:08:18<11:42:13,  7.99s/it] 20%|‚ñà‚ñâ        | 1288/6560 [3:08:26<11:40:22,  7.97s/it] 20%|‚ñà‚ñâ        | 1289/6560 [3:08:34<11:27:03,  7.82s/it] 20%|‚ñà‚ñâ        | 1290/6560 [3:08:43<11:57:57,  8.17s/it] 20%|‚ñà‚ñâ        | 1291/6560 [3:08:49<11:10:43,  7.64s/it] 20%|‚ñà‚ñâ        | 1292/6560 [3:08:56<10:38:17,  7.27s/it] 20%|‚ñà‚ñâ        | 1293/6560 [3:09:06<11:51:06,  8.10s/it] 20%|‚ñà‚ñâ        | 1294/6560 [3:09:13<11:20:15,  7.75s/it] 20%|‚ñà‚ñâ        | 1295/6560 [3:09:21<11:40:09,  7.98s/it] 20%|‚ñà‚ñâ        | 1296/6560 [3:09:28<11:23:50,  7.79s/it] 20%|‚ñà‚ñâ        | 1297/6560 [3:09:37<11:30:36,  7.87s/it] 20%|‚ñà‚ñâ        | 1298/6560 [3:09:44<11:29:49,  7.87s/it] 20%|‚ñà‚ñâ        | 1299/6560 [3:09:52<11:25:10,  7.81s/it] 20%|‚ñà‚ñâ        | 1300/6560 [3:10:00<11:34:24,  7.92s/it] 20%|‚ñà‚ñâ        | 1301/6560 [3:10:09<12:08:14,  8.31s/it] 20%|‚ñà‚ñâ        | 1302/6560 [3:10:18<12:00:54,  8.23s/it] 20%|‚ñà‚ñâ        | 1303/6560 [3:10:26<12:07:22,  8.30s/it] 20%|‚ñà‚ñâ        | 1304/6560 [3:10:34<12:12:06,  8.36s/it] 20%|‚ñà‚ñâ        | 1305/6560 [3:10:41<11:24:11,  7.81s/it] 20%|‚ñà‚ñâ        | 1306/6560 [3:10:50<12:02:15,  8.25s/it] 20%|‚ñà‚ñâ        | 1307/6560 [3:10:57<11:21:02,  7.78s/it] 20%|‚ñà‚ñâ        | 1308/6560 [3:11:04<10:50:21,  7.43s/it] 20%|‚ñà‚ñâ        | 1309/6560 [3:11:12<11:18:47,  7.76s/it] 20%|‚ñà‚ñâ        | 1310/6560 [3:11:21<11:56:01,  8.18s/it] 20%|‚ñà‚ñâ        | 1311/6560 [3:11:29<11:36:54,  7.97s/it] 20%|‚ñà‚ñà        | 1312/6560 [3:11:37<11:45:35,  8.07s/it] 20%|‚ñà‚ñà        | 1313/6560 [3:11:49<13:26:59,  9.23s/it] 20%|‚ñà‚ñà        | 1314/6560 [3:11:58<13:09:07,  9.03s/it] 20%|‚ñà‚ñà        | 1315/6560 [3:12:05<12:41:28,  8.71s/it] 20%|‚ñà‚ñà        | 1316/6560 [3:12:12<11:55:40,  8.19s/it] 20%|‚ñà‚ñà        | 1317/6560 [3:12:21<12:02:02,  8.26s/it] 20%|‚ñà‚ñà        | 1318/6560 [3:12:28<11:21:48,  7.80s/it] 20%|‚ñà‚ñà        | 1319/6560 [3:12:34<10:47:49,  7.42s/it] 20%|‚ñà‚ñà        | 1320/6560 [3:12:41<10:29:04,  7.20s/it]                                                         20%|‚ñà‚ñà        | 1320/6560 [3:12:41<10:29:04,  7.20s/it] 20%|‚ñà‚ñà        | 1321/6560 [3:12:49<10:46:39,  7.41s/it] 20%|‚ñà‚ñà        | 1322/6560 [3:12:56<10:45:55,  7.40s/it] 20%|‚ñà‚ñà        | 1323/6560 [3:13:04<11:03:12,  7.60s/it] 20%|‚ñà‚ñà        | 1324/6560 [3:13:11<10:48:42,  7.43s/it] 20%|‚ñà‚ñà        | 1325/6560 [3:13:18<10:39:39,  7.33s/it] 20%|‚ñà‚ñà        | 1326/6560 [3:13:28<11:41:55,  8.05s/it] 20%|‚ñà‚ñà        | 1327/6560 [3:13:36<11:32:25,  7.94s/it] 20%|‚ñà‚ñà        | 1328/6560 [3:13:43<11:10:55,  7.69s/it] 20%|‚ñà‚ñà        | 1329/6560 [3:13:51<11:22:42,  7.83s/it] 20%|‚ñà‚ñà        | 1330/6560 [3:13:58<11:02:22,  7.60s/it] 20%|‚ñà‚ñà        | 1331/6560 [3:14:06<11:06:03,  7.64s/it] 20%|‚ñà‚ñà        | 1332/6560 [3:14:12<10:35:48,  7.30s/it] 20%|‚ñà‚ñà        | 1333/6560 [3:14:22<11:31:32,  7.94s/it] 20%|‚ñà‚ñà        | 1334/6560 [3:14:30<11:44:56,  8.09s/it] 20%|‚ñà‚ñà        | 1335/6560 [3:14:37<11:17:17,  7.78s/it] 20%|‚ñà‚ñà        | 1336/6560 [3:14:45<11:06:23,  7.65s/it] 20%|‚ñà‚ñà        | 1337/6560 [3:14:51<10:43:47,  7.40s/it] 20%|‚ñà‚ñà        | 1338/6560 [3:14:59<10:50:50,  7.48s/it] 20%|‚ñà‚ñà        | 1339/6560 [3:15:06<10:42:36,  7.38s/it] 20%|‚ñà‚ñà        | 1340/6560 [3:15:14<11:02:10,  7.61s/it] 20%|‚ñà‚ñà        | 1341/6560 [3:15:21<10:29:50,  7.24s/it] 20%|‚ñà‚ñà        | 1342/6560 [3:15:29<10:45:19,  7.42s/it] 20%|‚ñà‚ñà        | 1343/6560 [3:15:34<10:01:58,  6.92s/it] 20%|‚ñà‚ñà        | 1344/6560 [3:15:41<9:55:54,  6.85s/it]  21%|‚ñà‚ñà        | 1345/6560 [3:15:49<10:13:55,  7.06s/it] 21%|‚ñà‚ñà        | 1346/6560 [3:15:58<11:10:58,  7.72s/it] 21%|‚ñà‚ñà        | 1347/6560 [3:16:06<11:20:16,  7.83s/it] 21%|‚ñà‚ñà        | 1348/6560 [3:16:13<10:52:17,  7.51s/it] 21%|‚ñà‚ñà        | 1349/6560 [3:16:22<11:32:45,  7.98s/it] 21%|‚ñà‚ñà        | 1350/6560 [3:16:30<11:39:07,  8.05s/it] 21%|‚ñà‚ñà        | 1351/6560 [3:16:36<10:50:53,  7.50s/it] 21%|‚ñà‚ñà        | 1352/6560 [3:16:43<10:40:19,  7.38s/it] 21%|‚ñà‚ñà        | 1353/6560 [3:16:50<10:22:06,  7.17s/it] 21%|‚ñà‚ñà        | 1354/6560 [3:16:58<10:48:08,  7.47s/it] 21%|‚ñà‚ñà        | 1355/6560 [3:17:05<10:22:03,  7.17s/it] 21%|‚ñà‚ñà        | 1356/6560 [3:17:13<10:42:20,  7.41s/it] 21%|‚ñà‚ñà        | 1357/6560 [3:17:21<11:16:28,  7.80s/it] 21%|‚ñà‚ñà        | 1358/6560 [3:17:28<10:56:32,  7.57s/it] 21%|‚ñà‚ñà        | 1359/6560 [3:17:37<11:24:13,  7.89s/it] 21%|‚ñà‚ñà        | 1360/6560 [3:17:45<11:38:35,  8.06s/it]                                                         21%|‚ñà‚ñà        | 1360/6560 [3:17:45<11:38:35,  8.06s/it] 21%|‚ñà‚ñà        | 1361/6560 [3:17:54<11:43:06,  8.11s/it] 21%|‚ñà‚ñà        | 1362/6560 [3:18:03<12:03:10,  8.35s/it] 21%|‚ñà‚ñà        | 1363/6560 [3:18:08<10:59:41,  7.62s/it] 21%|‚ñà‚ñà        | 1364/6560 [3:18:16<11:06:57,  7.70s/it] 21%|‚ñà‚ñà        | 1365/6560 [3:18:23<10:41:27,  7.41s/it] 21%|‚ñà‚ñà        | 1366/6560 [3:18:31<11:06:41,  7.70s/it] 21%|‚ñà‚ñà        | 1367/6560 [3:18:40<11:31:28,  7.99s/it] 21%|‚ñà‚ñà        | 1368/6560 [3:18:49<11:55:14,  8.27s/it] 21%|‚ñà‚ñà        | 1369/6560 [3:18:57<11:49:57,  8.21s/it] 21%|‚ñà‚ñà        | 1370/6560 [3:19:03<10:56:26,  7.59s/it] 21%|‚ñà‚ñà        | 1371/6560 [3:19:11<11:00:56,  7.64s/it] 21%|‚ñà‚ñà        | 1372/6560 [3:19:18<10:46:24,  7.48s/it] 21%|‚ñà‚ñà        | 1373/6560 [3:19:26<10:55:22,  7.58s/it] 21%|‚ñà‚ñà        | 1374/6560 [3:19:35<11:22:56,  7.90s/it] 21%|‚ñà‚ñà        | 1375/6560 [3:19:41<10:52:15,  7.55s/it] 21%|‚ñà‚ñà        | 1376/6560 [3:19:50<11:14:22,  7.81s/it] 21%|‚ñà‚ñà        | 1377/6560 [3:19:58<11:30:22,  7.99s/it] 21%|‚ñà‚ñà        | 1378/6560 [3:20:12<14:09:52,  9.84s/it] 21%|‚ñà‚ñà        | 1379/6560 [3:20:22<14:06:36,  9.80s/it] 21%|‚ñà‚ñà        | 1380/6560 [3:20:30<13:09:17,  9.14s/it] 21%|‚ñà‚ñà        | 1381/6560 [3:20:37<12:21:53,  8.59s/it] 21%|‚ñà‚ñà        | 1382/6560 [3:20:49<13:53:49,  9.66s/it] 21%|‚ñà‚ñà        | 1383/6560 [3:20:58<13:40:09,  9.51s/it] 21%|‚ñà‚ñà        | 1384/6560 [3:21:04<12:12:24,  8.49s/it] 21%|‚ñà‚ñà        | 1385/6560 [3:21:11<11:33:33,  8.04s/it] 21%|‚ñà‚ñà        | 1386/6560 [3:21:18<11:01:31,  7.67s/it] 21%|‚ñà‚ñà        | 1387/6560 [3:21:27<11:25:32,  7.95s/it] 21%|‚ñà‚ñà        | 1388/6560 [3:21:35<11:43:42,  8.16s/it] 21%|‚ñà‚ñà        | 1389/6560 [3:21:43<11:36:50,  8.09s/it] 21%|‚ñà‚ñà        | 1390/6560 [3:21:51<11:16:17,  7.85s/it] 21%|‚ñà‚ñà        | 1391/6560 [3:21:59<11:28:06,  7.99s/it] 21%|‚ñà‚ñà        | 1392/6560 [3:22:08<11:47:59,  8.22s/it] 21%|‚ñà‚ñà        | 1393/6560 [3:22:17<12:06:28,  8.44s/it] 21%|‚ñà‚ñà‚ñè       | 1394/6560 [3:22:26<12:37:09,  8.79s/it] 21%|‚ñà‚ñà‚ñè       | 1395/6560 [3:22:34<12:20:56,  8.61s/it] 21%|‚ñà‚ñà‚ñè       | 1396/6560 [3:22:42<12:00:55,  8.38s/it] 21%|‚ñà‚ñà‚ñè       | 1397/6560 [3:22:52<12:27:22,  8.69s/it] 21%|‚ñà‚ñà‚ñè       | 1398/6560 [3:23:02<12:59:57,  9.07s/it] 21%|‚ñà‚ñà‚ñè       | 1399/6560 [3:23:11<13:04:34,  9.12s/it] 21%|‚ñà‚ñà‚ñè       | 1400/6560 [3:23:19<12:43:58,  8.88s/it]                                                         21%|‚ñà‚ñà‚ñè       | 1400/6560 [3:23:19<12:43:58,  8.88s/it] 21%|‚ñà‚ñà‚ñè       | 1401/6560 [3:23:29<12:57:37,  9.04s/it] 21%|‚ñà‚ñà‚ñè       | 1402/6560 [3:23:36<12:17:19,  8.58s/it] 21%|‚ñà‚ñà‚ñè       | 1403/6560 [3:23:43<11:33:58,  8.07s/it] 21%|‚ñà‚ñà‚ñè       | 1404/6560 [3:23:51<11:36:52,  8.11s/it] 21%|‚ñà‚ñà‚ñè       | 1405/6560 [3:23:59<11:35:17,  8.09s/it] 21%|‚ñà‚ñà‚ñè       | 1406/6560 [3:24:06<10:48:28,  7.55s/it] 21%|‚ñà‚ñà‚ñè       | 1407/6560 [3:24:12<10:18:32,  7.20s/it] 21%|‚ñà‚ñà‚ñè       | 1408/6560 [3:24:21<11:10:47,  7.81s/it] 21%|‚ñà‚ñà‚ñè       | 1409/6560 [3:24:30<11:26:19,  7.99s/it] 21%|‚ñà‚ñà‚ñè       | 1410/6560 [3:24:38<11:33:17,  8.08s/it] 22%|‚ñà‚ñà‚ñè       | 1411/6560 [3:24:48<12:20:33,  8.63s/it] 22%|‚ñà‚ñà‚ñè       | 1412/6560 [3:24:55<11:46:36,  8.24s/it] 22%|‚ñà‚ñà‚ñè       | 1413/6560 [3:25:02<11:24:39,  7.98s/it] 22%|‚ñà‚ñà‚ñè       | 1414/6560 [3:25:10<11:24:02,  7.98s/it] 22%|‚ñà‚ñà‚ñè       | 1415/6560 [3:25:18<11:02:19,  7.72s/it] 22%|‚ñà‚ñà‚ñè       | 1416/6560 [3:25:27<11:54:40,  8.34s/it] 22%|‚ñà‚ñà‚ñè       | 1417/6560 [3:25:34<11:14:40,  7.87s/it] 22%|‚ñà‚ñà‚ñè       | 1418/6560 [3:25:42<11:17:32,  7.91s/it] 22%|‚ñà‚ñà‚ñè       | 1419/6560 [3:25:50<11:14:54,  7.88s/it] 22%|‚ñà‚ñà‚ñè       | 1420/6560 [3:25:57<11:05:48,  7.77s/it] 22%|‚ñà‚ñà‚ñè       | 1421/6560 [3:26:05<10:50:53,  7.60s/it] 22%|‚ñà‚ñà‚ñè       | 1422/6560 [3:26:12<10:41:27,  7.49s/it] 22%|‚ñà‚ñà‚ñè       | 1423/6560 [3:26:20<11:04:22,  7.76s/it] 22%|‚ñà‚ñà‚ñè       | 1424/6560 [3:26:27<10:43:52,  7.52s/it] 22%|‚ñà‚ñà‚ñè       | 1425/6560 [3:26:33<10:04:24,  7.06s/it] 22%|‚ñà‚ñà‚ñè       | 1426/6560 [3:26:41<10:29:07,  7.35s/it] 22%|‚ñà‚ñà‚ñè       | 1427/6560 [3:26:49<10:44:38,  7.54s/it] 22%|‚ñà‚ñà‚ñè       | 1428/6560 [3:26:57<10:55:47,  7.67s/it] 22%|‚ñà‚ñà‚ñè       | 1429/6560 [3:27:04<10:41:51,  7.51s/it] 22%|‚ñà‚ñà‚ñè       | 1430/6560 [3:27:11<10:16:17,  7.21s/it] 22%|‚ñà‚ñà‚ñè       | 1431/6560 [3:27:18<10:24:18,  7.30s/it] 22%|‚ñà‚ñà‚ñè       | 1432/6560 [3:27:27<10:58:39,  7.71s/it] 22%|‚ñà‚ñà‚ñè       | 1433/6560 [3:27:34<10:30:42,  7.38s/it] 22%|‚ñà‚ñà‚ñè       | 1434/6560 [3:27:46<12:48:11,  8.99s/it] 22%|‚ñà‚ñà‚ñè       | 1435/6560 [3:27:53<11:35:23,  8.14s/it] 22%|‚ñà‚ñà‚ñè       | 1436/6560 [3:28:00<11:14:01,  7.89s/it] 22%|‚ñà‚ñà‚ñè       | 1437/6560 [3:28:06<10:34:31,  7.43s/it] 22%|‚ñà‚ñà‚ñè       | 1438/6560 [3:28:15<11:06:15,  7.80s/it] 22%|‚ñà‚ñà‚ñè       | 1439/6560 [3:28:24<11:51:25,  8.34s/it] 22%|‚ñà‚ñà‚ñè       | 1440/6560 [3:28:31<11:00:56,  7.75s/it]                                                         22%|‚ñà‚ñà‚ñè       | 1440/6560 [3:28:31<11:00:56,  7.75s/it] 22%|‚ñà‚ñà‚ñè       | 1441/6560 [3:28:38<10:34:51,  7.44s/it] 22%|‚ñà‚ñà‚ñè       | 1442/6560 [3:28:44<9:57:41,  7.01s/it]  22%|‚ñà‚ñà‚ñè       | 1443/6560 [3:28:52<10:32:43,  7.42s/it] 22%|‚ñà‚ñà‚ñè       | 1444/6560 [3:29:00<10:42:57,  7.54s/it] 22%|‚ñà‚ñà‚ñè       | 1445/6560 [3:29:09<11:18:46,  7.96s/it] 22%|‚ñà‚ñà‚ñè       | 1446/6560 [3:29:16<11:10:53,  7.87s/it] 22%|‚ñà‚ñà‚ñè       | 1447/6560 [3:29:24<10:52:28,  7.66s/it] 22%|‚ñà‚ñà‚ñè       | 1448/6560 [3:29:31<10:48:41,  7.61s/it] 22%|‚ñà‚ñà‚ñè       | 1449/6560 [3:29:39<10:50:45,  7.64s/it] 22%|‚ñà‚ñà‚ñè       | 1450/6560 [3:29:48<11:45:10,  8.28s/it] 22%|‚ñà‚ñà‚ñè       | 1451/6560 [3:29:56<11:17:41,  7.96s/it] 22%|‚ñà‚ñà‚ñè       | 1452/6560 [3:30:01<10:21:53,  7.30s/it] 22%|‚ñà‚ñà‚ñè       | 1453/6560 [3:30:09<10:34:49,  7.46s/it] 22%|‚ñà‚ñà‚ñè       | 1454/6560 [3:30:17<10:35:56,  7.47s/it] 22%|‚ñà‚ñà‚ñè       | 1455/6560 [3:30:24<10:27:54,  7.38s/it] 22%|‚ñà‚ñà‚ñè       | 1456/6560 [3:30:32<10:41:08,  7.54s/it] 22%|‚ñà‚ñà‚ñè       | 1457/6560 [3:30:41<11:16:18,  7.95s/it] 22%|‚ñà‚ñà‚ñè       | 1458/6560 [3:30:48<10:55:27,  7.71s/it] 22%|‚ñà‚ñà‚ñè       | 1459/6560 [3:30:56<10:59:02,  7.75s/it] 22%|‚ñà‚ñà‚ñè       | 1460/6560 [3:31:04<11:09:53,  7.88s/it] 22%|‚ñà‚ñà‚ñè       | 1461/6560 [3:31:12<11:08:22,  7.86s/it] 22%|‚ñà‚ñà‚ñè       | 1462/6560 [3:31:20<11:15:44,  7.95s/it] 22%|‚ñà‚ñà‚ñè       | 1463/6560 [3:31:26<10:33:06,  7.45s/it] 22%|‚ñà‚ñà‚ñè       | 1464/6560 [3:31:34<10:33:15,  7.46s/it] 22%|‚ñà‚ñà‚ñè       | 1465/6560 [3:31:43<11:16:33,  7.97s/it] 22%|‚ñà‚ñà‚ñè       | 1466/6560 [3:31:51<11:22:40,  8.04s/it] 22%|‚ñà‚ñà‚ñè       | 1467/6560 [3:31:59<11:22:57,  8.05s/it] 22%|‚ñà‚ñà‚ñè       | 1468/6560 [3:32:06<11:04:31,  7.83s/it] 22%|‚ñà‚ñà‚ñè       | 1469/6560 [3:32:14<11:09:34,  7.89s/it] 22%|‚ñà‚ñà‚ñè       | 1470/6560 [3:32:23<11:17:33,  7.99s/it] 22%|‚ñà‚ñà‚ñè       | 1471/6560 [3:32:30<11:10:42,  7.91s/it] 22%|‚ñà‚ñà‚ñè       | 1472/6560 [3:32:39<11:30:09,  8.14s/it] 22%|‚ñà‚ñà‚ñè       | 1473/6560 [3:32:48<11:55:25,  8.44s/it] 22%|‚ñà‚ñà‚ñè       | 1474/6560 [3:32:56<11:34:37,  8.19s/it] 22%|‚ñà‚ñà‚ñè       | 1475/6560 [3:33:04<11:21:47,  8.04s/it] 22%|‚ñà‚ñà‚ñé       | 1476/6560 [3:33:10<10:39:32,  7.55s/it] 23%|‚ñà‚ñà‚ñé       | 1477/6560 [3:33:17<10:17:15,  7.29s/it] 23%|‚ñà‚ñà‚ñé       | 1478/6560 [3:33:23<10:06:05,  7.16s/it] 23%|‚ñà‚ñà‚ñé       | 1479/6560 [3:33:30<9:41:03,  6.86s/it]  23%|‚ñà‚ñà‚ñé       | 1480/6560 [3:33:39<10:52:04,  7.70s/it]                                                         23%|‚ñà‚ñà‚ñé       | 1480/6560 [3:33:39<10:52:04,  7.70s/it] 23%|‚ñà‚ñà‚ñé       | 1481/6560 [3:33:49<11:34:09,  8.20s/it] 23%|‚ñà‚ñà‚ñé       | 1482/6560 [3:33:57<11:36:13,  8.23s/it] 23%|‚ñà‚ñà‚ñé       | 1483/6560 [3:34:03<10:46:25,  7.64s/it] 23%|‚ñà‚ñà‚ñé       | 1484/6560 [3:34:10<10:14:43,  7.27s/it] 23%|‚ñà‚ñà‚ñé       | 1485/6560 [3:34:17<10:13:50,  7.26s/it] 23%|‚ñà‚ñà‚ñé       | 1486/6560 [3:34:27<11:18:36,  8.02s/it] 23%|‚ñà‚ñà‚ñé       | 1487/6560 [3:34:34<11:09:09,  7.91s/it] 23%|‚ñà‚ñà‚ñé       | 1488/6560 [3:34:43<11:35:41,  8.23s/it] 23%|‚ñà‚ñà‚ñé       | 1489/6560 [3:34:51<11:30:40,  8.17s/it] 23%|‚ñà‚ñà‚ñé       | 1490/6560 [3:34:59<11:25:45,  8.12s/it] 23%|‚ñà‚ñà‚ñé       | 1491/6560 [3:35:07<11:07:58,  7.91s/it] 23%|‚ñà‚ñà‚ñé       | 1492/6560 [3:35:15<11:21:47,  8.07s/it] 23%|‚ñà‚ñà‚ñé       | 1493/6560 [3:35:24<11:41:55,  8.31s/it] 23%|‚ñà‚ñà‚ñé       | 1494/6560 [3:35:33<11:46:34,  8.37s/it] 23%|‚ñà‚ñà‚ñé       | 1495/6560 [3:35:39<11:00:38,  7.83s/it] 23%|‚ñà‚ñà‚ñé       | 1496/6560 [3:35:45<10:05:02,  7.17s/it] 23%|‚ñà‚ñà‚ñé       | 1497/6560 [3:35:52<9:58:11,  7.09s/it]  23%|‚ñà‚ñà‚ñé       | 1498/6560 [3:36:00<10:40:54,  7.60s/it] 23%|‚ñà‚ñà‚ñé       | 1499/6560 [3:36:08<10:45:12,  7.65s/it] 23%|‚ñà‚ñà‚ñé       | 1500/6560 [3:36:15<10:29:52,  7.47s/it]
  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|‚ñè         | 2/125 [00:03<04:02,  1.97s/it][A
  2%|‚ñè         | 3/125 [00:07<05:30,  2.71s/it][A
  3%|‚ñé         | 4/125 [00:10<05:28,  2.72s/it][A
  4%|‚ñç         | 5/125 [00:12<05:16,  2.63s/it][A
  5%|‚ñç         | 6/125 [00:15<04:59,  2.51s/it][A
  6%|‚ñå         | 7/125 [00:17<04:55,  2.51s/it][A
  6%|‚ñã         | 8/125 [00:20<04:47,  2.46s/it][A
  7%|‚ñã         | 9/125 [00:21<04:10,  2.16s/it][A
  8%|‚ñä         | 10/125 [00:23<03:58,  2.07s/it][A
  9%|‚ñâ         | 11/125 [00:25<03:54,  2.06s/it][A
 10%|‚ñâ         | 12/125 [00:27<03:57,  2.11s/it][A
 10%|‚ñà         | 13/125 [00:29<04:04,  2.18s/it][A
 11%|‚ñà         | 14/125 [00:31<03:46,  2.04s/it][A
 12%|‚ñà‚ñè        | 15/125 [00:33<03:33,  1.94s/it][A
 13%|‚ñà‚ñé        | 16/125 [00:35<03:26,  1.90s/it][A
 14%|‚ñà‚ñé        | 17/125 [00:36<03:14,  1.80s/it][A
 14%|‚ñà‚ñç        | 18/125 [00:38<03:21,  1.88s/it][A
 15%|‚ñà‚ñå        | 19/125 [00:40<02:58,  1.68s/it][A
 16%|‚ñà‚ñå        | 20/125 [00:41<03:00,  1.72s/it][A
 17%|‚ñà‚ñã        | 21/125 [00:43<02:51,  1.65s/it][A
 18%|‚ñà‚ñä        | 22/125 [00:45<03:11,  1.86s/it][A
 18%|‚ñà‚ñä        | 23/125 [00:47<02:57,  1.74s/it][A
 19%|‚ñà‚ñâ        | 24/125 [00:48<02:51,  1.70s/it][A
 20%|‚ñà‚ñà        | 25/125 [00:51<03:16,  1.97s/it][A
 21%|‚ñà‚ñà        | 26/125 [00:54<03:37,  2.19s/it][A
 22%|‚ñà‚ñà‚ñè       | 27/125 [00:56<03:40,  2.25s/it][A
 22%|‚ñà‚ñà‚ñè       | 28/125 [00:59<03:56,  2.43s/it][A
 23%|‚ñà‚ñà‚ñé       | 29/125 [01:01<03:48,  2.38s/it][A
 24%|‚ñà‚ñà‚ñç       | 30/125 [01:03<03:21,  2.13s/it][A
 25%|‚ñà‚ñà‚ñç       | 31/125 [01:05<03:13,  2.06s/it][A
 26%|‚ñà‚ñà‚ñå       | 32/125 [01:06<03:05,  2.00s/it][A
 26%|‚ñà‚ñà‚ñã       | 33/125 [01:09<03:09,  2.07s/it][A
 27%|‚ñà‚ñà‚ñã       | 34/125 [01:11<03:15,  2.15s/it][A
 28%|‚ñà‚ñà‚ñä       | 35/125 [01:14<03:32,  2.36s/it][A
 29%|‚ñà‚ñà‚ñâ       | 36/125 [01:16<03:22,  2.28s/it][A
 30%|‚ñà‚ñà‚ñâ       | 37/125 [01:19<03:32,  2.42s/it][A
 30%|‚ñà‚ñà‚ñà       | 38/125 [01:21<03:34,  2.47s/it][A
 31%|‚ñà‚ñà‚ñà       | 39/125 [01:24<03:44,  2.61s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 40/125 [01:26<03:15,  2.30s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 41/125 [01:28<03:05,  2.21s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 42/125 [01:29<02:46,  2.00s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [01:31<02:41,  1.97s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 44/125 [01:34<02:57,  2.19s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 45/125 [01:35<02:40,  2.01s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 46/125 [01:39<03:17,  2.50s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 47/125 [01:41<03:12,  2.47s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 48/125 [01:44<03:13,  2.51s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 49/125 [01:48<03:32,  2.80s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 50/125 [01:49<03:02,  2.44s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 51/125 [01:51<02:54,  2.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 52/125 [01:53<02:42,  2.23s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 53/125 [01:56<02:54,  2.42s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [01:58<02:30,  2.12s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 55/125 [01:59<02:24,  2.06s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 56/125 [02:01<02:19,  2.02s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 57/125 [02:05<02:57,  2.61s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 58/125 [02:07<02:40,  2.39s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 59/125 [02:09<02:21,  2.15s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60/125 [02:11<02:14,  2.08s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 61/125 [02:13<02:22,  2.23s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 62/125 [02:15<02:06,  2.01s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 63/125 [02:17<02:09,  2.09s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 64/125 [02:19<02:03,  2.03s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [02:21<02:07,  2.13s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 66/125 [02:24<02:20,  2.37s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 67/125 [02:26<02:04,  2.14s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 68/125 [02:29<02:13,  2.35s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 69/125 [02:31<02:02,  2.18s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 70/125 [02:33<02:10,  2.38s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 71/125 [02:35<01:57,  2.18s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 72/125 [02:37<01:50,  2.09s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 73/125 [02:39<01:45,  2.03s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 74/125 [02:40<01:36,  1.90s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75/125 [02:43<01:42,  2.06s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [02:46<01:50,  2.26s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 77/125 [02:47<01:37,  2.04s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 78/125 [02:50<01:47,  2.29s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 79/125 [02:53<01:52,  2.45s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 80/125 [02:55<01:42,  2.27s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 81/125 [02:57<01:40,  2.27s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 82/125 [03:01<01:58,  2.75s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 83/125 [03:03<01:42,  2.44s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 84/125 [03:05<01:43,  2.53s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [03:07<01:37,  2.43s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 86/125 [03:10<01:34,  2.41s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [03:13<01:39,  2.61s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 88/125 [03:15<01:31,  2.48s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 89/125 [03:18<01:32,  2.58s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90/125 [03:20<01:24,  2.41s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 91/125 [03:22<01:17,  2.29s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 92/125 [03:24<01:13,  2.23s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 93/125 [03:26<01:11,  2.25s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 94/125 [03:28<01:08,  2.20s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 95/125 [03:30<00:59,  1.98s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 96/125 [03:32<00:55,  1.92s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 97/125 [03:33<00:49,  1.77s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [03:35<00:48,  1.81s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 99/125 [03:37<00:47,  1.83s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 100/125 [03:39<00:50,  2.01s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 101/125 [03:42<00:51,  2.15s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 102/125 [03:44<00:49,  2.15s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 103/125 [03:46<00:44,  2.03s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 104/125 [03:48<00:41,  1.98s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105/125 [03:52<00:53,  2.69s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 106/125 [03:55<00:54,  2.88s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 107/125 [03:58<00:50,  2.80s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 108/125 [04:01<00:47,  2.80s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [04:02<00:38,  2.40s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 110/125 [04:05<00:36,  2.43s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 111/125 [04:06<00:30,  2.15s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [04:08<00:28,  2.17s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 113/125 [04:10<00:24,  2.05s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 114/125 [04:12<00:20,  1.90s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 115/125 [04:14<00:21,  2.15s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 116/125 [04:17<00:20,  2.28s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 117/125 [04:19<00:17,  2.22s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 118/125 [04:21<00:14,  2.10s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 119/125 [04:23<00:13,  2.25s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [04:25<00:10,  2.14s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 121/125 [04:28<00:09,  2.34s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 122/125 [04:32<00:08,  2.86s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 123/125 [04:33<00:04,  2.38s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 124/125 [04:36<00:02,  2.49s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.41s/it][A                                                        
                                                 [A 23%|‚ñà‚ñà‚ñé       | 1500/6560 [3:40:56<10:29:52,  7.47s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.41s/it][A
                                                 [A 23%|‚ñà‚ñà‚ñé       | 1501/6560 [3:41:30<139:57:47, 99.60s/it] 23%|‚ñà‚ñà‚ñé       | 1502/6560 [3:41:37<100:48:00, 71.74s/it] 23%|‚ñà‚ñà‚ñé       | 1503/6560 [3:41:44<73:37:27, 52.41s/it]  23%|‚ñà‚ñà‚ñé       | 1504/6560 [3:41:51<54:33:37, 38.85s/it] 23%|‚ñà‚ñà‚ñé       | 1505/6560 [3:42:01<42:19:57, 30.15s/it] 23%|‚ñà‚ñà‚ñé       | 1506/6560 [3:42:10<33:25:13, 23.81s/it] 23%|‚ñà‚ñà‚ñé       | 1507/6560 [3:42:18<26:36:22, 18.96s/it] 23%|‚ñà‚ñà‚ñé       | 1508/6560 [3:42:27<22:23:16, 15.95s/it] 23%|‚ñà‚ñà‚ñé       | 1509/6560 [3:42:34<18:43:13, 13.34s/it] 23%|‚ñà‚ñà‚ñé       | 1510/6560 [3:42:42<16:41:09, 11.89s/it] 23%|‚ñà‚ñà‚ñé       | 1511/6560 [3:42:51<15:14:50, 10.87s/it] 23%|‚ñà‚ñà‚ñé       | 1512/6560 [3:42:59<14:02:06, 10.01s/it] 23%|‚ñà‚ñà‚ñé       | 1513/6560 [3:43:06<13:01:39,  9.29s/it] 23%|‚ñà‚ñà‚ñé       | 1514/6560 [3:43:15<12:37:40,  9.01s/it] 23%|‚ñà‚ñà‚ñé       | 1515/6560 [3:43:23<12:29:31,  8.91s/it] 23%|‚ñà‚ñà‚ñé       | 1516/6560 [3:43:31<11:44:21,  8.38s/it] 23%|‚ñà‚ñà‚ñé       | 1517/6560 [3:43:39<11:53:22,  8.49s/it] 23%|‚ñà‚ñà‚ñé       | 1518/6560 [3:43:46<11:16:26,  8.05s/it] 23%|‚ñà‚ñà‚ñé       | 1519/6560 [3:43:54<11:04:54,  7.91s/it] 23%|‚ñà‚ñà‚ñé       | 1520/6560 [3:44:01<10:36:57,  7.58s/it]                                                         23%|‚ñà‚ñà‚ñé       | 1520/6560 [3:44:01<10:36:57,  7.58s/it] 23%|‚ñà‚ñà‚ñé       | 1521/6560 [3:44:09<10:57:26,  7.83s/it] 23%|‚ñà‚ñà‚ñé       | 1522/6560 [3:44:18<11:25:20,  8.16s/it] 23%|‚ñà‚ñà‚ñé       | 1523/6560 [3:44:26<11:28:24,  8.20s/it] 23%|‚ñà‚ñà‚ñé       | 1524/6560 [3:44:34<11:01:40,  7.88s/it] 23%|‚ñà‚ñà‚ñé       | 1525/6560 [3:44:44<12:05:42,  8.65s/it] 23%|‚ñà‚ñà‚ñé       | 1526/6560 [3:44:51<11:32:58,  8.26s/it] 23%|‚ñà‚ñà‚ñé       | 1527/6560 [3:44:59<11:27:29,  8.20s/it] 23%|‚ñà‚ñà‚ñé       | 1528/6560 [3:45:06<10:50:52,  7.76s/it] 23%|‚ñà‚ñà‚ñé       | 1529/6560 [3:45:14<10:59:38,  7.87s/it] 23%|‚ñà‚ñà‚ñé       | 1530/6560 [3:45:21<10:36:42,  7.59s/it] 23%|‚ñà‚ñà‚ñé       | 1531/6560 [3:45:28<10:26:21,  7.47s/it] 23%|‚ñà‚ñà‚ñé       | 1532/6560 [3:45:37<11:03:10,  7.91s/it] 23%|‚ñà‚ñà‚ñé       | 1533/6560 [3:45:45<10:48:47,  7.74s/it] 23%|‚ñà‚ñà‚ñé       | 1534/6560 [3:45:51<10:25:57,  7.47s/it] 23%|‚ñà‚ñà‚ñé       | 1535/6560 [3:45:59<10:34:57,  7.58s/it] 23%|‚ñà‚ñà‚ñé       | 1536/6560 [3:46:07<10:46:17,  7.72s/it] 23%|‚ñà‚ñà‚ñé       | 1537/6560 [3:46:15<10:45:36,  7.71s/it] 23%|‚ñà‚ñà‚ñé       | 1538/6560 [3:46:22<10:31:16,  7.54s/it] 23%|‚ñà‚ñà‚ñé       | 1539/6560 [3:46:31<10:50:21,  7.77s/it] 23%|‚ñà‚ñà‚ñé       | 1540/6560 [3:46:37<10:26:16,  7.49s/it] 23%|‚ñà‚ñà‚ñé       | 1541/6560 [3:46:46<10:57:16,  7.86s/it] 24%|‚ñà‚ñà‚ñé       | 1542/6560 [3:46:53<10:29:53,  7.53s/it] 24%|‚ñà‚ñà‚ñé       | 1543/6560 [3:47:01<10:52:50,  7.81s/it] 24%|‚ñà‚ñà‚ñé       | 1544/6560 [3:47:10<11:21:11,  8.15s/it] 24%|‚ñà‚ñà‚ñé       | 1545/6560 [3:47:18<11:07:07,  7.98s/it] 24%|‚ñà‚ñà‚ñé       | 1546/6560 [3:47:25<10:36:57,  7.62s/it] 24%|‚ñà‚ñà‚ñé       | 1547/6560 [3:47:32<10:20:31,  7.43s/it] 24%|‚ñà‚ñà‚ñé       | 1548/6560 [3:47:39<10:17:14,  7.39s/it] 24%|‚ñà‚ñà‚ñé       | 1549/6560 [3:47:47<10:33:09,  7.58s/it] 24%|‚ñà‚ñà‚ñé       | 1550/6560 [3:47:58<12:10:56,  8.75s/it] 24%|‚ñà‚ñà‚ñé       | 1551/6560 [3:48:07<12:11:09,  8.76s/it] 24%|‚ñà‚ñà‚ñé       | 1552/6560 [3:48:15<11:58:22,  8.61s/it] 24%|‚ñà‚ñà‚ñé       | 1553/6560 [3:48:23<11:20:11,  8.15s/it] 24%|‚ñà‚ñà‚ñé       | 1554/6560 [3:48:31<11:37:49,  8.36s/it] 24%|‚ñà‚ñà‚ñé       | 1555/6560 [3:48:40<11:53:45,  8.56s/it] 24%|‚ñà‚ñà‚ñé       | 1556/6560 [3:48:47<11:14:58,  8.09s/it] 24%|‚ñà‚ñà‚ñé       | 1557/6560 [3:48:55<11:06:32,  7.99s/it] 24%|‚ñà‚ñà‚ñç       | 1558/6560 [3:49:03<10:53:35,  7.84s/it] 24%|‚ñà‚ñà‚ñç       | 1559/6560 [3:49:10<10:49:05,  7.79s/it] 24%|‚ñà‚ñà‚ñç       | 1560/6560 [3:49:17<10:11:25,  7.34s/it]                                                         24%|‚ñà‚ñà‚ñç       | 1560/6560 [3:49:17<10:11:25,  7.34s/it] 24%|‚ñà‚ñà‚ñç       | 1561/6560 [3:49:25<10:48:34,  7.78s/it] 24%|‚ñà‚ñà‚ñç       | 1562/6560 [3:49:34<11:06:22,  8.00s/it] 24%|‚ñà‚ñà‚ñç       | 1563/6560 [3:49:43<11:36:37,  8.36s/it] 24%|‚ñà‚ñà‚ñç       | 1564/6560 [3:49:51<11:19:54,  8.17s/it] 24%|‚ñà‚ñà‚ñç       | 1565/6560 [3:49:58<10:51:13,  7.82s/it] 24%|‚ñà‚ñà‚ñç       | 1566/6560 [3:50:06<10:51:57,  7.83s/it] 24%|‚ñà‚ñà‚ñç       | 1567/6560 [3:50:13<10:36:17,  7.65s/it] 24%|‚ñà‚ñà‚ñç       | 1568/6560 [3:50:21<10:51:30,  7.83s/it] 24%|‚ñà‚ñà‚ñç       | 1569/6560 [3:50:28<10:21:30,  7.47s/it] 24%|‚ñà‚ñà‚ñç       | 1570/6560 [3:50:36<10:49:01,  7.80s/it] 24%|‚ñà‚ñà‚ñç       | 1571/6560 [3:50:46<11:24:22,  8.23s/it] 24%|‚ñà‚ñà‚ñç       | 1572/6560 [3:50:54<11:36:16,  8.38s/it] 24%|‚ñà‚ñà‚ñç       | 1573/6560 [3:51:01<10:51:03,  7.83s/it] 24%|‚ñà‚ñà‚ñç       | 1574/6560 [3:51:08<10:39:20,  7.69s/it] 24%|‚ñà‚ñà‚ñç       | 1575/6560 [3:51:16<10:31:35,  7.60s/it] 24%|‚ñà‚ñà‚ñç       | 1576/6560 [3:51:26<11:37:59,  8.40s/it] 24%|‚ñà‚ñà‚ñç       | 1577/6560 [3:51:32<10:40:56,  7.72s/it] 24%|‚ñà‚ñà‚ñç       | 1578/6560 [3:51:40<10:41:25,  7.72s/it] 24%|‚ñà‚ñà‚ñç       | 1579/6560 [3:51:46<10:07:56,  7.32s/it] 24%|‚ñà‚ñà‚ñç       | 1580/6560 [3:51:55<10:37:05,  7.68s/it] 24%|‚ñà‚ñà‚ñç       | 1581/6560 [3:52:03<10:58:55,  7.94s/it] 24%|‚ñà‚ñà‚ñç       | 1582/6560 [3:52:12<11:15:01,  8.14s/it] 24%|‚ñà‚ñà‚ñç       | 1583/6560 [3:52:21<11:39:49,  8.44s/it] 24%|‚ñà‚ñà‚ñç       | 1584/6560 [3:52:28<10:53:31,  7.88s/it] 24%|‚ñà‚ñà‚ñç       | 1585/6560 [3:52:37<11:27:56,  8.30s/it] 24%|‚ñà‚ñà‚ñç       | 1586/6560 [3:52:43<10:37:50,  7.69s/it] 24%|‚ñà‚ñà‚ñç       | 1587/6560 [3:52:51<10:35:09,  7.66s/it] 24%|‚ñà‚ñà‚ñç       | 1588/6560 [3:52:58<10:16:14,  7.44s/it] 24%|‚ñà‚ñà‚ñç       | 1589/6560 [3:53:05<10:15:34,  7.43s/it] 24%|‚ñà‚ñà‚ñç       | 1590/6560 [3:53:16<11:40:02,  8.45s/it] 24%|‚ñà‚ñà‚ñç       | 1591/6560 [3:53:23<11:07:29,  8.06s/it] 24%|‚ñà‚ñà‚ñç       | 1592/6560 [3:53:30<10:51:42,  7.87s/it] 24%|‚ñà‚ñà‚ñç       | 1593/6560 [3:53:38<10:34:35,  7.67s/it] 24%|‚ñà‚ñà‚ñç       | 1594/6560 [3:53:44<9:59:36,  7.24s/it]  24%|‚ñà‚ñà‚ñç       | 1595/6560 [3:53:51<10:04:13,  7.30s/it] 24%|‚ñà‚ñà‚ñç       | 1596/6560 [3:53:59<10:08:08,  7.35s/it] 24%|‚ñà‚ñà‚ñç       | 1597/6560 [3:54:07<10:23:29,  7.54s/it] 24%|‚ñà‚ñà‚ñç       | 1598/6560 [3:54:14<10:17:58,  7.47s/it] 24%|‚ñà‚ñà‚ñç       | 1599/6560 [3:54:21<10:07:57,  7.35s/it] 24%|‚ñà‚ñà‚ñç       | 1600/6560 [3:54:28<10:07:31,  7.35s/it]                                                         24%|‚ñà‚ñà‚ñç       | 1600/6560 [3:54:28<10:07:31,  7.35s/it] 24%|‚ñà‚ñà‚ñç       | 1601/6560 [3:54:36<10:15:53,  7.45s/it] 24%|‚ñà‚ñà‚ñç       | 1602/6560 [3:54:45<10:46:33,  7.82s/it] 24%|‚ñà‚ñà‚ñç       | 1603/6560 [3:54:53<10:48:01,  7.84s/it] 24%|‚ñà‚ñà‚ñç       | 1604/6560 [3:55:00<10:37:34,  7.72s/it] 24%|‚ñà‚ñà‚ñç       | 1605/6560 [3:55:08<10:33:07,  7.67s/it] 24%|‚ñà‚ñà‚ñç       | 1606/6560 [3:55:15<10:12:23,  7.42s/it] 24%|‚ñà‚ñà‚ñç       | 1607/6560 [3:55:20<9:35:02,  6.97s/it]  25%|‚ñà‚ñà‚ñç       | 1608/6560 [3:55:28<9:52:53,  7.18s/it] 25%|‚ñà‚ñà‚ñç       | 1609/6560 [3:55:36<10:14:53,  7.45s/it] 25%|‚ñà‚ñà‚ñç       | 1610/6560 [3:55:44<10:21:54,  7.54s/it] 25%|‚ñà‚ñà‚ñç       | 1611/6560 [3:55:52<10:28:12,  7.62s/it] 25%|‚ñà‚ñà‚ñç       | 1612/6560 [3:56:00<10:54:00,  7.93s/it] 25%|‚ñà‚ñà‚ñç       | 1613/6560 [3:56:08<10:37:06,  7.73s/it] 25%|‚ñà‚ñà‚ñç       | 1614/6560 [3:56:14<10:08:40,  7.38s/it] 25%|‚ñà‚ñà‚ñç       | 1615/6560 [3:56:21<9:52:04,  7.18s/it]  25%|‚ñà‚ñà‚ñç       | 1616/6560 [3:56:28<9:59:12,  7.27s/it] 25%|‚ñà‚ñà‚ñç       | 1617/6560 [3:56:37<10:27:00,  7.61s/it] 25%|‚ñà‚ñà‚ñç       | 1618/6560 [3:56:44<10:22:15,  7.55s/it] 25%|‚ñà‚ñà‚ñç       | 1619/6560 [3:56:53<10:43:09,  7.81s/it] 25%|‚ñà‚ñà‚ñç       | 1620/6560 [3:57:00<10:30:55,  7.66s/it] 25%|‚ñà‚ñà‚ñç       | 1621/6560 [3:57:09<11:05:54,  8.09s/it] 25%|‚ñà‚ñà‚ñç       | 1622/6560 [3:57:17<10:58:47,  8.00s/it] 25%|‚ñà‚ñà‚ñç       | 1623/6560 [3:57:25<11:12:40,  8.18s/it] 25%|‚ñà‚ñà‚ñç       | 1624/6560 [3:57:32<10:34:19,  7.71s/it] 25%|‚ñà‚ñà‚ñç       | 1625/6560 [3:57:39<10:21:23,  7.55s/it] 25%|‚ñà‚ñà‚ñç       | 1626/6560 [3:57:47<10:25:34,  7.61s/it] 25%|‚ñà‚ñà‚ñç       | 1627/6560 [3:57:55<10:38:23,  7.76s/it] 25%|‚ñà‚ñà‚ñç       | 1628/6560 [3:58:03<10:47:43,  7.88s/it] 25%|‚ñà‚ñà‚ñç       | 1629/6560 [3:58:12<11:04:20,  8.08s/it] 25%|‚ñà‚ñà‚ñç       | 1630/6560 [3:58:20<11:17:27,  8.24s/it] 25%|‚ñà‚ñà‚ñç       | 1631/6560 [3:58:27<10:46:00,  7.86s/it] 25%|‚ñà‚ñà‚ñç       | 1632/6560 [3:58:35<10:38:07,  7.77s/it] 25%|‚ñà‚ñà‚ñç       | 1633/6560 [3:58:45<11:30:19,  8.41s/it] 25%|‚ñà‚ñà‚ñç       | 1634/6560 [3:58:53<11:19:38,  8.28s/it] 25%|‚ñà‚ñà‚ñç       | 1635/6560 [3:59:00<10:47:56,  7.89s/it] 25%|‚ñà‚ñà‚ñç       | 1636/6560 [3:59:07<10:35:20,  7.74s/it] 25%|‚ñà‚ñà‚ñç       | 1637/6560 [3:59:14<10:16:30,  7.51s/it] 25%|‚ñà‚ñà‚ñç       | 1638/6560 [3:59:23<10:57:05,  8.01s/it] 25%|‚ñà‚ñà‚ñç       | 1639/6560 [3:59:31<10:34:17,  7.73s/it] 25%|‚ñà‚ñà‚ñå       | 1640/6560 [3:59:37<10:08:31,  7.42s/it]                                                         25%|‚ñà‚ñà‚ñå       | 1640/6560 [3:59:37<10:08:31,  7.42s/it] 25%|‚ñà‚ñà‚ñå       | 1641/6560 [3:59:44<9:57:06,  7.28s/it]  25%|‚ñà‚ñà‚ñå       | 1642/6560 [3:59:54<10:52:05,  7.96s/it] 25%|‚ñà‚ñà‚ñå       | 1643/6560 [4:00:00<10:14:07,  7.49s/it] 25%|‚ñà‚ñà‚ñå       | 1644/6560 [4:00:09<10:38:38,  7.79s/it] 25%|‚ñà‚ñà‚ñå       | 1645/6560 [4:00:17<10:46:11,  7.89s/it] 25%|‚ñà‚ñà‚ñå       | 1646/6560 [4:00:23<10:14:52,  7.51s/it] 25%|‚ñà‚ñà‚ñå       | 1647/6560 [4:00:32<10:31:37,  7.71s/it] 25%|‚ñà‚ñà‚ñå       | 1648/6560 [4:00:38<10:10:51,  7.46s/it] 25%|‚ñà‚ñà‚ñå       | 1649/6560 [4:00:45<9:51:47,  7.23s/it]  25%|‚ñà‚ñà‚ñå       | 1650/6560 [4:00:54<10:24:45,  7.63s/it] 25%|‚ñà‚ñà‚ñå       | 1651/6560 [4:01:03<11:10:50,  8.20s/it] 25%|‚ñà‚ñà‚ñå       | 1652/6560 [4:01:11<10:50:55,  7.96s/it] 25%|‚ñà‚ñà‚ñå       | 1653/6560 [4:01:18<10:45:43,  7.90s/it] 25%|‚ñà‚ñà‚ñå       | 1654/6560 [4:01:25<10:12:19,  7.49s/it] 25%|‚ñà‚ñà‚ñå       | 1655/6560 [4:01:33<10:29:59,  7.71s/it] 25%|‚ñà‚ñà‚ñå       | 1656/6560 [4:01:41<10:44:40,  7.89s/it] 25%|‚ñà‚ñà‚ñå       | 1657/6560 [4:01:49<10:32:22,  7.74s/it] 25%|‚ñà‚ñà‚ñå       | 1658/6560 [4:01:57<10:52:03,  7.98s/it] 25%|‚ñà‚ñà‚ñå       | 1659/6560 [4:02:05<10:48:02,  7.93s/it] 25%|‚ñà‚ñà‚ñå       | 1660/6560 [4:02:15<11:23:41,  8.37s/it] 25%|‚ñà‚ñà‚ñå       | 1661/6560 [4:02:22<10:50:44,  7.97s/it] 25%|‚ñà‚ñà‚ñå       | 1662/6560 [4:02:30<11:08:21,  8.19s/it] 25%|‚ñà‚ñà‚ñå       | 1663/6560 [4:02:41<12:08:30,  8.93s/it] 25%|‚ñà‚ñà‚ñå       | 1664/6560 [4:02:50<12:05:30,  8.89s/it] 25%|‚ñà‚ñà‚ñå       | 1665/6560 [4:02:59<12:02:41,  8.86s/it] 25%|‚ñà‚ñà‚ñå       | 1666/6560 [4:03:06<11:38:57,  8.57s/it] 25%|‚ñà‚ñà‚ñå       | 1667/6560 [4:03:16<11:52:55,  8.74s/it] 25%|‚ñà‚ñà‚ñå       | 1668/6560 [4:03:23<11:09:08,  8.21s/it] 25%|‚ñà‚ñà‚ñå       | 1669/6560 [4:03:31<11:06:27,  8.18s/it] 25%|‚ñà‚ñà‚ñå       | 1670/6560 [4:03:38<10:48:30,  7.96s/it] 25%|‚ñà‚ñà‚ñå       | 1671/6560 [4:03:47<11:09:21,  8.21s/it] 25%|‚ñà‚ñà‚ñå       | 1672/6560 [4:03:54<10:52:26,  8.01s/it] 26%|‚ñà‚ñà‚ñå       | 1673/6560 [4:04:02<10:30:31,  7.74s/it] 26%|‚ñà‚ñà‚ñå       | 1674/6560 [4:04:09<10:14:53,  7.55s/it] 26%|‚ñà‚ñà‚ñå       | 1675/6560 [4:04:16<10:02:45,  7.40s/it] 26%|‚ñà‚ñà‚ñå       | 1676/6560 [4:04:24<10:36:44,  7.82s/it] 26%|‚ñà‚ñà‚ñå       | 1677/6560 [4:04:32<10:37:06,  7.83s/it] 26%|‚ñà‚ñà‚ñå       | 1678/6560 [4:04:39<10:19:23,  7.61s/it] 26%|‚ñà‚ñà‚ñå       | 1679/6560 [4:04:47<10:22:06,  7.65s/it] 26%|‚ñà‚ñà‚ñå       | 1680/6560 [4:04:55<10:32:02,  7.77s/it]                                                         26%|‚ñà‚ñà‚ñå       | 1680/6560 [4:04:55<10:32:02,  7.77s/it] 26%|‚ñà‚ñà‚ñå       | 1681/6560 [4:05:03<10:26:07,  7.70s/it] 26%|‚ñà‚ñà‚ñå       | 1682/6560 [4:05:11<10:29:45,  7.75s/it] 26%|‚ñà‚ñà‚ñå       | 1683/6560 [4:05:20<11:14:29,  8.30s/it] 26%|‚ñà‚ñà‚ñå       | 1684/6560 [4:05:27<10:28:36,  7.74s/it] 26%|‚ñà‚ñà‚ñå       | 1685/6560 [4:05:34<10:21:16,  7.65s/it] 26%|‚ñà‚ñà‚ñå       | 1686/6560 [4:05:42<10:21:54,  7.66s/it] 26%|‚ñà‚ñà‚ñå       | 1687/6560 [4:05:49<10:22:34,  7.67s/it] 26%|‚ñà‚ñà‚ñå       | 1688/6560 [4:05:56<9:44:41,  7.20s/it]  26%|‚ñà‚ñà‚ñå       | 1689/6560 [4:06:03<9:57:49,  7.36s/it] 26%|‚ñà‚ñà‚ñå       | 1690/6560 [4:06:13<10:48:32,  7.99s/it] 26%|‚ñà‚ñà‚ñå       | 1691/6560 [4:06:20<10:33:11,  7.80s/it] 26%|‚ñà‚ñà‚ñå       | 1692/6560 [4:06:26<9:54:07,  7.32s/it]  26%|‚ñà‚ñà‚ñå       | 1693/6560 [4:06:35<10:15:33,  7.59s/it] 26%|‚ñà‚ñà‚ñå       | 1694/6560 [4:06:42<10:03:21,  7.44s/it] 26%|‚ñà‚ñà‚ñå       | 1695/6560 [4:06:49<9:49:56,  7.28s/it]  26%|‚ñà‚ñà‚ñå       | 1696/6560 [4:06:56<9:47:39,  7.25s/it] 26%|‚ñà‚ñà‚ñå       | 1697/6560 [4:07:02<9:18:29,  6.89s/it] 26%|‚ñà‚ñà‚ñå       | 1698/6560 [4:07:09<9:16:34,  6.87s/it] 26%|‚ñà‚ñà‚ñå       | 1699/6560 [4:07:15<9:04:26,  6.72s/it] 26%|‚ñà‚ñà‚ñå       | 1700/6560 [4:07:23<9:26:48,  7.00s/it] 26%|‚ñà‚ñà‚ñå       | 1701/6560 [4:07:32<10:28:08,  7.76s/it] 26%|‚ñà‚ñà‚ñå       | 1702/6560 [4:07:40<10:22:08,  7.68s/it] 26%|‚ñà‚ñà‚ñå       | 1703/6560 [4:07:47<10:05:01,  7.47s/it] 26%|‚ñà‚ñà‚ñå       | 1704/6560 [4:07:55<10:24:23,  7.71s/it] 26%|‚ñà‚ñà‚ñå       | 1705/6560 [4:08:03<10:40:52,  7.92s/it] 26%|‚ñà‚ñà‚ñå       | 1706/6560 [4:08:11<10:27:56,  7.76s/it] 26%|‚ñà‚ñà‚ñå       | 1707/6560 [4:08:19<10:45:40,  7.98s/it] 26%|‚ñà‚ñà‚ñå       | 1708/6560 [4:08:27<10:47:04,  8.00s/it] 26%|‚ñà‚ñà‚ñå       | 1709/6560 [4:08:35<10:39:50,  7.91s/it] 26%|‚ñà‚ñà‚ñå       | 1710/6560 [4:08:42<10:12:58,  7.58s/it] 26%|‚ñà‚ñà‚ñå       | 1711/6560 [4:08:50<10:30:15,  7.80s/it] 26%|‚ñà‚ñà‚ñå       | 1712/6560 [4:08:59<10:46:32,  8.00s/it] 26%|‚ñà‚ñà‚ñå       | 1713/6560 [4:09:07<10:46:54,  8.01s/it] 26%|‚ñà‚ñà‚ñå       | 1714/6560 [4:09:14<10:30:06,  7.80s/it] 26%|‚ñà‚ñà‚ñå       | 1715/6560 [4:09:23<10:59:03,  8.16s/it] 26%|‚ñà‚ñà‚ñå       | 1716/6560 [4:09:29<10:19:11,  7.67s/it] 26%|‚ñà‚ñà‚ñå       | 1717/6560 [4:09:38<10:38:06,  7.91s/it] 26%|‚ñà‚ñà‚ñå       | 1718/6560 [4:09:46<10:40:15,  7.93s/it] 26%|‚ñà‚ñà‚ñå       | 1719/6560 [4:09:54<10:39:36,  7.93s/it] 26%|‚ñà‚ñà‚ñå       | 1720/6560 [4:10:01<10:28:50,  7.80s/it]                                                         26%|‚ñà‚ñà‚ñå       | 1720/6560 [4:10:01<10:28:50,  7.80s/it] 26%|‚ñà‚ñà‚ñå       | 1721/6560 [4:10:10<10:47:24,  8.03s/it] 26%|‚ñà‚ñà‚ñã       | 1722/6560 [4:10:17<10:35:05,  7.88s/it] 26%|‚ñà‚ñà‚ñã       | 1723/6560 [4:10:25<10:25:59,  7.77s/it] 26%|‚ñà‚ñà‚ñã       | 1724/6560 [4:10:31<9:58:08,  7.42s/it]  26%|‚ñà‚ñà‚ñã       | 1725/6560 [4:10:37<9:21:31,  6.97s/it] 26%|‚ñà‚ñà‚ñã       | 1726/6560 [4:10:44<9:15:43,  6.90s/it] 26%|‚ñà‚ñà‚ñã       | 1727/6560 [4:10:51<9:26:59,  7.04s/it] 26%|‚ñà‚ñà‚ñã       | 1728/6560 [4:11:02<10:44:41,  8.01s/it] 26%|‚ñà‚ñà‚ñã       | 1729/6560 [4:11:09<10:28:43,  7.81s/it] 26%|‚ñà‚ñà‚ñã       | 1730/6560 [4:11:17<10:26:45,  7.79s/it] 26%|‚ñà‚ñà‚ñã       | 1731/6560 [4:11:24<10:01:42,  7.48s/it] 26%|‚ñà‚ñà‚ñã       | 1732/6560 [4:11:30<9:44:16,  7.26s/it]  26%|‚ñà‚ñà‚ñã       | 1733/6560 [4:11:38<9:45:29,  7.28s/it] 26%|‚ñà‚ñà‚ñã       | 1734/6560 [4:11:46<10:04:08,  7.51s/it] 26%|‚ñà‚ñà‚ñã       | 1735/6560 [4:11:55<10:47:39,  8.05s/it] 26%|‚ñà‚ñà‚ñã       | 1736/6560 [4:12:02<10:20:25,  7.72s/it] 26%|‚ñà‚ñà‚ñã       | 1737/6560 [4:12:11<10:48:32,  8.07s/it] 26%|‚ñà‚ñà‚ñã       | 1738/6560 [4:12:18<10:18:30,  7.70s/it] 27%|‚ñà‚ñà‚ñã       | 1739/6560 [4:12:27<10:50:23,  8.09s/it] 27%|‚ñà‚ñà‚ñã       | 1740/6560 [4:12:34<10:29:02,  7.83s/it] 27%|‚ñà‚ñà‚ñã       | 1741/6560 [4:12:41<10:08:57,  7.58s/it] 27%|‚ñà‚ñà‚ñã       | 1742/6560 [4:12:48<10:07:04,  7.56s/it] 27%|‚ñà‚ñà‚ñã       | 1743/6560 [4:12:57<10:33:26,  7.89s/it] 27%|‚ñà‚ñà‚ñã       | 1744/6560 [4:13:05<10:28:38,  7.83s/it] 27%|‚ñà‚ñà‚ñã       | 1745/6560 [4:13:12<10:11:57,  7.63s/it] 27%|‚ñà‚ñà‚ñã       | 1746/6560 [4:13:20<10:22:09,  7.75s/it] 27%|‚ñà‚ñà‚ñã       | 1747/6560 [4:13:27<10:04:57,  7.54s/it] 27%|‚ñà‚ñà‚ñã       | 1748/6560 [4:13:34<9:45:37,  7.30s/it]  27%|‚ñà‚ñà‚ñã       | 1749/6560 [4:13:42<10:07:14,  7.57s/it] 27%|‚ñà‚ñà‚ñã       | 1750/6560 [4:13:49<9:57:55,  7.46s/it]  27%|‚ñà‚ñà‚ñã       | 1751/6560 [4:13:58<10:25:44,  7.81s/it] 27%|‚ñà‚ñà‚ñã       | 1752/6560 [4:14:06<10:33:02,  7.90s/it] 27%|‚ñà‚ñà‚ñã       | 1753/6560 [4:14:14<10:33:09,  7.90s/it] 27%|‚ñà‚ñà‚ñã       | 1754/6560 [4:14:22<10:40:56,  8.00s/it] 27%|‚ñà‚ñà‚ñã       | 1755/6560 [4:14:30<10:44:40,  8.05s/it] 27%|‚ñà‚ñà‚ñã       | 1756/6560 [4:14:39<10:51:27,  8.14s/it] 27%|‚ñà‚ñà‚ñã       | 1757/6560 [4:14:47<11:09:34,  8.36s/it] 27%|‚ñà‚ñà‚ñã       | 1758/6560 [4:14:56<11:23:50,  8.54s/it] 27%|‚ñà‚ñà‚ñã       | 1759/6560 [4:15:07<12:10:20,  9.13s/it] 27%|‚ñà‚ñà‚ñã       | 1760/6560 [4:15:14<11:25:51,  8.57s/it]                                                         27%|‚ñà‚ñà‚ñã       | 1760/6560 [4:15:14<11:25:51,  8.57s/it] 27%|‚ñà‚ñà‚ñã       | 1761/6560 [4:15:24<11:49:00,  8.86s/it] 27%|‚ñà‚ñà‚ñã       | 1762/6560 [4:15:31<11:02:25,  8.28s/it] 27%|‚ñà‚ñà‚ñã       | 1763/6560 [4:15:39<10:56:12,  8.21s/it] 27%|‚ñà‚ñà‚ñã       | 1764/6560 [4:15:46<10:40:23,  8.01s/it] 27%|‚ñà‚ñà‚ñã       | 1765/6560 [4:15:53<10:02:54,  7.54s/it] 27%|‚ñà‚ñà‚ñã       | 1766/6560 [4:16:00<10:08:30,  7.62s/it] 27%|‚ñà‚ñà‚ñã       | 1767/6560 [4:16:08<10:01:49,  7.53s/it] 27%|‚ñà‚ñà‚ñã       | 1768/6560 [4:16:17<10:46:51,  8.10s/it] 27%|‚ñà‚ñà‚ñã       | 1769/6560 [4:16:26<11:05:27,  8.33s/it] 27%|‚ñà‚ñà‚ñã       | 1770/6560 [4:16:33<10:38:01,  7.99s/it] 27%|‚ñà‚ñà‚ñã       | 1771/6560 [4:16:41<10:42:45,  8.05s/it] 27%|‚ñà‚ñà‚ñã       | 1772/6560 [4:16:50<10:41:54,  8.04s/it] 27%|‚ñà‚ñà‚ñã       | 1773/6560 [4:16:57<10:25:03,  7.83s/it] 27%|‚ñà‚ñà‚ñã       | 1774/6560 [4:17:04<10:02:09,  7.55s/it] 27%|‚ñà‚ñà‚ñã       | 1775/6560 [4:17:13<10:39:42,  8.02s/it] 27%|‚ñà‚ñà‚ñã       | 1776/6560 [4:17:20<10:27:48,  7.87s/it] 27%|‚ñà‚ñà‚ñã       | 1777/6560 [4:17:30<11:20:25,  8.54s/it] 27%|‚ñà‚ñà‚ñã       | 1778/6560 [4:17:38<11:00:17,  8.28s/it] 27%|‚ñà‚ñà‚ñã       | 1779/6560 [4:17:47<11:01:43,  8.30s/it] 27%|‚ñà‚ñà‚ñã       | 1780/6560 [4:17:55<11:15:51,  8.48s/it] 27%|‚ñà‚ñà‚ñã       | 1781/6560 [4:18:02<10:41:45,  8.06s/it] 27%|‚ñà‚ñà‚ñã       | 1782/6560 [4:18:11<10:44:30,  8.09s/it] 27%|‚ñà‚ñà‚ñã       | 1783/6560 [4:18:18<10:37:06,  8.00s/it] 27%|‚ñà‚ñà‚ñã       | 1784/6560 [4:18:27<10:41:09,  8.05s/it] 27%|‚ñà‚ñà‚ñã       | 1785/6560 [4:18:35<10:50:50,  8.18s/it] 27%|‚ñà‚ñà‚ñã       | 1786/6560 [4:18:42<10:08:16,  7.64s/it] 27%|‚ñà‚ñà‚ñã       | 1787/6560 [4:18:48<9:43:44,  7.34s/it]  27%|‚ñà‚ñà‚ñã       | 1788/6560 [4:18:56<10:00:43,  7.55s/it] 27%|‚ñà‚ñà‚ñã       | 1789/6560 [4:19:03<9:50:50,  7.43s/it]  27%|‚ñà‚ñà‚ñã       | 1790/6560 [4:19:12<10:23:00,  7.84s/it] 27%|‚ñà‚ñà‚ñã       | 1791/6560 [4:19:19<10:03:36,  7.59s/it] 27%|‚ñà‚ñà‚ñã       | 1792/6560 [4:19:25<9:31:17,  7.19s/it]  27%|‚ñà‚ñà‚ñã       | 1793/6560 [4:19:32<9:25:51,  7.12s/it] 27%|‚ñà‚ñà‚ñã       | 1794/6560 [4:19:40<9:36:55,  7.26s/it] 27%|‚ñà‚ñà‚ñã       | 1795/6560 [4:19:48<9:49:44,  7.43s/it] 27%|‚ñà‚ñà‚ñã       | 1796/6560 [4:19:56<10:04:03,  7.61s/it] 27%|‚ñà‚ñà‚ñã       | 1797/6560 [4:20:03<9:58:23,  7.54s/it]  27%|‚ñà‚ñà‚ñã       | 1798/6560 [4:20:13<10:45:30,  8.13s/it] 27%|‚ñà‚ñà‚ñã       | 1799/6560 [4:20:21<10:40:51,  8.08s/it] 27%|‚ñà‚ñà‚ñã       | 1800/6560 [4:20:27<10:08:29,  7.67s/it]                                                         27%|‚ñà‚ñà‚ñã       | 1800/6560 [4:20:27<10:08:29,  7.67s/it]
  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|‚ñè         | 2/125 [00:03<04:02,  1.97s/it][A
  2%|‚ñè         | 3/125 [00:07<05:29,  2.70s/it][A
  3%|‚ñé         | 4/125 [00:10<05:27,  2.71s/it][A
  4%|‚ñç         | 5/125 [00:12<05:15,  2.63s/it][A
  5%|‚ñç         | 6/125 [00:15<04:58,  2.50s/it][A
  6%|‚ñå         | 7/125 [00:17<04:54,  2.50s/it][A
  6%|‚ñã         | 8/125 [00:19<04:47,  2.45s/it][A
  7%|‚ñã         | 9/125 [00:21<04:09,  2.15s/it][A
  8%|‚ñä         | 10/125 [00:23<03:57,  2.07s/it][A
  9%|‚ñâ         | 11/125 [00:25<03:53,  2.05s/it][A
 10%|‚ñâ         | 12/125 [00:27<03:56,  2.10s/it][A
 10%|‚ñà         | 13/125 [00:29<04:03,  2.18s/it][A
 11%|‚ñà         | 14/125 [00:31<03:46,  2.04s/it][A
 12%|‚ñà‚ñè        | 15/125 [00:33<03:32,  1.93s/it][A
 13%|‚ñà‚ñé        | 16/125 [00:35<03:26,  1.89s/it][A
 14%|‚ñà‚ñé        | 17/125 [00:36<03:13,  1.79s/it][A
 14%|‚ñà‚ñç        | 18/125 [00:38<03:20,  1.87s/it][A
 15%|‚ñà‚ñå        | 19/125 [00:39<02:57,  1.68s/it][A
 16%|‚ñà‚ñå        | 20/125 [00:42<03:11,  1.83s/it][A
 17%|‚ñà‚ñã        | 21/125 [00:43<02:58,  1.72s/it][A
 18%|‚ñà‚ñä        | 22/125 [00:45<03:16,  1.91s/it][A
 18%|‚ñà‚ñä        | 23/125 [00:47<03:00,  1.77s/it][A
 19%|‚ñà‚ñâ        | 24/125 [00:48<02:53,  1.72s/it][A
 20%|‚ñà‚ñà        | 25/125 [00:51<03:17,  1.98s/it][A
 21%|‚ñà‚ñà        | 26/125 [00:54<03:37,  2.20s/it][A
 22%|‚ñà‚ñà‚ñè       | 27/125 [00:56<03:40,  2.25s/it][A
 22%|‚ñà‚ñà‚ñè       | 28/125 [00:59<03:55,  2.43s/it][A
 23%|‚ñà‚ñà‚ñé       | 29/125 [01:01<03:48,  2.38s/it][A
 24%|‚ñà‚ñà‚ñç       | 30/125 [01:03<03:21,  2.12s/it][A
 25%|‚ñà‚ñà‚ñç       | 31/125 [01:05<03:12,  2.05s/it][A
 26%|‚ñà‚ñà‚ñå       | 32/125 [01:07<03:05,  1.99s/it][A
 26%|‚ñà‚ñà‚ñã       | 33/125 [01:09<03:09,  2.06s/it][A
 27%|‚ñà‚ñà‚ñã       | 34/125 [01:11<03:15,  2.15s/it][A
 28%|‚ñà‚ñà‚ñä       | 35/125 [01:14<03:32,  2.36s/it][A
 29%|‚ñà‚ñà‚ñâ       | 36/125 [01:16<03:22,  2.27s/it][A
 30%|‚ñà‚ñà‚ñâ       | 37/125 [01:19<03:32,  2.41s/it][A
 30%|‚ñà‚ñà‚ñà       | 38/125 [01:21<03:34,  2.47s/it][A
 31%|‚ñà‚ñà‚ñà       | 39/125 [01:24<03:43,  2.60s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 40/125 [01:26<03:15,  2.29s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 41/125 [01:28<03:05,  2.21s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 42/125 [01:29<02:46,  2.00s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 43/125 [01:31<02:40,  1.96s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 44/125 [01:34<02:57,  2.19s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 45/125 [01:36<02:40,  2.01s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 46/125 [01:39<03:17,  2.50s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 47/125 [01:42<03:12,  2.47s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 48/125 [01:44<03:13,  2.51s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 49/125 [01:48<03:32,  2.80s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 50/125 [01:49<03:02,  2.44s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 51/125 [01:51<02:54,  2.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 52/125 [01:53<02:42,  2.22s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 53/125 [01:56<02:53,  2.42s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 54/125 [01:58<02:30,  2.12s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 55/125 [02:00<02:23,  2.05s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 56/125 [02:01<02:18,  2.01s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 57/125 [02:05<02:56,  2.60s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 58/125 [02:07<02:39,  2.38s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 59/125 [02:09<02:21,  2.14s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60/125 [02:11<02:14,  2.07s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 61/125 [02:13<02:22,  2.22s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 62/125 [02:15<02:06,  2.00s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 63/125 [02:17<02:09,  2.08s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 64/125 [02:19<02:02,  2.02s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 65/125 [02:21<02:07,  2.12s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 66/125 [02:24<02:19,  2.36s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 67/125 [02:26<02:03,  2.13s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 68/125 [02:29<02:13,  2.34s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 69/125 [02:30<02:01,  2.17s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 70/125 [02:33<02:09,  2.36s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 71/125 [02:35<01:57,  2.17s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 72/125 [02:37<01:50,  2.08s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 73/125 [02:39<01:44,  2.01s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 74/125 [02:40<01:36,  1.89s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75/125 [02:43<01:42,  2.04s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 76/125 [02:45<01:50,  2.25s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 77/125 [02:47<01:37,  2.03s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 78/125 [02:50<01:47,  2.28s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 79/125 [02:53<01:52,  2.44s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 80/125 [02:54<01:41,  2.27s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 81/125 [02:57<01:39,  2.27s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 82/125 [03:01<01:57,  2.74s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 83/125 [03:02<01:42,  2.43s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 84/125 [03:05<01:43,  2.52s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 85/125 [03:07<01:37,  2.43s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 86/125 [03:10<01:33,  2.40s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 87/125 [03:13<01:38,  2.60s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 88/125 [03:15<01:31,  2.47s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 89/125 [03:18<01:32,  2.57s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90/125 [03:20<01:24,  2.40s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 91/125 [03:22<01:17,  2.29s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 92/125 [03:24<01:13,  2.23s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 93/125 [03:26<01:11,  2.24s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 94/125 [03:28<01:08,  2.19s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 95/125 [03:30<00:59,  1.98s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 96/125 [03:31<00:55,  1.92s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 97/125 [03:33<00:49,  1.76s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 98/125 [03:35<00:48,  1.80s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 99/125 [03:37<00:47,  1.83s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 100/125 [03:39<00:50,  2.01s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 101/125 [03:41<00:51,  2.14s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 102/125 [03:44<00:49,  2.15s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 103/125 [03:45<00:44,  2.02s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 104/125 [03:47<00:41,  1.98s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105/125 [03:52<00:53,  2.69s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 106/125 [03:55<00:54,  2.88s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 107/125 [03:57<00:50,  2.79s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 108/125 [04:00<00:47,  2.80s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 109/125 [04:02<00:38,  2.40s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 110/125 [04:04<00:36,  2.42s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 111/125 [04:06<00:30,  2.15s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [04:08<00:28,  2.16s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 113/125 [04:10<00:24,  2.05s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 114/125 [04:11<00:20,  1.89s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 115/125 [04:14<00:21,  2.14s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 116/125 [04:17<00:20,  2.27s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 117/125 [04:19<00:17,  2.21s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 118/125 [04:20<00:14,  2.09s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 119/125 [04:23<00:13,  2.24s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120/125 [04:25<00:10,  2.12s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 121/125 [04:28<00:09,  2.32s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 122/125 [04:32<00:08,  2.85s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 123/125 [04:33<00:04,  2.36s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 124/125 [04:36<00:02,  2.47s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.40s/it][A                                                        
                                                 [A 27%|‚ñà‚ñà‚ñã       | 1800/6560 [4:25:08<10:08:29,  7.67s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [04:38<00:00,  2.40s/it][A
                                                 [A 27%|‚ñà‚ñà‚ñã       | 1801/6560 [4:25:38<130:20:33, 98.60s/it] 27%|‚ñà‚ñà‚ñã       | 1802/6560 [4:25:47<94:43:44, 71.67s/it]  27%|‚ñà‚ñà‚ñã       | 1803/6560 [4:25:55<69:26:21, 52.55s/it] 28%|‚ñà‚ñà‚ñä       | 1804/6560 [4:26:04<52:18:16, 39.59s/it] 28%|‚ñà‚ñà‚ñä       | 1805/6560 [4:26:12<39:32:16, 29.93s/it] 28%|‚ñà‚ñà‚ñä       | 1806/6560 [4:26:19<30:44:19, 23.28s/it] 28%|‚ñà‚ñà‚ñä       | 1807/6560 [4:26:28<24:51:06, 18.82s/it] 28%|‚ñà‚ñà‚ñä       | 1808/6560 [4:26:36<20:49:43, 15.78s/it] 28%|‚ñà‚ñà‚ñä       | 1809/6560 [4:26:45<17:50:38, 13.52s/it] 28%|‚ñà‚ñà‚ñä       | 1810/6560 [4:26:52<15:28:47, 11.73s/it] 28%|‚ñà‚ñà‚ñä       | 1811/6560 [4:26:59<13:20:02, 10.11s/it] 28%|‚ñà‚ñà‚ñä       | 1812/6560 [4:27:07<12:45:38,  9.68s/it] 28%|‚ñà‚ñà‚ñä       | 1813/6560 [4:27:15<12:06:43,  9.19s/it] 28%|‚ñà‚ñà‚ñä       | 1814/6560 [4:27:23<11:24:55,  8.66s/it] 28%|‚ñà‚ñà‚ñä       | 1815/6560 [4:27:31<11:13:00,  8.51s/it] 28%|‚ñà‚ñà‚ñä       | 1816/6560 [4:27:40<11:22:54,  8.64s/it] 28%|‚ñà‚ñà‚ñä       | 1817/6560 [4:27:47<10:52:11,  8.25s/it] 28%|‚ñà‚ñà‚ñä       | 1818/6560 [4:27:55<10:41:49,  8.12s/it] 28%|‚ñà‚ñà‚ñä       | 1819/6560 [4:28:04<10:53:04,  8.27s/it] 28%|‚ñà‚ñà‚ñä       | 1820/6560 [4:28:10<10:14:36,  7.78s/it] 28%|‚ñà‚ñà‚ñä       | 1821/6560 [4:28:17<9:42:09,  7.37s/it]  28%|‚ñà‚ñà‚ñä       | 1822/6560 [4:28:26<10:19:43,  7.85s/it] 28%|‚ñà‚ñà‚ñä       | 1823/6560 [4:28:34<10:21:08,  7.87s/it] 28%|‚ñà‚ñà‚ñä       | 1824/6560 [4:28:40<9:46:34,  7.43s/it]  28%|‚ñà‚ñà‚ñä       | 1825/6560 [4:28:48<9:48:54,  7.46s/it] 28%|‚ñà‚ñà‚ñä       | 1826/6560 [4:28:54<9:34:46,  7.28s/it] 28%|‚ñà‚ñà‚ñä       | 1827/6560 [4:29:02<9:32:37,  7.26s/it] 28%|‚ñà‚ñà‚ñä       | 1828/6560 [4:29:09<9:42:18,  7.38s/it] 28%|‚ñà‚ñà‚ñä       | 1829/6560 [4:29:18<10:24:51,  7.92s/it] 28%|‚ñà‚ñà‚ñä       | 1830/6560 [4:29:27<10:31:04,  8.01s/it] 28%|‚ñà‚ñà‚ñä       | 1831/6560 [4:29:34<10:16:39,  7.82s/it] 28%|‚ñà‚ñà‚ñä       | 1832/6560 [4:29:41<9:58:42,  7.60s/it]  28%|‚ñà‚ñà‚ñä       | 1833/6560 [4:29:50<10:18:32,  7.85s/it] 28%|‚ñà‚ñà‚ñä       | 1834/6560 [4:29:57<10:19:28,  7.86s/it] 28%|‚ñà‚ñà‚ñä       | 1835/6560 [4:30:04<9:50:42,  7.50s/it]  28%|‚ñà‚ñà‚ñä       | 1836/6560 [4:30:11<9:32:53,  7.28s/it] 28%|‚ñà‚ñà‚ñä       | 1837/6560 [4:30:19<9:54:04,  7.55s/it] 28%|‚ñà‚ñà‚ñä       | 1838/6560 [4:30:27<9:57:42,  7.59s/it] 28%|‚ñà‚ñà‚ñä       | 1839/6560 [4:30:35<10:16:38,  7.84s/it] 28%|‚ñà‚ñà‚ñä       | 1840/6560 [4:30:43<10:19:54,  7.88s/it]                                                         28%|‚ñà‚ñà‚ñä       | 1840/6560 [4:30:43<10:19:54,  7.88s/it] 28%|‚ñà‚ñà‚ñä       | 1841/6560 [4:30:51<10:26:50,  7.97s/it] 28%|‚ñà‚ñà‚ñä       | 1842/6560 [4:30:59<10:09:48,  7.76s/it] 28%|‚ñà‚ñà‚ñä       | 1843/6560 [4:31:07<10:15:17,  7.83s/it] 28%|‚ñà‚ñà‚ñä       | 1844/6560 [4:31:14<10:17:12,  7.85s/it] 28%|‚ñà‚ñà‚ñä       | 1845/6560 [4:31:22<9:59:50,  7.63s/it]  28%|‚ñà‚ñà‚ñä       | 1846/6560 [4:31:30<10:20:25,  7.90s/it] 28%|‚ñà‚ñà‚ñä       | 1847/6560 [4:31:37<10:08:14,  7.74s/it] 28%|‚ñà‚ñà‚ñä       | 1848/6560 [4:31:45<9:58:16,  7.62s/it]  28%|‚ñà‚ñà‚ñä       | 1849/6560 [4:31:52<9:50:35,  7.52s/it] 28%|‚ñà‚ñà‚ñä       | 1850/6560 [4:31:59<9:40:59,  7.40s/it] 28%|‚ñà‚ñà‚ñä       | 1851/6560 [4:32:09<10:47:27,  8.25s/it] 28%|‚ñà‚ñà‚ñä       | 1852/6560 [4:32:17<10:25:35,  7.97s/it] 28%|‚ñà‚ñà‚ñä       | 1853/6560 [4:32:25<10:28:44,  8.01s/it] 28%|‚ñà‚ñà‚ñä       | 1854/6560 [4:32:32<10:01:46,  7.67s/it] 28%|‚ñà‚ñà‚ñä       | 1855/6560 [4:32:39<9:52:19,  7.55s/it]  28%|‚ñà‚ñà‚ñä       | 1856/6560 [4:32:46<9:35:30,  7.34s/it] 28%|‚ñà‚ñà‚ñä       | 1857/6560 [4:32:56<10:32:14,  8.07s/it] 28%|‚ñà‚ñà‚ñä       | 1858/6560 [4:33:03<10:06:51,  7.74s/it] 28%|‚ñà‚ñà‚ñä       | 1859/6560 [4:33:12<10:48:05,  8.27s/it] 28%|‚ñà‚ñà‚ñä       | 1860/6560 [4:33:20<10:46:34,  8.25s/it] 28%|‚ñà‚ñà‚ñä       | 1861/6560 [4:33:28<10:30:07,  8.05s/it] 28%|‚ñà‚ñà‚ñä       | 1862/6560 [4:33:34<9:49:28,  7.53s/it]  28%|‚ñà‚ñà‚ñä       | 