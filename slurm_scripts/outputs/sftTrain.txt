ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 05-26 21:15:51 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A30. Num GPUs = 1. Max memory: 23.498 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
trainable params: 167,772,160 || all params: 8,198,033,408 || trainable%: 2.0465
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mLlama base with SFT dataset. 4 epochs. Lr 1e-4[0m at: [34mhttps://wandb.ai/jbarrutia006-upv-ehu/viperSFT/runs/03gvlgwm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250526_211556-03gvlgwm/logs[0m
