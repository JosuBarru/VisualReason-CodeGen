ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 04-16 01:13:52 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.325 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 12.961, 'grad_norm': 49.25, 'learning_rate': 3.80952380952381e-06, 'epoch': 0.08}
{'loss': 9.6057, 'grad_norm': 18.5, 'learning_rate': 7.61904761904762e-06, 'epoch': 0.15}
{'eval_loss': 5.9590020179748535, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 441.973, 'eval_samples_per_second': 1.131, 'eval_steps_per_second': 0.283, 'epoch': 0.19}
{'loss': 5.5324, 'grad_norm': 4.1875, 'learning_rate': 1.1428571428571429e-05, 'epoch': 0.23}
{'loss': 4.3653, 'grad_norm': 1.0859375, 'learning_rate': 1.523809523809524e-05, 'epoch': 0.31}
{'loss': 3.8666, 'grad_norm': 0.55859375, 'learning_rate': 1.904761904761905e-05, 'epoch': 0.38}
{'eval_loss': 2.6955950260162354, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.4917, 'eval_samples_per_second': 1.145, 'eval_steps_per_second': 0.286, 'epoch': 0.38}
{'loss': 3.7168, 'grad_norm': 0.41796875, 'learning_rate': 1.9987516438572035e-05, 'epoch': 0.46}
{'loss': 3.6087, 'grad_norm': 0.4921875, 'learning_rate': 1.993209678455383e-05, 'epoch': 0.53}
{'eval_loss': 2.493553638458252, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 441.0009, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.283, 'epoch': 0.57}
{'loss': 3.6519, 'grad_norm': 1.2421875, 'learning_rate': 1.9832599664797306e-05, 'epoch': 0.61}
{'loss': 3.7964, 'grad_norm': 0.64453125, 'learning_rate': 1.9689466635701106e-05, 'epoch': 0.69}
{'loss': 3.7414, 'grad_norm': 0.2060546875, 'learning_rate': 1.9503332904646188e-05, 'epoch': 0.76}
{'eval_loss': 2.4682488441467285, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.8324, 'eval_samples_per_second': 1.145, 'eval_steps_per_second': 0.286, 'epoch': 0.76}
{'loss': 3.6226, 'grad_norm': 0.306640625, 'learning_rate': 1.927502451102095e-05, 'epoch': 0.84}
{'loss': 3.6316, 'grad_norm': 0.337890625, 'learning_rate': 1.9005554660356505e-05, 'epoch': 0.92}
{'eval_loss': 2.458251953125, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 440.5717, 'eval_samples_per_second': 1.135, 'eval_steps_per_second': 0.284, 'epoch': 0.95}
{'loss': 3.5649, 'grad_norm': 0.35546875, 'learning_rate': 1.8696119227840937e-05, 'epoch': 0.99}
{'loss': 3.7085, 'grad_norm': 0.1142578125, 'learning_rate': 1.8348091451167224e-05, 'epoch': 1.07}
{'loss': 3.669, 'grad_norm': 0.1767578125, 'learning_rate': 1.7963015836267502e-05, 'epoch': 1.15}
{'eval_loss': 2.451533317565918, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.2797, 'eval_samples_per_second': 1.146, 'eval_steps_per_second': 0.287, 'epoch': 1.15}
{'loss': 3.6134, 'grad_norm': 0.1357421875, 'learning_rate': 1.7542601302979213e-05, 'epoch': 1.22}
{'loss': 3.6647, 'grad_norm': 0.67578125, 'learning_rate': 1.7088713601061823e-05, 'epoch': 1.3}
{'eval_loss': 2.447671413421631, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 440.9815, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.283, 'epoch': 1.34}
{'loss': 3.7031, 'grad_norm': 0.578125, 'learning_rate': 1.660336703022106e-05, 'epoch': 1.37}
{'loss': 3.6471, 'grad_norm': 0.265625, 'learning_rate': 1.608871550088606e-05, 'epoch': 1.45}
{'loss': 3.5625, 'grad_norm': 0.10498046875, 'learning_rate': 1.554704297541074e-05, 'epoch': 1.53}
{'eval_loss': 2.4351701736450195, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.2379, 'eval_samples_per_second': 1.146, 'eval_steps_per_second': 0.287, 'epoch': 1.53}
{'loss': 3.7379, 'grad_norm': 0.201171875, 'learning_rate': 1.4980753332120193e-05, 'epoch': 1.6}
{'loss': 3.7414, 'grad_norm': 0.16796875, 'learning_rate': 1.4392359697184197e-05, 'epoch': 1.68}
{'eval_loss': 2.4325263500213623, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 441.3359, 'eval_samples_per_second': 1.133, 'eval_steps_per_second': 0.283, 'epoch': 1.72}
{'loss': 3.6984, 'grad_norm': 0.416015625, 'learning_rate': 1.3784473291661824e-05, 'epoch': 1.76}
{'loss': 3.6967, 'grad_norm': 0.251953125, 'learning_rate': 1.3159791843212542e-05, 'epoch': 1.83}
{'loss': 3.7073, 'grad_norm': 0.33984375, 'learning_rate': 1.2521087613901313e-05, 'epoch': 1.91}
{'eval_loss': 2.4313433170318604, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.264, 'eval_samples_per_second': 1.146, 'eval_steps_per_second': 0.287, 'epoch': 1.91}
{'loss': 3.7203, 'grad_norm': 0.5234375, 'learning_rate': 1.1871195097228864e-05, 'epoch': 1.98}
{'loss': 3.6428, 'grad_norm': 0.314453125, 'learning_rate': 1.1212998438986223e-05, 'epoch': 2.06}
{'eval_loss': 2.4273934364318848, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 440.5435, 'eval_samples_per_second': 1.135, 'eval_steps_per_second': 0.284, 'epoch': 2.1}
{'loss': 3.6684, 'grad_norm': 0.15234375, 'learning_rate': 1.0549418637758284e-05, 'epoch': 2.14}
{'loss': 3.5906, 'grad_norm': 0.2158203125, 'learning_rate': 9.883400581879077e-06, 'epoch': 2.21}
{'loss': 3.5008, 'grad_norm': 0.828125, 'learning_rate': 9.217899980367142e-06, 'epoch': 2.29}
{'eval_loss': 2.4251441955566406, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.4602, 'eval_samples_per_second': 1.146, 'eval_steps_per_second': 0.286, 'epoch': 2.29}
{'loss': 3.7125, 'grad_norm': 0.412109375, 'learning_rate': 8.555870245840005e-06, 'epoch': 2.37}
{'loss': 3.6563, 'grad_norm': 0.134765625, 'learning_rate': 7.900249387619797e-06, 'epoch': 2.44}
{'eval_loss': 2.424584150314331, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 440.4562, 'eval_samples_per_second': 1.135, 'eval_steps_per_second': 0.284, 'epoch': 2.48}
{'loss': 3.5467, 'grad_norm': 0.28515625, 'learning_rate': 7.253946973196888e-06, 'epoch': 2.52}
{'loss': 3.6465, 'grad_norm': 0.326171875, 'learning_rate': 6.619831215914974e-06, 'epoch': 2.6}
{'loss': 3.6846, 'grad_norm': 0.3515625, 'learning_rate': 6.000716246180953e-06, 'epoch': 2.67}
{'eval_loss': 2.423185110092163, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.5635, 'eval_samples_per_second': 1.145, 'eval_steps_per_second': 0.286, 'epoch': 2.67}
{'loss': 3.5811, 'grad_norm': 0.30859375, 'learning_rate': 5.399349622688479e-06, 'epoch': 2.75}
{'loss': 3.683, 'grad_norm': 0.25390625, 'learning_rate': 4.818400139078824e-06, 'epoch': 2.82}
{'eval_loss': 2.423387289047241, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 440.8638, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.284, 'epoch': 2.86}
{'loss': 3.6413, 'grad_norm': 0.3125, 'learning_rate': 4.260445980151725e-06, 'epoch': 2.9}
{'loss': 3.7464, 'grad_norm': 0.1689453125, 'learning_rate': 3.7279632801875076e-06, 'epoch': 2.98}
{'loss': 3.6427, 'grad_norm': 0.162109375, 'learning_rate': 3.223315134157253e-06, 'epoch': 3.05}
{'eval_loss': 2.4243295192718506, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.3853, 'eval_samples_per_second': 1.146, 'eval_steps_per_second': 0.286, 'epoch': 3.05}
{'loss': 3.7287, 'grad_norm': 0.291015625, 'learning_rate': 2.7487411105880356e-06, 'epoch': 3.13}
{'loss': 3.646, 'grad_norm': 0.3359375, 'learning_rate': 2.30634731262383e-06, 'epoch': 3.21}
{'eval_loss': 2.4237375259399414, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 440.9084, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.284, 'epoch': 3.24}
{'loss': 3.7044, 'grad_norm': 0.314453125, 'learning_rate': 1.8980970313899193e-06, 'epoch': 3.28}
{'loss': 3.7224, 'grad_norm': 0.3046875, 'learning_rate': 1.5258020331401102e-06, 'epoch': 3.36}
{'loss': 3.6759, 'grad_norm': 0.12890625, 'learning_rate': 1.1911145188532936e-06, 'epoch': 3.44}
{'eval_loss': 2.423837423324585, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 435.7585, 'eval_samples_per_second': 1.147, 'eval_steps_per_second': 0.287, 'epoch': 3.44}
{'loss': 3.7564, 'grad_norm': 0.1083984375, 'learning_rate': 8.955197919617653e-07, 'epoch': 3.51}
{'loss': 3.6479, 'grad_norm': 0.1884765625, 'learning_rate': 6.403296667510339e-07, 'epoch': 3.59}
{'eval_loss': 2.4234321117401123, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 440.3592, 'eval_samples_per_second': 1.135, 'eval_steps_per_second': 0.284, 'epoch': 3.63}
{'loss': 3.5672, 'grad_norm': 0.201171875, 'learning_rate': 4.266766466838335e-07, 'epoch': 3.66}
{'loss': 3.6723, 'grad_norm': 0.19921875, 'learning_rate': 2.555088984842868e-07, 'epoch': 3.74}
{'loss': 3.6797, 'grad_norm': 0.2216796875, 'learning_rate': 1.2758604428661836e-07, 'epoch': 3.82}
{'eval_loss': 2.424433708190918, 'eval_model_preparation_time': 0.0065, 'eval_runtime': 436.3073, 'eval_samples_per_second': 1.146, 'eval_steps_per_second': 0.286, 'epoch': 3.82}
{'loss': 3.7932, 'grad_norm': 0.1982421875, 'learning_rate': 4.347579052234374e-08, 'epoch': 3.89}
{'loss': 3.7437, 'grad_norm': 0.1708984375, 'learning_rate': 3.5514085065690984e-09, 'epoch': 3.97}
{'train_runtime': 34005.9778, 'train_samples_per_second': 0.985, 'train_steps_per_second': 0.031, 'train_loss': 4.012841998165801, 'epoch': 4.0}
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mLlama with SFT dataset. 3 epochs[0m at: [34mhttps://wandb.ai/jbarrutia006-upv-ehu/viperSFT/runs/603bjhbe[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250416_011356-603bjhbe/logs[0m
