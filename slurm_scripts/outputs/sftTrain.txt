ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 04-27 11:54:43 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.325 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
trainable params: 167,772,160 || all params: 8,198,033,408 || trainable%: 2.0465
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 12.4005, 'grad_norm': 47.75, 'learning_rate': 2.0408163265306125e-06, 'epoch': 0.08}
{'loss': 9.9706, 'grad_norm': 22.75, 'learning_rate': 4.081632653061225e-06, 'epoch': 0.16}
{'eval_loss': 6.630702018737793, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 892.6759, 'eval_samples_per_second': 1.12, 'eval_steps_per_second': 0.28, 'epoch': 0.2}
{'loss': 6.4057, 'grad_norm': 4.78125, 'learning_rate': 6.122448979591837e-06, 'epoch': 0.24}
{'loss': 4.9037, 'grad_norm': 1.9375, 'learning_rate': 8.16326530612245e-06, 'epoch': 0.33}
{'loss': 3.9971, 'grad_norm': 0.8203125, 'learning_rate': 9.999873129474573e-06, 'epoch': 0.41}
{'eval_loss': 3.614388942718506, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 887.9391, 'eval_samples_per_second': 1.126, 'eval_steps_per_second': 0.282, 'epoch': 0.41}
{'loss': 3.7433, 'grad_norm': 0.5234375, 'learning_rate': 9.984656455408591e-06, 'epoch': 0.49}
{'loss': 3.6773, 'grad_norm': 0.236328125, 'learning_rate': 9.944154131125643e-06, 'epoch': 0.57}
{'eval_loss': 3.1843340396881104, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 892.021, 'eval_samples_per_second': 1.121, 'eval_steps_per_second': 0.28, 'epoch': 0.61}
{'loss': 3.5324, 'grad_norm': 0.462890625, 'learning_rate': 9.878571612631364e-06, 'epoch': 0.65}
{'loss': 3.7731, 'grad_norm': 0.9375, 'learning_rate': 9.788241580149123e-06, 'epoch': 0.73}
{'loss': 3.7716, 'grad_norm': 0.1669921875, 'learning_rate': 9.673622250534155e-06, 'epoch': 0.82}
{'eval_loss': 3.13623046875, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 887.4095, 'eval_samples_per_second': 1.127, 'eval_steps_per_second': 0.282, 'epoch': 0.82}
{'loss': 3.7168, 'grad_norm': 0.443359375, 'learning_rate': 9.53529505287845e-06, 'epoch': 0.9}
{'loss': 3.8845, 'grad_norm': 0.25390625, 'learning_rate': 9.37396167909733e-06, 'epoch': 0.98}
{'eval_loss': 3.094149112701416, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 893.6864, 'eval_samples_per_second': 1.119, 'eval_steps_per_second': 0.28, 'epoch': 1.02}
{'loss': 3.4716, 'grad_norm': 0.50390625, 'learning_rate': 9.190440524459203e-06, 'epoch': 1.06}
{'loss': 3.7883, 'grad_norm': 0.2138671875, 'learning_rate': 8.985662536114614e-06, 'epoch': 1.14}
{'loss': 3.6634, 'grad_norm': 0.357421875, 'learning_rate': 8.76066649068372e-06, 'epoch': 1.22}
{'eval_loss': 3.0287647247314453, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 894.0379, 'eval_samples_per_second': 1.119, 'eval_steps_per_second': 0.28, 'epoch': 1.22}
{'loss': 3.8301, 'grad_norm': 0.53515625, 'learning_rate': 8.516593724857598e-06, 'epoch': 1.31}
{'loss': 3.6275, 'grad_norm': 0.1630859375, 'learning_rate': 8.254682345743406e-06, 'epoch': 1.39}
{'eval_loss': 3.012009382247925, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 892.871, 'eval_samples_per_second': 1.12, 'eval_steps_per_second': 0.28, 'epoch': 1.43}
{'loss': 3.7202, 'grad_norm': 0.1474609375, 'learning_rate': 7.976260950322572e-06, 'epoch': 1.47}
{'loss': 3.775, 'grad_norm': 0.1494140625, 'learning_rate': 7.682741885881314e-06, 'epoch': 1.55}
{'loss': 3.6999, 'grad_norm': 0.17578125, 'learning_rate': 7.375614085601265e-06, 'epoch': 1.63}
{'eval_loss': 2.983058452606201, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 928.7861, 'eval_samples_per_second': 1.077, 'eval_steps_per_second': 0.269, 'epoch': 1.63}
{'loss': 3.7605, 'grad_norm': 0.17578125, 'learning_rate': 7.056435515653059e-06, 'epoch': 1.71}
{'loss': 3.7831, 'grad_norm': 0.54296875, 'learning_rate': 6.726825272106539e-06, 'epoch': 1.8}
{'eval_loss': 2.9564831256866455, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 925.4028, 'eval_samples_per_second': 1.081, 'eval_steps_per_second': 0.27, 'epoch': 1.84}
{'loss': 3.6885, 'grad_norm': 0.1328125, 'learning_rate': 6.388455367747503e-06, 'epoch': 1.88}
{'loss': 3.6546, 'grad_norm': 0.169921875, 'learning_rate': 6.043042250464005e-06, 'epoch': 1.96}
{'loss': 3.6487, 'grad_norm': 0.2333984375, 'learning_rate': 5.69233809622687e-06, 'epoch': 2.04}
{'eval_loss': 2.9305365085601807, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 899.9901, 'eval_samples_per_second': 1.111, 'eval_steps_per_second': 0.278, 'epoch': 2.04}
{'loss': 3.7413, 'grad_norm': 0.2021484375, 'learning_rate': 5.3381219208324755e-06, 'epoch': 2.12}
{'loss': 4.0308, 'grad_norm': 0.2890625, 'learning_rate': 4.982190555495236e-06, 'epoch': 2.2}
{'eval_loss': 2.913003921508789, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 888.0542, 'eval_samples_per_second': 1.126, 'eval_steps_per_second': 0.282, 'epoch': 2.24}
{'loss': 3.753, 'grad_norm': 0.11279296875, 'learning_rate': 4.626349532067879e-06, 'epoch': 2.29}
{'loss': 3.611, 'grad_norm': 0.11181640625, 'learning_rate': 4.272403924126035e-06, 'epoch': 2.37}
{'loss': 3.7734, 'grad_norm': 0.13671875, 'learning_rate': 3.9221491903775014e-06, 'epoch': 2.45}
{'eval_loss': 2.910032272338867, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 883.768, 'eval_samples_per_second': 1.132, 'eval_steps_per_second': 0.283, 'epoch': 2.45}
{'loss': 3.6753, 'grad_norm': 0.1533203125, 'learning_rate': 3.5773620668448384e-06, 'epoch': 2.53}
{'loss': 3.5071, 'grad_norm': 0.240234375, 'learning_rate': 3.2397915540224493e-06, 'epoch': 2.61}
{'eval_loss': 2.9011645317077637, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 887.2341, 'eval_samples_per_second': 1.127, 'eval_steps_per_second': 0.282, 'epoch': 2.65}
{'loss': 3.8099, 'grad_norm': 0.1416015625, 'learning_rate': 2.9111500447276053e-06, 'epoch': 2.69}
{'loss': 3.642, 'grad_norm': 0.1513671875, 'learning_rate': 2.5931046376510875e-06, 'epoch': 2.78}
{'loss': 3.6747, 'grad_norm': 0.1748046875, 'learning_rate': 2.2872686806712037e-06, 'epoch': 2.86}
{'eval_loss': 2.9216878414154053, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 883.297, 'eval_samples_per_second': 1.132, 'eval_steps_per_second': 0.283, 'epoch': 2.86}
{'loss': 3.749, 'grad_norm': 0.208984375, 'learning_rate': 1.995193586829387e-06, 'epoch': 2.94}
{'loss': 3.8301, 'grad_norm': 0.408203125, 'learning_rate': 1.7183609644824096e-06, 'epoch': 3.02}
{'eval_loss': 2.902688503265381, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 888.9063, 'eval_samples_per_second': 1.125, 'eval_steps_per_second': 0.281, 'epoch': 3.06}
{'loss': 3.8724, 'grad_norm': 0.267578125, 'learning_rate': 1.4581751015526035e-06, 'epoch': 3.1}
{'loss': 3.9237, 'grad_norm': 0.1435546875, 'learning_rate': 1.2159558420011907e-06, 'epoch': 3.18}
{'loss': 3.7668, 'grad_norm': 0.146484375, 'learning_rate': 9.929318906602176e-07, 'epoch': 3.27}
{'eval_loss': 2.911313772201538, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 883.3334, 'eval_samples_per_second': 1.132, 'eval_steps_per_second': 0.283, 'epoch': 3.27}
{'loss': 3.5784, 'grad_norm': 0.27734375, 'learning_rate': 7.902345803856265e-07, 'epoch': 3.35}
{'loss': 3.8146, 'grad_norm': 0.130859375, 'learning_rate': 6.088921331488568e-07, 'epoch': 3.43}
{'eval_loss': 2.9105563163757324, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 888.1224, 'eval_samples_per_second': 1.126, 'eval_steps_per_second': 0.281, 'epoch': 3.47}
{'loss': 3.6392, 'grad_norm': 0.15234375, 'learning_rate': 4.4982444417866753e-07, 'epoch': 3.51}
{'loss': 3.7, 'grad_norm': 0.1455078125, 'learning_rate': 3.138384156116614e-07, 'epoch': 3.59}
{'loss': 3.5765, 'grad_norm': 0.1826171875, 'learning_rate': 2.016238633225165e-07, 'epoch': 3.67}
{'eval_loss': 2.8981289863586426, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 883.357, 'eval_samples_per_second': 1.132, 'eval_steps_per_second': 0.283, 'epoch': 3.67}
{'loss': 3.802, 'grad_norm': 0.2265625, 'learning_rate': 1.1375001769728e-07, 'epoch': 3.76}
{'loss': 3.6485, 'grad_norm': 0.18359375, 'learning_rate': 5.0662636100292094e-08, 'epoch': 3.84}
{'eval_loss': 2.9057016372680664, 'eval_model_preparation_time': 0.0061, 'eval_runtime': 887.4125, 'eval_samples_per_second': 1.127, 'eval_steps_per_second': 0.282, 'epoch': 3.88}
{'loss': 3.6818, 'grad_norm': 0.232421875, 'learning_rate': 1.2681741682282755e-08, 'epoch': 3.92}
{'loss': 3.7538, 'grad_norm': 0.482421875, 'learning_rate': 0.0, 'epoch': 4.0}
{'train_runtime': 43195.6426, 'train_samples_per_second': 0.725, 'train_steps_per_second': 0.023, 'train_loss': 4.1110916449099175, 'epoch': 4.0}
