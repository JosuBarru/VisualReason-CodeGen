ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 03-15 11:43:48 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.739 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 7.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.6897, 'grad_norm': 3.04256534576416, 'learning_rate': 1.4440433212996392e-06, 'rewards/chosen': 0.025389159098267555, 'rewards/rejected': 0.018180526793003082, 'rewards/accuracies': 0.5921875238418579, 'rewards/margins': 0.007208631839603186, 'logps/chosen': -171.5666046142578, 'logps/rejected': -206.66403198242188, 'logits/chosen': -0.6782562136650085, 'logits/rejected': -0.6466115117073059, 'epoch': 0.09}
{'loss': 0.6462, 'grad_norm': 3.378099203109741, 'learning_rate': 2.8880866425992783e-06, 'rewards/chosen': 0.32690685987472534, 'rewards/rejected': 0.2055124044418335, 'rewards/accuracies': 0.6640625, 'rewards/margins': 0.12139443308115005, 'logps/chosen': -172.69815063476562, 'logps/rejected': -197.77688598632812, 'logits/chosen': -0.6840718388557434, 'logits/rejected': -0.6404507160186768, 'epoch': 0.17}
{'eval_loss': 0.5690808296203613, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.6958, 'eval_samples_per_second': 3.694, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': 0.6820017099380493, 'eval_rewards/rejected': 0.2902083694934845, 'eval_rewards/accuracies': 0.7059999704360962, 'eval_rewards/margins': 0.39179328083992004, 'eval_logps/chosen': -170.88760375976562, 'eval_logps/rejected': -197.14114379882812, 'eval_logits/chosen': -0.6594622731208801, 'eval_logits/rejected': -0.582590639591217, 'epoch': 0.22}
{'loss': 0.5966, 'grad_norm': 4.484020709991455, 'learning_rate': 4.332129963898917e-06, 'rewards/chosen': 0.6152632832527161, 'rewards/rejected': 0.30669349431991577, 'rewards/accuracies': 0.6796875, 'rewards/margins': 0.3085697293281555, 'logps/chosen': -173.27212524414062, 'logps/rejected': -198.99737548828125, 'logits/chosen': -0.6296370625495911, 'logits/rejected': -0.637877345085144, 'epoch': 0.26}
{'loss': 0.507, 'grad_norm': 4.149714946746826, 'learning_rate': 5.776173285198557e-06, 'rewards/chosen': 0.990443229675293, 'rewards/rejected': 0.32616740465164185, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.6642759442329407, 'logps/chosen': -165.59422302246094, 'logps/rejected': -193.25656127929688, 'logits/chosen': -0.5445522665977478, 'logits/rejected': -0.49328407645225525, 'epoch': 0.35}
{'loss': 0.4714, 'grad_norm': 4.334943771362305, 'learning_rate': 7.220216606498196e-06, 'rewards/chosen': 1.727518081665039, 'rewards/rejected': 0.8038183450698853, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.9236998558044434, 'logps/chosen': -156.8570556640625, 'logps/rejected': -189.01351928710938, 'logits/chosen': -0.42461198568344116, 'logits/rejected': -0.40101760625839233, 'epoch': 0.43}
{'eval_loss': 0.46256452798843384, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.7375, 'eval_samples_per_second': 3.694, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': 2.4570837020874023, 'eval_rewards/rejected': 1.3924154043197632, 'eval_rewards/accuracies': 0.7850000262260437, 'eval_rewards/margins': 1.0646681785583496, 'eval_logps/chosen': -153.1367950439453, 'eval_logps/rejected': -186.11907958984375, 'eval_logits/chosen': -0.3857816159725189, 'eval_logits/rejected': -0.31946176290512085, 'epoch': 0.43}
{'loss': 0.4486, 'grad_norm': 6.706897258758545, 'learning_rate': 8.664259927797834e-06, 'rewards/chosen': 2.2329678535461426, 'rewards/rejected': 0.9251570701599121, 'rewards/accuracies': 0.7718750238418579, 'rewards/margins': 1.307810664176941, 'logps/chosen': -152.33975219726562, 'logps/rejected': -185.54727172851562, 'logits/chosen': -0.2822999060153961, 'logits/rejected': -0.25205644965171814, 'epoch': 0.52}
{'loss': 0.4568, 'grad_norm': 4.462523937225342, 'learning_rate': 9.999984068754815e-06, 'rewards/chosen': 2.2295546531677246, 'rewards/rejected': 0.8569827079772949, 'rewards/accuracies': 0.778124988079071, 'rewards/margins': 1.3725721836090088, 'logps/chosen': -158.32186889648438, 'logps/rejected': -194.59518432617188, 'logits/chosen': -0.23671765625476837, 'logits/rejected': -0.21683254837989807, 'epoch': 0.61}
{'eval_loss': 0.41969555616378784, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 271.1015, 'eval_samples_per_second': 3.689, 'eval_steps_per_second': 0.461, 'eval_rewards/chosen': 2.419037103652954, 'eval_rewards/rejected': 0.8951483368873596, 'eval_rewards/accuracies': 0.7929999828338623, 'eval_rewards/margins': 1.5238890647888184, 'eval_logps/chosen': -153.51727294921875, 'eval_logps/rejected': -191.09176635742188, 'eval_logits/chosen': -0.15759992599487305, 'eval_logits/rejected': -0.08299709856510162, 'epoch': 0.65}
{'loss': 0.4116, 'grad_norm': 4.157078742980957, 'learning_rate': 9.9929759623292e-06, 'rewards/chosen': 2.3710899353027344, 'rewards/rejected': 0.8454621434211731, 'rewards/accuracies': 0.809374988079071, 'rewards/margins': 1.525627851486206, 'logps/chosen': -152.78704833984375, 'logps/rejected': -191.14532470703125, 'logits/chosen': -0.13098740577697754, 'logits/rejected': -0.11840194463729858, 'epoch': 0.69}
{'loss': 0.4297, 'grad_norm': 3.1917266845703125, 'learning_rate': 9.973243460482701e-06, 'rewards/chosen': 2.7101433277130127, 'rewards/rejected': 0.907485842704773, 'rewards/accuracies': 0.7890625, 'rewards/margins': 1.8026574850082397, 'logps/chosen': -148.39369201660156, 'logps/rejected': -186.68948364257812, 'logits/chosen': -0.014540521427989006, 'logits/rejected': 0.043245136737823486, 'epoch': 0.78}
{'loss': 0.3932, 'grad_norm': 6.203333377838135, 'learning_rate': 9.940836850690774e-06, 'rewards/chosen': 2.3181190490722656, 'rewards/rejected': 0.5099679231643677, 'rewards/accuracies': 0.8140624761581421, 'rewards/margins': 1.8081512451171875, 'logps/chosen': -149.9619598388672, 'logps/rejected': -189.24429321289062, 'logits/chosen': 0.011756432242691517, 'logits/rejected': 0.053021371364593506, 'epoch': 0.87}
{'eval_loss': 0.41328659653663635, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 271.0886, 'eval_samples_per_second': 3.689, 'eval_steps_per_second': 0.461, 'eval_rewards/chosen': 2.0036206245422363, 'eval_rewards/rejected': -0.09581924229860306, 'eval_rewards/accuracies': 0.8050000071525574, 'eval_rewards/margins': 2.099439859390259, 'eval_logps/chosen': -157.67140197753906, 'eval_logps/rejected': -201.0014190673828, 'eval_logits/chosen': 0.012358414940536022, 'eval_logits/rejected': 0.0921541303396225, 'epoch': 0.87}
{'loss': 0.3984, 'grad_norm': 6.839776039123535, 'learning_rate': 9.895838719875592e-06, 'rewards/chosen': 2.1187288761138916, 'rewards/rejected': 0.14704227447509766, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.971686601638794, 'logps/chosen': -153.60943603515625, 'logps/rejected': -199.65896606445312, 'logits/chosen': 0.05719602108001709, 'logits/rejected': 0.11201997846364975, 'epoch': 0.95}
{'loss': 0.3871, 'grad_norm': 6.211038112640381, 'learning_rate': 9.838363743936667e-06, 'rewards/chosen': 2.311008930206299, 'rewards/rejected': 0.23861755430698395, 'rewards/accuracies': 0.8121117949485779, 'rewards/margins': 2.0723917484283447, 'logps/chosen': -155.2700653076172, 'logps/rejected': -194.94552612304688, 'logits/chosen': 0.10383933037519455, 'logits/rejected': 0.13286639750003815, 'epoch': 1.04}
{'eval_loss': 0.382785826921463, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 271.5185, 'eval_samples_per_second': 3.683, 'eval_steps_per_second': 0.46, 'eval_rewards/chosen': 2.6037821769714355, 'eval_rewards/rejected': 0.44239774346351624, 'eval_rewards/accuracies': 0.8149999976158142, 'eval_rewards/margins': 2.1613845825195312, 'eval_logps/chosen': -151.66981506347656, 'eval_logps/rejected': -195.61924743652344, 'eval_logits/chosen': 0.1153930127620697, 'eval_logits/rejected': 0.19372855126857758, 'epoch': 1.08}
{'loss': 0.2763, 'grad_norm': 2.960829257965088, 'learning_rate': 9.76855839550398e-06, 'rewards/chosen': 2.6489102840423584, 'rewards/rejected': 0.2007923573255539, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 2.448117971420288, 'logps/chosen': -150.73764038085938, 'logps/rejected': -194.3114776611328, 'logits/chosen': 0.11509928852319717, 'logits/rejected': 0.1627388447523117, 'epoch': 1.13}
{'loss': 0.3288, 'grad_norm': 2.918527841567993, 'learning_rate': 9.686600570658478e-06, 'rewards/chosen': 2.451547145843506, 'rewards/rejected': -0.32201987504959106, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.7735671997070312, 'logps/chosen': -153.94790649414062, 'logps/rejected': -202.0919952392578, 'logits/chosen': 0.13556553423404694, 'logits/rejected': 0.213724285364151, 'epoch': 1.21}
{'loss': 0.2792, 'grad_norm': 2.409734010696411, 'learning_rate': 9.592699135571163e-06, 'rewards/chosen': 2.5327658653259277, 'rewards/rejected': -0.26770922541618347, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.8004748821258545, 'logps/chosen': -148.91676330566406, 'logps/rejected': -202.77139282226562, 'logits/chosen': 0.19927458465099335, 'logits/rejected': 0.23941035568714142, 'epoch': 1.3}
{'eval_loss': 0.39925602078437805, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.6144, 'eval_samples_per_second': 3.695, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': 2.0770134925842285, 'eval_rewards/rejected': -0.61861652135849, 'eval_rewards/accuracies': 0.8180000185966492, 'eval_rewards/margins': 2.695629835128784, 'eval_logps/chosen': -156.9375, 'eval_logps/rejected': -206.22938537597656, 'eval_logits/chosen': 0.18115483224391937, 'eval_logits/rejected': 0.2636375427246094, 'epoch': 1.3}
{'loss': 0.314, 'grad_norm': 4.374218463897705, 'learning_rate': 9.487093394216193e-06, 'rewards/chosen': 2.4227943420410156, 'rewards/rejected': -0.5894843935966492, 'rewards/accuracies': 0.854687511920929, 'rewards/margins': 3.0122787952423096, 'logps/chosen': -151.35911560058594, 'logps/rejected': -199.9766845703125, 'logits/chosen': 0.22530655562877655, 'logits/rejected': 0.2716994881629944, 'epoch': 1.39}
{'loss': 0.2895, 'grad_norm': 7.204453468322754, 'learning_rate': 9.370052478514457e-06, 'rewards/chosen': 2.745008945465088, 'rewards/rejected': -0.34301450848579407, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0880234241485596, 'logps/chosen': -148.7169952392578, 'logps/rejected': -207.41989135742188, 'logits/chosen': 0.2718642055988312, 'logits/rejected': 0.28364869952201843, 'epoch': 1.47}
{'eval_loss': 0.3707854151725769, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.1964, 'eval_samples_per_second': 3.701, 'eval_steps_per_second': 0.463, 'eval_rewards/chosen': 2.2798027992248535, 'eval_rewards/rejected': -0.6827873587608337, 'eval_rewards/accuracies': 0.8299999833106995, 'eval_rewards/margins': 2.962590217590332, 'eval_logps/chosen': -154.9095916748047, 'eval_logps/rejected': -206.87109375, 'eval_logits/chosen': 0.21458888053894043, 'eval_logits/rejected': 0.30291298031806946, 'epoch': 1.52}
{'loss': 0.2763, 'grad_norm': 5.036905765533447, 'learning_rate': 9.241874662461875e-06, 'rewards/chosen': 2.6418519020080566, 'rewards/rejected': -0.6087861061096191, 'rewards/accuracies': 0.885937511920929, 'rewards/margins': 3.2506377696990967, 'logps/chosen': -148.0280303955078, 'logps/rejected': -207.50186157226562, 'logits/chosen': 0.23395392298698425, 'logits/rejected': 0.28794994950294495, 'epoch': 1.56}
{'loss': 0.3205, 'grad_norm': 5.948733329772949, 'learning_rate': 9.10288660199029e-06, 'rewards/chosen': 3.1496939659118652, 'rewards/rejected': 0.10607852041721344, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.0436155796051025, 'logps/chosen': -140.94546508789062, 'logps/rejected': -194.96910095214844, 'logits/chosen': 0.24441885948181152, 'logits/rejected': 0.30764612555503845, 'epoch': 1.65}
{'loss': 0.2807, 'grad_norm': 6.4548020362854, 'learning_rate': 8.95344250249816e-06, 'rewards/chosen': 2.916682243347168, 'rewards/rejected': -0.1441042423248291, 'rewards/accuracies': 0.8765624761581421, 'rewards/margins': 3.060786485671997, 'logps/chosen': -145.9727325439453, 'logps/rejected': -197.31394958496094, 'logits/chosen': 0.2709610164165497, 'logits/rejected': 0.3145065903663635, 'epoch': 1.73}
{'eval_loss': 0.3478035032749176, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.3849, 'eval_samples_per_second': 3.698, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': 2.632627010345459, 'eval_rewards/rejected': -0.42897099256515503, 'eval_rewards/accuracies': 0.8389999866485596, 'eval_rewards/margins': 3.061598062515259, 'eval_logps/chosen': -151.38136291503906, 'eval_logps/rejected': -204.33291625976562, 'eval_logits/chosen': 0.25621023774147034, 'eval_logits/rejected': 0.345298171043396, 'epoch': 1.73}
{'loss': 0.2808, 'grad_norm': 5.410454273223877, 'learning_rate': 8.793923216172556e-06, 'rewards/chosen': 2.4579014778137207, 'rewards/rejected': -1.0384302139282227, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.4963316917419434, 'logps/chosen': -148.064697265625, 'logps/rejected': -215.65673828125, 'logits/chosen': 0.2311706244945526, 'logits/rejected': 0.29470810294151306, 'epoch': 1.82}
{'loss': 0.2987, 'grad_norm': 6.174285411834717, 'learning_rate': 8.624735271402914e-06, 'rewards/chosen': 3.0349698066711426, 'rewards/rejected': 0.009679466485977173, 'rewards/accuracies': 0.8609374761581421, 'rewards/margins': 3.025290012359619, 'logps/chosen': -146.17697143554688, 'logps/rejected': -200.62313842773438, 'logits/chosen': 0.2648843228816986, 'logits/rejected': 0.30323144793510437, 'epoch': 1.91}
{'eval_loss': 0.3439573347568512, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.3988, 'eval_samples_per_second': 3.698, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': 3.1308906078338623, 'eval_rewards/rejected': -0.02122841216623783, 'eval_rewards/accuracies': 0.8330000042915344, 'eval_rewards/margins': 3.152118682861328, 'eval_logps/chosen': -146.39871215820312, 'eval_logps/rejected': -200.25550842285156, 'eval_logits/chosen': 0.22934827208518982, 'eval_logits/rejected': 0.3181450664997101, 'epoch': 1.95}
{'loss': 0.3129, 'grad_norm': 3.917377471923828, 'learning_rate': 8.446309836760029e-06, 'rewards/chosen': 3.252796173095703, 'rewards/rejected': 0.18130826950073242, 'rewards/accuracies': 0.8578125238418579, 'rewards/margins': 3.0714876651763916, 'logps/chosen': -146.72769165039062, 'logps/rejected': -196.5175018310547, 'logits/chosen': 0.25244140625, 'logits/rejected': 0.27725547552108765, 'epoch': 1.99}
{'loss': 0.1755, 'grad_norm': 3.134944200515747, 'learning_rate': 8.259101622180558e-06, 'rewards/chosen': 2.844466209411621, 'rewards/rejected': -1.3182193040847778, 'rewards/accuracies': 0.9270186424255371, 'rewards/margins': 4.162685871124268, 'logps/chosen': -149.3016815185547, 'logps/rejected': -211.2451934814453, 'logits/chosen': 0.24698366224765778, 'logits/rejected': 0.28260818123817444, 'epoch': 2.08}
{'loss': 0.1579, 'grad_norm': 3.341468334197998, 'learning_rate': 8.063587720157298e-06, 'rewards/chosen': 2.911895275115967, 'rewards/rejected': -1.8092567920684814, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 4.721152305603027, 'logps/chosen': -143.0246124267578, 'logps/rejected': -217.3567657470703, 'logits/chosen': 0.22617189586162567, 'logits/rejected': 0.2985606789588928, 'epoch': 2.17}
{'eval_loss': 0.3987312316894531, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.6254, 'eval_samples_per_second': 3.695, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': 2.6809370517730713, 'eval_rewards/rejected': -1.560072898864746, 'eval_rewards/accuracies': 0.8370000123977661, 'eval_rewards/margins': 4.2410101890563965, 'eval_logps/chosen': -150.89825439453125, 'eval_logps/rejected': -215.64395141601562, 'eval_logits/chosen': 0.23835866153240204, 'eval_logits/rejected': 0.32730570435523987, 'epoch': 2.17}
{'loss': 0.1758, 'grad_norm': 6.756343364715576, 'learning_rate': 7.860266389888446e-06, 'rewards/chosen': 2.4973864555358887, 'rewards/rejected': -2.2987093925476074, 'rewards/accuracies': 0.934374988079071, 'rewards/margins': 4.796095848083496, 'logps/chosen': -149.44302368164062, 'logps/rejected': -223.4529266357422, 'logits/chosen': 0.28112533688545227, 'logits/rejected': 0.31185635924339294, 'epoch': 2.26}
{'loss': 0.1388, 'grad_norm': 5.436707019805908, 'learning_rate': 7.64965578748438e-06, 'rewards/chosen': 2.778794765472412, 'rewards/rejected': -2.569817543029785, 'rewards/accuracies': 0.9453125, 'rewards/margins': 5.348612308502197, 'logps/chosen': -145.42178344726562, 'logps/rejected': -223.9853973388672, 'logits/chosen': 0.29591384530067444, 'logits/rejected': 0.36400145292282104, 'epoch': 2.34}
{'eval_loss': 0.39680016040802, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.3021, 'eval_samples_per_second': 3.7, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': 2.624999761581421, 'eval_rewards/rejected': -1.7687952518463135, 'eval_rewards/accuracies': 0.8399999737739563, 'eval_rewards/margins': 4.393795013427734, 'eval_logps/chosen': -151.45762634277344, 'eval_logps/rejected': -217.73117065429688, 'eval_logits/chosen': 0.2970482110977173, 'eval_logits/rejected': 0.38389426469802856, 'epoch': 2.39}
{'loss': 0.1667, 'grad_norm': 12.385211944580078, 'learning_rate': 7.432292645467955e-06, 'rewards/chosen': 3.0284571647644043, 'rewards/rejected': -1.9774677753448486, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 5.005924701690674, 'logps/chosen': -144.58200073242188, 'logps/rejected': -220.7151336669922, 'logits/chosen': 0.3225739896297455, 'logits/rejected': 0.3791191577911377, 'epoch': 2.43}
{'loss': 0.1404, 'grad_norm': 6.112334728240967, 'learning_rate': 7.208730904933583e-06, 'rewards/chosen': 2.986098527908325, 'rewards/rejected': -1.8942302465438843, 'rewards/accuracies': 0.942187488079071, 'rewards/margins': 4.88032865524292, 'logps/chosen': -147.31263732910156, 'logps/rejected': -220.9394073486328, 'logits/chosen': 0.3227345049381256, 'logits/rejected': 0.37720996141433716, 'epoch': 2.52}
{'loss': 0.1406, 'grad_norm': 5.6072235107421875, 'learning_rate': 6.979540303850965e-06, 'rewards/chosen': 2.098416566848755, 'rewards/rejected': -3.390496015548706, 'rewards/accuracies': 0.9468749761581421, 'rewards/margins': 5.488913059234619, 'logps/chosen': -153.4031219482422, 'logps/rejected': -228.52542114257812, 'logits/chosen': 0.3387807011604309, 'logits/rejected': 0.38259997963905334, 'epoch': 2.6}
{'eval_loss': 0.39114484190940857, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.2859, 'eval_samples_per_second': 3.7, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': 1.80924654006958, 'eval_rewards/rejected': -3.0175819396972656, 'eval_rewards/accuracies': 0.8360000252723694, 'eval_rewards/margins': 4.8268280029296875, 'eval_logps/chosen': -159.6151580810547, 'eval_logps/rejected': -230.2190399169922, 'eval_logits/chosen': 0.3448698818683624, 'eval_logits/rejected': 0.4306486248970032, 'epoch': 2.6}
{'loss': 0.1512, 'grad_norm': 1.6874008178710938, 'learning_rate': 6.745304925111131e-06, 'rewards/chosen': 2.563885450363159, 'rewards/rejected': -2.6262047290802, 'rewards/accuracies': 0.9468749761581421, 'rewards/margins': 5.190090179443359, 'logps/chosen': -151.647216796875, 'logps/rejected': -223.4672088623047, 'logits/chosen': 0.3849043846130371, 'logits/rejected': 0.41557759046554565, 'epoch': 2.69}
{'loss': 0.196, 'grad_norm': 6.92507266998291, 'learning_rate': 6.5066217080150374e-06, 'rewards/chosen': 2.4827921390533447, 'rewards/rejected': -2.674731731414795, 'rewards/accuracies': 0.9156249761581421, 'rewards/margins': 5.157524108886719, 'logps/chosen': -153.66409301757812, 'logps/rejected': -231.3454132080078, 'logits/chosen': 0.38891923427581787, 'logits/rejected': 0.449517160654068, 'epoch': 2.78}
