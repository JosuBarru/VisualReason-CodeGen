ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 03-14 11:55:24 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.48.2.
   \\   /|    GPU: Tesla V100-PCIE-32GB. Max memory: 31.739 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 7.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
{'loss': 0.693, 'grad_norm': 3.0397567749023438, 'learning_rate': 1.4440433212996388e-07, 'rewards/chosen': 0.0006308651645667851, 'rewards/rejected': 0.0003115088038612157, 'rewards/accuracies': 0.4609375, 'rewards/margins': 0.00031935638980939984, 'logps/chosen': -171.81417846679688, 'logps/rejected': -206.8427276611328, 'logits/chosen': -0.6799067258834839, 'logits/rejected': -0.6481128931045532, 'epoch': 0.09}
{'loss': 0.6918, 'grad_norm': 3.6429591178894043, 'learning_rate': 2.8880866425992776e-07, 'rewards/chosen': 0.00884273275732994, 'rewards/rejected': 0.006075362674891949, 'rewards/accuracies': 0.5921875238418579, 'rewards/margins': 0.0027673703152686357, 'logps/chosen': -175.8787841796875, 'logps/rejected': -199.77127075195312, 'logits/chosen': -0.7004960775375366, 'logits/rejected': -0.6559855937957764, 'epoch': 0.17}
{'eval_loss': 0.6840041279792786, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.7158, 'eval_samples_per_second': 3.614, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.042113836854696274, 'eval_rewards/rejected': 0.02321707271039486, 'eval_rewards/accuracies': 0.6710000038146973, 'eval_rewards/margins': 0.018896762281656265, 'eval_logps/chosen': -177.2864990234375, 'eval_logps/rejected': -199.81105041503906, 'eval_logits/chosen': -0.6977875828742981, 'eval_logits/rejected': -0.6154060959815979, 'epoch': 0.22}
{'loss': 0.6854, 'grad_norm': 3.7344589233398438, 'learning_rate': 4.3321299638989166e-07, 'rewards/chosen': 0.04099992662668228, 'rewards/rejected': 0.0247174222022295, 'rewards/accuracies': 0.628125011920929, 'rewards/margins': 0.016282502561807632, 'logps/chosen': -179.01475524902344, 'logps/rejected': -201.81712341308594, 'logits/chosen': -0.6713511347770691, 'logits/rejected': -0.6753646731376648, 'epoch': 0.26}
{'loss': 0.6664, 'grad_norm': 3.9609854221343994, 'learning_rate': 5.776173285198555e-07, 'rewards/chosen': 0.12279315292835236, 'rewards/rejected': 0.06391619145870209, 'rewards/accuracies': 0.682812511920929, 'rewards/margins': 0.05887696146965027, 'logps/chosen': -174.27072143554688, 'logps/rejected': -195.8791046142578, 'logits/chosen': -0.6875366568565369, 'logits/rejected': -0.6355651617050171, 'epoch': 0.35}
{'loss': 0.6481, 'grad_norm': 3.2572336196899414, 'learning_rate': 7.220216606498195e-07, 'rewards/chosen': 0.2496955841779709, 'rewards/rejected': 0.1372615247964859, 'rewards/accuracies': 0.6703125238418579, 'rewards/margins': 0.11243407428264618, 'logps/chosen': -171.6352996826172, 'logps/rejected': -195.6790771484375, 'logits/chosen': -0.6729611158370972, 'logits/rejected': -0.6365880370140076, 'epoch': 0.43}
{'eval_loss': 0.630760669708252, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.7668, 'eval_samples_per_second': 3.613, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.34746408462524414, 'eval_rewards/rejected': 0.1893048733472824, 'eval_rewards/accuracies': 0.6859999895095825, 'eval_rewards/margins': 0.15815919637680054, 'eval_logps/chosen': -174.2329864501953, 'eval_logps/rejected': -198.1501922607422, 'eval_logits/chosen': -0.6899631023406982, 'eval_logits/rejected': -0.6095653176307678, 'epoch': 0.43}
{'loss': 0.6231, 'grad_norm': 3.5223100185394287, 'learning_rate': 8.664259927797833e-07, 'rewards/chosen': 0.4559692442417145, 'rewards/rejected': 0.2690727710723877, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.1868964433670044, 'logps/chosen': -170.10975646972656, 'logps/rejected': -192.1081085205078, 'logits/chosen': -0.6686955094337463, 'logits/rejected': -0.6218807101249695, 'epoch': 0.52}
{'loss': 0.5888, 'grad_norm': 3.898831605911255, 'learning_rate': 9.99996415472213e-07, 'rewards/chosen': 0.641464352607727, 'rewards/rejected': 0.3488454520702362, 'rewards/accuracies': 0.729687511920929, 'rewards/margins': 0.29261887073516846, 'logps/chosen': -174.20277404785156, 'logps/rejected': -199.67654418945312, 'logits/chosen': -0.668038010597229, 'logits/rejected': -0.6373237371444702, 'epoch': 0.61}
{'eval_loss': 0.5697144865989685, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.2551, 'eval_samples_per_second': 3.62, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.7524620294570923, 'eval_rewards/rejected': 0.3855648934841156, 'eval_rewards/accuracies': 0.7110000252723694, 'eval_rewards/margins': 0.3668970763683319, 'eval_logps/chosen': -170.18299865722656, 'eval_logps/rejected': -196.18759155273438, 'eval_logits/chosen': -0.6623775959014893, 'eval_logits/rejected': -0.5840068459510803, 'epoch': 0.65}
{'loss': 0.5778, 'grad_norm': 2.829315185546875, 'learning_rate': 9.9929759623292e-07, 'rewards/chosen': 0.7584857940673828, 'rewards/rejected': 0.4083508551120758, 'rewards/accuracies': 0.7109375, 'rewards/margins': 0.3501349091529846, 'logps/chosen': -168.91307067871094, 'logps/rejected': -195.51644897460938, 'logits/chosen': -0.6467668414115906, 'logits/rejected': -0.6342287063598633, 'epoch': 0.69}
{'loss': 0.5595, 'grad_norm': 3.1398301124572754, 'learning_rate': 9.9732434604827e-07, 'rewards/chosen': 0.9577953219413757, 'rewards/rejected': 0.5352931618690491, 'rewards/accuracies': 0.714062511920929, 'rewards/margins': 0.4225021302700043, 'logps/chosen': -165.9171600341797, 'logps/rejected': -190.41140747070312, 'logits/chosen': -0.6524180173873901, 'logits/rejected': -0.5969864130020142, 'epoch': 0.78}
{'loss': 0.527, 'grad_norm': 4.520618438720703, 'learning_rate': 9.940836850690772e-07, 'rewards/chosen': 1.0221961736679077, 'rewards/rejected': 0.4880998730659485, 'rewards/accuracies': 0.754687488079071, 'rewards/margins': 0.534096360206604, 'logps/chosen': -162.92117309570312, 'logps/rejected': -189.4629364013672, 'logits/chosen': -0.6130661964416504, 'logits/rejected': -0.5681483745574951, 'epoch': 0.87}
{'eval_loss': 0.525288462638855, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.6241, 'eval_samples_per_second': 3.615, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 1.0837359428405762, 'eval_rewards/rejected': 0.5074805021286011, 'eval_rewards/accuracies': 0.7369999885559082, 'eval_rewards/margins': 0.5762553811073303, 'eval_logps/chosen': -166.87026977539062, 'eval_logps/rejected': -194.96841430664062, 'eval_logits/chosen': -0.6186537146568298, 'eval_logits/rejected': -0.5425225496292114, 'epoch': 0.87}
{'loss': 0.5316, 'grad_norm': 3.2326719760894775, 'learning_rate': 9.895838719875592e-07, 'rewards/chosen': 1.0271764993667603, 'rewards/rejected': 0.4531235694885254, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.5740529894828796, 'logps/chosen': -164.52496337890625, 'logps/rejected': -196.59815979003906, 'logits/chosen': -0.6046401858329773, 'logits/rejected': -0.5549517869949341, 'epoch': 0.95}
{'loss': 0.5116, 'grad_norm': 4.801398277282715, 'learning_rate': 9.838363743936666e-07, 'rewards/chosen': 1.1762323379516602, 'rewards/rejected': 0.5226130485534668, 'rewards/accuracies': 0.760869562625885, 'rewards/margins': 0.653619110584259, 'logps/chosen': -166.61782836914062, 'logps/rejected': -192.10556030273438, 'logits/chosen': -0.5938952565193176, 'logits/rejected': -0.5766822099685669, 'epoch': 1.04}
{'eval_loss': 0.4964040219783783, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.7323, 'eval_samples_per_second': 3.614, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 1.3411624431610107, 'eval_rewards/rejected': 0.6248399019241333, 'eval_rewards/accuracies': 0.7590000033378601, 'eval_rewards/margins': 0.7163223624229431, 'eval_logps/chosen': -164.29600524902344, 'eval_logps/rejected': -193.79483032226562, 'eval_logits/chosen': -0.5884060263633728, 'eval_logits/rejected': -0.5181800723075867, 'epoch': 1.08}
{'loss': 0.4936, 'grad_norm': 3.510772466659546, 'learning_rate': 9.76855839550398e-07, 'rewards/chosen': 1.328070878982544, 'rewards/rejected': 0.620513916015625, 'rewards/accuracies': 0.778124988079071, 'rewards/margins': 0.7075569033622742, 'logps/chosen': -163.946044921875, 'logps/rejected': -190.1142578125, 'logits/chosen': -0.6000183820724487, 'logits/rejected': -0.5681568384170532, 'epoch': 1.13}
{'loss': 0.4903, 'grad_norm': 4.386542797088623, 'learning_rate': 9.686600570658477e-07, 'rewards/chosen': 1.3867347240447998, 'rewards/rejected': 0.6367665529251099, 'rewards/accuracies': 0.765625, 'rewards/margins': 0.7499681711196899, 'logps/chosen': -164.59603881835938, 'logps/rejected': -192.50413513183594, 'logits/chosen': -0.579148530960083, 'logits/rejected': -0.4979066252708435, 'epoch': 1.21}
{'loss': 0.455, 'grad_norm': 3.798252582550049, 'learning_rate': 9.592699135571163e-07, 'rewards/chosen': 1.441919207572937, 'rewards/rejected': 0.5686860084533691, 'rewards/accuracies': 0.778124988079071, 'rewards/margins': 0.8732331991195679, 'logps/chosen': -159.82521057128906, 'logps/rejected': -194.40744018554688, 'logits/chosen': -0.5325261950492859, 'logits/rejected': -0.507132351398468, 'epoch': 1.3}
{'eval_loss': 0.47347208857536316, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.4843, 'eval_samples_per_second': 3.617, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 1.4275990724563599, 'eval_rewards/rejected': 0.5498176217079163, 'eval_rewards/accuracies': 0.7689999938011169, 'eval_rewards/margins': 0.8777815699577332, 'eval_logps/chosen': -163.43162536621094, 'eval_logps/rejected': -194.5450439453125, 'eval_logits/chosen': -0.5323430299758911, 'eval_logits/rejected': -0.46385297179222107, 'epoch': 1.3}
{'loss': 0.4739, 'grad_norm': 4.030181407928467, 'learning_rate': 9.487093394216191e-07, 'rewards/chosen': 1.4726022481918335, 'rewards/rejected': 0.6113758087158203, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 0.8612265586853027, 'logps/chosen': -160.86105346679688, 'logps/rejected': -187.9680633544922, 'logits/chosen': -0.475114107131958, 'logits/rejected': -0.4552547335624695, 'epoch': 1.39}
{'loss': 0.4745, 'grad_norm': 4.38151216506958, 'learning_rate': 9.370052478514456e-07, 'rewards/chosen': 1.6607545614242554, 'rewards/rejected': 0.7825623154640198, 'rewards/accuracies': 0.785937488079071, 'rewards/margins': 0.8781924247741699, 'logps/chosen': -159.55953979492188, 'logps/rejected': -196.1641387939453, 'logits/chosen': -0.4720049798488617, 'logits/rejected': -0.4726129472255707, 'epoch': 1.47}
{'eval_loss': 0.4601975083351135, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.5126, 'eval_samples_per_second': 3.616, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 1.6829774379730225, 'eval_rewards/rejected': 0.7049484252929688, 'eval_rewards/accuracies': 0.7739999890327454, 'eval_rewards/margins': 0.9780291318893433, 'eval_logps/chosen': -160.8778533935547, 'eval_logps/rejected': -192.99374389648438, 'eval_logits/chosen': -0.488773912191391, 'eval_logits/rejected': -0.4225725829601288, 'epoch': 1.52}
{'loss': 0.4321, 'grad_norm': 5.722225666046143, 'learning_rate': 9.241874662461875e-07, 'rewards/chosen': 1.7440789937973022, 'rewards/rejected': 0.732974648475647, 'rewards/accuracies': 0.807812511920929, 'rewards/margins': 1.0111043453216553, 'logps/chosen': -157.00575256347656, 'logps/rejected': -194.084228515625, 'logits/chosen': -0.4707752764225006, 'logits/rejected': -0.44674691557884216, 'epoch': 1.56}
{'loss': 0.4601, 'grad_norm': 6.81640625, 'learning_rate': 9.10288660199029e-07, 'rewards/chosen': 1.6198976039886475, 'rewards/rejected': 0.5776089429855347, 'rewards/accuracies': 0.7640625238418579, 'rewards/margins': 1.0422886610031128, 'logps/chosen': -156.24343872070312, 'logps/rejected': -190.2537841796875, 'logits/chosen': -0.452352374792099, 'logits/rejected': -0.42088183760643005, 'epoch': 1.65}
{'loss': 0.4376, 'grad_norm': 4.272233486175537, 'learning_rate': 8.953442502498159e-07, 'rewards/chosen': 1.72190260887146, 'rewards/rejected': 0.6715874075889587, 'rewards/accuracies': 0.7828124761581421, 'rewards/margins': 1.0503151416778564, 'logps/chosen': -157.9205322265625, 'logps/rejected': -189.1570281982422, 'logits/chosen': -0.4323321282863617, 'logits/rejected': -0.41873806715011597, 'epoch': 1.73}
{'eval_loss': 0.4469221830368042, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 277.2552, 'eval_samples_per_second': 3.607, 'eval_steps_per_second': 0.451, 'eval_rewards/chosen': 1.7282154560089111, 'eval_rewards/rejected': 0.6228781342506409, 'eval_rewards/accuracies': 0.7850000262260437, 'eval_rewards/margins': 1.105337381362915, 'eval_logps/chosen': -160.42547607421875, 'eval_logps/rejected': -193.814453125, 'eval_logits/chosen': -0.437747597694397, 'eval_logits/rejected': -0.3717438876628876, 'epoch': 1.73}
{'loss': 0.4329, 'grad_norm': 5.839365482330322, 'learning_rate': 8.793923216172555e-07, 'rewards/chosen': 1.70639967918396, 'rewards/rejected': 0.5179544687271118, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.1884452104568481, 'logps/chosen': -155.5797119140625, 'logps/rejected': -200.0928955078125, 'logits/chosen': -0.4353920817375183, 'logits/rejected': -0.39500123262405396, 'epoch': 1.82}
{'loss': 0.446, 'grad_norm': 4.708091735839844, 'learning_rate': 8.624735271402912e-07, 'rewards/chosen': 1.8389513492584229, 'rewards/rejected': 0.7449263334274292, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.094024896621704, 'logps/chosen': -158.13717651367188, 'logps/rejected': -193.2706756591797, 'logits/chosen': -0.37772366404533386, 'logits/rejected': -0.36964166164398193, 'epoch': 1.91}
{'eval_loss': 0.44377321004867554, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 277.6976, 'eval_samples_per_second': 3.601, 'eval_steps_per_second': 0.45, 'eval_rewards/chosen': 2.0220301151275635, 'eval_rewards/rejected': 0.8623577952384949, 'eval_rewards/accuracies': 0.7829999923706055, 'eval_rewards/margins': 1.1596721410751343, 'eval_logps/chosen': -157.48733520507812, 'eval_logps/rejected': -191.41966247558594, 'eval_logits/chosen': -0.39484280347824097, 'eval_logits/rejected': -0.3293098509311676, 'epoch': 1.95}
{'loss': 0.477, 'grad_norm': 5.042165756225586, 'learning_rate': 8.446309836760028e-07, 'rewards/chosen': 1.9797223806381226, 'rewards/rejected': 0.9688013195991516, 'rewards/accuracies': 0.770312488079071, 'rewards/margins': 1.0109210014343262, 'logps/chosen': -159.4584197998047, 'logps/rejected': -188.64259338378906, 'logits/chosen': -0.37927520275115967, 'logits/rejected': -0.3831161558628082, 'epoch': 1.99}
{'loss': 0.4265, 'grad_norm': 3.578702449798584, 'learning_rate': 8.259101622180557e-07, 'rewards/chosen': 2.099436044692993, 'rewards/rejected': 0.9253348708152771, 'rewards/accuracies': 0.8121117949485779, 'rewards/margins': 1.1741011142730713, 'logps/chosen': -156.75198364257812, 'logps/rejected': -188.80963134765625, 'logits/chosen': -0.37038370966911316, 'logits/rejected': -0.3673785924911499, 'epoch': 2.08}
{'loss': 0.3896, 'grad_norm': 4.26688289642334, 'learning_rate': 8.063587720157297e-07, 'rewards/chosen': 2.0447192192077637, 'rewards/rejected': 0.7382025122642517, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.3065168857574463, 'logps/chosen': -151.6963653564453, 'logps/rejected': -191.88217163085938, 'logits/chosen': -0.3816675841808319, 'logits/rejected': -0.3378615379333496, 'epoch': 2.17}
{'eval_loss': 0.4384165108203888, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 278.3611, 'eval_samples_per_second': 3.592, 'eval_steps_per_second': 0.449, 'eval_rewards/chosen': 1.9988276958465576, 'eval_rewards/rejected': 0.7393909692764282, 'eval_rewards/accuracies': 0.7850000262260437, 'eval_rewards/margins': 1.259436845779419, 'eval_logps/chosen': -157.71934509277344, 'eval_logps/rejected': -192.64932250976562, 'eval_logits/chosen': -0.3542342782020569, 'eval_logits/rejected': -0.289320707321167, 'epoch': 2.17}
{'loss': 0.4221, 'grad_norm': 5.033224105834961, 'learning_rate': 7.860266389888445e-07, 'rewards/chosen': 2.0815322399139404, 'rewards/rejected': 0.8154817819595337, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.2660505771636963, 'logps/chosen': -153.60157775878906, 'logps/rejected': -192.31101989746094, 'logits/chosen': -0.330108642578125, 'logits/rejected': -0.305488646030426, 'epoch': 2.26}
{'loss': 0.3761, 'grad_norm': 3.918238639831543, 'learning_rate': 7.649655787484379e-07, 'rewards/chosen': 2.0948004722595215, 'rewards/rejected': 0.6332191228866577, 'rewards/accuracies': 0.8296874761581421, 'rewards/margins': 1.4615814685821533, 'logps/chosen': -152.26171875, 'logps/rejected': -191.95504760742188, 'logits/chosen': -0.34146299958229065, 'logits/rejected': -0.2950482666492462, 'epoch': 2.34}
{'eval_loss': 0.43461889028549194, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.5642, 'eval_samples_per_second': 3.616, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 2.1305172443389893, 'eval_rewards/rejected': 0.7519336938858032, 'eval_rewards/accuracies': 0.7839999794960022, 'eval_rewards/margins': 1.3785839080810547, 'eval_logps/chosen': -156.40243530273438, 'eval_logps/rejected': -192.52391052246094, 'eval_logits/chosen': -0.32602575421333313, 'eval_logits/rejected': -0.2617185413837433, 'epoch': 2.39}
{'loss': 0.3957, 'grad_norm': 7.606703281402588, 'learning_rate': 7.432292645467953e-07, 'rewards/chosen': 2.163808822631836, 'rewards/rejected': 0.7784087061882019, 'rewards/accuracies': 0.823437511920929, 'rewards/margins': 1.3854000568389893, 'logps/chosen': -153.2284698486328, 'logps/rejected': -193.1563720703125, 'logits/chosen': -0.3083011507987976, 'logits/rejected': -0.2904861569404602, 'epoch': 2.43}
{'loss': 0.3686, 'grad_norm': 6.579385757446289, 'learning_rate': 7.208730904933582e-07, 'rewards/chosen': 2.2345337867736816, 'rewards/rejected': 0.7191705107688904, 'rewards/accuracies': 0.8421875238418579, 'rewards/margins': 1.5153634548187256, 'logps/chosen': -154.82827758789062, 'logps/rejected': -194.80538940429688, 'logits/chosen': -0.30169302225112915, 'logits/rejected': -0.2889407277107239, 'epoch': 2.52}
{'loss': 0.4046, 'grad_norm': 6.555016040802002, 'learning_rate': 6.979540303850964e-07, 'rewards/chosen': 2.1766579151153564, 'rewards/rejected': 0.7847933173179626, 'rewards/accuracies': 0.8359375, 'rewards/margins': 1.391864538192749, 'logps/chosen': -152.62069702148438, 'logps/rejected': -186.77252197265625, 'logits/chosen': -0.29751402139663696, 'logits/rejected': -0.27937617897987366, 'epoch': 2.6}
{'eval_loss': 0.4269745647907257, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.7001, 'eval_samples_per_second': 3.614, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 2.160562038421631, 'eval_rewards/rejected': 0.7034006714820862, 'eval_rewards/accuracies': 0.7929999828338623, 'eval_rewards/margins': 1.4571616649627686, 'eval_logps/chosen': -156.1020050048828, 'eval_logps/rejected': -193.00921630859375, 'eval_logits/chosen': -0.30774810910224915, 'eval_logits/rejected': -0.2426455020904541, 'epoch': 2.6}
{'loss': 0.4314, 'grad_norm': 5.083587169647217, 'learning_rate': 6.74530492511113e-07, 'rewards/chosen': 2.1451656818389893, 'rewards/rejected': 0.7631198763847351, 'rewards/accuracies': 0.785937488079071, 'rewards/margins': 1.3820456266403198, 'logps/chosen': -155.8344268798828, 'logps/rejected': -189.57395935058594, 'logits/chosen': -0.2756381630897522, 'logits/rejected': -0.2803456783294678, 'epoch': 2.69}
{'loss': 0.4299, 'grad_norm': 5.146786689758301, 'learning_rate': 6.506621708015036e-07, 'rewards/chosen': 2.203378200531006, 'rewards/rejected': 0.8858340382575989, 'rewards/accuracies': 0.7890625, 'rewards/margins': 1.3175442218780518, 'logps/chosen': -156.458251953125, 'logps/rejected': -195.73973083496094, 'logits/chosen': -0.29076510667800903, 'logits/rejected': -0.2617158591747284, 'epoch': 2.78}
{'eval_loss': 0.42100411653518677, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.5704, 'eval_samples_per_second': 3.616, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 2.260612726211548, 'eval_rewards/rejected': 0.8347827196121216, 'eval_rewards/accuracies': 0.7960000038146973, 'eval_rewards/margins': 1.4258301258087158, 'eval_logps/chosen': -155.10150146484375, 'eval_logps/rejected': -191.69540405273438, 'eval_logits/chosen': -0.29191699624061584, 'eval_logits/rejected': -0.2255866378545761, 'epoch': 2.82}
{'loss': 0.4089, 'grad_norm': 4.817833423614502, 'learning_rate': 6.264098926998127e-07, 'rewards/chosen': 2.277377128601074, 'rewards/rejected': 0.8562029004096985, 'rewards/accuracies': 0.809374988079071, 'rewards/margins': 1.421174168586731, 'logps/chosen': -154.68333435058594, 'logps/rejected': -186.53585815429688, 'logits/chosen': -0.2914826273918152, 'logits/rejected': -0.24629756808280945, 'epoch': 2.86}
{'loss': 0.3939, 'grad_norm': 4.84436559677124, 'learning_rate': 6.018354641467756e-07, 'rewards/chosen': 2.214538812637329, 'rewards/rejected': 0.7258667945861816, 'rewards/accuracies': 0.815625011920929, 'rewards/margins': 1.488671898841858, 'logps/chosen': -153.75877380371094, 'logps/rejected': -191.29417419433594, 'logits/chosen': -0.2498820573091507, 'logits/rejected': -0.27656739950180054, 'epoch': 2.95}
{'loss': 0.384, 'grad_norm': 6.348462104797363, 'learning_rate': 5.770015120704032e-07, 'rewards/chosen': 2.256635904312134, 'rewards/rejected': 0.8000878691673279, 'rewards/accuracies': 0.8229813575744629, 'rewards/margins': 1.4565483331680298, 'logps/chosen': -152.94805908203125, 'logps/rejected': -190.4658660888672, 'logits/chosen': -0.24885417520999908, 'logits/rejected': -0.2456287294626236, 'epoch': 3.04}
{'eval_loss': 0.42007163166999817, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.6057, 'eval_samples_per_second': 3.615, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 2.197629690170288, 'eval_rewards/rejected': 0.7050968408584595, 'eval_rewards/accuracies': 0.7929999828338623, 'eval_rewards/margins': 1.492532730102539, 'eval_logps/chosen': -155.73130798339844, 'eval_logps/rejected': -192.99224853515625, 'eval_logits/chosen': -0.27737003564834595, 'eval_logits/rejected': -0.21039074659347534, 'epoch': 3.04}
{'loss': 0.3657, 'grad_norm': 6.860082149505615, 'learning_rate': 5.51971324783811e-07, 'rewards/chosen': 2.271228075027466, 'rewards/rejected': 0.6352816820144653, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.63594651222229, 'logps/chosen': -153.88316345214844, 'logps/rejected': -194.60891723632812, 'logits/chosen': -0.26428693532943726, 'logits/rejected': -0.252755343914032, 'epoch': 3.12}
{'loss': 0.371, 'grad_norm': 8.201836585998535, 'learning_rate': 5.268086906975375e-07, 'rewards/chosen': 2.3036246299743652, 'rewards/rejected': 0.7233613133430481, 'rewards/accuracies': 0.8359375, 'rewards/margins': 1.580263376235962, 'logps/chosen': -147.67227172851562, 'logps/rejected': -185.700439453125, 'logits/chosen': -0.27131080627441406, 'logits/rejected': -0.2407437264919281, 'epoch': 3.21}
{'eval_loss': 0.4178555905818939, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 277.3266, 'eval_samples_per_second': 3.606, 'eval_steps_per_second': 0.451, 'eval_rewards/chosen': 2.2319610118865967, 'eval_rewards/rejected': 0.7166489362716675, 'eval_rewards/accuracies': 0.8009999990463257, 'eval_rewards/margins': 1.5153119564056396, 'eval_logps/chosen': -155.3880157470703, 'eval_logps/rejected': -192.87672424316406, 'eval_logits/chosen': -0.2607116997241974, 'eval_logits/rejected': -0.19391052424907684, 'epoch': 3.25}
{'loss': 0.3642, 'grad_norm': 4.751784324645996, 'learning_rate': 5.015777357573835e-07, 'rewards/chosen': 2.235652446746826, 'rewards/rejected': 0.6217290163040161, 'rewards/accuracies': 0.8531249761581421, 'rewards/margins': 1.6139236688613892, 'logps/chosen': -154.04293823242188, 'logps/rejected': -194.5013427734375, 'logits/chosen': -0.25093716382980347, 'logits/rejected': -0.22743935883045197, 'epoch': 3.3}
{'loss': 0.3827, 'grad_norm': 5.83626651763916, 'learning_rate': 4.763427600220566e-07, 'rewards/chosen': 2.357954502105713, 'rewards/rejected': 0.8131626844406128, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.5447918176651, 'logps/chosen': -151.41635131835938, 'logps/rejected': -189.9910125732422, 'logits/chosen': -0.23335865139961243, 'logits/rejected': -0.2122184932231903, 'epoch': 3.38}
{'loss': 0.397, 'grad_norm': 3.2222890853881836, 'learning_rate': 4.511680737970975e-07, 'rewards/chosen': 2.366237163543701, 'rewards/rejected': 0.8483455777168274, 'rewards/accuracies': 0.823437511920929, 'rewards/margins': 1.51789128780365, 'logps/chosen': -156.8898468017578, 'logps/rejected': -183.9893035888672, 'logits/chosen': -0.22818918526172638, 'logits/rejected': -0.2105279266834259, 'epoch': 3.47}
{'eval_loss': 0.415856271982193, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.5889, 'eval_samples_per_second': 3.615, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 2.442133903503418, 'eval_rewards/rejected': 0.9174897074699402, 'eval_rewards/accuracies': 0.7950000166893005, 'eval_rewards/margins': 1.5246440172195435, 'eval_logps/chosen': -153.28628540039062, 'eval_logps/rejected': -190.8683319091797, 'eval_logits/chosen': -0.2443205565214157, 'eval_logits/rejected': -0.1771034300327301, 'epoch': 3.47}
{'loss': 0.3825, 'grad_norm': 6.369370937347412, 'learning_rate': 4.2611783374269006e-07, 'rewards/chosen': 2.402942180633545, 'rewards/rejected': 0.8116474151611328, 'rewards/accuracies': 0.828125, 'rewards/margins': 1.5912950038909912, 'logps/chosen': -151.8708953857422, 'logps/rejected': -196.94137573242188, 'logits/chosen': -0.24060583114624023, 'logits/rejected': -0.20758941769599915, 'epoch': 3.56}
{'loss': 0.3795, 'grad_norm': 3.5874080657958984, 'learning_rate': 4.0125587937303327e-07, 'rewards/chosen': 2.269684314727783, 'rewards/rejected': 0.6749860048294067, 'rewards/accuracies': 0.8218749761581421, 'rewards/margins': 1.594698190689087, 'logps/chosen': -152.87359619140625, 'logps/rejected': -196.40951538085938, 'logits/chosen': -0.23835711181163788, 'logits/rejected': -0.22155770659446716, 'epoch': 3.64}
