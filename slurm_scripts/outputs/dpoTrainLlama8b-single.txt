ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 03-15 17:07:16 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.739 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 7.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
{'eval_loss': 0.5933068990707397, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.8921, 'eval_samples_per_second': 3.692, 'eval_steps_per_second': 0.461, 'eval_rewards/chosen': 0.17233167588710785, 'eval_rewards/rejected': -7.170253753662109, 'eval_rewards/accuracies': 0.8220000267028809, 'eval_rewards/margins': 7.342584609985352, 'eval_logps/chosen': -175.98431396484375, 'eval_logps/rejected': -271.7457580566406, 'eval_logits/chosen': 0.48346632719039917, 'eval_logits/rejected': 0.5613785982131958, 'epoch': 4.12}
{'loss': 0.0146, 'grad_norm': 0.7807064652442932, 'learning_rate': 2.6008602063539706e-06, 'rewards/chosen': 1.3611888885498047, 'rewards/rejected': -8.223154067993164, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 9.584342002868652, 'logps/chosen': -162.15199279785156, 'logps/rejected': -278.83355712890625, 'logits/chosen': 0.4987131655216217, 'logits/rejected': 0.5416523218154907, 'epoch': 4.16}
{'loss': 0.0193, 'grad_norm': 4.694387435913086, 'learning_rate': 2.3825315586194004e-06, 'rewards/chosen': 1.3671470880508423, 'rewards/rejected': -8.461115837097168, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 9.828264236450195, 'logps/chosen': -161.86508178710938, 'logps/rejected': -276.67266845703125, 'logits/chosen': 0.46926555037498474, 'logits/rejected': 0.549639880657196, 'epoch': 4.25}
{'loss': 0.0132, 'grad_norm': 4.995148658752441, 'learning_rate': 2.170873422359566e-06, 'rewards/chosen': 1.1336368322372437, 'rewards/rejected': -8.691282272338867, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 9.824920654296875, 'logps/chosen': -165.89138793945312, 'logps/rejected': -289.47845458984375, 'logits/chosen': 0.49510249495506287, 'logits/rejected': 0.5461580157279968, 'epoch': 4.34}
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 7.220216606498196e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -171.82049560546875, 'logps/rejected': -206.84585571289062, 'logits/chosen': -0.6799721121788025, 'logits/rejected': -0.6481619477272034, 'epoch': 0.09}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 1.4440433212996392e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -175.9672393798828, 'logps/rejected': -199.83200073242188, 'logits/chosen': -0.7009104490280151, 'logits/rejected': -0.6563663482666016, 'epoch': 0.17}
{'eval_loss': 0.598005473613739, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.0169, 'eval_samples_per_second': 3.703, 'eval_steps_per_second': 0.463, 'eval_rewards/chosen': -0.034658219665288925, 'eval_rewards/rejected': -7.609906196594238, 'eval_rewards/accuracies': 0.8270000219345093, 'eval_rewards/margins': 7.575249195098877, 'eval_logps/chosen': -178.05419921875, 'eval_logps/rejected': -276.14227294921875, 'eval_logits/chosen': 0.47839969396591187, 'eval_logits/rejected': 0.557711660861969, 'epoch': 4.34}
{'loss': 0.0107, 'grad_norm': 0.7392640113830566, 'learning_rate': 1.966425199694597e-06, 'rewards/chosen': 1.72592294216156, 'rewards/rejected': -8.154908180236816, 'rewards/accuracies': 1.0, 'rewards/margins': 9.880830764770508, 'logps/chosen': -159.67544555664062, 'logps/rejected': -281.68719482421875, 'logits/chosen': 0.5030592083930969, 'logits/rejected': 0.564889132976532, 'epoch': 4.42}
{'loss': 0.0169, 'grad_norm': 0.37889304757118225, 'learning_rate': 1.769707918574139e-06, 'rewards/chosen': 1.120642900466919, 'rewards/rejected': -8.634977340698242, 'rewards/accuracies': 0.996874988079071, 'rewards/margins': 9.755620002746582, 'logps/chosen': -163.73312377929688, 'logps/rejected': -285.12127685546875, 'logits/chosen': 0.5289553999900818, 'logits/rejected': 0.5754750967025757, 'epoch': 4.51}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 277.7576, 'eval_samples_per_second': 3.6, 'eval_steps_per_second': 0.45, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 0.22}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 2.1660649819494585e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -179.4247589111328, 'logps/rejected': -202.06430053710938, 'logits/chosen': -0.6717093586921692, 'logits/rejected': -0.6754660606384277, 'epoch': 0.26}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 2.8880866425992783e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -175.4986572265625, 'logps/rejected': -196.5182647705078, 'logits/chosen': -0.6898489594459534, 'logits/rejected': -0.6367985010147095, 'epoch': 0.35}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 3.610108303249098e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -174.13223266601562, 'logps/rejected': -197.05169677734375, 'logits/chosen': -0.677651047706604, 'logits/rejected': -0.6394821405410767, 'epoch': 0.43}
{'eval_loss': 0.6349643468856812, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.4645, 'eval_samples_per_second': 3.697, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': -0.07508816570043564, 'eval_rewards/rejected': -8.009870529174805, 'eval_rewards/accuracies': 0.828000009059906, 'eval_rewards/margins': 7.934782028198242, 'eval_logps/chosen': -178.45849609375, 'eval_logps/rejected': -280.1419372558594, 'eval_logits/chosen': 0.5212766528129578, 'eval_logits/rejected': 0.5997135043144226, 'epoch': 4.55}
{'loss': 0.0128, 'grad_norm': 0.4373663365840912, 'learning_rate': 1.5812229049588966e-06, 'rewards/chosen': 1.2478586435317993, 'rewards/rejected': -8.781373023986816, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 10.0292329788208, 'logps/chosen': -165.33267211914062, 'logps/rejected': -284.8229675292969, 'logits/chosen': 0.5346266627311707, 'logits/rejected': 0.6017867922782898, 'epoch': 4.6}
{'loss': 0.0137, 'grad_norm': 6.10302209854126, 'learning_rate': 1.4014505052118893e-06, 'rewards/chosen': 1.1271063089370728, 'rewards/rejected': -9.495222091674805, 'rewards/accuracies': 0.996874988079071, 'rewards/margins': 10.622329711914062, 'logps/chosen': -163.69131469726562, 'logps/rejected': -295.7982177734375, 'logits/chosen': 0.5538627505302429, 'logits/rejected': 0.6005154848098755, 'epoch': 4.68}
{'loss': 0.0167, 'grad_norm': 1.4652050733566284, 'learning_rate': 1.2308488619553566e-06, 'rewards/chosen': 1.1132614612579346, 'rewards/rejected': -9.23930549621582, 'rewards/accuracies': 0.995312511920929, 'rewards/margins': 10.352567672729492, 'logps/chosen': -163.3758087158203, 'logps/rejected': -286.80694580078125, 'logits/chosen': 0.5365844368934631, 'logits/rejected': 0.6256410479545593, 'epoch': 4.77}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.702, 'eval_samples_per_second': 3.614, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 0.43}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.332129963898917e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -174.66943359375, 'logps/rejected': -194.79873657226562, 'logits/chosen': -0.6838659048080444, 'logits/rejected': -0.6339160203933716, 'epoch': 0.52}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.999982077361065e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -180.617431640625, 'logps/rejected': -203.16497802734375, 'logits/chosen': -0.6948853135108948, 'logits/rejected': -0.6598199605941772, 'epoch': 0.61}
{'eval_loss': 0.6435941457748413, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.1085, 'eval_samples_per_second': 3.702, 'eval_steps_per_second': 0.463, 'eval_rewards/chosen': -0.20636722445487976, 'eval_rewards/rejected': -8.424830436706543, 'eval_rewards/accuracies': 0.8309999704360962, 'eval_rewards/margins': 8.218463897705078, 'eval_logps/chosen': -179.7713165283203, 'eval_logps/rejected': -284.29150390625, 'eval_logits/chosen': 0.5317031145095825, 'eval_logits/rejected': 0.6096969246864319, 'epoch': 4.77}
{'loss': 0.0158, 'grad_norm': 2.922463893890381, 'learning_rate': 1.0698527465129744e-06, 'rewards/chosen': 0.9666543006896973, 'rewards/rejected': -9.675407409667969, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 10.642061233520508, 'logps/chosen': -161.2261505126953, 'logps/rejected': -297.83172607421875, 'logits/chosen': 0.5677874088287354, 'logits/rejected': 0.6099807024002075, 'epoch': 4.86}
{'loss': 0.0123, 'grad_norm': 0.18441306054592133, 'learning_rate': 9.18872450912901e-07, 'rewards/chosen': 1.1137341260910034, 'rewards/rejected': -9.041288375854492, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 10.155023574829102, 'logps/chosen': -165.74534606933594, 'logps/rejected': -294.67156982421875, 'logits/chosen': 0.5713038444519043, 'logits/rejected': 0.5994220972061157, 'epoch': 4.94}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.4092, 'eval_samples_per_second': 3.618, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 0.65}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.9963187927753734e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -176.49795532226562, 'logps/rejected': -199.59996032714844, 'logits/chosen': -0.6830450296401978, 'logits/rejected': -0.667224109172821, 'epoch': 0.69}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.986293741648944e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -175.49510192871094, 'logps/rejected': -195.76434326171875, 'logits/chosen': -0.7124788165092468, 'logits/rejected': -0.6532296538352966, 'epoch': 0.78}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.969932472415339e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -173.1431427001953, 'logps/rejected': -194.34396362304688, 'logits/chosen': -0.6883911490440369, 'logits/rejected': -0.6378542184829712, 'epoch': 0.87}
{'eval_loss': 0.6503934860229492, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.0142, 'eval_samples_per_second': 3.704, 'eval_steps_per_second': 0.463, 'eval_rewards/chosen': -0.4126293957233429, 'eval_rewards/rejected': -8.632303237915039, 'eval_rewards/accuracies': 0.8289999961853027, 'eval_rewards/margins': 8.219674110412598, 'eval_logps/chosen': -181.8339080810547, 'eval_logps/rejected': -286.3662414550781, 'eval_logits/chosen': 0.5552402138710022, 'eval_logits/rejected': 0.6329100728034973, 'epoch': 4.99}
{'loss': 0.0074, 'grad_norm': 1.0038357973098755, 'learning_rate': 7.782927422752812e-07, 'rewards/chosen': 1.1544287204742432, 'rewards/rejected': -9.607560157775879, 'rewards/accuracies': 1.0, 'rewards/margins': 10.76198959350586, 'logps/chosen': -170.010986328125, 'logps/rejected': -293.7151184082031, 'logits/chosen': 0.5808731913566589, 'logits/rejected': 0.6203523278236389, 'epoch': 5.03}
{'loss': 0.0046, 'grad_norm': 0.9441259503364563, 'learning_rate': 6.484718822489494e-07, 'rewards/chosen': 0.8000343441963196, 'rewards/rejected': -10.287638664245605, 'rewards/accuracies': 1.0, 'rewards/margins': 11.087675094604492, 'logps/chosen': -164.7435760498047, 'logps/rejected': -297.0412902832031, 'logits/chosen': 0.5745313763618469, 'logits/rejected': 0.6515942215919495, 'epoch': 5.12}
{'loss': 0.0046, 'grad_norm': 0.4594746232032776, 'learning_rate': 5.29740713996243e-07, 'rewards/chosen': 0.3935185670852661, 'rewards/rejected': -11.250091552734375, 'rewards/accuracies': 1.0, 'rewards/margins': 11.643610000610352, 'logps/chosen': -168.28631591796875, 'logps/rejected': -311.70245361328125, 'logits/chosen': 0.5949243903160095, 'logits/rejected': 0.6586195230484009, 'epoch': 5.21}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.2201, 'eval_samples_per_second': 3.62, 'eval_steps_per_second': 0.453, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 0.87}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.947276681101313e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -174.79672241210938, 'logps/rejected': -201.12937927246094, 'logits/chosen': -0.6888669729232788, 'logits/rejected': -0.6300977468490601, 'epoch': 0.95}
{'loss': 0.6975, 'grad_norm': 0.0, 'learning_rate': 4.9183841050661935e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -178.38015747070312, 'logps/rejected': -197.33169555664062, 'logits/chosen': -0.6932548880577087, 'logits/rejected': -0.6653873324394226, 'epoch': 1.04}
{'eval_loss': 0.6845577955245972, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 269.9089, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 0.463, 'eval_rewards/chosen': -0.8915108442306519, 'eval_rewards/rejected': -9.420644760131836, 'eval_rewards/accuracies': 0.8240000009536743, 'eval_rewards/margins': 8.529133796691895, 'eval_logps/chosen': -186.62271118164062, 'eval_logps/rejected': -294.24969482421875, 'eval_logits/chosen': 0.5667338967323303, 'eval_logits/rejected': 0.6439420580863953, 'epoch': 5.21}
{'loss': 0.004, 'grad_norm': 0.2761087417602539, 'learning_rate': 4.224018190527085e-07, 'rewards/chosen': 0.5820227861404419, 'rewards/rejected': -10.945719718933105, 'rewards/accuracies': 1.0, 'rewards/margins': 11.527743339538574, 'logps/chosen': -176.9844207763672, 'logps/rejected': -308.14837646484375, 'logits/chosen': 0.5891575217247009, 'logits/rejected': 0.6377221345901489, 'epoch': 5.29}
{'loss': 0.0055, 'grad_norm': 1.0071617364883423, 'learning_rate': 3.2672874621041296e-07, 'rewards/chosen': 0.7068487405776978, 'rewards/rejected': -10.27488899230957, 'rewards/accuracies': 1.0, 'rewards/margins': 10.981738090515137, 'logps/chosen': -171.48245239257812, 'logps/rejected': -301.89837646484375, 'logits/chosen': 0.5774445533752441, 'logits/rejected': 0.6435925364494324, 'epoch': 5.38}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.272, 'eval_samples_per_second': 3.62, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 1.08}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.883328375860579e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -177.2267608642578, 'logps/rejected': -196.31939697265625, 'logits/chosen': -0.7128525376319885, 'logits/rejected': -0.6674104928970337, 'epoch': 1.13}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.842198831579332e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -178.46337890625, 'logps/rejected': -198.87179565429688, 'logits/chosen': -0.7143213748931885, 'logits/rejected': -0.6187225580215454, 'epoch': 1.21}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.795100289187099e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -174.24440002441406, 'logps/rejected': -200.0942840576172, 'logits/chosen': -0.6893296241760254, 'logits/rejected': -0.6512609720230103, 'epoch': 1.3}
{'eval_loss': 0.6788843870162964, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 269.9079, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 0.463, 'eval_rewards/chosen': -0.6545853018760681, 'eval_rewards/rejected': -9.155036926269531, 'eval_rewards/accuracies': 0.8259999752044678, 'eval_rewards/margins': 8.500452995300293, 'eval_logps/chosen': -184.2534637451172, 'eval_logps/rejected': -291.5936279296875, 'eval_logits/chosen': 0.5683725476264954, 'eval_logits/rejected': 0.6454733610153198, 'epoch': 5.42}
{'loss': 0.0045, 'grad_norm': 0.5351840257644653, 'learning_rate': 2.429653143900057e-07, 'rewards/chosen': 0.7373378276824951, 'rewards/rejected': -10.176851272583008, 'rewards/accuracies': 1.0, 'rewards/margins': 10.914189338684082, 'logps/chosen': -169.4355010986328, 'logps/rejected': -303.09649658203125, 'logits/chosen': 0.5895653963088989, 'logits/rejected': 0.6179131269454956, 'epoch': 5.47}
{'loss': 0.0037, 'grad_norm': 1.0625616312026978, 'learning_rate': 1.7132499127816115e-07, 'rewards/chosen': 0.8123553395271301, 'rewards/rejected': -10.709453582763672, 'rewards/accuracies': 1.0, 'rewards/margins': 11.521809577941895, 'logps/chosen': -172.33351135253906, 'logps/rejected': -315.6246337890625, 'logits/chosen': 0.5920864939689636, 'logits/rejected': 0.6372354626655579, 'epoch': 5.55}
{'loss': 0.0034, 'grad_norm': 0.19010157883167267, 'learning_rate': 1.1199034931388742e-07, 'rewards/chosen': 0.7099217176437378, 'rewards/rejected': -10.431666374206543, 'rewards/accuracies': 1.0, 'rewards/margins': 11.14158821105957, 'logps/chosen': -163.9603271484375, 'logps/rejected': -305.9126892089844, 'logits/chosen': 0.5849420428276062, 'logits/rejected': 0.6201058030128479, 'epoch': 5.64}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.2626, 'eval_samples_per_second': 3.62, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 1.3}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.742152777396548e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -175.58706665039062, 'logps/rejected': -194.0818328857422, 'logits/chosen': -0.6514244079589844, 'logits/rejected': -0.6205896735191345, 'epoch': 1.39}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.683491230780099e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -176.16708374023438, 'logps/rejected': -203.9896240234375, 'logits/chosen': -0.6779401898384094, 'logits/rejected': -0.6633226275444031, 'epoch': 1.47}
{'eval_loss': 0.6863096952438354, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 269.993, 'eval_samples_per_second': 3.704, 'eval_steps_per_second': 0.463, 'eval_rewards/chosen': -0.724586546421051, 'eval_rewards/rejected': -9.301145553588867, 'eval_rewards/accuracies': 0.824999988079071, 'eval_rewards/margins': 8.576560020446777, 'eval_logps/chosen': -184.95350646972656, 'eval_logps/rejected': -293.0546875, 'eval_logits/chosen': 0.5736687779426575, 'eval_logits/rejected': 0.6505822539329529, 'epoch': 5.64}
{'loss': 0.004, 'grad_norm': 0.6439827680587769, 'learning_rate': 6.511260041012269e-08, 'rewards/chosen': 0.8680680394172668, 'rewards/rejected': -11.035534858703613, 'rewards/accuracies': 1.0, 'rewards/margins': 11.903602600097656, 'logps/chosen': -164.51718139648438, 'logps/rejected': -311.5950927734375, 'logits/chosen': 0.5736068487167358, 'logits/rejected': 0.6258304715156555, 'epoch': 5.73}
{'loss': 0.0042, 'grad_norm': 0.6415219306945801, 'learning_rate': 3.0811210596341514e-08, 'rewards/chosen': 0.8810604214668274, 'rewards/rejected': -10.194891929626465, 'rewards/accuracies': 1.0, 'rewards/margins': 11.075952529907227, 'logps/chosen': -167.43557739257812, 'logps/rejected': -294.95947265625, 'logits/chosen': 0.584428608417511, 'logits/rejected': 0.6509725451469421, 'epoch': 5.81}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.3446, 'eval_samples_per_second': 3.619, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 1.52}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.619265145894669e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -174.446533203125, 'logps/rejected': -201.4139862060547, 'logits/chosen': -0.6837905645370483, 'logits/rejected': -0.6426323652267456, 'epoch': 1.56}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.549638200295807e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -172.44241333007812, 'logps/rejected': -196.02987670898438, 'logits/chosen': -0.6867903470993042, 'logits/rejected': -0.6420338153839111, 'epoch': 1.65}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.474787835412118e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -175.13955688476562, 'logps/rejected': -195.87290954589844, 'logits/chosen': -0.6917546391487122, 'logits/rejected': -0.6635499596595764, 'epoch': 1.73}
{'eval_loss': 0.6903210282325745, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 270.6053, 'eval_samples_per_second': 3.695, 'eval_steps_per_second': 0.462, 'eval_rewards/chosen': -0.758114755153656, 'eval_rewards/rejected': -9.376785278320312, 'eval_rewards/accuracies': 0.824999988079071, 'eval_rewards/margins': 8.618669509887695, 'eval_logps/chosen': -185.2887725830078, 'eval_logps/rejected': -293.8110656738281, 'eval_logits/chosen': 0.5750510096549988, 'eval_logits/rejected': 0.6518933773040771, 'epoch': 5.86}
{'loss': 0.0036, 'grad_norm': 0.3834759294986725, 'learning_rate': 9.17359556426245e-09, 'rewards/chosen': 0.996423602104187, 'rewards/rejected': -10.111515998840332, 'rewards/accuracies': 1.0, 'rewards/margins': 11.107940673828125, 'logps/chosen': -162.0611572265625, 'logps/rejected': -298.51898193359375, 'logits/chosen': 0.5923731327056885, 'logits/rejected': 0.6381428241729736, 'epoch': 5.9}
{'loss': 0.0034, 'grad_norm': 0.6129221320152283, 'learning_rate': 2.54897892522088e-10, 'rewards/chosen': 0.7067886590957642, 'rewards/rejected': -10.908628463745117, 'rewards/accuracies': 1.0, 'rewards/margins': 11.615418434143066, 'logps/chosen': -166.54852294921875, 'logps/rejected': -307.47711181640625, 'logits/chosen': 0.5941930413246155, 'logits/rejected': 0.6360470056533813, 'epoch': 5.99}
{'train_runtime': 27480.2164, 'train_samples_per_second': 1.612, 'train_steps_per_second': 0.101, 'train_loss': 0.17173574863450194, 'epoch': 6.0}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.57, 'eval_samples_per_second': 3.616, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 1.73}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.394904804343029e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -172.64373779296875, 'logps/rejected': -205.27243041992188, 'logits/chosen': -0.7090154886245728, 'logits/rejected': -0.6458669304847717, 'epoch': 1.82}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.310192685732298e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -176.5266571044922, 'logps/rejected': -200.71995544433594, 'logits/chosen': -0.6731781959533691, 'logits/rejected': -0.651256263256073, 'epoch': 1.91}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.2579, 'eval_samples_per_second': 3.62, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 1.95}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.220867364956161e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -179.25564575195312, 'logps/rejected': -198.33058166503906, 'logits/chosen': -0.687900185585022, 'logits/rejected': -0.6687357425689697, 'epoch': 1.99}
{'loss': 0.6975, 'grad_norm': 0.0, 'learning_rate': 4.127156483948249e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -177.746337890625, 'logps/rejected': -198.06298828125, 'logits/chosen': -0.6863711476325989, 'logits/rejected': -0.6674118041992188, 'epoch': 2.08}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 4.029298861063425e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -172.1435546875, 'logps/rejected': -199.2642059326172, 'logits/chosen': -0.716086745262146, 'logits/rejected': -0.6460078358650208, 'epoch': 2.17}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.2721, 'eval_samples_per_second': 3.62, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 2.17}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 3.927543882458945e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -174.41690063476562, 'logps/rejected': -200.46572875976562, 'logits/chosen': -0.6865240335464478, 'logits/rejected': -0.6395058631896973, 'epoch': 2.26}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 3.82215086654403e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -173.20970153808594, 'logps/rejected': -198.28724670410156, 'logits/chosen': -0.6963976621627808, 'logits/rejected': -0.6246064901351929, 'epoch': 2.34}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 276.0757, 'eval_samples_per_second': 3.622, 'eval_steps_per_second': 0.453, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 2.39}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 3.7133884031174698e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -174.8665771484375, 'logps/rejected': -200.94046020507812, 'logits/chosen': -0.6840192675590515, 'logits/rejected': -0.6447437405586243, 'epoch': 2.43}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 3.6015336688774977e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -177.17361450195312, 'logps/rejected': -201.99710083007812, 'logits/chosen': -0.6843854784965515, 'logits/rejected': -0.6569691896438599, 'epoch': 2.52}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 3.486871721048283e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -174.38729858398438, 'logps/rejected': -194.62045288085938, 'logits/chosen': -0.6872791051864624, 'logits/rejected': -0.6566376090049744, 'epoch': 2.6}
{'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0082, 'eval_runtime': 275.8364, 'eval_samples_per_second': 3.625, 'eval_steps_per_second': 0.453, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -177.70762634277344, 'eval_logps/rejected': -200.04324340820312, 'eval_logits/chosen': -0.6981191635131836, 'eval_logits/rejected': -0.6153547167778015, 'epoch': 2.6}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 3.3696947709232337e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -177.2860870361328, 'logps/rejected': -197.20516967773438, 'logits/chosen': -0.6595826745033264, 'logits/rejected': -0.6557034254074097, 'epoch': 2.69}
{'loss': 0.6931, 'grad_norm': 0.0, 'learning_rate': 3.250301439176443e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -178.4920196533203, 'logps/rejected': -204.59805297851562, 'logits/chosen': -0.6836627721786499, 'logits/rejected': -0.6429182887077332, 'epoch': 2.78}
