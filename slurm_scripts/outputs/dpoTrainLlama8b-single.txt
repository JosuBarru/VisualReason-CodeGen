ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 03-14 11:55:24 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.48.2.
   \\   /|    GPU: Tesla V100-PCIE-32GB. Max memory: 31.739 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 7.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
{'loss': 0.693, 'grad_norm': 3.0397567749023438, 'learning_rate': 1.4440433212996388e-07, 'rewards/chosen': 0.0006308651645667851, 'rewards/rejected': 0.0003115088038612157, 'rewards/accuracies': 0.4609375, 'rewards/margins': 0.00031935638980939984, 'logps/chosen': -171.81417846679688, 'logps/rejected': -206.8427276611328, 'logits/chosen': -0.6799067258834839, 'logits/rejected': -0.6481128931045532, 'epoch': 0.09}
{'loss': 0.6918, 'grad_norm': 3.6429591178894043, 'learning_rate': 2.8880866425992776e-07, 'rewards/chosen': 0.00884273275732994, 'rewards/rejected': 0.006075362674891949, 'rewards/accuracies': 0.5921875238418579, 'rewards/margins': 0.0027673703152686357, 'logps/chosen': -175.8787841796875, 'logps/rejected': -199.77127075195312, 'logits/chosen': -0.7004960775375366, 'logits/rejected': -0.6559855937957764, 'epoch': 0.17}
{'eval_loss': 0.6840041279792786, 'eval_model_preparation_time': 0.0262, 'eval_runtime': 276.7158, 'eval_samples_per_second': 3.614, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': 0.042113836854696274, 'eval_rewards/rejected': 0.02321707271039486, 'eval_rewards/accuracies': 0.6710000038146973, 'eval_rewards/margins': 0.018896762281656265, 'eval_logps/chosen': -177.2864990234375, 'eval_logps/rejected': -199.81105041503906, 'eval_logits/chosen': -0.6977875828742981, 'eval_logits/rejected': -0.6154060959815979, 'epoch': 0.22}
{'loss': 0.6854, 'grad_norm': 3.7344589233398438, 'learning_rate': 4.3321299638989166e-07, 'rewards/chosen': 0.04099992662668228, 'rewards/rejected': 0.0247174222022295, 'rewards/accuracies': 0.628125011920929, 'rewards/margins': 0.016282502561807632, 'logps/chosen': -179.01475524902344, 'logps/rejected': -201.81712341308594, 'logits/chosen': -0.6713511347770691, 'logits/rejected': -0.6753646731376648, 'epoch': 0.26}
{'loss': 0.6664, 'grad_norm': 3.9609854221343994, 'learning_rate': 5.776173285198555e-07, 'rewards/chosen': 0.12279315292835236, 'rewards/rejected': 0.06391619145870209, 'rewards/accuracies': 0.682812511920929, 'rewards/margins': 0.05887696146965027, 'logps/chosen': -174.27072143554688, 'logps/rejected': -195.8791046142578, 'logits/chosen': -0.6875366568565369, 'logits/rejected': -0.6355651617050171, 'epoch': 0.35}
{'loss': 0.6481, 'grad_norm': 3.2572336196899414, 'learning_rate': 7.220216606498195e-07, 'rewards/chosen': 0.2496955841779709, 'rewards/rejected': 0.1372615247964859, 'rewards/accuracies': 0.6703125238418579, 'rewards/margins': 0.11243407428264618, 'logps/chosen': -171.6352996826172, 'logps/rejected': -195.6790771484375, 'logits/chosen': -0.6729611158370972, 'logits/rejected': -0.6365880370140076, 'epoch': 0.43}
