SELECTED CONFIG FILES: gqa/general_config,gqa/train
LOADING MODEL: ENABLED
modelo: <class 'vision_models.BLIPModel'> , proceso:  blip
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
modelo: <class 'vision_models.GLIPModel'> , proceso:  glip
modelo: <class 'vision_models.MaskRCNNModel'> , proceso:  maskrcnn
modelo: <class 'vision_models.XVLMModel'> , proceso:  xvlm
{'blip': <function make_fn.<locals>._function at 0x7f0eedb251c0>, 'glip': <function make_fn.<locals>._function at 0x7f089b3c87c0>, 'maskrcnn': <function make_fn.<locals>._function at 0x7f0e6c5158a0>, 'xvlm': <function make_fn.<locals>._function at 0x7f089ac979c0>}
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 31.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 754.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 153.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 761.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 736.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 769.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 133.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 620.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 806.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.16 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 1010.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 9.12 MiB is free. Including non-PyTorch memory, this process has 31.73 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 938.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 766.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 811.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 265.12 MiB is free. Including non-PyTorch memory, this process has 31.48 GiB memory in use. Of the allocated memory 30.43 GiB is allocated by PyTorch, and 688.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 9.12 MiB is free. Including non-PyTorch memory, this process has 31.73 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 772.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 734.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 734.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 155.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 709.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 155.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 905.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 155.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 820.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 31.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 883.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 15.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 771.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 540.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 31.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 830.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 708.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 877.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 633.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 566.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 527.12 MiB is free. Including non-PyTorch memory, this process has 31.22 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 455.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 151.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 611.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 239.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.74 GiB is allocated by PyTorch, and 401.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 538.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 655.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 655.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 655.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 816.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 247.12 MiB is free. Including non-PyTorch memory, this process has 31.49 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 646.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 920.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 855.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 920.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 889.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 846.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 790.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 804.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 932.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 804.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 867.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 836.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 900.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 932.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 804.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 867.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 804.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 932.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 185.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 598.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
towel found
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 235.12 MiB is free. Including non-PyTorch memory, this process has 31.51 GiB memory in use. Of the allocated memory 30.48 GiB is allocated by PyTorch, and 664.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 21.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 571.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 7.12 MiB is free. Including non-PyTorch memory, this process has 31.73 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 617.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
84 249 124 179
Error in glip model: CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 195.12 MiB is free. Including non-PyTorch memory, this process has 31.54 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 682.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in xvlm model: 'ImagePatch' object is not iterable
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 651.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 167.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 648.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 167.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 714.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 167.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 810.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 167.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 810.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 167.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 778.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 167.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 810.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 151.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 632.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 151.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 632.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 151.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 826.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 151.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 632.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 648.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 547.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 932.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 867.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 836.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 900.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 900.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 900.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 739.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 25.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 668.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 25.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 759.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 25.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 856.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 7.12 MiB is free. Including non-PyTorch memory, this process has 31.73 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 617.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 721.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 772.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 836.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 698.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 57.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 651.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 57.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.22 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 57.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 23.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 812.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 151.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 632.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 745.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 675.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 502.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 417.12 MiB is free. Including non-PyTorch memory, this process has 31.33 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 707.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 884.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 81.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 892.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 817.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 478.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 269.12 MiB is free. Including non-PyTorch memory, this process has 31.47 GiB memory in use. Of the allocated memory 30.21 GiB is allocated by PyTorch, and 910.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 627.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 659.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 659.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 659.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 659.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 659.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 659.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 724.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
carrots
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 692.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 724.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 659.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 659.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 778.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 801.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 649.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 842.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 617.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 783.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 649.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 756.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 617.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 649.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 746.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 560.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 842.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 777.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 649.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 842.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.43 GiB is allocated by PyTorch, and 826.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 649.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 135.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 777.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 63.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 737.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 63.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 721.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 63.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 721.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 63.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 851.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 63.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 721.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 63.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 721.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 380.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 383.12 MiB is free. Including non-PyTorch memory, this process has 31.36 GiB memory in use. Of the allocated memory 30.21 GiB is allocated by PyTorch, and 799.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 676.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 676.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 815.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 815.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 843.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 815.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 899.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 676.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 815.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 815.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 676.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 982.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 77.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 608.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 77.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 882.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 526.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 451.12 MiB is free. Including non-PyTorch memory, this process has 31.29 GiB memory in use. Of the allocated memory 30.31 GiB is allocated by PyTorch, and 620.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 892.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 912.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 916.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 820.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 746.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 746.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 746.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 844.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 908.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 875.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Brown suitcase is 38.0 away from the paper
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 844.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 746.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 19.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 843.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 191.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 813.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 626.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 909.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.22 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 875.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 909.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 909.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 875.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 632.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 155.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 628.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 361.12 MiB is free. Including non-PyTorch memory, this process has 31.38 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 754.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in xvlm model: 'ImagePatch' object is not iterable
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 179.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 613.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 179.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 636.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 571.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 81.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 702.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 81.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 800.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 81.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 864.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 789.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 804.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 916.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 777.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 916.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 945.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 916.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 945.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 549.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 829.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 996.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.35 GiB is allocated by PyTorch, and 885.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 856.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 829.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 913.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 996.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 969.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 829.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 940.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 913.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 829.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 614.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 19.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.88 GiB is allocated by PyTorch, and 477.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 569.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 857.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 768.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 907.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 814.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 910.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 878.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 165.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 703.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 165.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 920.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 241.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 729.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 944.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 944.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 862.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 203.12 MiB is free. Including non-PyTorch memory, this process has 31.54 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 597.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 15.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 958.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 179.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 604.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.84 GiB is allocated by PyTorch, and 425.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 732.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 21.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 730.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 65.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 718.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 65.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 718.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 65.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 718.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 181.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 654.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 181.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 793.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 101.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 610.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 101.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 924.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 101.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 887.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 101.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 780.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 101.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 780.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 101.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 706.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 866.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 737.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 737.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 737.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 400.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 401.12 MiB is free. Including non-PyTorch memory, this process has 31.34 GiB memory in use. Of the allocated memory 30.26 GiB is allocated by PyTorch, and 727.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 15.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 713.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 71.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 688.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 205.12 MiB is free. Including non-PyTorch memory, this process has 31.54 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 630.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 17.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 766.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 179.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 604.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 179.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 604.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 119.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 633.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 119.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 665.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 119.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 665.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 119.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 698.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 119.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 665.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 563.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 916.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 916.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 851.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 723.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 788.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 71.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 752.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 71.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 71.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 764.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.84 GiB is allocated by PyTorch, and 425.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 681.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 746.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 489.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 992.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 733.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 733.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 627.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 649.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 412.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 299.12 MiB is free. Including non-PyTorch memory, this process has 31.44 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 794.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 89.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 746.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 667.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 699.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 699.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 663.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 825.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 663.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 663.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 663.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 663.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 663.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 642.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: object of type 'ImagePatch' has no len()
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 675.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 675.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 245.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 873.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 57.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 57.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 760.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 57.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 917.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 57.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 917.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Found cars
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 11.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.91 GiB is allocated by PyTorch, and 451.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 183.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 600.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 183.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 600.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 53.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 730.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 53.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 730.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 53.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 730.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 53.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 730.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 41.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 711.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 41.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 808.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 41.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 743.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 25.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 768.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 151.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 632.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 802.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 830.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 802.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 678.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.16 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 725.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 870.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.22 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 926.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 926.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 926.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 163.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 614.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 163.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 163.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 864.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 163.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 163.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 839.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 718.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 131.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 846.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 199.12 MiB is free. Including non-PyTorch memory, this process has 31.54 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 524.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 23.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 857.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 63.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 694.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 776.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 800.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 183.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 732.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 11.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 899.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 580.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 646.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 183.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 538.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 604.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 939.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 939.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.35 GiB is allocated by PyTorch, and 911.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 855.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 855.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 855.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 1022.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 855.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 743.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 939.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 939.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 827.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 117.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 855.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 27.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 771.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 27.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 945.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 27.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 907.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 27.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 945.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 27.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 945.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 27.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 778.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 707.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 11.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 747.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 113.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 667.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 113.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 797.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 113.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 692.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 113.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 113.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 113.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 943.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 113.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 998.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 113.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 580.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 698.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 663.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 13.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 609.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 149.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 632.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 682.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.14 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 944.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 739.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.16 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 962.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 962.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 823.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 971.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.16 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 878.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 878.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 878.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 878.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 923.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 803.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 803.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 803.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.35 GiB is allocated by PyTorch, and 859.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 125.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 592.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 832.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 703.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 703.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in xvlm model: 'ImagePatch' object is not iterable
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 703.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 703.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 703.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 671.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 717.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 1014.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 683.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 901.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 683.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 683.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 812.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 683.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 650.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Distance between player and printer: -0.06 pixels
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 683.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 622.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 748.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 817.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 428.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 947.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 99.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 873.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 235.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 807.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 735.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 800.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 953.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 925.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 925.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 646.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 925.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 925.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 735.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 468.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 888.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 925.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 589.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 717.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 800.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 772.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[]
[ImagePatch(227, 156, 316, 226), ImagePatch(61, 180, 164, 254), ImagePatch(345, 143, 449, 240), ImagePatch(180, 169, 254, 228), ImagePatch(141, 174, 206, 232), ImagePatch(297, 148, 371, 210), ImagePatch(283, 157, 354, 226)]
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 717.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 883.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 814.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 478.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 879.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 717.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 814.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 717.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 782.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 827.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 901.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 800.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 772.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 420.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 653.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 782.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 814.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 772.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 25.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.81 GiB is allocated by PyTorch, and 533.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 69.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 688.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 688.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 207.12 MiB is free. Including non-PyTorch memory, this process has 31.53 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 570.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 896.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 625.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 753.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 753.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 753.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 850.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 723.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 943.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in xvlm model: 'ImagePatch' object is not iterable
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 21.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 700.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 608.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 802.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 769.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
What is the person carrying?Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 834.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 661.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 661.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 115.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.74 GiB is allocated by PyTorch, and 521.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 115.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 997.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 21.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 754.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 613.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 57.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 692.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 53.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 729.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 53.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 729.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 53.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 729.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 53.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 890.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 23.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 567.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 23.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 887.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 23.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 599.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 604.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 191.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 780.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.79 GiB is allocated by PyTorch, and 460.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 851.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 121.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 851.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 229.12 MiB is free. Including non-PyTorch memory, this process has 31.51 GiB memory in use. Of the allocated memory 30.43 GiB is allocated by PyTorch, and 720.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 17.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 954.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 654.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 637.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 183.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 597.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 183.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 664.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 733.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 674.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 803.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 674.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 708.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 13.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 609.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 41.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.81 GiB is allocated by PyTorch, and 517.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 41.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 902.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 41.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 902.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 153.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 736.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 830.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 915.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 803.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 942.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 975.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 803.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 830.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 975.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 942.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 830.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 235.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 787.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 924.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 682.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 924.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 924.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 924.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 924.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 953.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 924.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 47.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 924.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 249.12 MiB is free. Including non-PyTorch memory, this process has 31.49 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 688.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
420.0
278
317
457
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 721.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 721.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 721.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 488.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 795.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 133.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 648.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 299.12 MiB is free. Including non-PyTorch memory, this process has 31.44 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 613.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 127.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 783.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 932.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 817.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 689.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 83.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.55 GiB is allocated by PyTorch, and 741.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
black
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 825.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 241.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 565.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 303.12 MiB is free. Including non-PyTorch memory, this process has 31.44 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 905.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 555.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 19.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.84 GiB is allocated by PyTorch, and 507.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 730.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 73.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 656.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 73.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.16 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
tomatoes
food
pizza
food
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 73.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 73.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.16 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 73.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 734.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 590.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 437.12 MiB is free. Including non-PyTorch memory, this process has 31.31 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 489.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 199.12 MiB is free. Including non-PyTorch memory, this process has 31.54 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 690.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 15.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 985.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 529.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 882.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 93.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 882.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 420.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 824.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 846.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 656.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 729.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 674.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 976.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 674.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
a girl
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 688.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 730.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 674.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 901.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 688.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 701.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 757.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
What is the color of the shirt?
True
yellow
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 701.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 159.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 813.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 638.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 147.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 671.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 41.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 613.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 41.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 741.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
There are no surfboards in the image.
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.81 GiB is allocated by PyTorch, and 519.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 829.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 804.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.31 GiB is allocated by PyTorch, and 931.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 708.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 804.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 836.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 428.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 31.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 828.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 31.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 826.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 31.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 774.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 637.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 638.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 832.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: object of type 'ImagePatch' has no len()
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 638.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 638.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 638.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 207.12 MiB is free. Including non-PyTorch memory, this process has 31.53 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 831.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 19.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 761.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 526.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 325.12 MiB is free. Including non-PyTorch memory, this process has 31.42 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 452.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 822.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 169.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 802.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 133.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 727.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 133.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 839.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 133.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 839.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 673.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 891.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 863.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 863.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 109.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 863.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 880.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 791.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 648.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 759.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 625.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 625.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 542.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 637.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 660.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.74 GiB is allocated by PyTorch, and 539.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 695.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 685.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 685.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 685.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 685.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
box
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 695.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 708.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 708.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 685.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 654.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 685.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 654.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 685.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 685.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 193.12 MiB is free. Including non-PyTorch memory, this process has 31.54 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 429.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 181.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 568.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 181.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 601.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 181.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 791.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 832.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 639.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 726.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 893.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 642.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 893.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 754.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 37.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 777.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 205.12 MiB is free. Including non-PyTorch memory, this process has 31.53 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 516.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 17.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 765.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 103.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 646.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 153.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 757.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 153.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 818.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 153.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 818.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 388.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 201.12 MiB is free. Including non-PyTorch memory, this process has 31.54 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 788.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
brown and white
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 727.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 55.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 537.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 697.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 730.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 697.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 9.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 670.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 177.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 604.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 620.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 686.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 620.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 620.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 620.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 814.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 718.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 620.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 782.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 620.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.60 GiB is allocated by PyTorch, and 620.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 534.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 787.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 899.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 814.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 955.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 814.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 926.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 758.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 955.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 814.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 955.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 157.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 787.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 782.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 932.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 794.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 1017.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 932.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 932.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 39.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 794.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 195.12 MiB is free. Including non-PyTorch memory, this process has 31.54 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 767.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 730.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 141.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 769.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 145.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 699.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 129.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 842.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 129.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 814.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 129.12 MiB is free. Including non-PyTorch memory, this process has 31.61 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 846.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 85.12 MiB is free. Including non-PyTorch memory, this process has 31.65 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 748.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 526.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 287.12 MiB is free. Including non-PyTorch memory, this process has 31.45 GiB memory in use. Of the allocated memory 30.31 GiB is allocated by PyTorch, and 782.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 59.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 595.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
Final accuracy: 0.13753968253968255
