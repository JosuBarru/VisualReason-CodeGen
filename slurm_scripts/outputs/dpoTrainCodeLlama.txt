ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 05-28 22:29:43 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.325 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
codellama/CodeLlama-7b-hf does not have a padding token! Will use pad_token = <unk>.
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.6935, 'grad_norm': 1.921875, 'learning_rate': 1.5220700152207001e-06, 'rewards/chosen': -0.0020835220348089933, 'rewards/rejected': -0.001634631073102355, 'rewards/accuracies': 0.4625000059604645, 'rewards/margins': -0.000448891194537282, 'logps/chosen': -184.93466186523438, 'logps/rejected': -199.91879272460938, 'logits/chosen': -2.498203754425049, 'logits/rejected': -2.466789722442627, 'epoch': 0.01}
{'loss': 0.6933, 'grad_norm': 1.3515625, 'learning_rate': 3.0441400304414002e-06, 'rewards/chosen': 0.004012534394860268, 'rewards/rejected': 0.004006415605545044, 'rewards/accuracies': 0.46875, 'rewards/margins': 6.119022145867348e-06, 'logps/chosen': -166.08206176757812, 'logps/rejected': -196.16708374023438, 'logits/chosen': nan, 'logits/rejected': -2.415858745574951, 'epoch': 0.01}
{'loss': 0.6904, 'grad_norm': 1.4609375, 'learning_rate': 4.566210045662101e-06, 'rewards/chosen': 0.023927226662635803, 'rewards/rejected': 0.017872000113129616, 'rewards/accuracies': 0.534375011920929, 'rewards/margins': 0.006055227480828762, 'logps/chosen': -178.93577575683594, 'logps/rejected': -208.0055694580078, 'logits/chosen': -2.488809108734131, 'logits/rejected': -2.4716949462890625, 'epoch': 0.02}
{'loss': 0.6845, 'grad_norm': 1.3125, 'learning_rate': 6.0882800608828005e-06, 'rewards/chosen': 0.07611369341611862, 'rewards/rejected': 0.05761294439435005, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.01850074529647827, 'logps/chosen': -172.76174926757812, 'logps/rejected': -207.54513549804688, 'logits/chosen': -2.495232105255127, 'logits/rejected': -2.4726667404174805, 'epoch': 0.02}
{'loss': 0.6745, 'grad_norm': 1.5234375, 'learning_rate': 7.6103500761035e-06, 'rewards/chosen': 0.18661527335643768, 'rewards/rejected': 0.1451977789402008, 'rewards/accuracies': 0.637499988079071, 'rewards/margins': 0.04141748696565628, 'logps/chosen': -168.79043579101562, 'logps/rejected': -201.0048065185547, 'logits/chosen': -2.4869518280029297, 'logits/rejected': -2.466702461242676, 'epoch': 0.03}
{'loss': 0.6616, 'grad_norm': 1.1953125, 'learning_rate': 9.132420091324201e-06, 'rewards/chosen': 0.28217214345932007, 'rewards/rejected': 0.2080446183681488, 'rewards/accuracies': 0.653124988079071, 'rewards/margins': 0.07412752509117126, 'logps/chosen': -173.32424926757812, 'logps/rejected': -200.73605346679688, 'logits/chosen': -2.500323534011841, 'logits/rejected': -2.471440076828003, 'epoch': 0.04}
{'loss': 0.6288, 'grad_norm': 1.5078125, 'learning_rate': 1.06544901065449e-05, 'rewards/chosen': 0.4289645254611969, 'rewards/rejected': 0.27111107110977173, 'rewards/accuracies': 0.7093750238418579, 'rewards/margins': 0.15785351395606995, 'logps/chosen': -169.14468383789062, 'logps/rejected': -200.8193359375, 'logits/chosen': -2.4983086585998535, 'logits/rejected': -2.4702510833740234, 'epoch': 0.04}
{'loss': 0.5912, 'grad_norm': 1.4765625, 'learning_rate': 1.2176560121765601e-05, 'rewards/chosen': 0.5874082446098328, 'rewards/rejected': 0.2872689366340637, 'rewards/accuracies': 0.7093750238418579, 'rewards/margins': 0.30013930797576904, 'logps/chosen': -169.51719665527344, 'logps/rejected': -211.29873657226562, 'logits/chosen': -2.5247058868408203, 'logits/rejected': -2.4917590618133545, 'epoch': 0.05}
{'loss': 0.6254, 'grad_norm': 1.6328125, 'learning_rate': 1.3698630136986302e-05, 'rewards/chosen': 0.8164095878601074, 'rewards/rejected': 0.5529454350471497, 'rewards/accuracies': 0.653124988079071, 'rewards/margins': 0.26346415281295776, 'logps/chosen': -168.1742706298828, 'logps/rejected': -201.51516723632812, 'logits/chosen': -2.5215675830841064, 'logits/rejected': -2.47291898727417, 'epoch': 0.05}
{'loss': 0.5667, 'grad_norm': 1.8671875, 'learning_rate': 1.5220700152207e-05, 'rewards/chosen': 1.2993460893630981, 'rewards/rejected': 0.8784557580947876, 'rewards/accuracies': 0.715624988079071, 'rewards/margins': 0.42089027166366577, 'logps/chosen': -161.37759399414062, 'logps/rejected': -201.45578002929688, 'logits/chosen': -2.5326335430145264, 'logits/rejected': -2.5039753913879395, 'epoch': 0.06}
{'loss': 0.5337, 'grad_norm': 1.953125, 'learning_rate': 1.67427701674277e-05, 'rewards/chosen': 1.4183729887008667, 'rewards/rejected': 0.798638105392456, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.6197348833084106, 'logps/chosen': -159.98248291015625, 'logps/rejected': -197.77725219726562, 'logits/chosen': -2.5432093143463135, 'logits/rejected': -2.527446985244751, 'epoch': 0.07}
{'loss': 0.5736, 'grad_norm': 1.484375, 'learning_rate': 1.8264840182648402e-05, 'rewards/chosen': 1.5982372760772705, 'rewards/rejected': 1.0237553119659424, 'rewards/accuracies': 0.721875011920929, 'rewards/margins': 0.5744820237159729, 'logps/chosen': -155.30126953125, 'logps/rejected': -186.2060089111328, 'logits/chosen': -2.573890209197998, 'logits/rejected': -2.558419704437256, 'epoch': 0.07}
{'loss': 0.5308, 'grad_norm': 1.703125, 'learning_rate': 1.97869101978691e-05, 'rewards/chosen': 2.2497384548187256, 'rewards/rejected': 1.6000502109527588, 'rewards/accuracies': 0.7281249761581421, 'rewards/margins': 0.6496884226799011, 'logps/chosen': -153.73878479003906, 'logps/rejected': -185.34906005859375, 'logits/chosen': -2.5854651927948, 'logits/rejected': -2.5545783042907715, 'epoch': 0.08}
{'loss': 0.5003, 'grad_norm': 1.9140625, 'learning_rate': 2.13089802130898e-05, 'rewards/chosen': 2.504713773727417, 'rewards/rejected': 1.6014063358306885, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.9033075571060181, 'logps/chosen': -156.22341918945312, 'logps/rejected': -188.73464965820312, 'logits/chosen': -2.6138100624084473, 'logits/rejected': -2.574446201324463, 'epoch': 0.09}
{'loss': 0.4651, 'grad_norm': 2.09375, 'learning_rate': 2.2831050228310503e-05, 'rewards/chosen': 2.571770191192627, 'rewards/rejected': 1.5058348178863525, 'rewards/accuracies': 0.7718750238418579, 'rewards/margins': 1.0659352540969849, 'logps/chosen': -153.4534912109375, 'logps/rejected': -195.6225128173828, 'logits/chosen': -2.626312255859375, 'logits/rejected': -2.585784435272217, 'epoch': 0.09}
