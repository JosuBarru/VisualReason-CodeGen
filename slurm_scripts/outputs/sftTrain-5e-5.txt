ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 04-20 18:28:06 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.151 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
trainable params: 167,772,160 || all params: 8,198,033,408 || trainable%: 2.0465
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 12.1272, 'grad_norm': 21.0, 'learning_rate': 9.523809523809523e-06, 'epoch': 0.08}
{'loss': 6.7837, 'grad_norm': 4.0625, 'learning_rate': 1.9047619047619046e-05, 'epoch': 0.15}
{'eval_loss': 3.486734390258789, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 410.2527, 'eval_samples_per_second': 1.219, 'eval_steps_per_second': 0.305, 'epoch': 0.19}
{'loss': 4.2436, 'grad_norm': 0.75, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.23}
{'loss': 3.6853, 'grad_norm': 0.482421875, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.31}
{'loss': 3.7663, 'grad_norm': 0.451171875, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.38}
{'eval_loss': 2.4003939628601074, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 405.4055, 'eval_samples_per_second': 1.233, 'eval_steps_per_second': 0.308, 'epoch': 0.38}
{'loss': 3.72, 'grad_norm': 0.76171875, 'learning_rate': 4.9968791096430083e-05, 'epoch': 0.46}
{'loss': 3.6121, 'grad_norm': 0.2041015625, 'learning_rate': 4.983024196138457e-05, 'epoch': 0.53}
{'eval_loss': 2.388014793395996, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.4077, 'eval_samples_per_second': 1.221, 'eval_steps_per_second': 0.305, 'epoch': 0.57}
{'loss': 3.6538, 'grad_norm': 0.41796875, 'learning_rate': 4.9581499161993266e-05, 'epoch': 0.61}
{'loss': 3.8035, 'grad_norm': 0.71484375, 'learning_rate': 4.922366658925276e-05, 'epoch': 0.69}
{'loss': 3.7385, 'grad_norm': 0.2177734375, 'learning_rate': 4.875833226161547e-05, 'epoch': 0.76}
{'eval_loss': 2.3703062534332275, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 405.2426, 'eval_samples_per_second': 1.234, 'eval_steps_per_second': 0.308, 'epoch': 0.76}
{'loss': 3.6164, 'grad_norm': 0.546875, 'learning_rate': 4.8187561277552374e-05, 'epoch': 0.84}
{'loss': 3.6308, 'grad_norm': 0.1474609375, 'learning_rate': 4.751388665089127e-05, 'epoch': 0.92}
{'eval_loss': 2.3631112575531006, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.2779, 'eval_samples_per_second': 1.222, 'eval_steps_per_second': 0.305, 'epoch': 0.95}
{'loss': 3.561, 'grad_norm': 0.314453125, 'learning_rate': 4.674029806960234e-05, 'epoch': 0.99}
{'loss': 3.7059, 'grad_norm': 0.330078125, 'learning_rate': 4.5870228627918056e-05, 'epoch': 1.07}
{'loss': 3.6689, 'grad_norm': 0.2138671875, 'learning_rate': 4.490753959066876e-05, 'epoch': 1.15}
{'eval_loss': 2.364701271057129, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 405.1655, 'eval_samples_per_second': 1.234, 'eval_steps_per_second': 0.309, 'epoch': 1.15}
{'loss': 3.6082, 'grad_norm': 0.1640625, 'learning_rate': 4.385650325744803e-05, 'epoch': 1.22}
{'loss': 3.6588, 'grad_norm': 0.2470703125, 'learning_rate': 4.272178400265456e-05, 'epoch': 1.3}
{'eval_loss': 2.3610424995422363, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.7997, 'eval_samples_per_second': 1.22, 'eval_steps_per_second': 0.305, 'epoch': 1.34}
{'loss': 3.6944, 'grad_norm': 0.38671875, 'learning_rate': 4.150841757555265e-05, 'epoch': 1.37}
{'loss': 3.6392, 'grad_norm': 0.1875, 'learning_rate': 4.022178875221515e-05, 'epoch': 1.45}
{'loss': 3.5562, 'grad_norm': 0.1826171875, 'learning_rate': 3.886760743852685e-05, 'epoch': 1.53}
{'eval_loss': 2.3541269302368164, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 404.8562, 'eval_samples_per_second': 1.235, 'eval_steps_per_second': 0.309, 'epoch': 1.53}
{'loss': 3.7369, 'grad_norm': 0.12255859375, 'learning_rate': 3.745188333030048e-05, 'epoch': 1.6}
{'loss': 3.7374, 'grad_norm': 0.1455078125, 'learning_rate': 3.5980899242960495e-05, 'epoch': 1.68}
{'eval_loss': 2.3560779094696045, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.2595, 'eval_samples_per_second': 1.222, 'eval_steps_per_second': 0.305, 'epoch': 1.72}
{'loss': 3.6967, 'grad_norm': 0.11865234375, 'learning_rate': 3.446118322915456e-05, 'epoch': 1.76}
{'loss': 3.6907, 'grad_norm': 0.40625, 'learning_rate': 3.2899479608031354e-05, 'epoch': 1.83}
{'loss': 3.7047, 'grad_norm': 0.333984375, 'learning_rate': 3.130271903475328e-05, 'epoch': 1.91}
{'eval_loss': 2.3565640449523926, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 405.0633, 'eval_samples_per_second': 1.234, 'eval_steps_per_second': 0.309, 'epoch': 1.91}
{'loss': 3.7174, 'grad_norm': 0.11474609375, 'learning_rate': 2.9677987743072163e-05, 'epoch': 1.98}
{'loss': 3.6369, 'grad_norm': 0.3125, 'learning_rate': 2.8032496097465556e-05, 'epoch': 2.06}
{'eval_loss': 2.3524258136749268, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.6399, 'eval_samples_per_second': 1.221, 'eval_steps_per_second': 0.305, 'epoch': 2.1}
{'loss': 3.6626, 'grad_norm': 0.1474609375, 'learning_rate': 2.6373546594395708e-05, 'epoch': 2.14}
{'loss': 3.5818, 'grad_norm': 0.158203125, 'learning_rate': 2.4708501454697693e-05, 'epoch': 2.21}
{'loss': 3.4903, 'grad_norm': 0.2275390625, 'learning_rate': 2.3044749950917856e-05, 'epoch': 2.29}
{'eval_loss': 2.3473472595214844, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 405.2039, 'eval_samples_per_second': 1.234, 'eval_steps_per_second': 0.308, 'epoch': 2.29}
{'loss': 3.7025, 'grad_norm': 0.1357421875, 'learning_rate': 2.1389675614600013e-05, 'epoch': 2.37}
{'loss': 3.6499, 'grad_norm': 0.396484375, 'learning_rate': 1.9750623469049492e-05, 'epoch': 2.44}
{'eval_loss': 2.34706449508667, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.2555, 'eval_samples_per_second': 1.222, 'eval_steps_per_second': 0.305, 'epoch': 2.48}
{'loss': 3.5381, 'grad_norm': 0.259765625, 'learning_rate': 1.813486743299222e-05, 'epoch': 2.52}
{'loss': 3.6368, 'grad_norm': 0.1318359375, 'learning_rate': 1.6549578039787436e-05, 'epoch': 2.6}
{'loss': 3.6783, 'grad_norm': 0.41796875, 'learning_rate': 1.5001790615452383e-05, 'epoch': 2.67}
{'eval_loss': 2.350537061691284, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 406.0409, 'eval_samples_per_second': 1.231, 'eval_steps_per_second': 0.308, 'epoch': 2.67}
{'loss': 3.5738, 'grad_norm': 0.482421875, 'learning_rate': 1.3498374056721197e-05, 'epoch': 2.75}
{'loss': 3.676, 'grad_norm': 0.181640625, 'learning_rate': 1.2046000347697058e-05, 'epoch': 2.82}
{'eval_loss': 2.3491387367248535, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.4472, 'eval_samples_per_second': 1.221, 'eval_steps_per_second': 0.305, 'epoch': 2.86}
{'loss': 3.6348, 'grad_norm': 0.37890625, 'learning_rate': 1.0651114950379312e-05, 'epoch': 2.9}
{'loss': 3.7392, 'grad_norm': 0.287109375, 'learning_rate': 9.319908200468769e-06, 'epoch': 2.98}
{'loss': 3.6349, 'grad_norm': 0.1435546875, 'learning_rate': 8.058287835393132e-06, 'epoch': 3.05}
{'eval_loss': 2.3475914001464844, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 405.2459, 'eval_samples_per_second': 1.234, 'eval_steps_per_second': 0.308, 'epoch': 3.05}
{'loss': 3.7203, 'grad_norm': 0.423828125, 'learning_rate': 6.871852776470089e-06, 'epoch': 3.13}
{'loss': 3.6387, 'grad_norm': 0.3203125, 'learning_rate': 5.765868281559575e-06, 'epoch': 3.21}
{'eval_loss': 2.348480463027954, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.6192, 'eval_samples_per_second': 1.221, 'eval_steps_per_second': 0.305, 'epoch': 3.24}
{'loss': 3.6967, 'grad_norm': 0.40625, 'learning_rate': 4.745242578474798e-06, 'epoch': 3.28}
{'loss': 3.7148, 'grad_norm': 0.1533203125, 'learning_rate': 3.8145050828502755e-06, 'epoch': 3.36}
{'loss': 3.6669, 'grad_norm': 0.13671875, 'learning_rate': 2.977786297133234e-06, 'epoch': 3.44}
{'eval_loss': 2.3483829498291016, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 404.5167, 'eval_samples_per_second': 1.236, 'eval_steps_per_second': 0.309, 'epoch': 3.44}
{'loss': 3.7487, 'grad_norm': 0.09912109375, 'learning_rate': 2.238799479904413e-06, 'epoch': 3.51}
{'loss': 3.6397, 'grad_norm': 0.125, 'learning_rate': 1.6008241668775848e-06, 'epoch': 3.59}
{'eval_loss': 2.3484010696411133, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 409.3971, 'eval_samples_per_second': 1.221, 'eval_steps_per_second': 0.305, 'epoch': 3.63}
{'loss': 3.5583, 'grad_norm': 0.197265625, 'learning_rate': 1.0666916167095836e-06, 'epoch': 3.66}
{'loss': 3.6647, 'grad_norm': 0.18359375, 'learning_rate': 6.387722462107171e-07, 'epoch': 3.74}
{'loss': 3.6719, 'grad_norm': 0.216796875, 'learning_rate': 3.189651107165459e-07, 'epoch': 3.82}
{'eval_loss': 2.3483433723449707, 'eval_model_preparation_time': 0.0075, 'eval_runtime': 404.9898, 'eval_samples_per_second': 1.235, 'eval_steps_per_second': 0.309, 'epoch': 3.82}
{'loss': 3.7855, 'grad_norm': 0.1875, 'learning_rate': 1.0868947630585936e-07, 'epoch': 3.89}
{'loss': 3.7364, 'grad_norm': 0.12890625, 'learning_rate': 8.878521266422746e-09, 'epoch': 3.97}
{'train_runtime': 32402.8991, 'train_samples_per_second': 1.034, 'train_steps_per_second': 0.032, 'train_loss': 3.898632593737304, 'epoch': 4.0}
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mLlama with SFT dataset. 3 epochs. Lr 5e-5[0m at: [34mhttps://wandb.ai/jbarrutia006-upv-ehu/viperSFT/runs/a4gnw8k9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250420_182809-a4gnw8k9/logs[0m
