SELECTED CONFIG FILES: gqa/general_config,gqa/train
LOADING MODEL: ENABLED
modelo: <class 'vision_models.BLIPModel'> , proceso:  blip
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
modelo: <class 'vision_models.GLIPModel'> , proceso:  glip
modelo: <class 'vision_models.MaskRCNNModel'> , proceso:  maskrcnn
modelo: <class 'vision_models.XVLMModel'> , proceso:  xvlm
{'blip': <function make_fn.<locals>._function at 0x7fbd357511c0>, 'glip': <function make_fn.<locals>._function at 0x7fb6da8507c0>, 'maskrcnn': <function make_fn.<locals>._function at 0x7fbca71e98a0>, 'xvlm': <function make_fn.<locals>._function at 0x7fb6da3639c0>}
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 187.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 481.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 800.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 801.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 773.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 912.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 7.12 MiB is free. Including non-PyTorch memory, this process has 31.73 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 940.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 181.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 573.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Car is to the left of the bus
Error in glip model: CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 688.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 613.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 646.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 581.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 623.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 784.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 816.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 239.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 965.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 801.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 716.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Best match is 0
Best match is index 0, which is mug
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 716.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 686.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 819.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 15.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 785.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 209.12 MiB is free. Including non-PyTorch memory, this process has 31.53 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 653.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 181.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 792.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 698.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 161.12 MiB is free. Including non-PyTorch memory, this process has 31.58 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 623.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 584.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 802.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The toaster oven is silver.
The toaster oven is brown
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 610.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 705.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 79.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 802.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 111.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 859.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 111.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 863.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([3, 300, 134]) is to the -0.011945211328566074 left of torch.Size([3, 464, 242])
Man at (162.0, 358.0) is to the -0.011945211328566074 left of statue at (344.0, 414.0)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 111.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 835.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
black
hat is not red
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 111.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 835.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 111.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 807.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 111.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 863.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 111.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 835.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 111.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 984.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 802.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The wallet is brown
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 792.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 931.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 893.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 931.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 931.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 931.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 826.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 43.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 848.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The image contains a tables and chairs made of plastic.
Found cheese at center (95.00, 200.00)
Cheese is goat cheese
This is goat cheese cheese.
The cheese is white
Error in glip model: CUDA out of memory. Tried to allocate 380.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.37 GiB is allocated by PyTorch, and 981.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 911.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 883.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 947.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 883.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 35.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 749.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 784.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 830.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 784.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 723.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 774.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 885.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 830.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 723.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 885.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 830.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 983.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 723.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
There are cabinets.
There are couches.
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 723.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 919.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 723.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
laptop
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 723.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 801.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 671.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 746.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 746.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 690.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 774.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 61.12 MiB is free. Including non-PyTorch memory, this process has 31.68 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 723.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 919.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Found a fireplace on the fireplace.
Error in glip model: CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 45.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 412.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 883.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 1015.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 627.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 684.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 563.12 MiB is free. Including non-PyTorch memory, this process has 31.19 GiB memory in use. Of the allocated memory 30.06 GiB is allocated by PyTorch, and 764.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 187.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 596.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 187.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 786.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 187.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 786.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 187.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 786.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 149.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 574.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 149.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 658.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 149.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 825.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 149.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 825.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 149.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 825.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 149.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 825.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 149.12 MiB is free. Including non-PyTorch memory, this process has 31.59 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 825.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 566.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 521.12 MiB is free. Including non-PyTorch memory, this process has 31.23 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 460.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 361.12 MiB is free. Including non-PyTorch memory, this process has 31.38 GiB memory in use. Of the allocated memory 30.16 GiB is allocated by PyTorch, and 866.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 617.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 143.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 617.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 95.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 728.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 95.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 689.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 239.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 731.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 733.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 784.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 923.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 923.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 923.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 990.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 743.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 1017.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
