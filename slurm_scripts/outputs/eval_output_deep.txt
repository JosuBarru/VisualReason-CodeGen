SELECTED CONFIG FILES: gqa/general_config,gqa/train
LOADING MODEL: ENABLED
modelo: <class 'vision_models.BLIPModel'> , proceso:  blip
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
modelo: <class 'vision_models.GLIPModel'> , proceso:  glip
modelo: <class 'vision_models.MaskRCNNModel'> , proceso:  maskrcnn
modelo: <class 'vision_models.XVLMModel'> , proceso:  xvlm
{'blip': <function make_fn.<locals>._function at 0x7f82afe9d1c0>, 'glip': <function make_fn.<locals>._function at 0x7f81296f87c0>, 'maskrcnn': <function make_fn.<locals>._function at 0x7f82168598a0>, 'xvlm': <function make_fn.<locals>._function at 0x7f812907b9c0>}
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 187.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 481.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 800.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 801.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 175.12 MiB is free. Including non-PyTorch memory, this process has 31.56 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 773.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 3.12 MiB is free. Including non-PyTorch memory, this process has 31.73 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 911.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 123.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 757.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 119.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 795.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 119.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 828.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 119.12 MiB is free. Including non-PyTorch memory, this process has 31.62 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 860.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 686.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Car is to the left of the bus
Error in glip model: CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 688.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 613.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 646.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 173.12 MiB is free. Including non-PyTorch memory, this process has 31.57 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 581.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 623.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 784.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 33.12 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 816.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 239.12 MiB is free. Including non-PyTorch memory, this process has 31.50 GiB memory in use. Of the allocated memory 30.18 GiB is allocated by PyTorch, and 965.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 801.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 716.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Best match is 0
Best match is index 0, which is mug
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 716.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 686.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 29.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 819.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 15.12 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 785.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 25.12 MiB is free. Including non-PyTorch memory, this process has 31.71 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 631.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 185.12 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 789.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 720.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 645.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.43 GiB is allocated by PyTorch, and 812.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 742.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The toaster oven is silver.
The toaster oven is brown
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 550.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 645.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 139.12 MiB is free. Including non-PyTorch memory, this process has 31.60 GiB memory in use. Of the allocated memory 30.50 GiB is allocated by PyTorch, and 742.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 263.12 MiB is free. Including non-PyTorch memory, this process has 31.48 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 707.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 898.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([3, 300, 134]) is to the -0.011945211328566074 left of torch.Size([3, 464, 242])
Man at (162.0, 358.0) is to the -0.011945211328566074 left of statue at (344.0, 414.0)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 871.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
black
hat is not red
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 871.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 843.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 899.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 871.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 950.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 770.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The wallet is brown
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 760.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 899.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 861.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 899.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 899.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.41 GiB is allocated by PyTorch, and 899.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 75.12 MiB is free. Including non-PyTorch memory, this process has 31.66 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The image contains a tables and chairs made of plastic.
Found cheese at center (95.00, 200.00)
Cheese is goat cheese
This is goat cheese cheese.
The cheese is white
Error in glip model: CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 866.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 717.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 717.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 921.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 879.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 851.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 915.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.46 GiB is allocated by PyTorch, and 851.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 717.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 67.12 MiB is free. Including non-PyTorch memory, this process has 31.67 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 717.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 598.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 29.95 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 794.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 1003.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 687.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 738.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 849.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 794.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 687.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, and 849.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 794.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 947.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 687.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
There are cabinets.
There are couches.
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 687.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 883.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 687.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
laptop
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 687.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 765.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 634.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 710.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 710.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.63 GiB is allocated by PyTorch, and 654.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.54 GiB is allocated by PyTorch, and 738.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 687.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.25 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Found a fireplace on the fireplace.
Error in glip model: CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 928.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 412.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.29 GiB is allocated by PyTorch, and 996.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 947.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 97.12 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 30.52 GiB is allocated by PyTorch, and 765.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.73 GiB is allocated by PyTorch, and 536.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.88 GiB is allocated by PyTorch, and 389.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 485.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 566.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 874.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 961.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 716.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 936.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 517.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 934.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 961.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 613.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 613.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.88 GiB is allocated by PyTorch, and 389.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 762.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 517.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 900.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 388.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.23 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 961.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The laptop is flat
The screen is flat
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The shirt color is white
Error in xvlm model: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 693.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 436.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 920.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 613.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The shirt is blue
Is the shirt blue?yes
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 762.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The curtain is black.
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 549.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 502.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 740.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
black
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in maskrcnn model: The size of tensor a (0) must match the size of tensor b (3) at non-singleton dimension 0
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The clouds are white.
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.88 GiB is allocated by PyTorch, and 389.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 420.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.31 GiB is allocated by PyTorch, and 964.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 582.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The cat is black.
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
No kite found.
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.88 GiB is allocated by PyTorch, and 389.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 518.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 983.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 485.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.78 GiB is allocated by PyTorch, and 485.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 549.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 900.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 807.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The water hose is white.
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.40 GiB is allocated by PyTorch, and 875.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 613.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 588.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.84 GiB is allocated by PyTorch, and 421.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 436.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 918.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 693.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The boy is wearing brown.
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.57 GiB is allocated by PyTorch, and 699.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 900.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 693.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 807.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 582.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 801.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The towel is white
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 738.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 517.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 517.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 936.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 526.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.31 GiB is allocated by PyTorch, and 964.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 784.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 582.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 934.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 613.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 613.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 784.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
This object is indoors
This object is outdoors
This object is outdoors
This object is outdoors
This object is outdoors
This object is outdoors
This object is outdoors
This object is outdoors
This object is outdoors
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 762.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 1008.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 784.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 829.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The telephone is in the lower half.
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.81 GiB is allocated by PyTorch, and 453.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 738.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 549.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 574.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 857.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 588.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.65 GiB is allocated by PyTorch, and 625.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
There is a racket in the image.
Man is to the right of the woman
Error in glip model: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.88 GiB is allocated by PyTorch, and 389.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.68 GiB is allocated by PyTorch, and 588.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The bed cover is not red.
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 807.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Color is pink
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 693.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Found 4 doughnuts.
The leftmost doughnut is at position 0
The rightmost doughant is at position 269
The topmost doughnut is at position 121
Error in glip model: CUDA out of memory. Tried to allocate 592.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 29.95 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.81 GiB is allocated by PyTorch, and 453.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 738.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.84 GiB is allocated by PyTorch, and 421.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The hair is red
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 388.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.23 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 613.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The cap is orange
Error in glip model: CUDA out of memory. Tried to allocate 388.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.23 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 517.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 468.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.45 GiB is allocated by PyTorch, and 829.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 561.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 561.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Found player at position: 100, 23, 226, 356
Horizontal center: 163.0
Vertical center: 189.5
Width: 126
Height: 333
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 762.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 937.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 936.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 549.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
The bowl is black.
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 738.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
hot dog
white
plastic
Is it modern?  True
Is it a table lamp?  True
white
Error in glip model: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.49 GiB is allocated by PyTorch, and 784.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.58 GiB is allocated by PyTorch, and 693.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 549.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 918.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 738.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.84 GiB is allocated by PyTorch, and 421.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 762.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 807.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.66 GiB is allocated by PyTorch, and 613.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Found a chair at center 439.00, 42.50
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 444.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 896.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 918.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 549.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.32 GiB is allocated by PyTorch, and 961.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.47 GiB is allocated by PyTorch, and 807.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 428.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, and 941.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.72 GiB is allocated by PyTorch, and 549.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 460.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.42 GiB is allocated by PyTorch, and 852.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.53 GiB is allocated by PyTorch, and 742.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 517.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.62 GiB is allocated by PyTorch, and 646.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.81 GiB is allocated by PyTorch, and 453.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.38 GiB is allocated by PyTorch, and 900.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.56 GiB is allocated by PyTorch, and 710.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.59 GiB is allocated by PyTorch, and 677.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Found apples to the right of the woman.
Error in glip model: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.75 GiB is allocated by PyTorch, and 517.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 688.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.07 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 378.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.36 GiB is allocated by PyTorch, and 919.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error in glip model: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 31.63 GiB memory in use. Of the allocated memory 30.61 GiB is allocated by PyTorch, and 658.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
No sneakers found.
The bird is gray and white.
Ball found: metal, 2 inches
The fence is brown.
No cell phones found
Shelf wood
Found brown furniture.
The woman is wearing a scarf
Found a square cake.
This a person is on the left half.
The rightmost napkin is a person.
The weather is cloudy
Yes, there is a white plate.
Color difference: tensor(0.4157)
Shape difference: True
Size difference: True
Position difference: True
white
The grass is green
Indoor scene
The sky is called blue, it is blue, and it's full of smoke.
There is a window.
There is a door.
Error in blip model: 'list' object has no attribute 'lower'
The truck is white in color, tow truck type, medium size, towing use.
Yes
The best match is red
Could not determine the item of furniture
The man's name is john
The boy is brown
The bowl is green
The clothes are green
The image has False laptops and printers.
For person john, the pants are blue
There are buses in this image.
There are cabinets in the image.
The house is brown
white
No speakers found close to the laptop.
laptop
The chair is blue
Found an orange. Its color is blue
For blue and white, the color is tan.
The sweater is red
The left_person is to the left of the boy
Man's color: black
Cropped man: ImagePatch(221, 0, 359, 151)
The boy's shirt is blue
Man is on the left of the boy
male
male
male
brown
The microwave shows: microwave
Found a goat or cow that is walking.
The table is brown
The scissors are black
brown
The table is not brown.
wood
The table is round
square
The shirt is not black
The animal is dog
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
Final accuracy: 0.14595238095238094
