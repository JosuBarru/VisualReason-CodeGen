wandb: Currently logged in as: jbarrutia006 (jbarrutia006-upv-ehu). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /sorgin1/users/jbarrutia006/viper/wandb/run-20250309_141159-4qkgrb01
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Primera prueba A100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jbarrutia006-upv-ehu/viperDPO
wandb: üöÄ View run at https://wandb.ai/jbarrutia006-upv-ehu/viperDPO/runs/4qkgrb01
2025-03-09 14:12:01,268 - INFO - Loading model and tokenizer...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.09it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:01,  1.05it/s]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:02<00:00,  1.02it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.24it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.16it/s]
Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2025-03-09 14:12:19,219 - INFO - Loading dataset from /sorgin1/users/jbarrutia006/viper/PrefDatasets/dpo_dataset_single_train.arrow as train and /sorgin1/users/jbarrutia006/viper/PrefDatasets/dpo_dataset_single_train.arrow as dev
Map:   0%|          | 0/7381 [00:00<?, ? examples/s]2025-03-09 14:12:19,237 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the utensil on the left?
def execute_command(image)->str:
2025-03-09 14:12:19,239 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    utensil_patches = image_patch.find("utensil")
    
    if not utensil_patches:
        return image_patch.simple_query("Is the utensil on the left?")
    
    for utensil_patch in utensil_patches:
        if utensil_patch.horizontal_center < image_patch.horizontal_center:
            return "yes"
    
    return "no"

2025-03-09 14:12:19,241 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    # not a relational verb, so go step by step
    utensil_patches = image_patch.find("utensils")
    # Question assumes at least one utensil patch
    if len(unstable_patchs) == 0:
        # If no utensil is found, query the image directly
        return image_patch.simple_query("Is the utensil on the left")
    for utensil_patch in utensil_patches:
        is_on_left = (unstable_patch//image_patch.width for unstable_patch in unstable_patchs)
        return bool_to_yesno(is_on_left)
2025-03-09 14:12:19,275 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the palm near the horse green and short?
def execute_command(image)->str:
2025-03-09 14:12:19,276 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # Check if both objects exist
    has_palm = image_patch.exists("palm")
    has_horse = image_patch.exists("horse")
    if not (has_palm and has_horse):
        # If either object isn't found, query directly
        return image_patch.simple_query("Is the palm near the horse? Is the palm green and short?")
    
    # Determine if the palm is near the horse
    if not image_patch.find("palm")[0].best_text_match(["near", "far"]) == "near":
        return "no"
    
    # Check palm properties
    if (image_patch.find("palm")[0].verify_property("palm", "green") and
        image_patch.find("palm")[0].verify_property("palm", "short")):
        return "yes"
    else:
        return "no"

2025-03-09 14:12:19,277 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    palm_patches = image_patch.find("palm")
    horse_patches = image_patch.find("horse")
    
    # Question assumes only one palm
    if len(palm_patches) == 0:
        return image_patch.simple_query("Is the palm near the horse green and short?")
    palm = palm_patches[0]
    
    # Find nearby horse
    nearby_horse = None
    for horse in horse_patches:
        if horse.horizontal_center > palm.horizontal_center:
            nearby_horse = horse
            break
    if nearby_horse is None:
        return image_patch.simple_query("Is the palm near the horse green and short?")
    
    # Check if palm is green
    if not palm.simple_query("Is the palm green?"):
        return image_patch.simple_query("Is the palm near the horse green and short?")
    
    # Check if palm is short (height)
    if not palm.simple_query("Is the palm short?"):
        return image_patch.simple_query("Is the palm near the horse green and short?")
    
    return "yes"

2025-03-09 14:12:19,297 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are the palm trees in the bottom or in the top of the image?
def execute_command(image)->str:
2025-03-09 14:12:19,298 - INFO - Chosen response:  # the question is about the image, not the patch
    image_patch = ImagePatch(image)
    palm_patches = image_patch.find("palm tree")
    # Question assumes only one palm patch
    if len(palm_patches) == 0:
        # If no palm is found, query the image directly
        return image_patch.simple_query("Are the palm trees in the bottom or in the top of the image?")
    palm_patch = palm_patches[0]
    if palm_patch.vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"
2025-03-09 14:12:19,299 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    palm_trees = image_patch.find("palm tree")
    
    if not palm_trees:
        return image_patch.simple_query("What is present in the image?")
    
    for palm_tree in palm_trees:
        tree_center = palm_tree.vertical_center
        image_center = image_patch.vertical_center
        
        if tree_center < image_center:
            return "yes"
    
    return "no"

2025-03-09 14:12:19,318 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is there a chair in the photo?
def execute_command(image)->str:
2025-03-09 14:12:19,320 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    return bool_to_yesno(image_patch.exists("chair"))

2025-03-09 14:12:19,321 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    chairs = image_patch.find("chair")
    return bool_to_yesno(len(chairs) > 0)

2025-03-09 14:12:19,338 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the man wearing a cap?
def execute_command(image)->str:
2025-03-09 14:12:19,340 - INFO - Chosen response:  
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Is the man wearing a cap?")
2025-03-09 14:12:19,342 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    if len(man_patches) == 0:

Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5000/7381 [00:00<00:00, 40055.54 examples/s]2025-03-09 14:12:19,360 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Does the lawn look ugly?
def execute_command(image)->str:
2025-03-09 14:12:19,361 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Does the lawn look ugly?")

2025-03-09 14:12:19,362 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    lawn_patches = image_patch.find("lawn")
    if len(lawn_patches) == 0:
        # If no lawn is found, query the image directly
        return image_patch.simple_query("Does the lawn look ugly?")
    else:
        # If a lawn is found, ask specifically about the lawn
        return bool_to_yesno(image_patch.simple_query("Does the lawn look ugly?"))

2025-03-09 14:12:19,378 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the plate in front of a lady?
def execute_command(image)->str:
2025-03-09 14:12:19,379 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    plate_patches = image_patch.find("plate")
    lady_patches = image_patch.find("lady")
    
    if not plate_patches or not lady_patches:
        return "no"
    
    for plate_patch in plate_patches:
        for lady_patch in lady_patches:
            if plate_patch.horizontal_center > lady_patch.horizontal_center:
                return "yes"
    return "no"

2025-03-09 14:12:19,381 - INFO - Rejected response:     
    plate_patches = image_patch.find("plate")
    # Question assumes one plate patch
    if len(plate_patches) == 0:
        # If no plate is found, query the image directly
        return image_patch.simple_query("Is the plate in front of a lady?")
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("Is the plate in front of a lady?")
2025-03-09 14:12:19,393 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# On which side is the faucet?
def execute_command(image)->str:
2025-03-09 14:12:19,394 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    faucets = image_patch.find("faucet")
    if not faucets:
        return "The faucet is not in the image."
    for faucet in faucets:
        if faucet.horizontal_center < image_patch.horizontal_center:
            return "left"
        elif faucet.horizontal_center > image_patch.horizontal_center:
            return "right"
    return "The faucet is not in the image."

2025-03-09 14:12:19,395 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    is_faucet = image_patch.exists("faucet")
    if is_faucet:
        return image_patch.simple_query("On which side is the faucet?") # crop would include the faucet so keep it in the query
    else:
        return "not in the image"
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7381/7381 [00:01<00:00, 6490.28 examples/s] 
Map:   0%|          | 0/7381 [00:00<?, ? examples/s]2025-03-09 14:12:20,383 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the utensil on the left?
def execute_command(image)->str:
2025-03-09 14:12:20,385 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    utensil_patches = image_patch.find("utensil")
    
    if not utensil_patches:
        return image_patch.simple_query("Is the utensil on the left?")
    
    for utensil_patch in utensil_patches:
        if utensil_patch.horizontal_center < image_patch.horizontal_center:
            return "yes"
    
    return "no"

2025-03-09 14:12:20,386 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    # not a relational verb, so go step by step
    utensil_patches = image_patch.find("utensils")
    # Question assumes at least one utensil patch
    if len(unstable_patchs) == 0:
        # If no utensil is found, query the image directly
        return image_patch.simple_query("Is the utensil on the left")
    for utensil_patch in utensil_patches:
        is_on_left = (unstable_patch//image_patch.width for unstable_patch in unstable_patchs)
        return bool_to_yesno(is_on_left)
2025-03-09 14:12:20,407 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the palm near the horse green and short?
def execute_command(image)->str:
2025-03-09 14:12:20,408 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    # Check if both objects exist
    has_palm = image_patch.exists("palm")
    has_horse = image_patch.exists("horse")
    if not (has_palm and has_horse):
        # If either object isn't found, query directly
        return image_patch.simple_query("Is the palm near the horse? Is the palm green and short?")
    
    # Determine if the palm is near the horse
    if not image_patch.find("palm")[0].best_text_match(["near", "far"]) == "near":
        return "no"
    
    # Check palm properties
    if (image_patch.find("palm")[0].verify_property("palm", "green") and
        image_patch.find("palm")[0].verify_property("palm", "short")):
        return "yes"
    else:
        return "no"

2025-03-09 14:12:20,409 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    palm_patches = image_patch.find("palm")
    horse_patches = image_patch.find("horse")
    
    # Question assumes only one palm
    if len(palm_patches) == 0:
        return image_patch.simple_query("Is the palm near the horse green and short?")
    palm = palm_patches[0]
    
    # Find nearby horse
    nearby_horse = None
    for horse in horse_patches:
        if horse.horizontal_center > palm.horizontal_center:
            nearby_horse = horse
            break
    if nearby_horse is None:
        return image_patch.simple_query("Is the palm near the horse green and short?")
    
    # Check if palm is green
    if not palm.simple_query("Is the palm green?"):
        return image_patch.simple_query("Is the palm near the horse green and short?")
    
    # Check if palm is short (height)
    if not palm.simple_query("Is the palm short?"):
        return image_patch.simple_query("Is the palm near the horse green and short?")
    
    return "yes"

2025-03-09 14:12:20,427 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are the palm trees in the bottom or in the top of the image?
def execute_command(image)->str:
2025-03-09 14:12:20,429 - INFO - Chosen response:  # the question is about the image, not the patch
    image_patch = ImagePatch(image)
    palm_patches = image_patch.find("palm tree")
    # Question assumes only one palm patch
    if len(palm_patches) == 0:
        # If no palm is found, query the image directly
        return image_patch.simple_query("Are the palm trees in the bottom or in the top of the image?")
    palm_patch = palm_patches[0]
    if palm_patch.vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"
2025-03-09 14:12:20,430 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    palm_trees = image_patch.find("palm tree")
    
    if not palm_trees:
        return image_patch.simple_query("What is present in the image?")
    
    for palm_tree in palm_trees:
        tree_center = palm_tree.vertical_center
        image_center = image_patch.vertical_center
        
        if tree_center < image_center:
            return "yes"
    
    return "no"

2025-03-09 14:12:20,447 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is there a chair in the photo?
def execute_command(image)->str:
2025-03-09 14:12:20,449 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    return bool_to_yesno(image_patch.exists("chair"))

2025-03-09 14:12:20,450 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    chairs = image_patch.find("chair")
    return bool_to_yesno(len(chairs) > 0)

2025-03-09 14:12:20,467 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the man wearing a cap?
def execute_command(image)->str:
2025-03-09 14:12:20,468 - INFO - Chosen response:  
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Is the man wearing a cap?")
2025-03-09 14:12:20,470 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    if len(man_patches) == 0:

2025-03-09 14:12:20,488 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Does the lawn look ugly?
def execute_command(image)->str:
2025-03-09 14:12:20,490 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Does the lawn look ugly?")

2025-03-09 14:12:20,491 - INFO - Rejected response: 
    image_patch = ImagePatch(image)
    lawn_patches = image_patch.find("lawn")
    if len(lawn_patches) == 0:
        # If no lawn is found, query the image directly
        return image_patch.simple_query("Does the lawn look ugly?")
    else:
        # If a lawn is found, ask specifically about the lawn
        return bool_to_yesno(image_patch.simple_query("Does the lawn look ugly?"))

Map:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 6000/7381 [00:00<00:00, 47982.25 examples/s]2025-03-09 14:12:20,509 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the plate in front of a lady?
def execute_command(image)->str:
2025-03-09 14:12:20,510 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    plate_patches = image_patch.find("plate")
    lady_patches = image_patch.find("lady")
    
    if not plate_patches or not lady_patches:
        return "no"
    
    for plate_patch in plate_patches:
        for lady_patch in lady_patches:
            if plate_patch.horizontal_center > lady_patch.horizontal_center:
                return "yes"
    return "no"

2025-03-09 14:12:20,512 - INFO - Rejected response:     
    plate_patches = image_patch.find("plate")
    # Question assumes one plate patch
    if len(plate_patches) == 0:
        # If no plate is found, query the image directly
        return image_patch.simple_query("Is the plate in front of a lady?")
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("Is the plate in front of a lady?")
2025-03-09 14:12:20,526 - INFO - Prompt example: from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# On which side is the faucet?
def execute_command(image)->str:
2025-03-09 14:12:20,527 - INFO - Chosen response: 
    image_patch = ImagePatch(image)
    faucets = image_patch.find("faucet")
    if not faucets:
        return "The faucet is not in the image."
    for faucet in faucets:
        if faucet.horizontal_center < image_patch.horizontal_center:
            return "left"
        elif faucet.horizontal_center > image_patch.horizontal_center:
            return "right"
    return "The faucet is not in the image."

2025-03-09 14:12:20,527 - INFO - Rejected response:  
    image_patch = ImagePatch(image)
    is_faucet = image_patch.exists("faucet")
    if is_faucet:
        return image_patch.simple_query("On which side is the faucet?") # crop would include the faucet so keep it in the query
    else:
        return "not in the image"
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7381/7381 [00:01<00:00, 6583.96 examples/s] 
2025-03-09 14:12:21,498 - INFO - Initializing DPOTrainer...
Extracting prompt in train dataset:   0%|          | 0/7381 [00:00<?, ? examples/s]Extracting prompt in train dataset:  11%|‚ñà‚ñè        | 831/7381 [00:00<00:00, 8235.22 examples/s]Extracting prompt in train dataset:  23%|‚ñà‚ñà‚ñé       | 1680/7381 [00:00<00:00, 8376.53 examples/s]Extracting prompt in train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 2805/7381 [00:00<00:00, 7879.35 examples/s]Extracting prompt in train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3899/7381 [00:00<00:00, 7601.38 examples/s]Extracting prompt in train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5030/7381 [00:00<00:00, 7564.90 examples/s]Extracting prompt in train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5829/7381 [00:00<00:00, 7676.06 examples/s]Extracting prompt in train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 6660/7381 [00:00<00:00, 7838.60 examples/s]Extracting prompt in train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7381/7381 [00:02<00:00, 2471.50 examples/s]
Applying chat template to train dataset:   0%|          | 0/7381 [00:00<?, ? examples/s]Applying chat template to train dataset:  20%|‚ñà‚ñâ        | 1472/7381 [00:00<00:00, 14642.20 examples/s]Applying chat template to train dataset:  40%|‚ñà‚ñà‚ñà‚ñâ      | 2948/7381 [00:00<00:00, 14707.15 examples/s]Applying chat template to train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4468/7381 [00:00<00:00, 14922.88 examples/s]Applying chat template to train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5980/7381 [00:00<00:00, 14980.83 examples/s]Applying chat template to train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7381/7381 [00:02<00:00, 2980.51 examples/s] 
Tokenizing train dataset:   0%|          | 0/7381 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 18/7381 [00:00<00:41, 175.98 examples/s]Tokenizing train dataset:   1%|          | 40/7381 [00:00<00:38, 190.84 examples/s]Tokenizing train dataset:   1%|          | 61/7381 [00:00<00:37, 193.55 examples/s]Tokenizing train dataset:   1%|          | 83/7381 [00:00<00:36, 197.56 examples/s]Tokenizing train dataset:   1%|‚ñè         | 105/7381 [00:00<00:36, 199.29 examples/s]Tokenizing train dataset:   2%|‚ñè         | 126/7381 [00:00<00:36, 199.97 examples/s]Tokenizing train dataset:   2%|‚ñè         | 147/7381 [00:00<00:36, 200.40 examples/s]Tokenizing train dataset:   2%|‚ñè         | 175/7381 [00:00<00:37, 192.39 examples/s]Tokenizing train dataset:   3%|‚ñé         | 195/7381 [00:01<00:37, 193.70 examples/s]Tokenizing train dataset:   3%|‚ñé         | 215/7381 [00:01<00:36, 194.83 examples/s]Tokenizing train dataset:   3%|‚ñé         | 237/7381 [00:01<00:36, 197.15 examples/s]Tokenizing train dataset:   3%|‚ñé         | 258/7381 [00:01<00:35, 198.35 examples/s]Tokenizing train dataset:   4%|‚ñç         | 279/7381 [00:01<00:35, 198.83 examples/s]Tokenizing train dataset:   4%|‚ñç         | 299/7381 [00:01<00:35, 198.73 examples/s]Tokenizing train dataset:   4%|‚ñç         | 320/7381 [00:01<00:35, 199.02 examples/s]Tokenizing train dataset:   5%|‚ñç         | 342/7381 [00:01<00:35, 200.39 examples/s]Tokenizing train dataset:   5%|‚ñç         | 364/7381 [00:01<00:34, 201.46 examples/s]Tokenizing train dataset:   5%|‚ñå         | 394/7381 [00:01<00:35, 198.24 examples/s]Tokenizing train dataset:   6%|‚ñå         | 416/7381 [00:02<00:34, 200.00 examples/s]Tokenizing train dataset:   6%|‚ñå         | 437/7381 [00:02<00:34, 199.71 examples/s]Tokenizing train dataset:   6%|‚ñå         | 458/7381 [00:02<00:34, 200.21 examples/s]Tokenizing train dataset:   7%|‚ñã         | 488/7381 [00:02<00:34, 199.71 examples/s]Tokenizing train dataset:   7%|‚ñã         | 509/7381 [00:02<00:34, 199.73 examples/s]Tokenizing train dataset:   7%|‚ñã         | 529/7381 [00:02<00:34, 199.23 examples/s]Tokenizing train dataset:   7%|‚ñã         | 550/7381 [00:02<00:34, 199.35 examples/s]Tokenizing train dataset:   8%|‚ñä         | 572/7381 [00:02<00:33, 200.41 examples/s]Tokenizing train dataset:   8%|‚ñä         | 593/7381 [00:02<00:33, 200.54 examples/s]Tokenizing train dataset:   8%|‚ñä         | 622/7381 [00:03<00:35, 192.85 examples/s]Tokenizing train dataset:   9%|‚ñä         | 643/7381 [00:03<00:34, 193.58 examples/s]Tokenizing train dataset:   9%|‚ñâ         | 663/7381 [00:03<00:34, 194.89 examples/s]Tokenizing train dataset:   9%|‚ñâ         | 684/7381 [00:03<00:34, 196.55 examples/s]Tokenizing train dataset:  10%|‚ñâ         | 705/7381 [00:03<00:33, 197.16 examples/s]Tokenizing train dataset:  10%|‚ñâ         | 725/7381 [00:03<00:33, 197.24 examples/s]Tokenizing train dataset:  10%|‚ñà         | 746/7381 [00:03<00:33, 198.18 examples/s]Tokenizing train dataset:  10%|‚ñà         | 766/7381 [00:03<00:33, 197.83 examples/s]Tokenizing train dataset:  11%|‚ñà         | 786/7381 [00:03<00:33, 197.09 examples/s]Tokenizing train dataset:  11%|‚ñà         | 807/7381 [00:04<00:33, 198.50 examples/s]Tokenizing train dataset:  11%|‚ñà         | 827/7381 [00:04<00:33, 195.60 examples/s]Tokenizing train dataset:  12%|‚ñà‚ñè        | 855/7381 [00:04<00:34, 188.74 examples/s]Tokenizing train dataset:  12%|‚ñà‚ñè        | 876/7381 [00:04<00:33, 191.72 examples/s]Tokenizing train dataset:  12%|‚ñà‚ñè        | 897/7381 [00:04<00:33, 194.04 examples/s]Tokenizing train dataset:  12%|‚ñà‚ñè        | 917/7381 [00:04<00:33, 195.08 examples/s]Tokenizing train dataset:  13%|‚ñà‚ñé        | 937/7381 [00:04<00:33, 195.27 examples/s]Tokenizing train dataset:  13%|‚ñà‚ñé        | 959/7381 [00:04<00:32, 197.45 examples/s]Tokenizing train dataset:  13%|‚ñà‚ñé        | 980/7381 [00:04<00:32, 196.90 examples/s]Tokenizing train dataset:  14%|‚ñà‚ñé        | 1007/7381 [00:05<00:34, 187.21 examples/s]Tokenizing train dataset:  14%|‚ñà‚ñç        | 1034/7381 [00:05<00:35, 179.72 examples/s]Tokenizing train dataset:  14%|‚ñà‚ñç        | 1062/7381 [00:05<00:35, 179.75 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñç        | 1082/7381 [00:05<00:34, 183.43 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñç        | 1102/7381 [00:05<00:33, 186.98 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñå        | 1122/7381 [00:05<00:33, 189.61 examples/s]Tokenizing train dataset:  15%|‚ñà‚ñå        | 1142/7381 [00:05<00:32, 191.37 examples/s]Tokenizing train dataset:  16%|‚ñà‚ñå        | 1163/7381 [00:05<00:32, 193.64 examples/s]Tokenizing train dataset:  16%|‚ñà‚ñå        | 1183/7381 [00:06<00:31, 195.18 examples/s]Tokenizing train dataset:  16%|‚ñà‚ñã        | 1203/7381 [00:06<00:31, 195.65 examples/s]Tokenizing train dataset:  17%|‚ñà‚ñã        | 1223/7381 [00:06<00:31, 195.46 examples/s]Tokenizing train dataset:  17%|‚ñà‚ñã        | 1245/7381 [00:06<00:31, 197.42 examples/s]Tokenizing train dataset:  17%|‚ñà‚ñã        | 1273/7381 [00:06<00:32, 189.45 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 1293/7381 [00:06<00:32, 189.01 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 1313/7381 [00:06<00:31, 191.09 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 1333/7381 [00:06<00:31, 192.01 examples/s]Tokenizing train dataset:  18%|‚ñà‚ñä        | 1353/7381 [00:06<00:31, 192.78 examples/s]Tokenizing train dataset:  19%|‚ñà‚ñä        | 1374/7381 [00:07<00:30, 194.67 examples/s]Tokenizing train dataset:  19%|‚ñà‚ñâ        | 1394/7381 [00:07<00:30, 195.05 examples/s]Tokenizing train dataset:  19%|‚ñà‚ñâ        | 1414/7381 [00:07<00:30, 193.86 examples/s]Tokenizing train dataset:  19%|‚ñà‚ñâ        | 1434/7381 [00:07<00:31, 191.38 examples/s]Tokenizing train dataset:  20%|‚ñà‚ñâ        | 1454/7381 [00:07<00:30, 193.32 examples/s]Tokenizing train dataset:  20%|‚ñà‚ñâ        | 1474/7381 [00:07<00:30, 191.97 examples/s]Tokenizing train dataset:  20%|‚ñà‚ñà        | 1494/7381 [00:07<00:30, 191.22 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà        | 1514/7381 [00:07<00:30, 192.76 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà        | 1534/7381 [00:07<00:30, 193.21 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà        | 1555/7381 [00:07<00:29, 194.66 examples/s]Tokenizing train dataset:  21%|‚ñà‚ñà‚ñè       | 1576/7381 [00:08<00:29, 195.94 examples/s]Tokenizing train dataset:  22%|‚ñà‚ñà‚ñè       | 1597/7381 [00:08<00:29, 196.93 examples/s]Tokenizing train dataset:  22%|‚ñà‚ñà‚ñè       | 1617/7381 [00:08<00:29, 197.35 examples/s]Tokenizing train dataset:  22%|‚ñà‚ñà‚ñè       | 1637/7381 [00:08<00:29, 197.52 examples/s]Tokenizing train dataset:  22%|‚ñà‚ñà‚ñè       | 1658/7381 [00:08<00:28, 198.25 examples/s]Tokenizing train dataset:  23%|‚ñà‚ñà‚ñé       | 1679/7381 [00:08<00:28, 198.76 examples/s]Tokenizing train dataset:  23%|‚ñà‚ñà‚ñé       | 1700/7381 [00:08<00:28, 196.98 examples/s]Tokenizing train dataset:  23%|‚ñà‚ñà‚ñé       | 1720/7381 [00:08<00:28, 196.94 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñé       | 1741/7381 [00:08<00:28, 197.87 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñç       | 1761/7381 [00:09<00:28, 196.90 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñç       | 1781/7381 [00:09<00:28, 196.97 examples/s]Tokenizing train dataset:  24%|‚ñà‚ñà‚ñç       | 1802/7381 [00:09<00:28, 196.02 examples/s]Tokenizing train dataset:  25%|‚ñà‚ñà‚ñç       | 1832/7381 [00:09<00:28, 192.85 examples/s]Tokenizing train dataset:  25%|‚ñà‚ñà‚ñå       | 1853/7381 [00:09<00:28, 193.94 examples/s]Tokenizing train dataset:  25%|‚ñà‚ñà‚ñå       | 1873/7381 [00:09<00:28, 192.04 examples/s]Tokenizing train dataset:  26%|‚ñà‚ñà‚ñå       | 1894/7381 [00:09<00:28, 192.79 examples/s]Tokenizing train dataset:  26%|‚ñà‚ñà‚ñå       | 1922/7381 [00:09<00:29, 188.04 examples/s]Tokenizing train dataset:  26%|‚ñà‚ñà‚ñã       | 1943/7381 [00:09<00:28, 190.85 examples/s]Tokenizing train dataset:  27%|‚ñà‚ñà‚ñã       | 1971/7381 [00:10<00:29, 183.35 examples/s]Tokenizing train dataset:  27%|‚ñà‚ñà‚ñã       | 1999/7381 [00:10<00:29, 179.83 examples/s]Tokenizing train dataset:  27%|‚ñà‚ñà‚ñã       | 2019/7381 [00:10<00:29, 178.74 examples/s]Tokenizing train dataset:  28%|‚ñà‚ñà‚ñä       | 2038/7381 [00:10<00:30, 177.45 examples/s]Tokenizing train dataset:  28%|‚ñà‚ñà‚ñä       | 2059/7381 [00:10<00:29, 180.96 examples/s]Tokenizing train dataset:  28%|‚ñà‚ñà‚ñä       | 2079/7381 [00:10<00:28, 184.26 examples/s]Tokenizing train dataset:  28%|‚ñà‚ñà‚ñä       | 2099/7381 [00:10<00:28, 188.01 examples/s]Tokenizing train dataset:  29%|‚ñà‚ñà‚ñä       | 2119/7381 [00:10<00:27, 189.21 examples/s]Tokenizing train dataset:  29%|‚ñà‚ñà‚ñâ       | 2139/7381 [00:11<00:27, 189.18 examples/s]Tokenizing train dataset:  29%|‚ñà‚ñà‚ñâ       | 2159/7381 [00:11<00:27, 191.90 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñâ       | 2179/7381 [00:11<00:26, 193.27 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñâ       | 2209/7381 [00:11<00:27, 190.57 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñà       | 2229/7381 [00:11<00:26, 192.42 examples/s]Tokenizing train dataset:  30%|‚ñà‚ñà‚ñà       | 2250/7381 [00:11<00:26, 193.51 examples/s]Tokenizing train dataset:  31%|‚ñà‚ñà‚ñà       | 2271/7381 [00:11<00:26, 196.16 examples/s]Tokenizing train dataset:  31%|‚ñà‚ñà‚ñà       | 2292/7381 [00:11<00:25, 196.87 examples/s]Tokenizing train dataset:  31%|‚ñà‚ñà‚ñà‚ñè      | 2312/7381 [00:11<00:25, 197.19 examples/s]Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 2332/7381 [00:12<00:25, 195.57 examples/s]Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 2352/7381 [00:12<00:25, 193.92 examples/s]Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 2373/7381 [00:12<00:25, 195.07 examples/s]Tokenizing train dataset:  32%|‚ñà‚ñà‚ñà‚ñè      | 2393/7381 [00:12<00:25, 195.83 examples/s]Tokenizing train dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 2413/7381 [00:12<00:25, 196.01 examples/s]Tokenizing train dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 2433/7381 [00:12<00:25, 196.27 examples/s]Tokenizing train dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 2454/7381 [00:12<00:24, 197.59 examples/s]Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñé      | 2476/7381 [00:12<00:24, 198.64 examples/s]Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñç      | 2497/7381 [00:12<00:24, 199.03 examples/s]Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñç      | 2518/7381 [00:12<00:24, 198.78 examples/s]Tokenizing train dataset:  34%|‚ñà‚ñà‚ñà‚ñç      | 2538/7381 [00:13<00:24, 197.95 examples/s]Tokenizing train dataset:  35%|‚ñà‚ñà‚ñà‚ñç      | 2558/7381 [00:13<00:24, 196.04 examples/s]Tokenizing train dataset:  35%|‚ñà‚ñà‚ñà‚ñç      | 2578/7381 [00:13<00:24, 195.20 examples/s]Tokenizing train dataset:  35%|‚ñà‚ñà‚ñà‚ñå      | 2606/7381 [00:13<00:25, 188.43 examples/s]Tokenizing train dataset:  36%|‚ñà‚ñà‚ñà‚ñå      | 2626/7381 [00:13<00:24, 191.11 examples/s]Tokenizing train dataset:  36%|‚ñà‚ñà‚ñà‚ñå      | 2646/7381 [00:13<00:24, 192.91 examples/s]Tokenizing train dataset:  36%|‚ñà‚ñà‚ñà‚ñå      | 2675/7381 [00:13<00:24, 188.87 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 2695/7381 [00:13<00:25, 187.03 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 2715/7381 [00:14<00:24, 189.26 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 2744/7381 [00:14<00:24, 186.59 examples/s]Tokenizing train dataset:  37%|‚ñà‚ñà‚ñà‚ñã      | 2764/7381 [00:14<00:24, 189.39 examples/s]Tokenizing train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 2785/7381 [00:14<00:23, 192.52 examples/s]Tokenizing train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 2806/7381 [00:14<00:23, 194.33 examples/s]Tokenizing train dataset:  38%|‚ñà‚ñà‚ñà‚ñä      | 2826/7381 [00:14<00:23, 195.24 examples/s]Tokenizing train dataset:  39%|‚ñà‚ñà‚ñà‚ñä      | 2846/7381 [00:14<00:23, 196.43 examples/s]Tokenizing train dataset:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2866/7381 [00:14<00:23, 194.75 examples/s]Tokenizing train dataset:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2892/7381 [00:14<00:24, 184.55 examples/s]Tokenizing train dataset:  39%|‚ñà‚ñà‚ñà‚ñâ      | 2913/7381 [00:15<00:23, 188.85 examples/s]Tokenizing train dataset:  40%|‚ñà‚ñà‚ñà‚ñâ      | 2934/7381 [00:15<00:23, 191.45 examples/s]Tokenizing train dataset:  40%|‚ñà‚ñà‚ñà‚ñà      | 2954/7381 [00:15<00:22, 192.91 examples/s]Tokenizing train dataset:  40%|‚ñà‚ñà‚ñà‚ñà      | 2975/7381 [00:15<00:22, 194.28 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà      | 2995/7381 [00:15<00:22, 195.27 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà      | 3015/7381 [00:15<00:22, 196.27 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà      | 3036/7381 [00:15<00:22, 197.24 examples/s]Tokenizing train dataset:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3056/7381 [00:15<00:21, 196.88 examples/s]Tokenizing train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3077/7381 [00:15<00:21, 197.48 examples/s]Tokenizing train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3097/7381 [00:15<00:21, 196.69 examples/s]Tokenizing train dataset:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3117/7381 [00:16<00:21, 196.19 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3137/7381 [00:16<00:21, 196.24 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3159/7381 [00:16<00:21, 198.05 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3180/7381 [00:16<00:21, 196.68 examples/s]Tokenizing train dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3201/7381 [00:16<00:21, 197.92 examples/s]Tokenizing train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3222/7381 [00:16<00:20, 198.42 examples/s]Tokenizing train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3243/7381 [00:16<00:20, 199.22 examples/s]Tokenizing train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3263/7381 [00:16<00:20, 198.53 examples/s]Tokenizing train dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3283/7381 [00:16<00:20, 198.19 examples/s]Tokenizing train dataset:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3304/7381 [00:17<00:20, 198.87 examples/s]Tokenizing train dataset:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 3324/7381 [00:17<00:20, 198.78 examples/s]Tokenizing train dataset:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 3352/7381 [00:17<00:21, 189.03 examples/s]Tokenizing train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 3380/7381 [00:17<00:21, 184.04 examples/s]Tokenizing train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 3402/7381 [00:17<00:21, 188.88 examples/s]Tokenizing train dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3422/7381 [00:17<00:20, 190.99 examples/s]Tokenizing train dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3442/7381 [00:17<00:20, 190.08 examples/s]Tokenizing train dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3462/7381 [00:17<00:20, 192.48 examples/s]Tokenizing train dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3482/7381 [00:17<00:20, 192.37 examples/s]Tokenizing train dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3502/7381 [00:18<00:19, 194.05 examples/s]Tokenizing train dataset:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 3523/7381 [00:18<00:19, 195.90 examples/s]Tokenizing train dataset:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 3544/7381 [00:18<00:19, 196.96 examples/s]Tokenizing train dataset:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 3566/7381 [00:18<00:19, 198.26 examples/s]Tokenizing train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 3587/7381 [00:18<00:19, 198.28 examples/s]Tokenizing train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3607/7381 [00:18<00:19, 195.85 examples/s]Tokenizing train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3628/7381 [00:18<00:19, 196.29 examples/s]Tokenizing train dataset:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3649/7381 [00:18<00:18, 197.38 examples/s]Tokenizing train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3670/7381 [00:18<00:18, 196.80 examples/s]Tokenizing train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3691/7381 [00:19<00:18, 197.63 examples/s]Tokenizing train dataset:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3711/7381 [00:19<00:18, 198.09 examples/s]Tokenizing train dataset:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3732/7381 [00:19<00:18, 198.44 examples/s]Tokenizing train dataset:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3753/7381 [00:19<00:18, 198.03 examples/s]Tokenizing train dataset:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3773/7381 [00:19<00:18, 197.85 examples/s]Tokenizing train dataset:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3794/7381 [00:19<00:18, 198.16 examples/s]Tokenizing train dataset:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3815/7381 [00:19<00:17, 199.10 examples/s]Tokenizing train dataset:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3845/7381 [00:19<00:17, 196.76 examples/s]Tokenizing train dataset:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3866/7381 [00:19<00:17, 197.26 examples/s]Tokenizing train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3896/7381 [00:20<00:17, 195.89 examples/s]Tokenizing train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3916/7381 [00:20<00:17, 195.79 examples/s]Tokenizing train dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3937/7381 [00:20<00:17, 194.77 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3958/7381 [00:20<00:17, 196.05 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3979/7381 [00:20<00:17, 196.22 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4000/7381 [00:20<00:17, 192.95 examples/s]Tokenizing train dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4021/7381 [00:20<00:17, 195.00 examples/s]Tokenizing train dataset:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4043/7381 [00:20<00:16, 196.63 examples/s]Tokenizing train dataset:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4064/7381 [00:20<00:17, 194.21 examples/s]Tokenizing train dataset:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4085/7381 [00:21<00:16, 196.74 examples/s]Tokenizing train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4106/7381 [00:21<00:16, 197.62 examples/s]Tokenizing train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4134/7381 [00:21<00:17, 189.90 examples/s]Tokenizing train dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4154/7381 [00:21<00:16, 191.58 examples/s]Tokenizing train dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4174/7381 [00:21<00:16, 192.04 examples/s]Tokenizing train dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4203/7381 [00:21<00:16, 191.88 examples/s]Tokenizing train dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4224/7381 [00:21<00:16, 193.58 examples/s]Tokenizing train dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4244/7381 [00:21<00:16, 192.61 examples/s]Tokenizing train dataset:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4264/7381 [00:21<00:16, 194.16 examples/s]Tokenizing train dataset:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4284/7381 [00:22<00:15, 194.76 examples/s]Tokenizing train dataset:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4305/7381 [00:22<00:15, 196.42 examples/s]Tokenizing train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 4325/7381 [00:22<00:15, 196.00 examples/s]Tokenizing train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4346/7381 [00:22<00:15, 196.89 examples/s]Tokenizing train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4366/7381 [00:22<00:15, 196.19 examples/s]Tokenizing train dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4387/7381 [00:22<00:15, 195.70 examples/s]Tokenizing train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4408/7381 [00:22<00:15, 196.35 examples/s]Tokenizing train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4429/7381 [00:22<00:15, 195.95 examples/s]Tokenizing train dataset:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4449/7381 [00:22<00:15, 194.30 examples/s]Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4469/7381 [00:23<00:14, 195.65 examples/s]Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4489/7381 [00:23<00:14, 196.40 examples/s]Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4510/7381 [00:23<00:14, 195.87 examples/s]Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4531/7381 [00:23<00:14, 197.19 examples/s]Tokenizing train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4552/7381 [00:23<00:14, 197.76 examples/s]Tokenizing train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4581/7381 [00:23<00:14, 194.74 examples/s]Tokenizing train dataset:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 4601/7381 [00:23<00:14, 194.84 examples/s]Tokenizing train dataset:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4621/7381 [00:23<00:14, 193.62 examples/s]Tokenizing train dataset:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4642/7381 [00:23<00:13, 195.93 examples/s]Tokenizing train dataset:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4670/7381 [00:24<00:14, 189.13 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4691/7381 [00:24<00:14, 192.08 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4712/7381 [00:24<00:13, 194.91 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4734/7381 [00:24<00:13, 196.97 examples/s]Tokenizing train dataset:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4756/7381 [00:24<00:13, 199.38 examples/s]Tokenizing train dataset:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4786/7381 [00:24<00:13, 197.25 examples/s]Tokenizing train dataset:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4807/7381 [00:24<00:13, 197.97 examples/s]Tokenizing train dataset:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4827/7381 [00:24<00:12, 197.44 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4847/7381 [00:24<00:12, 197.57 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4867/7381 [00:25<00:12, 198.07 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4887/7381 [00:25<00:12, 197.34 examples/s]Tokenizing train dataset:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4907/7381 [00:25<00:12, 197.10 examples/s]Tokenizing train dataset:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4928/7381 [00:25<00:12, 197.25 examples/s]Tokenizing train dataset:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4948/7381 [00:25<00:12, 194.29 examples/s]Tokenizing train dataset:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4969/7381 [00:25<00:12, 196.52 examples/s]Tokenizing train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4991/7381 [00:25<00:12, 197.49 examples/s]Tokenizing train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5011/7381 [00:25<00:12, 194.46 examples/s]Tokenizing train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5032/7381 [00:25<00:11, 195.96 examples/s]Tokenizing train dataset:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5053/7381 [00:25<00:11, 196.01 examples/s]Tokenizing train dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 5082/7381 [00:26<00:11, 194.06 examples/s]Tokenizing train dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 5104/7381 [00:26<00:11, 195.63 examples/s]Tokenizing train dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 5124/7381 [00:26<00:11, 196.14 examples/s]Tokenizing train dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 5146/7381 [00:26<00:11, 198.64 examples/s]Tokenizing train dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 5166/7381 [00:26<00:11, 196.96 examples/s]Tokenizing train dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5187/7381 [00:26<00:11, 197.71 examples/s]Tokenizing train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5207/7381 [00:26<00:11, 197.61 examples/s]Tokenizing train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5227/7381 [00:26<00:11, 195.60 examples/s]Tokenizing train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 5248/7381 [00:26<00:10, 196.27 examples/s]Tokenizing train dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5269/7381 [00:27<00:10, 197.06 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5289/7381 [00:27<00:10, 197.57 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5309/7381 [00:27<00:10, 193.16 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5330/7381 [00:27<00:10, 194.79 examples/s]Tokenizing train dataset:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5351/7381 [00:27<00:10, 196.45 examples/s]Tokenizing train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 5371/7381 [00:27<00:10, 196.58 examples/s]Tokenizing train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 5391/7381 [00:27<00:10, 195.41 examples/s]Tokenizing train dataset:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 5412/7381 [00:27<00:09, 196.91 examples/s]Tokenizing train dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 5433/7381 [00:27<00:09, 197.41 examples/s]Tokenizing train dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 5463/7381 [00:28<00:09, 194.84 examples/s]Tokenizing train dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 5485/7381 [00:28<00:09, 197.22 examples/s]Tokenizing train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 5507/7381 [00:28<00:09, 198.67 examples/s]Tokenizing train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5537/7381 [00:28<00:09, 195.56 examples/s]Tokenizing train dataset:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5559/7381 [00:28<00:09, 197.84 examples/s]Tokenizing train dataset:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5581/7381 [00:28<00:09, 198.71 examples/s]Tokenizing train dataset:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5611/7381 [00:28<00:09, 195.62 examples/s]Tokenizing train dataset:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5633/7381 [00:28<00:08, 197.44 examples/s]Tokenizing train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5654/7381 [00:29<00:08, 198.08 examples/s]Tokenizing train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5684/7381 [00:29<00:08, 194.65 examples/s]Tokenizing train dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5705/7381 [00:29<00:08, 195.85 examples/s]Tokenizing train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5725/7381 [00:29<00:08, 196.58 examples/s]Tokenizing train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5745/7381 [00:29<00:08, 194.35 examples/s]Tokenizing train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5767/7381 [00:29<00:08, 197.73 examples/s]Tokenizing train dataset:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5787/7381 [00:29<00:08, 197.66 examples/s]Tokenizing train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 5808/7381 [00:29<00:07, 198.30 examples/s]Tokenizing train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5829/7381 [00:29<00:07, 196.87 examples/s]Tokenizing train dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5851/7381 [00:30<00:07, 197.25 examples/s]Tokenizing train dataset:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5881/7381 [00:30<00:07, 194.36 examples/s]Tokenizing train dataset:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5902/7381 [00:30<00:07, 196.39 examples/s]Tokenizing train dataset:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5922/7381 [00:30<00:07, 195.48 examples/s]Tokenizing train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5944/7381 [00:30<00:07, 197.63 examples/s]Tokenizing train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5966/7381 [00:30<00:07, 200.36 examples/s]Tokenizing train dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5997/7381 [00:30<00:06, 199.54 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 6018/7381 [00:30<00:06, 200.20 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 6039/7381 [00:31<00:06, 200.03 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 6060/7381 [00:31<00:06, 198.21 examples/s]Tokenizing train dataset:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 6082/7381 [00:31<00:06, 199.48 examples/s]Tokenizing train dataset:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 6102/7381 [00:31<00:06, 198.49 examples/s]Tokenizing train dataset:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 6123/7381 [00:31<00:06, 200.63 examples/s]Tokenizing train dataset:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 6144/7381 [00:31<00:06, 201.14 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 6166/7381 [00:31<00:06, 201.32 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 6187/7381 [00:31<00:05, 201.11 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 6208/7381 [00:31<00:05, 200.16 examples/s]Tokenizing train dataset:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 6230/7381 [00:31<00:05, 200.06 examples/s]Tokenizing train dataset:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 6251/7381 [00:32<00:05, 198.32 examples/s]Tokenizing train dataset:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 6272/7381 [00:32<00:05, 199.45 examples/s]Tokenizing train dataset:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6294/7381 [00:32<00:05, 201.20 examples/s]Tokenizing train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6324/7381 [00:32<00:05, 197.33 examples/s]Tokenizing train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6346/7381 [00:32<00:05, 199.21 examples/s]Tokenizing train dataset:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 6367/7381 [00:32<00:05, 200.03 examples/s]Tokenizing train dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 6388/7381 [00:32<00:05, 197.60 examples/s]Tokenizing train dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 6409/7381 [00:32<00:04, 198.35 examples/s]Tokenizing train dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 6429/7381 [00:32<00:04, 198.46 examples/s]Tokenizing train dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 6449/7381 [00:33<00:04, 196.19 examples/s]Tokenizing train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 6470/7381 [00:33<00:04, 197.04 examples/s]Tokenizing train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 6491/7381 [00:33<00:04, 196.63 examples/s]Tokenizing train dataset:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 6512/7381 [00:33<00:04, 197.28 examples/s]Tokenizing train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 6533/7381 [00:33<00:04, 198.58 examples/s]Tokenizing train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 6554/7381 [00:33<00:04, 197.70 examples/s]Tokenizing train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 6576/7381 [00:33<00:04, 199.34 examples/s]Tokenizing train dataset:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 6597/7381 [00:33<00:03, 198.70 examples/s]Tokenizing train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 6617/7381 [00:33<00:03, 196.46 examples/s]Tokenizing train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 6638/7381 [00:34<00:03, 198.51 examples/s]Tokenizing train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 6659/7381 [00:34<00:03, 199.37 examples/s]Tokenizing train dataset:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 6679/7381 [00:34<00:03, 195.83 examples/s]Tokenizing train dataset:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 6701/7381 [00:34<00:03, 197.38 examples/s]Tokenizing train dataset:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 6722/7381 [00:34<00:03, 198.85 examples/s]Tokenizing train dataset:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 6742/7381 [00:34<00:03, 198.85 examples/s]Tokenizing train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 6762/7381 [00:34<00:03, 196.30 examples/s]Tokenizing train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 6783/7381 [00:34<00:03, 197.40 examples/s]Tokenizing train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 6805/7381 [00:34<00:02, 198.73 examples/s]Tokenizing train dataset:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 6825/7381 [00:34<00:02, 196.83 examples/s]Tokenizing train dataset:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 6846/7381 [00:35<00:02, 198.17 examples/s]Tokenizing train dataset:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 6868/7381 [00:35<00:02, 199.16 examples/s]Tokenizing train dataset:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 6888/7381 [00:35<00:02, 196.37 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 6908/7381 [00:35<00:02, 196.85 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 6928/7381 [00:35<00:02, 195.40 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 6948/7381 [00:35<00:02, 196.10 examples/s]Tokenizing train dataset:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 6969/7381 [00:35<00:02, 196.24 examples/s]Tokenizing train dataset:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 6990/7381 [00:35<00:02, 193.18 examples/s]Tokenizing train dataset:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 7012/7381 [00:35<00:01, 196.30 examples/s]Tokenizing train dataset:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 7032/7381 [00:36<00:01, 195.77 examples/s]Tokenizing train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 7062/7381 [00:36<00:01, 193.94 examples/s]Tokenizing train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 7083/7381 [00:36<00:01, 194.99 examples/s]Tokenizing train dataset:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 7103/7381 [00:36<00:01, 193.40 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 7125/7381 [00:36<00:01, 195.97 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 7145/7381 [00:36<00:01, 194.87 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 7167/7381 [00:36<00:01, 196.89 examples/s]Tokenizing train dataset:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 7188/7381 [00:36<00:00, 198.05 examples/s]Tokenizing train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 7208/7381 [00:36<00:00, 196.45 examples/s]Tokenizing train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 7229/7381 [00:37<00:00, 197.62 examples/s]Tokenizing train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 7249/7381 [00:37<00:00, 195.30 examples/s]Tokenizing train dataset:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 7270/7381 [00:37<00:00, 196.26 examples/s]Tokenizing train dataset:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 7292/7381 [00:37<00:00, 198.19 examples/s]Tokenizing train dataset:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 7322/7381 [00:37<00:00, 194.92 examples/s]Tokenizing train dataset:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 7342/7381 [00:37<00:00, 195.91 examples/s]Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 7362/7381 [00:37<00:00, 195.82 examples/s]Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7381/7381 [00:38<00:00, 191.76 examples/s]
2025-03-09 14:13:06,206 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-03-09 14:13:06,220 - INFO - Performing pre-training evaluation on the dev dataset...
  0%|          | 0/923 [00:00<?, ?it/s]  0%|          | 2/923 [00:03<27:32,  1.79s/it]  0%|          | 3/923 [00:07<37:59,  2.48s/it]  0%|          | 4/923 [00:09<38:36,  2.52s/it]  1%|          | 5/923 [00:12<39:58,  2.61s/it]  1%|          | 6/923 [00:15<44:54,  2.94s/it]  1%|          | 7/923 [00:20<51:28,  3.37s/it]  1%|          | 8/923 [00:22<47:40,  3.13s/it]  1%|          | 9/923 [00:25<47:35,  3.12s/it]  1%|          | 10/923 [00:28<45:55,  3.02s/it]  1%|          | 11/923 [00:31<45:30,  2.99s/it]  1%|‚ñè         | 12/923 [00:34<45:04,  2.97s/it]  1%|‚ñè         | 13/923 [00:37<44:23,  2.93s/it]  2%|‚ñè         | 14/923 [00:40<43:14,  2.85s/it]  2%|‚ñè         | 15/923 [00:43<44:19,  2.93s/it]  2%|‚ñè         | 16/923 [00:46<44:16,  2.93s/it]  2%|‚ñè         | 17/923 [00:49<45:48,  3.03s/it]  2%|‚ñè         | 18/923 [00:52<47:31,  3.15s/it]  2%|‚ñè         | 19/923 [00:55<47:15,  3.14s/it]  2%|‚ñè         | 20/923 [00:59<47:48,  3.18s/it]  2%|‚ñè         | 21/923 [01:01<45:49,  3.05s/it]  2%|‚ñè         | 22/923 [01:05<46:03,  3.07s/it]  2%|‚ñè         | 23/923 [01:08<45:15,  3.02s/it]  3%|‚ñé         | 24/923 [01:11<45:49,  3.06s/it]  3%|‚ñé         | 25/923 [01:14<46:43,  3.12s/it]  3%|‚ñé         | 26/923 [01:17<47:18,  3.16s/it]  3%|‚ñé         | 27/923 [01:21<47:57,  3.21s/it]  3%|‚ñé         | 28/923 [01:23<45:39,  3.06s/it]  3%|‚ñé         | 29/923 [01:27<46:40,  3.13s/it]  3%|‚ñé         | 30/923 [01:29<43:48,  2.94s/it]  3%|‚ñé         | 31/923 [01:32<43:35,  2.93s/it]  3%|‚ñé         | 32/923 [01:35<42:00,  2.83s/it]  4%|‚ñé         | 33/923 [01:37<41:47,  2.82s/it]  4%|‚ñé         | 34/923 [01:41<43:42,  2.95s/it]  4%|‚ñç         | 35/923 [01:44<45:04,  3.05s/it]  4%|‚ñç         | 36/923 [01:47<45:37,  3.09s/it]  4%|‚ñç         | 37/923 [01:50<46:51,  3.17s/it]  4%|‚ñç         | 38/923 [01:53<44:29,  3.02s/it]  4%|‚ñç         | 39/923 [01:56<43:57,  2.98s/it]  4%|‚ñç         | 40/923 [01:59<42:41,  2.90s/it]  4%|‚ñç         | 41/923 [02:02<43:44,  2.98s/it]  5%|‚ñç         | 42/923 [02:05<42:44,  2.91s/it]  5%|‚ñç         | 43/923 [02:08<44:31,  3.04s/it]  5%|‚ñç         | 44/923 [02:10<42:04,  2.87s/it]  5%|‚ñç         | 45/923 [02:13<42:14,  2.89s/it]  5%|‚ñç         | 46/923 [02:16<43:08,  2.95s/it]  5%|‚ñå         | 47/923 [02:19<42:16,  2.90s/it]  5%|‚ñå         | 48/923 [02:22<41:59,  2.88s/it]  5%|‚ñå         | 49/923 [02:25<41:21,  2.84s/it]  5%|‚ñå         | 50/923 [02:27<40:36,  2.79s/it]  6%|‚ñå         | 51/923 [02:30<40:04,  2.76s/it]  6%|‚ñå         | 52/923 [02:33<40:03,  2.76s/it]  6%|‚ñå         | 53/923 [02:36<43:30,  3.00s/it]  6%|‚ñå         | 54/923 [02:40<45:09,  3.12s/it]  6%|‚ñå         | 55/923 [02:43<43:41,  3.02s/it]  6%|‚ñå         | 56/923 [02:46<43:09,  2.99s/it]  6%|‚ñå         | 57/923 [02:48<41:38,  2.89s/it]  6%|‚ñã         | 58/923 [02:51<41:41,  2.89s/it]  6%|‚ñã         | 59/923 [02:54<42:52,  2.98s/it]  7%|‚ñã         | 60/923 [02:57<41:59,  2.92s/it]  7%|‚ñã         | 61/923 [03:00<43:57,  3.06s/it]  7%|‚ñã         | 62/923 [03:03<42:29,  2.96s/it]  7%|‚ñã         | 63/923 [03:06<43:53,  3.06s/it]  7%|‚ñã         | 64/923 [03:09<43:14,  3.02s/it]  7%|‚ñã         | 65/923 [03:12<42:44,  2.99s/it]  7%|‚ñã         | 66/923 [03:15<42:01,  2.94s/it]  7%|‚ñã         | 67/923 [03:18<41:57,  2.94s/it]  7%|‚ñã         | 68/923 [03:21<40:39,  2.85s/it]  7%|‚ñã         | 69/923 [03:24<42:45,  3.00s/it]  8%|‚ñä         | 70/923 [03:27<43:58,  3.09s/it]  8%|‚ñä         | 71/923 [03:30<42:33,  3.00s/it]  8%|‚ñä         | 72/923 [03:33<43:11,  3.04s/it]  8%|‚ñä         | 73/923 [03:36<41:25,  2.92s/it]  8%|‚ñä         | 74/923 [03:39<40:48,  2.88s/it]  8%|‚ñä         | 75/923 [03:42<42:00,  2.97s/it]  8%|‚ñä         | 76/923 [03:45<43:11,  3.06s/it]  8%|‚ñä         | 77/923 [03:48<41:46,  2.96s/it]  8%|‚ñä         | 78/923 [03:51<41:37,  2.96s/it]  9%|‚ñä         | 79/923 [03:54<41:00,  2.92s/it]  9%|‚ñä         | 80/923 [03:57<40:53,  2.91s/it]  9%|‚ñâ         | 81/923 [03:59<40:29,  2.89s/it]  9%|‚ñâ         | 82/923 [04:02<39:45,  2.84s/it]  9%|‚ñâ         | 83/923 [04:05<41:09,  2.94s/it]  9%|‚ñâ         | 84/923 [04:09<43:13,  3.09s/it]  9%|‚ñâ         | 85/923 [04:11<41:17,  2.96s/it]  9%|‚ñâ         | 86/923 [04:14<41:04,  2.94s/it]  9%|‚ñâ         | 87/923 [04:17<39:58,  2.87s/it] 10%|‚ñâ         | 88/923 [04:20<38:45,  2.78s/it] 10%|‚ñâ         | 89/923 [04:23<40:07,  2.89s/it] 10%|‚ñâ         | 90/923 [04:26<41:17,  2.97s/it] 10%|‚ñâ         | 91/923 [04:29<41:50,  3.02s/it] 10%|‚ñâ         | 92/923 [04:32<40:15,  2.91s/it] 10%|‚ñà         | 93/923 [04:35<42:26,  3.07s/it] 10%|‚ñà         | 94/923 [04:38<42:31,  3.08s/it] 10%|‚ñà         | 95/923 [04:42<43:38,  3.16s/it] 10%|‚ñà         | 96/923 [04:45<43:36,  3.16s/it] 11%|‚ñà         | 97/923 [04:48<42:32,  3.09s/it] 11%|‚ñà         | 98/923 [04:51<43:34,  3.17s/it] 11%|‚ñà         | 99/923 [04:54<41:22,  3.01s/it] 11%|‚ñà         | 100/923 [04:57<41:55,  3.06s/it] 11%|‚ñà         | 101/923 [05:00<40:58,  2.99s/it] 11%|‚ñà         | 102/923 [05:03<43:11,  3.16s/it] 11%|‚ñà         | 103/923 [05:06<41:25,  3.03s/it] 11%|‚ñà‚ñè        | 104/923 [05:09<40:03,  2.94s/it] 11%|‚ñà‚ñè        | 105/923 [05:12<40:58,  3.01s/it] 11%|‚ñà‚ñè        | 106/923 [05:15<39:49,  2.92s/it] 12%|‚ñà‚ñè        | 107/923 [05:17<39:19,  2.89s/it] 12%|‚ñà‚ñè        | 108/923 [05:20<38:34,  2.84s/it] 12%|‚ñà‚ñè        | 109/923 [05:23<37:32,  2.77s/it] 12%|‚ñà‚ñè        | 110/923 [05:26<39:55,  2.95s/it] 12%|‚ñà‚ñè        | 111/923 [05:29<38:37,  2.85s/it] 12%|‚ñà‚ñè        | 112/923 [05:31<37:54,  2.80s/it] 12%|‚ñà‚ñè        | 113/923 [05:35<39:34,  2.93s/it] 12%|‚ñà‚ñè        | 114/923 [05:37<38:50,  2.88s/it] 12%|‚ñà‚ñè        | 115/923 [05:40<38:34,  2.86s/it] 13%|‚ñà‚ñé        | 116/923 [05:43<38:27,  2.86s/it] 13%|‚ñà‚ñé        | 117/923 [05:46<37:43,  2.81s/it] 13%|‚ñà‚ñé        | 118/923 [05:49<39:51,  2.97s/it] 13%|‚ñà‚ñé        | 119/923 [05:52<38:57,  2.91s/it] 13%|‚ñà‚ñé        | 120/923 [05:55<39:46,  2.97s/it] 13%|‚ñà‚ñé        | 121/923 [05:58<41:00,  3.07s/it] 13%|‚ñà‚ñé        | 122/923 [06:01<40:01,  3.00s/it] 13%|‚ñà‚ñé        | 123/923 [06:04<38:51,  2.91s/it] 13%|‚ñà‚ñé        | 124/923 [06:07<38:01,  2.86s/it] 14%|‚ñà‚ñé        | 125/923 [06:10<39:50,  3.00s/it] 14%|‚ñà‚ñé        | 126/923 [06:13<39:05,  2.94s/it] 14%|‚ñà‚ñç        | 127/923 [06:16<40:38,  3.06s/it] 14%|‚ñà‚ñç        | 128/923 [06:19<39:08,  2.95s/it] 14%|‚ñà‚ñç        | 129/923 [06:21<38:25,  2.90s/it] 14%|‚ñà‚ñç        | 130/923 [06:25<39:54,  3.02s/it] 14%|‚ñà‚ñç        | 131/923 [06:28<39:09,  2.97s/it] 14%|‚ñà‚ñç        | 132/923 [06:30<38:24,  2.91s/it] 14%|‚ñà‚ñç        | 133/923 [06:33<37:51,  2.88s/it] 15%|‚ñà‚ñç        | 134/923 [06:36<39:18,  2.99s/it] 15%|‚ñà‚ñç        | 135/923 [06:40<40:18,  3.07s/it] 15%|‚ñà‚ñç        | 136/923 [06:44<43:36,  3.32s/it] 15%|‚ñà‚ñç        | 137/923 [06:47<41:53,  3.20s/it] 15%|‚ñà‚ñç        | 138/923 [06:49<40:14,  3.08s/it] 15%|‚ñà‚ñå        | 139/923 [06:52<40:29,  3.10s/it] 15%|‚ñà‚ñå        | 140/923 [06:55<39:20,  3.01s/it] 15%|‚ñà‚ñå        | 141/923 [06:59<40:36,  3.12s/it] 15%|‚ñà‚ñå        | 142/923 [07:01<39:00,  3.00s/it] 15%|‚ñà‚ñå        | 143/923 [07:04<37:02,  2.85s/it] 16%|‚ñà‚ñå        | 144/923 [07:07<38:58,  3.00s/it] 16%|‚ñà‚ñå        | 145/923 [07:11<40:12,  3.10s/it] 16%|‚ñà‚ñå        | 146/923 [07:14<40:25,  3.12s/it] 16%|‚ñà‚ñå        | 147/923 [07:17<39:01,  3.02s/it] 16%|‚ñà‚ñå        | 148/923 [07:19<36:55,  2.86s/it] 16%|‚ñà‚ñå        | 149/923 [07:22<37:55,  2.94s/it] 16%|‚ñà‚ñã        | 150/923 [07:25<36:43,  2.85s/it] 16%|‚ñà‚ñã        | 151/923 [07:28<39:38,  3.08s/it] 16%|‚ñà‚ñã        | 152/923 [07:32<40:30,  3.15s/it] 17%|‚ñà‚ñã        | 153/923 [07:36<43:23,  3.38s/it] 17%|‚ñà‚ñã        | 154/923 [07:39<43:15,  3.38s/it] 17%|‚ñà‚ñã        | 155/923 [07:42<40:08,  3.14s/it] 17%|‚ñà‚ñã        | 156/923 [07:45<41:43,  3.26s/it] 17%|‚ñà‚ñã        | 157/923 [07:48<39:47,  3.12s/it] 17%|‚ñà‚ñã        | 158/923 [07:51<38:40,  3.03s/it] 17%|‚ñà‚ñã        | 159/923 [07:54<37:52,  2.97s/it] 17%|‚ñà‚ñã        | 160/923 [07:56<36:49,  2.90s/it] 17%|‚ñà‚ñã        | 161/923 [08:00<38:10,  3.01s/it] 18%|‚ñà‚ñä        | 162/923 [08:02<37:50,  2.98s/it] 18%|‚ñà‚ñä        | 163/923 [08:05<37:07,  2.93s/it] 18%|‚ñà‚ñä        | 164/923 [08:08<36:39,  2.90s/it] 18%|‚ñà‚ñä        | 165/923 [08:11<36:42,  2.91s/it] 18%|‚ñà‚ñä        | 166/923 [08:14<35:50,  2.84s/it] 18%|‚ñà‚ñä        | 167/923 [08:18<39:25,  3.13s/it] 18%|‚ñà‚ñä        | 168/923 [08:20<38:32,  3.06s/it] 18%|‚ñà‚ñä        | 169/923 [08:24<40:19,  3.21s/it] 18%|‚ñà‚ñä        | 170/923 [08:27<38:35,  3.07s/it] 19%|‚ñà‚ñä        | 171/923 [08:29<36:56,  2.95s/it] 19%|‚ñà‚ñä        | 172/923 [08:32<37:27,  2.99s/it] 19%|‚ñà‚ñä        | 173/923 [08:35<37:04,  2.97s/it] 19%|‚ñà‚ñâ        | 174/923 [08:38<36:49,  2.95s/it] 19%|‚ñà‚ñâ        | 175/923 [08:41<36:11,  2.90s/it] 19%|‚ñà‚ñâ        | 176/923 [08:44<37:12,  2.99s/it] 19%|‚ñà‚ñâ        | 177/923 [08:48<38:24,  3.09s/it] 19%|‚ñà‚ñâ        | 178/923 [08:50<36:27,  2.94s/it] 19%|‚ñà‚ñâ        | 179/923 [08:53<37:03,  2.99s/it] 20%|‚ñà‚ñâ        | 180/923 [08:57<37:52,  3.06s/it] 20%|‚ñà‚ñâ        | 181/923 [08:59<36:48,  2.98s/it] 20%|‚ñà‚ñâ        | 182/923 [09:03<40:13,  3.26s/it] 20%|‚ñà‚ñâ        | 183/923 [09:06<38:10,  3.10s/it] 20%|‚ñà‚ñâ        | 184/923 [09:09<38:25,  3.12s/it] 20%|‚ñà‚ñà        | 185/923 [09:12<39:15,  3.19s/it] 20%|‚ñà‚ñà        | 186/923 [09:15<37:37,  3.06s/it] 20%|‚ñà‚ñà        | 187/923 [09:18<36:21,  2.96s/it] 20%|‚ñà‚ñà        | 188/923 [09:21<36:12,  2.96s/it] 20%|‚ñà‚ñà        | 189/923 [09:24<35:02,  2.86s/it] 21%|‚ñà‚ñà        | 190/923 [09:26<34:12,  2.80s/it] 21%|‚ñà‚ñà        | 191/923 [09:30<38:22,  3.15s/it] 21%|‚ñà‚ñà        | 192/923 [09:34<39:57,  3.28s/it] 21%|‚ñà‚ñà        | 193/923 [09:37<41:05,  3.38s/it] 21%|‚ñà‚ñà        | 194/923 [09:40<40:03,  3.30s/it] 21%|‚ñà‚ñà        | 195/923 [09:44<39:35,  3.26s/it] 21%|‚ñà‚ñà        | 196/923 [09:47<38:12,  3.15s/it] 21%|‚ñà‚ñà‚ñè       | 197/923 [09:50<38:25,  3.18s/it] 21%|‚ñà‚ñà‚ñè       | 198/923 [09:53<37:24,  3.10s/it] 22%|‚ñà‚ñà‚ñè       | 199/923 [09:56<37:49,  3.14s/it] 22%|‚ñà‚ñà‚ñè       | 200/923 [09:59<36:07,  3.00s/it] 22%|‚ñà‚ñà‚ñè       | 201/923 [10:02<35:47,  2.97s/it] 22%|‚ñà‚ñà‚ñè       | 202/923 [10:05<37:55,  3.16s/it] 22%|‚ñà‚ñà‚ñè       | 203/923 [10:08<36:34,  3.05s/it] 22%|‚ñà‚ñà‚ñè       | 204/923 [10:11<35:21,  2.95s/it] 22%|‚ñà‚ñà‚ñè       | 205/923 [10:14<36:52,  3.08s/it] 22%|‚ñà‚ñà‚ñè       | 206/923 [10:17<35:14,  2.95s/it] 22%|‚ñà‚ñà‚ñè       | 207/923 [10:19<34:25,  2.88s/it] 23%|‚ñà‚ñà‚ñé       | 208/923 [10:23<36:46,  3.09s/it] 23%|‚ñà‚ñà‚ñé       | 209/923 [10:26<35:22,  2.97s/it] 23%|‚ñà‚ñà‚ñé       | 210/923 [10:28<34:29,  2.90s/it] 23%|‚ñà‚ñà‚ñé       | 211/923 [10:31<34:30,  2.91s/it] 23%|‚ñà‚ñà‚ñé       | 212/923 [10:34<33:57,  2.87s/it] 23%|‚ñà‚ñà‚ñé       | 213/923 [10:37<35:13,  2.98s/it] 23%|‚ñà‚ñà‚ñé       | 214/923 [10:40<35:41,  3.02s/it] 23%|‚ñà‚ñà‚ñé       | 215/923 [10:44<36:08,  3.06s/it] 23%|‚ñà‚ñà‚ñé       | 216/923 [10:46<34:35,  2.94s/it] 24%|‚ñà‚ñà‚ñé       | 217/923 [10:49<33:45,  2.87s/it] 24%|‚ñà‚ñà‚ñé       | 218/923 [10:51<32:31,  2.77s/it] 24%|‚ñà‚ñà‚ñé       | 219/923 [10:55<35:10,  3.00s/it] 24%|‚ñà‚ñà‚ñç       | 220/923 [10:58<34:10,  2.92s/it] 24%|‚ñà‚ñà‚ñç       | 221/923 [11:01<33:41,  2.88s/it] 24%|‚ñà‚ñà‚ñç       | 222/923 [11:03<33:33,  2.87s/it] 24%|‚ñà‚ñà‚ñç       | 223/923 [11:07<35:04,  3.01s/it] 24%|‚ñà‚ñà‚ñç       | 224/923 [11:09<33:26,  2.87s/it] 24%|‚ñà‚ñà‚ñç       | 225/923 [11:12<34:10,  2.94s/it] 24%|‚ñà‚ñà‚ñç       | 226/923 [11:15<34:47,  2.99s/it] 25%|‚ñà‚ñà‚ñç       | 227/923 [11:19<36:00,  3.10s/it] 25%|‚ñà‚ñà‚ñç       | 228/923 [11:22<35:55,  3.10s/it] 25%|‚ñà‚ñà‚ñç       | 229/923 [11:25<34:43,  3.00s/it] 25%|‚ñà‚ñà‚ñç       | 230/923 [11:27<33:27,  2.90s/it] 25%|‚ñà‚ñà‚ñå       | 231/923 [11:30<32:46,  2.84s/it] 25%|‚ñà‚ñà‚ñå       | 232/923 [11:33<31:32,  2.74s/it] 25%|‚ñà‚ñà‚ñå       | 233/923 [11:36<32:44,  2.85s/it] 25%|‚ñà‚ñà‚ñå       | 234/923 [11:38<31:58,  2.78s/it] 25%|‚ñà‚ñà‚ñå       | 235/923 [11:41<32:05,  2.80s/it] 26%|‚ñà‚ñà‚ñå       | 236/923 [11:44<32:24,  2.83s/it] 26%|‚ñà‚ñà‚ñå       | 237/923 [11:47<32:19,  2.83s/it] 26%|‚ñà‚ñà‚ñå       | 238/923 [11:50<33:13,  2.91s/it] 26%|‚ñà‚ñà‚ñå       | 239/923 [11:53<33:14,  2.92s/it] 26%|‚ñà‚ñà‚ñå       | 240/923 [11:56<32:44,  2.88s/it] 26%|‚ñà‚ñà‚ñå       | 241/923 [11:58<32:11,  2.83s/it] 26%|‚ñà‚ñà‚ñå       | 242/923 [12:02<35:27,  3.12s/it] 26%|‚ñà‚ñà‚ñã       | 243/923 [12:05<34:40,  3.06s/it] 26%|‚ñà‚ñà‚ñã       | 244/923 [12:08<35:40,  3.15s/it] 27%|‚ñà‚ñà‚ñã       | 245/923 [12:12<36:20,  3.22s/it] 27%|‚ñà‚ñà‚ñã       | 246/923 [12:15<35:18,  3.13s/it] 27%|‚ñà‚ñà‚ñã       | 247/923 [12:18<36:01,  3.20s/it] 27%|‚ñà‚ñà‚ñã       | 248/923 [12:21<35:43,  3.17s/it] 27%|‚ñà‚ñà‚ñã       | 249/923 [12:24<34:06,  3.04s/it] 27%|‚ñà‚ñà‚ñã       | 250/923 [12:27<34:56,  3.11s/it] 27%|‚ñà‚ñà‚ñã       | 251/923 [12:30<34:15,  3.06s/it] 27%|‚ñà‚ñà‚ñã       | 252/923 [12:33<34:36,  3.09s/it] 27%|‚ñà‚ñà‚ñã       | 253/923 [12:36<33:17,  2.98s/it] 28%|‚ñà‚ñà‚ñä       | 254/923 [12:39<33:50,  3.04s/it] 28%|‚ñà‚ñà‚ñä       | 255/923 [12:42<33:26,  3.00s/it] 28%|‚ñà‚ñà‚ñä       | 256/923 [12:45<32:36,  2.93s/it] 28%|‚ñà‚ñà‚ñä       | 257/923 [12:48<31:59,  2.88s/it] 28%|‚ñà‚ñà‚ñä       | 258/923 [12:51<32:39,  2.95s/it] 28%|‚ñà‚ñà‚ñä       | 259/923 [12:54<32:17,  2.92s/it] 28%|‚ñà‚ñà‚ñä       | 260/923 [12:57<32:11,  2.91s/it] 28%|‚ñà‚ñà‚ñä       | 261/923 [12:59<31:56,  2.89s/it] 28%|‚ñà‚ñà‚ñä       | 262/923 [13:03<33:17,  3.02s/it] 28%|‚ñà‚ñà‚ñä       | 263/923 [13:06<34:25,  3.13s/it] 29%|‚ñà‚ñà‚ñä       | 264/923 [13:09<33:14,  3.03s/it] 29%|‚ñà‚ñà‚ñä       | 265/923 [13:12<33:58,  3.10s/it] 29%|‚ñà‚ñà‚ñâ       | 266/923 [13:16<35:21,  3.23s/it] 29%|‚ñà‚ñà‚ñâ       | 267/923 [13:19<35:32,  3.25s/it] 29%|‚ñà‚ñà‚ñâ       | 268/923 [13:22<33:31,  3.07s/it] 29%|‚ñà‚ñà‚ñâ       | 269/923 [13:24<32:35,  2.99s/it] 29%|‚ñà‚ñà‚ñâ       | 270/923 [13:28<32:52,  3.02s/it] 29%|‚ñà‚ñà‚ñâ       | 271/923 [13:31<33:43,  3.10s/it] 29%|‚ñà‚ñà‚ñâ       | 272/923 [13:34<32:28,  2.99s/it] 30%|‚ñà‚ñà‚ñâ       | 273/923 [13:37<32:13,  2.97s/it] 30%|‚ñà‚ñà‚ñâ       | 274/923 [13:40<33:57,  3.14s/it] 30%|‚ñà‚ñà‚ñâ       | 275/923 [13:43<32:41,  3.03s/it] 30%|‚ñà‚ñà‚ñâ       | 276/923 [13:46<31:58,  2.96s/it] 30%|‚ñà‚ñà‚ñà       | 277/923 [13:49<31:45,  2.95s/it] 30%|‚ñà‚ñà‚ñà       | 278/923 [13:52<32:41,  3.04s/it] 30%|‚ñà‚ñà‚ñà       | 279/923 [13:55<31:57,  2.98s/it] 30%|‚ñà‚ñà‚ñà       | 280/923 [13:58<33:01,  3.08s/it] 30%|‚ñà‚ñà‚ñà       | 281/923 [14:01<32:02,  2.99s/it] 31%|‚ñà‚ñà‚ñà       | 282/923 [14:04<32:19,  3.03s/it] 31%|‚ñà‚ñà‚ñà       | 283/923 [14:06<31:01,  2.91s/it] 31%|‚ñà‚ñà‚ñà       | 284/923 [14:09<29:47,  2.80s/it] 31%|‚ñà‚ñà‚ñà       | 285/923 [14:12<31:16,  2.94s/it] 31%|‚ñà‚ñà‚ñà       | 286/923 [14:16<32:07,  3.03s/it] 31%|‚ñà‚ñà‚ñà       | 287/923 [14:18<31:03,  2.93s/it] 31%|‚ñà‚ñà‚ñà       | 288/923 [14:21<30:32,  2.89s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 289/923 [14:24<31:43,  3.00s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 290/923 [14:27<31:24,  2.98s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 291/923 [14:31<33:05,  3.14s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 292/923 [14:34<34:32,  3.28s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 293/923 [14:38<34:44,  3.31s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 294/923 [14:41<34:36,  3.30s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 295/923 [14:44<33:10,  3.17s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 296/923 [14:47<33:37,  3.22s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 297/923 [14:50<33:26,  3.21s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 298/923 [14:53<32:17,  3.10s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 299/923 [14:56<31:24,  3.02s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 300/923 [14:59<30:25,  2.93s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 301/923 [15:02<30:53,  2.98s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 302/923 [15:05<32:01,  3.09s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 303/923 [15:08<31:27,  3.05s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 304/923 [15:12<33:00,  3.20s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 305/923 [15:15<32:38,  3.17s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 306/923 [15:18<31:21,  3.05s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 307/923 [15:20<30:16,  2.95s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 308/923 [15:23<30:51,  3.01s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 309/923 [15:26<29:29,  2.88s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 310/923 [15:29<29:17,  2.87s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 311/923 [15:32<28:49,  2.83s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 312/923 [15:35<29:48,  2.93s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 313/923 [15:38<29:21,  2.89s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 314/923 [15:40<28:06,  2.77s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 315/923 [15:43<29:15,  2.89s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 316/923 [15:46<28:44,  2.84s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 317/923 [15:50<31:00,  3.07s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 318/923 [15:52<29:54,  2.97s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 319/923 [15:55<29:25,  2.92s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 320/923 [15:58<30:45,  3.06s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 321/923 [16:01<29:10,  2.91s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 322/923 [16:04<28:43,  2.87s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 323/923 [16:07<30:03,  3.01s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 324/923 [16:10<28:48,  2.89s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 325/923 [16:13<29:46,  2.99s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 326/923 [16:17<32:51,  3.30s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 327/923 [16:20<31:16,  3.15s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 328/923 [16:23<30:33,  3.08s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 329/923 [16:26<30:45,  3.11s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 330/923 [16:29<31:26,  3.18s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 331/923 [16:33<31:47,  3.22s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 332/923 [16:36<31:58,  3.25s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 333/923 [16:39<30:32,  3.11s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 334/923 [16:41<28:59,  2.95s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 335/923 [16:44<29:26,  3.01s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 336/923 [16:47<28:26,  2.91s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 337/923 [16:50<29:01,  2.97s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 338/923 [16:53<28:16,  2.90s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 339/923 [16:56<27:43,  2.85s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 340/923 [16:58<27:04,  2.79s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 341/923 [17:01<28:01,  2.89s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 342/923 [17:04<27:00,  2.79s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 343/923 [17:07<27:04,  2.80s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 344/923 [17:10<27:56,  2.90s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 345/923 [17:12<26:44,  2.78s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 346/923 [17:16<28:17,  2.94s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 347/923 [17:18<27:47,  2.89s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 348/923 [17:21<27:45,  2.90s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 349/923 [17:25<28:31,  2.98s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 350/923 [17:28<29:32,  3.09s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 351/923 [17:31<28:24,  2.98s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 352/923 [17:34<28:42,  3.02s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 353/923 [17:38<31:07,  3.28s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 354/923 [17:40<28:51,  3.04s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 355/923 [17:43<27:55,  2.95s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 356/923 [17:47<31:43,  3.36s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 357/923 [17:50<31:31,  3.34s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 358/923 [17:54<30:47,  3.27s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 359/923 [17:57<31:02,  3.30s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 360/923 [18:00<29:27,  3.14s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 361/923 [18:02<27:54,  2.98s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 362/923 [18:05<28:20,  3.03s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 363/923 [18:09<28:33,  3.06s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 364/923 [18:12<29:20,  3.15s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 365/923 [18:15<28:06,  3.02s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 366/923 [18:18<28:29,  3.07s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 367/923 [18:21<27:37,  2.98s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 368/923 [18:23<26:45,  2.89s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 369/923 [18:26<27:30,  2.98s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 370/923 [18:30<28:16,  3.07s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 371/923 [18:33<28:54,  3.14s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 372/923 [18:36<29:27,  3.21s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 373/923 [18:40<29:43,  3.24s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 374/923 [18:43<28:34,  3.12s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 375/923 [18:45<27:28,  3.01s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 376/923 [18:48<27:39,  3.03s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 377/923 [18:52<27:49,  3.06s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 378/923 [18:54<26:29,  2.92s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 379/923 [18:57<26:02,  2.87s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 380/923 [19:00<25:34,  2.83s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 381/923 [19:03<26:58,  2.99s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 382/923 [19:07<30:01,  3.33s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 383/923 [19:10<28:52,  3.21s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 384/923 [19:13<28:32,  3.18s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 385/923 [19:17<29:09,  3.25s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 386/923 [19:19<27:33,  3.08s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 387/923 [19:23<28:16,  3.17s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 388/923 [19:26<28:39,  3.21s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 389/923 [19:30<30:23,  3.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 390/923 [19:33<28:31,  3.21s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 391/923 [19:36<28:09,  3.18s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 392/923 [19:39<28:04,  3.17s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 393/923 [19:41<26:21,  2.98s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 394/923 [19:44<25:53,  2.94s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 395/923 [19:47<26:20,  2.99s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 396/923 [19:51<26:47,  3.05s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 397/923 [19:54<27:11,  3.10s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 398/923 [19:57<26:16,  3.00s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 399/923 [19:59<25:47,  2.95s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 400/923 [20:02<25:10,  2.89s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 401/923 [20:05<24:29,  2.82s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 402/923 [20:07<24:10,  2.78s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 403/923 [20:11<25:49,  2.98s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 404/923 [20:14<26:44,  3.09s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 405/923 [20:17<25:45,  2.98s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 406/923 [20:20<24:50,  2.88s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 407/923 [20:23<25:34,  2.97s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 408/923 [20:26<26:26,  3.08s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 409/923 [20:29<25:55,  3.03s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 410/923 [20:33<28:05,  3.28s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 411/923 [20:36<26:37,  3.12s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 412/923 [20:38<25:31,  3.00s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 413/923 [20:42<26:24,  3.11s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 414/923 [20:45<25:51,  3.05s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 415/923 [20:47<24:48,  2.93s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 416/923 [20:50<24:07,  2.85s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 417/923 [20:54<25:50,  3.06s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 418/923 [20:57<26:35,  3.16s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 419/923 [21:00<25:41,  3.06s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 420/923 [21:03<27:03,  3.23s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 421/923 [21:07<27:13,  3.25s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 422/923 [21:09<25:45,  3.09s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 423/923 [21:13<26:08,  3.14s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 424/923 [21:15<24:52,  2.99s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 425/923 [21:18<23:47,  2.87s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 426/923 [21:21<24:42,  2.98s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 427/923 [21:24<24:56,  3.02s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 428/923 [21:27<24:10,  2.93s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 429/923 [21:30<23:29,  2.85s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 430/923 [21:32<23:21,  2.84s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 431/923 [21:35<23:19,  2.84s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 432/923 [21:38<23:07,  2.83s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 433/923 [21:42<26:40,  3.27s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 434/923 [21:45<25:43,  3.16s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 435/923 [21:49<26:13,  3.23s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 436/923 [21:52<25:24,  3.13s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 437/923 [21:55<25:54,  3.20s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 438/923 [21:59<27:19,  3.38s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 439/923 [22:02<26:42,  3.31s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 440/923 [22:05<25:12,  3.13s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 441/923 [22:08<25:41,  3.20s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 442/923 [22:11<25:34,  3.19s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 443/923 [22:14<25:29,  3.19s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 444/923 [22:17<24:18,  3.05s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 445/923 [22:20<23:55,  3.00s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 446/923 [22:23<24:25,  3.07s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 447/923 [22:26<23:50,  3.01s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 448/923 [22:29<24:01,  3.03s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 449/923 [22:32<23:15,  2.94s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 450/923 [22:35<24:34,  3.12s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 451/923 [22:38<23:41,  3.01s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 452/923 [22:41<23:15,  2.96s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 453/923 [22:44<22:47,  2.91s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 454/923 [22:47<23:14,  2.97s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 455/923 [22:50<22:36,  2.90s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 456/923 [22:52<21:50,  2.81s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 457/923 [22:55<21:35,  2.78s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 458/923 [22:58<21:26,  2.77s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 459/923 [23:00<21:12,  2.74s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 460/923 [23:03<21:14,  2.75s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 461/923 [23:06<20:56,  2.72s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 462/923 [23:08<20:27,  2.66s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 463/923 [23:11<20:08,  2.63s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 464/923 [23:14<20:43,  2.71s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 465/923 [23:17<21:52,  2.87s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 466/923 [23:20<22:24,  2.94s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 467/923 [23:23<22:19,  2.94s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 468/923 [23:26<21:42,  2.86s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 469/923 [23:29<22:55,  3.03s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 470/923 [23:32<22:09,  2.93s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 471/923 [23:35<22:39,  3.01s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 472/923 [23:38<22:03,  2.94s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 473/923 [23:41<21:46,  2.90s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 474/923 [23:43<21:32,  2.88s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 475/923 [23:46<21:14,  2.84s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 476/923 [23:49<21:10,  2.84s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 477/923 [23:52<20:58,  2.82s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 478/923 [23:54<20:43,  2.79s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 479/923 [23:58<21:39,  2.93s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 480/923 [24:01<21:37,  2.93s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 481/923 [24:03<21:21,  2.90s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 482/923 [24:07<21:52,  2.98s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 483/923 [24:09<21:10,  2.89s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 484/923 [24:13<22:05,  3.02s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 485/923 [24:16<22:46,  3.12s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 486/923 [24:19<21:57,  3.02s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 487/923 [24:21<21:00,  2.89s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 488/923 [24:25<21:45,  3.00s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 489/923 [24:27<21:21,  2.95s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 490/923 [24:30<21:06,  2.92s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 491/923 [24:33<21:01,  2.92s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 492/923 [24:36<20:34,  2.86s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 493/923 [24:39<20:36,  2.88s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 494/923 [24:42<21:32,  3.01s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 495/923 [24:45<21:18,  2.99s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 496/923 [24:48<20:55,  2.94s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 497/923 [24:51<20:26,  2.88s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 498/923 [24:54<20:16,  2.86s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 499/923 [24:56<19:31,  2.76s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 500/923 [24:59<19:18,  2.74s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 501/923 [25:01<19:11,  2.73s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 502/923 [25:04<19:34,  2.79s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 503/923 [25:07<19:37,  2.80s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 504/923 [25:10<19:33,  2.80s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 505/923 [25:13<19:29,  2.80s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 506/923 [25:16<19:32,  2.81s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 507/923 [25:18<19:33,  2.82s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 508/923 [25:21<19:25,  2.81s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 509/923 [25:25<20:29,  2.97s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 510/923 [25:27<19:39,  2.86s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 511/923 [25:30<19:02,  2.77s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 512/923 [25:33<20:11,  2.95s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 513/923 [25:36<20:06,  2.94s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 514/923 [25:39<19:37,  2.88s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 515/923 [25:42<19:20,  2.85s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 516/923 [25:45<20:51,  3.08s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 517/923 [25:48<20:21,  3.01s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 518/923 [25:51<19:50,  2.94s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 519/923 [25:53<19:00,  2.82s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 520/923 [25:56<19:32,  2.91s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 521/923 [26:00<20:24,  3.05s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 522/923 [26:03<19:37,  2.94s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 523/923 [26:05<18:11,  2.73s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 524/923 [26:08<19:44,  2.97s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 525/923 [26:11<20:00,  3.02s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 526/923 [26:15<20:49,  3.15s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 527/923 [26:18<20:50,  3.16s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 528/923 [26:21<20:18,  3.09s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 529/923 [26:24<19:34,  2.98s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 530/923 [26:27<20:05,  3.07s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 531/923 [26:30<19:27,  2.98s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 532/923 [26:33<19:41,  3.02s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 533/923 [26:36<20:36,  3.17s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 534/923 [26:40<20:34,  3.17s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 535/923 [26:42<19:24,  3.00s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 536/923 [26:45<19:01,  2.95s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 537/923 [26:48<18:38,  2.90s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 538/923 [26:51<18:28,  2.88s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 539/923 [26:54<18:57,  2.96s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 540/923 [26:56<18:21,  2.88s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 541/923 [27:00<19:06,  3.00s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 542/923 [27:03<18:40,  2.94s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 543/923 [27:06<19:32,  3.09s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 544/923 [27:09<18:59,  3.01s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 545/923 [27:12<18:31,  2.94s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 546/923 [27:15<19:12,  3.06s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 547/923 [27:18<19:37,  3.13s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 548/923 [27:21<19:49,  3.17s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 549/923 [27:25<20:16,  3.25s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 550/923 [27:28<19:22,  3.12s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 551/923 [27:31<18:49,  3.04s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 552/923 [27:33<18:24,  2.98s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 553/923 [27:36<17:59,  2.92s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 554/923 [27:39<17:18,  2.82s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 555/923 [27:42<18:02,  2.94s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 556/923 [27:45<17:39,  2.89s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 557/923 [27:48<17:25,  2.86s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 558/923 [27:51<18:07,  2.98s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 559/923 [27:54<17:44,  2.92s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 560/923 [27:56<17:24,  2.88s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 561/923 [27:59<17:05,  2.83s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 562/923 [28:02<17:59,  2.99s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 563/923 [28:05<17:41,  2.95s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 564/923 [28:08<17:33,  2.93s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 565/923 [28:11<17:27,  2.93s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 566/923 [28:14<17:16,  2.90s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 567/923 [28:17<17:44,  2.99s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 568/923 [28:20<17:17,  2.92s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 569/923 [28:23<16:52,  2.86s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 570/923 [28:26<17:29,  2.97s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 571/923 [28:29<17:11,  2.93s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 572/923 [28:32<17:53,  3.06s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 573/923 [28:36<18:43,  3.21s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 574/923 [28:39<18:42,  3.22s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 575/923 [28:42<17:54,  3.09s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 576/923 [28:44<17:20,  3.00s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 577/923 [28:47<16:56,  2.94s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 578/923 [28:50<16:49,  2.93s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 579/923 [28:54<17:48,  3.11s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 580/923 [28:56<16:16,  2.85s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 581/923 [28:59<15:59,  2.81s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 582/923 [29:02<16:59,  2.99s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 583/923 [29:06<18:22,  3.24s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 584/923 [29:08<17:15,  3.05s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 585/923 [29:12<17:23,  3.09s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 586/923 [29:14<16:48,  2.99s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 587/923 [29:17<16:13,  2.90s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 588/923 [29:20<16:59,  3.04s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 589/923 [29:23<16:23,  2.94s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 590/923 [29:26<16:35,  2.99s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 591/923 [29:29<16:24,  2.96s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 592/923 [29:32<15:53,  2.88s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 593/923 [29:35<15:55,  2.90s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 594/923 [29:38<15:36,  2.85s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 595/923 [29:40<15:34,  2.85s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 596/923 [29:44<16:02,  2.94s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 597/923 [29:47<16:17,  3.00s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 598/923 [29:50<17:06,  3.16s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 599/923 [29:53<16:41,  3.09s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 600/923 [29:56<16:13,  3.01s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 601/923 [29:59<16:20,  3.05s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 602/923 [30:02<15:39,  2.93s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 603/923 [30:05<16:05,  3.02s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 604/923 [30:08<15:21,  2.89s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 605/923 [30:11<15:58,  3.01s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 606/923 [30:14<15:37,  2.96s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 607/923 [30:17<15:31,  2.95s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 608/923 [30:20<15:27,  2.94s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 609/923 [30:23<15:57,  3.05s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 610/923 [30:26<16:23,  3.14s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 611/923 [30:29<15:41,  3.02s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 612/923 [30:32<16:07,  3.11s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 613/923 [30:35<15:26,  2.99s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 614/923 [30:37<14:40,  2.85s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 615/923 [30:40<14:24,  2.81s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 616/923 [30:43<14:53,  2.91s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 617/923 [30:46<14:36,  2.86s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 618/923 [30:49<14:24,  2.83s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 619/923 [30:52<14:11,  2.80s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 620/923 [30:56<15:53,  3.15s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 621/923 [30:58<15:07,  3.00s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 622/923 [31:01<14:27,  2.88s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 623/923 [31:04<14:09,  2.83s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 624/923 [31:06<13:52,  2.79s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 625/923 [31:09<13:52,  2.79s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 626/923 [31:12<13:47,  2.79s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 627/923 [31:14<13:39,  2.77s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 628/923 [31:18<14:29,  2.95s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 629/923 [31:21<14:22,  2.93s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 630/923 [31:23<13:48,  2.83s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 631/923 [31:27<14:24,  2.96s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 632/923 [31:30<14:47,  3.05s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 633/923 [31:33<14:19,  2.96s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 634/923 [31:36<14:38,  3.04s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 635/923 [31:39<14:25,  3.01s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 636/923 [31:42<14:52,  3.11s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 637/923 [31:45<14:21,  3.01s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 638/923 [31:48<14:08,  2.98s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 639/923 [31:51<13:52,  2.93s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 640/923 [31:54<14:22,  3.05s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 641/923 [31:56<13:36,  2.90s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 642/923 [31:59<13:22,  2.85s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 643/923 [32:02<13:24,  2.87s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 644/923 [32:05<13:42,  2.95s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 645/923 [32:08<13:36,  2.94s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 646/923 [32:11<13:52,  3.01s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 647/923 [32:14<13:29,  2.93s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 648/923 [32:17<12:58,  2.83s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 649/923 [32:19<12:47,  2.80s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 650/923 [32:23<13:21,  2.94s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 651/923 [32:26<13:16,  2.93s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 652/923 [32:29<13:11,  2.92s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 653/923 [32:31<12:51,  2.86s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 654/923 [32:34<12:25,  2.77s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 655/923 [32:37<12:32,  2.81s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 656/923 [32:40<13:14,  2.98s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 657/923 [32:43<12:56,  2.92s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 658/923 [32:46<12:52,  2.92s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 659/923 [32:49<13:05,  2.98s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 660/923 [32:52<13:36,  3.10s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 661/923 [32:56<13:54,  3.19s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 662/923 [32:59<13:58,  3.21s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 663/923 [33:02<13:46,  3.18s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 664/923 [33:05<13:07,  3.04s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 665/923 [33:08<13:14,  3.08s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 666/923 [33:11<13:21,  3.12s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 667/923 [33:14<13:22,  3.14s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 668/923 [33:17<12:57,  3.05s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 669/923 [33:20<12:38,  2.99s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 670/923 [33:23<12:44,  3.02s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 671/923 [33:26<12:27,  2.97s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 672/923 [33:29<12:08,  2.90s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 673/923 [33:32<12:22,  2.97s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 674/923 [33:34<11:46,  2.84s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 675/923 [33:37<12:04,  2.92s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 676/923 [33:41<12:27,  3.02s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 677/923 [33:44<12:43,  3.11s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 678/923 [33:47<12:27,  3.05s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 679/923 [33:50<12:28,  3.07s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 680/923 [33:53<12:48,  3.16s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 681/923 [33:57<12:44,  3.16s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 682/923 [34:00<12:36,  3.14s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 683/923 [34:03<12:18,  3.08s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 684/923 [34:05<11:48,  2.97s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 685/923 [34:08<11:31,  2.90s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 686/923 [34:11<11:18,  2.86s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 687/923 [34:13<10:55,  2.78s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 688/923 [34:16<10:57,  2.80s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 689/923 [34:19<10:50,  2.78s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 690/923 [34:22<10:42,  2.76s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 691/923 [34:25<10:49,  2.80s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 692/923 [34:28<11:07,  2.89s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 693/923 [34:31<11:06,  2.90s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 694/923 [34:33<10:33,  2.77s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 695/923 [34:36<10:31,  2.77s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 696/923 [34:39<10:51,  2.87s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 697/923 [34:42<10:30,  2.79s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 698/923 [34:44<10:30,  2.80s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 699/923 [34:48<10:57,  2.93s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 700/923 [34:51<11:23,  3.06s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 701/923 [34:54<11:10,  3.02s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 702/923 [34:57<10:48,  2.93s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 703/923 [35:00<10:56,  2.98s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 704/923 [35:03<11:05,  3.04s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 705/923 [35:06<10:44,  2.96s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 706/923 [35:08<10:27,  2.89s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 707/923 [35:11<10:05,  2.80s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 708/923 [35:14<10:23,  2.90s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 709/923 [35:17<10:20,  2.90s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 710/923 [35:20<10:46,  3.04s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 711/923 [35:24<11:05,  3.14s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 712/923 [35:27<11:30,  3.27s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 713/923 [35:30<10:58,  3.14s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 714/923 [35:33<10:55,  3.14s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 715/923 [35:37<11:02,  3.19s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 716/923 [35:40<11:00,  3.19s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 717/923 [35:43<10:51,  3.16s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 718/923 [35:46<10:33,  3.09s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 719/923 [35:49<10:11,  3.00s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 720/923 [35:51<09:51,  2.92s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 721/923 [35:54<09:30,  2.82s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 722/923 [35:57<09:25,  2.82s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 723/923 [36:00<09:42,  2.91s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 724/923 [36:03<10:03,  3.03s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 725/923 [36:06<10:04,  3.05s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 726/923 [36:10<10:12,  3.11s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 727/923 [36:13<10:11,  3.12s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 728/923 [36:15<09:43,  2.99s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 729/923 [36:18<09:22,  2.90s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 730/923 [36:21<09:09,  2.85s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 731/923 [36:24<09:45,  3.05s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 732/923 [36:28<09:59,  3.14s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 733/923 [36:30<09:33,  3.02s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 734/923 [36:35<10:44,  3.41s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 735/923 [36:38<10:06,  3.23s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 736/923 [36:40<09:41,  3.11s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 737/923 [36:43<09:40,  3.12s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 738/923 [36:47<09:36,  3.12s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 739/923 [36:49<09:19,  3.04s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 740/923 [36:52<08:58,  2.94s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 741/923 [36:55<08:47,  2.90s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 742/923 [36:58<09:18,  3.09s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 743/923 [37:01<08:48,  2.94s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 744/923 [37:04<08:34,  2.87s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 745/923 [37:06<08:00,  2.70s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 746/923 [37:09<07:56,  2.69s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 747/923 [37:12<08:19,  2.84s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 748/923 [37:15<08:07,  2.79s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 749/923 [37:17<08:04,  2.78s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 750/923 [37:20<07:51,  2.73s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 751/923 [37:23<07:44,  2.70s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 752/923 [37:25<07:45,  2.72s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 753/923 [37:29<08:15,  2.92s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 754/923 [37:32<08:22,  2.97s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 755/923 [37:34<08:01,  2.86s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 756/923 [37:37<07:47,  2.80s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 757/923 [37:41<08:22,  3.03s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 758/923 [37:43<08:04,  2.94s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 759/923 [37:46<07:50,  2.87s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 760/923 [37:49<08:00,  2.95s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 761/923 [37:52<08:08,  3.01s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 762/923 [37:56<08:10,  3.04s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 763/923 [37:58<08:01,  3.01s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 764/923 [38:01<07:49,  2.95s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 765/923 [38:04<07:45,  2.95s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 766/923 [38:07<07:29,  2.87s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 767/923 [38:11<08:15,  3.17s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 768/923 [38:14<07:55,  3.07s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 769/923 [38:16<07:33,  2.94s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 770/923 [38:19<07:23,  2.90s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 771/923 [38:22<07:17,  2.88s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 772/923 [38:25<07:36,  3.02s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 773/923 [38:28<07:20,  2.94s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 774/923 [38:31<07:37,  3.07s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 775/923 [38:34<07:22,  2.99s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 776/923 [38:38<07:35,  3.10s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 777/923 [38:40<07:21,  3.02s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 778/923 [38:43<07:01,  2.91s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 779/923 [38:46<06:53,  2.87s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 780/923 [38:49<07:11,  3.02s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 781/923 [38:52<06:56,  2.93s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 782/923 [38:55<06:41,  2.85s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 783/923 [38:57<06:41,  2.87s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 784/923 [39:00<06:30,  2.81s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 785/923 [39:03<06:41,  2.91s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 786/923 [39:06<06:48,  2.98s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 787/923 [39:10<06:51,  3.03s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 788/923 [39:13<06:51,  3.05s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 789/923 [39:15<06:40,  2.99s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 790/923 [39:19<06:49,  3.08s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 791/923 [39:22<07:07,  3.24s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 792/923 [39:25<06:40,  3.06s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 793/923 [39:28<06:39,  3.07s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 794/923 [39:31<06:20,  2.95s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 795/923 [39:34<06:13,  2.92s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 796/923 [39:36<06:05,  2.88s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 797/923 [39:40<06:11,  2.95s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 798/923 [39:42<06:02,  2.90s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 799/923 [39:46<06:17,  3.05s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 800/923 [39:49<06:17,  3.07s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 801/923 [39:53<06:59,  3.44s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 802/923 [39:56<06:45,  3.36s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 803/923 [39:59<06:13,  3.11s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 804/923 [40:02<05:56,  3.00s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 805/923 [40:05<06:00,  3.05s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 806/923 [40:08<05:52,  3.01s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 807/923 [40:11<06:09,  3.19s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 808/923 [40:15<06:11,  3.23s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 809/923 [40:17<05:44,  3.02s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 810/923 [40:20<05:32,  2.95s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 811/923 [40:22<05:16,  2.83s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 812/923 [40:25<05:16,  2.86s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 813/923 [40:28<05:16,  2.88s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 814/923 [40:31<05:22,  2.96s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 815/923 [40:35<05:26,  3.02s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 816/923 [40:37<05:09,  2.89s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 817/923 [40:40<04:53,  2.77s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 818/923 [40:43<04:55,  2.81s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 819/923 [40:45<04:48,  2.77s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 820/923 [40:48<04:43,  2.76s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 821/923 [40:51<04:35,  2.70s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 822/923 [40:55<05:17,  3.15s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 823/923 [40:58<05:02,  3.03s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 824/923 [41:02<05:37,  3.41s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 825/923 [41:05<05:15,  3.22s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 826/923 [41:08<05:12,  3.23s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 827/923 [41:11<04:56,  3.09s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 828/923 [41:13<04:39,  2.94s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 829/923 [41:16<04:31,  2.88s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 830/923 [41:19<04:43,  3.05s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 831/923 [41:23<04:44,  3.09s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 832/923 [41:25<04:33,  3.01s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 833/923 [41:29<04:42,  3.13s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 834/923 [41:31<04:15,  2.88s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 835/923 [41:34<04:08,  2.83s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 836/923 [41:37<04:13,  2.92s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 837/923 [41:40<04:17,  3.00s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 838/923 [41:43<04:21,  3.08s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 839/923 [41:47<04:25,  3.16s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 840/923 [41:50<04:16,  3.09s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 841/923 [41:53<04:14,  3.10s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 842/923 [41:56<04:17,  3.18s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 843/923 [41:59<04:04,  3.06s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 844/923 [42:02<03:57,  3.01s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 845/923 [42:05<03:59,  3.07s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 846/923 [42:08<04:00,  3.12s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 847/923 [42:12<04:02,  3.19s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 848/923 [42:15<04:02,  3.23s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 849/923 [42:18<03:45,  3.05s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 850/923 [42:20<03:36,  2.97s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 851/923 [42:23<03:36,  3.01s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 852/923 [42:26<03:25,  2.90s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 853/923 [42:29<03:18,  2.84s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 854/923 [42:32<03:21,  2.92s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 855/923 [42:35<03:23,  3.00s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 856/923 [42:38<03:28,  3.11s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 857/923 [42:41<03:20,  3.03s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 858/923 [42:44<03:14,  3.00s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 859/923 [42:47<03:14,  3.03s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 860/923 [42:50<03:07,  2.97s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 861/923 [42:54<03:11,  3.09s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 862/923 [42:56<03:03,  3.02s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 863/923 [42:59<02:55,  2.93s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 864/923 [43:03<03:03,  3.12s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 865/923 [43:05<02:52,  2.98s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 866/923 [43:09<03:06,  3.27s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 867/923 [43:12<03:01,  3.23s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 868/923 [43:15<02:52,  3.14s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 869/923 [43:20<03:08,  3.49s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 870/923 [43:23<02:55,  3.31s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 871/923 [43:25<02:45,  3.19s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 872/923 [43:28<02:37,  3.08s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 873/923 [43:31<02:30,  3.00s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 874/923 [43:34<02:24,  2.96s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 875/923 [43:37<02:27,  3.08s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 876/923 [43:40<02:18,  2.95s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 877/923 [43:43<02:21,  3.07s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 878/923 [43:46<02:12,  2.94s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 879/923 [43:49<02:14,  3.06s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 880/923 [43:52<02:06,  2.95s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 881/923 [43:55<02:03,  2.94s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 882/923 [43:58<02:05,  3.07s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 883/923 [44:02<02:08,  3.21s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 884/923 [44:05<02:04,  3.19s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 885/923 [44:08<02:00,  3.17s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 886/923 [44:11<01:54,  3.09s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 887/923 [44:14<01:54,  3.17s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 888/923 [44:18<01:55,  3.30s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 889/923 [44:21<01:45,  3.11s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 890/923 [44:24<01:42,  3.12s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 891/923 [44:27<01:36,  3.03s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 892/923 [44:30<01:36,  3.10s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 893/923 [44:33<01:30,  3.02s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 894/923 [44:36<01:30,  3.11s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 895/923 [44:40<01:30,  3.24s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 896/923 [44:42<01:24,  3.15s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 897/923 [44:46<01:23,  3.20s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 898/923 [44:48<01:15,  3.02s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 899/923 [44:51<01:12,  3.04s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 900/923 [44:54<01:06,  2.90s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 901/923 [44:57<01:06,  3.04s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 902/923 [45:01<01:04,  3.08s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 903/923 [45:04<01:03,  3.16s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 904/923 [45:07<00:58,  3.08s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 905/923 [45:09<00:52,  2.92s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 906/923 [45:13<00:52,  3.07s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 907/923 [45:16<00:49,  3.09s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 908/923 [45:19<00:46,  3.11s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 909/923 [45:22<00:43,  3.11s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 910/923 [45:25<00:39,  3.01s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 911/923 [45:28<00:37,  3.09s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 912/923 [45:31<00:32,  2.98s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 913/923 [45:34<00:30,  3.09s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 914/923 [45:38<00:28,  3.20s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 915/923 [45:41<00:24,  3.12s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 916/923 [45:43<00:20,  2.98s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 917/923 [45:46<00:17,  2.94s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 918/923 [45:49<00:14,  2.94s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 919/923 [45:53<00:12,  3.12s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 920/923 [45:55<00:09,  3.03s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 921/923 [46:00<00:06,  3.39s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 922/923 [46:03<00:03,  3.24s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 923/923 [46:04<00:00,  2.76s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 923/923 [46:04<00:00,  3.00s/it]
2025-03-09 14:59:14,992 - INFO - Initial evaluation results: {'eval_loss': 0.6931472420692444, 'eval_model_preparation_time': 0.0209, 'eval_runtime': 2768.7255, 'eval_samples_per_second': 2.666, 'eval_steps_per_second': 0.333, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -67.39481353759766, 'eval_logps/rejected': -105.4847640991211, 'eval_logits/chosen': 0.0264672189950943, 'eval_logits/rejected': -0.040978219360113144}
2025-03-09 14:59:14,993 - INFO - Starting training...
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 7,381 | Num Epochs = 4
O^O/ \_/ \    Batch size per device = 32 | Gradient Accumulation steps = 1
\        /    Total batch size = 32 | Total steps = 924
 "-____-"     Number of trainable parameters = 167,772,160
Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/scripts/dpotrain.py", line 134, in <module>
    train_dpo(args)
  File "/sorgin1/users/jbarrutia006/viper/scripts/dpotrain.py", line 124, in train_dpo
    trainer.train()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/trainer.py", line 2171, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 226, in _fast_inner_training_loop
RuntimeError: Unsloth currently does not support multi GPU setups - but we are working on it!
Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/scripts/dpotrain.py", line 134, in <module>
    train_dpo(args)
  File "/sorgin1/users/jbarrutia006/viper/scripts/dpotrain.py", line 124, in train_dpo
    trainer.train()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/trainer.py", line 2171, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 226, in _fast_inner_training_loop
RuntimeError: Unsloth currently does not support multi GPU setups - but we are working on it!
wandb: - 0.016 MB of 0.016 MB uploadedwandb: \ 0.016 MB of 0.016 MB uploadedwandb: | 0.016 MB of 0.016 MB uploadedwandb: / 0.055 MB of 0.264 MB uploaded (0.006 MB deduped)wandb: - 0.283 MB of 0.283 MB uploaded (0.006 MB deduped)wandb: 
wandb: Run history:
wandb:          eval/logits/chosen ‚ñÅ
wandb:        eval/logits/rejected ‚ñÅ
wandb:           eval/logps/chosen ‚ñÅ
wandb:         eval/logps/rejected ‚ñÅ
wandb:                   eval/loss ‚ñÅ
wandb: eval/model_preparation_time ‚ñÅ
wandb:     eval/rewards/accuracies ‚ñÅ
wandb:         eval/rewards/chosen ‚ñÅ
wandb:        eval/rewards/margins ‚ñÅ
wandb:       eval/rewards/rejected ‚ñÅ
wandb:                eval/runtime ‚ñÅ
wandb:     eval/samples_per_second ‚ñÅ
wandb:       eval/steps_per_second ‚ñÅ
wandb:           train/global_step ‚ñÅ
wandb: 
wandb: Run summary:
wandb:          eval/logits/chosen 0.02647
wandb:        eval/logits/rejected -0.04098
wandb:           eval/logps/chosen -67.39481
wandb:         eval/logps/rejected -105.48476
wandb:                   eval/loss 0.69315
wandb: eval/model_preparation_time 0.0209
wandb:     eval/rewards/accuracies 0.0
wandb:         eval/rewards/chosen 0.0
wandb:        eval/rewards/margins 0.0
wandb:       eval/rewards/rejected 0.0
wandb:                eval/runtime 2768.7255
wandb:     eval/samples_per_second 2.666
wandb:       eval/steps_per_second 0.333
wandb:           train/global_step 0
wandb: 
wandb: üöÄ View run Primera prueba A100 at: https://wandb.ai/jbarrutia006-upv-ehu/viperDPO/runs/4qkgrb01
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jbarrutia006-upv-ehu/viperDPO
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250309_141159-4qkgrb01/logs
srun: error: localhost: task 0: Exited with exit code 1
