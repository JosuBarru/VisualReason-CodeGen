ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 05-28 22:37:10 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Qwen2 patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.325 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Qwen/Qwen2.5-Math-7B does not have a padding token! Will use pad_token = <|vision_pad|>.
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.692, 'grad_norm': 1.3828125, 'learning_rate': 1.5220700152207001e-06, 'rewards/chosen': 0.0024197555612772703, 'rewards/rejected': -0.000325370958307758, 'rewards/accuracies': 0.46562498807907104, 'rewards/margins': 0.0027451268397271633, 'logps/chosen': -192.251708984375, 'logps/rejected': -207.09341430664062, 'logits/chosen': -1.5276970863342285, 'logits/rejected': -1.6671772003173828, 'epoch': 0.01}
{'loss': 0.6915, 'grad_norm': 1.6171875, 'learning_rate': 3.0441400304414002e-06, 'rewards/chosen': 0.004754581488668919, 'rewards/rejected': 0.0008885170100256801, 'rewards/accuracies': 0.565625011920929, 'rewards/margins': 0.0038660645950585604, 'logps/chosen': -183.42776489257812, 'logps/rejected': -212.82608032226562, 'logits/chosen': -1.5977756977081299, 'logits/rejected': -1.616899847984314, 'epoch': 0.01}
{'loss': 0.6917, 'grad_norm': 1.453125, 'learning_rate': 4.566210045662101e-06, 'rewards/chosen': 0.010821041651070118, 'rewards/rejected': 0.007319630589336157, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.003501411061733961, 'logps/chosen': -188.2235565185547, 'logps/rejected': -214.0783233642578, 'logits/chosen': -1.5250943899154663, 'logits/rejected': -1.585015058517456, 'epoch': 0.02}
{'loss': 0.687, 'grad_norm': 1.53125, 'learning_rate': 6.0882800608828005e-06, 'rewards/chosen': 0.04432535544037819, 'rewards/rejected': 0.031157299876213074, 'rewards/accuracies': 0.578125, 'rewards/margins': 0.013168057426810265, 'logps/chosen': -179.2633514404297, 'logps/rejected': -213.74331665039062, 'logits/chosen': -1.624267339706421, 'logits/rejected': -1.634838342666626, 'epoch': 0.02}
{'loss': 0.6816, 'grad_norm': 1.5234375, 'learning_rate': 7.6103500761035e-06, 'rewards/chosen': 0.11316747963428497, 'rewards/rejected': 0.08745861053466797, 'rewards/accuracies': 0.612500011920929, 'rewards/margins': 0.025708865374326706, 'logps/chosen': -176.49362182617188, 'logps/rejected': -207.7812957763672, 'logits/chosen': -1.7379238605499268, 'logits/rejected': -1.6372907161712646, 'epoch': 0.03}
{'loss': 0.6603, 'grad_norm': 2.046875, 'learning_rate': 9.132420091324201e-06, 'rewards/chosen': 0.234567329287529, 'rewards/rejected': 0.1606450080871582, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.0739222913980484, 'logps/chosen': -180.7272186279297, 'logps/rejected': -207.5587158203125, 'logits/chosen': -1.4802333116531372, 'logits/rejected': -1.6395145654678345, 'epoch': 0.04}
{'loss': 0.6264, 'grad_norm': 1.7890625, 'learning_rate': 1.06544901065449e-05, 'rewards/chosen': 0.44946974515914917, 'rewards/rejected': 0.2871238589286804, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.16234591603279114, 'logps/chosen': -177.57728576660156, 'logps/rejected': -207.3076629638672, 'logits/chosen': -1.5651276111602783, 'logits/rejected': -1.5339001417160034, 'epoch': 0.04}
{'loss': 0.601, 'grad_norm': 1.6484375, 'learning_rate': 1.2176560121765601e-05, 'rewards/chosen': 0.7540234923362732, 'rewards/rejected': 0.48918694257736206, 'rewards/accuracies': 0.684374988079071, 'rewards/margins': 0.26483654975891113, 'logps/chosen': -175.5041961669922, 'logps/rejected': -215.6499786376953, 'logits/chosen': -1.576819658279419, 'logits/rejected': -1.5686330795288086, 'epoch': 0.05}
{'loss': 0.6234, 'grad_norm': 2.609375, 'learning_rate': 1.3698630136986302e-05, 'rewards/chosen': 0.7786563038825989, 'rewards/rejected': 0.515422523021698, 'rewards/accuracies': 0.637499988079071, 'rewards/margins': 0.2632337808609009, 'logps/chosen': -176.425048828125, 'logps/rejected': -207.47607421875, 'logits/chosen': -1.4270789623260498, 'logits/rejected': -1.5232863426208496, 'epoch': 0.05}
{'loss': 0.5565, 'grad_norm': 2.21875, 'learning_rate': 1.5220700152207e-05, 'rewards/chosen': 1.1497787237167358, 'rewards/rejected': 0.6940337419509888, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.45574507117271423, 'logps/chosen': -170.84536743164062, 'logps/rejected': -208.7860870361328, 'logits/chosen': -1.374298334121704, 'logits/rejected': -1.4728621244430542, 'epoch': 0.06}
{'loss': 0.5301, 'grad_norm': 2.0, 'learning_rate': 1.67427701674277e-05, 'rewards/chosen': 1.3389514684677124, 'rewards/rejected': 0.7989829778671265, 'rewards/accuracies': 0.734375, 'rewards/margins': 0.5399684906005859, 'logps/chosen': -168.84463500976562, 'logps/rejected': -205.1692657470703, 'logits/chosen': -1.3503611087799072, 'logits/rejected': -1.2887080907821655, 'epoch': 0.07}
{'loss': 0.576, 'grad_norm': 1.390625, 'learning_rate': 1.8264840182648402e-05, 'rewards/chosen': 1.3591716289520264, 'rewards/rejected': 0.8416409492492676, 'rewards/accuracies': 0.6781250238418579, 'rewards/margins': 0.5175308585166931, 'logps/chosen': -166.6806640625, 'logps/rejected': -194.66380310058594, 'logits/chosen': -1.0451607704162598, 'logits/rejected': -1.149094581604004, 'epoch': 0.07}
{'loss': 0.5341, 'grad_norm': 2.65625, 'learning_rate': 1.97869101978691e-05, 'rewards/chosen': 1.9603773355484009, 'rewards/rejected': 1.3690491914749146, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.5913282036781311, 'logps/chosen': -163.61993408203125, 'logps/rejected': -194.84561157226562, 'logits/chosen': -1.1349979639053345, 'logits/rejected': -1.219970703125, 'epoch': 0.08}
{'loss': 0.5182, 'grad_norm': 2.15625, 'learning_rate': 2.13089802130898e-05, 'rewards/chosen': 2.154977798461914, 'rewards/rejected': 1.3434079885482788, 'rewards/accuracies': 0.7281249761581421, 'rewards/margins': 0.8115699887275696, 'logps/chosen': -166.9989776611328, 'logps/rejected': -196.63088989257812, 'logits/chosen': -1.0606921911239624, 'logits/rejected': -1.192800760269165, 'epoch': 0.09}
{'loss': 0.4895, 'grad_norm': 1.7578125, 'learning_rate': 2.2831050228310503e-05, 'rewards/chosen': 2.0859713554382324, 'rewards/rejected': 1.143264651298523, 'rewards/accuracies': 0.746874988079071, 'rewards/margins': 0.9427064061164856, 'logps/chosen': -165.95094299316406, 'logps/rejected': -205.96487426757812, 'logits/chosen': -1.178383469581604, 'logits/rejected': -1.2595405578613281, 'epoch': 0.09}
