SELECTED CONFIG FILES: gqa/general_config,gqa/train
LOADING MODEL: ENABLED
modelo: <class 'vision_models.BLIPModel'> , proceso:  blip
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
modelo: <class 'vision_models.GLIPModel'> , proceso:  glip
modelo: <class 'vision_models.MaskRCNNModel'> , proceso:  maskrcnn
modelo: <class 'vision_models.XVLMModel'> , proceso:  xvlm
{'blip': <function make_fn.<locals>._function at 0x7fc3ffb8db20>, 'glip': <function make_fn.<locals>._function at 0x7fc13c1dcb80>, 'maskrcnn': <function make_fn.<locals>._function at 0x7fc13d2c7f60>, 'xvlm': <function make_fn.<locals>._function at 0x7fc03e1bb920>}
5 100
159 100
5 96
159 96
5 194
159 194
5 104
159 104
5 122
159 122
5 93
159 93
5 97
159 97
5 120
159 120
5 202
159 202
5 125
159 125
More than one animal in the image, use direct query
tensor([[[0.8275, 0.8549, 0.6902,  ..., 0.4118, 0.3922, 0.3922],
         [0.7961, 0.7922, 0.5529,  ..., 0.4745, 0.4392, 0.4824],
         [0.7922, 0.7961, 0.7373,  ..., 0.6314, 0.6196, 0.6235],
         ...,
         [0.4510, 0.4118, 0.3647,  ..., 0.3961, 0.3961, 0.3608],
         [0.4078, 0.4039, 0.3725,  ..., 0.3843, 0.3765, 0.3765],
         [0.4235, 0.4275, 0.4196,  ..., 0.3608, 0.3451, 0.3882]],

        [[0.8118, 0.8353, 0.6706,  ..., 0.4941, 0.4588, 0.4549],
         [0.7725, 0.7686, 0.5294,  ..., 0.4941, 0.4745, 0.5176],
         [0.7608, 0.7647, 0.7137,  ..., 0.6078, 0.6235, 0.6431],
         ...,
         [0.4471, 0.4157, 0.3686,  ..., 0.3804, 0.3804, 0.3451],
         [0.4118, 0.4235, 0.3961,  ..., 0.3490, 0.3490, 0.3529],
         [0.4431, 0.4627, 0.4627,  ..., 0.3255, 0.3216, 0.3765]],

        [[0.7137, 0.7490, 0.5843,  ..., 0.5608, 0.5216, 0.5176],
         [0.6784, 0.6824, 0.4431,  ..., 0.5098, 0.4706, 0.5059],
         [0.6784, 0.6824, 0.6275,  ..., 0.5529, 0.5529, 0.5569],
         ...,
         [0.4314, 0.3961, 0.3490,  ..., 0.3451, 0.3451, 0.3098],
         [0.3922, 0.4000, 0.3804,  ..., 0.3216, 0.3098, 0.3059],
         [0.4157, 0.4431, 0.4471,  ..., 0.2902, 0.2745, 0.3176]]])
candle
500 333
Enter your guess for the place as a string (e.g. 'table', 'chair', 'painting', etc.)
watermelon
My mistake
small
[ImagePatch(16, 249, 136, 437), ImagePatch(0, 230, 375, 500)]
vertical arg 661.0
left arg 16
num_clusters 375
Error in blip model: Unsupported number of image dimensions: 2
outdoors
Distance between plane and crop center: 88.0
man
ImagePatch(24, 0, 496, 422) ImagePatch(247, 253, 309, 331)
monkey, boy, rider from bottom right to top
left has -58.0 pixels out of a total of 57.0 pixelsreak
ImagePatch(0, 0, 500, 375)
航班号：(a cat)
