SELECTED CONFIG FILES: gqa/general_config,gqa/train
LOADING MODEL: ENABLED
modelo: <class 'vision_models.BLIPModel'> , proceso:  blip
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
modelo: <class 'vision_models.GLIPModel'> , proceso:  glip
modelo: <class 'vision_models.MaskRCNNModel'> , proceso:  maskrcnn
modelo: <class 'vision_models.XVLMModel'> , proceso:  xvlm
{'blip': <function make_fn.<locals>._function at 0x7f28d5b6d940>, 'glip': <function make_fn.<locals>._function at 0x7f24847d09a0>, 'maskrcnn': <function make_fn.<locals>._function at 0x7f24f1327e20>, 'xvlm': <function make_fn.<locals>._function at 0x7f23e0a67740>}
5 100
159 100
5 96
159 96
5 194
159 194
5 104
159 104
5 122
159 122
5 93
159 93
5 97
159 97
5 120
159 120
5 202
159 202
5 125
159 125
More than one animal in the image, use direct query
tensor([[[0.8275, 0.8549, 0.6902,  ..., 0.4118, 0.3922, 0.3922],
         [0.7961, 0.7922, 0.5529,  ..., 0.4745, 0.4392, 0.4824],
         [0.7922, 0.7961, 0.7373,  ..., 0.6314, 0.6196, 0.6235],
         ...,
         [0.4510, 0.4118, 0.3647,  ..., 0.3961, 0.3961, 0.3608],
         [0.4078, 0.4039, 0.3725,  ..., 0.3843, 0.3765, 0.3765],
         [0.4235, 0.4275, 0.4196,  ..., 0.3608, 0.3451, 0.3882]],

        [[0.8118, 0.8353, 0.6706,  ..., 0.4941, 0.4588, 0.4549],
         [0.7725, 0.7686, 0.5294,  ..., 0.4941, 0.4745, 0.5176],
         [0.7608, 0.7647, 0.7137,  ..., 0.6078, 0.6235, 0.6431],
         ...,
         [0.4471, 0.4157, 0.3686,  ..., 0.3804, 0.3804, 0.3451],
         [0.4118, 0.4235, 0.3961,  ..., 0.3490, 0.3490, 0.3529],
         [0.4431, 0.4627, 0.4627,  ..., 0.3255, 0.3216, 0.3765]],

        [[0.7137, 0.7490, 0.5843,  ..., 0.5608, 0.5216, 0.5176],
         [0.6784, 0.6824, 0.4431,  ..., 0.5098, 0.4706, 0.5059],
         [0.6784, 0.6824, 0.6275,  ..., 0.5529, 0.5529, 0.5569],
         ...,
         [0.4314, 0.3961, 0.3490,  ..., 0.3451, 0.3451, 0.3098],
         [0.3922, 0.4000, 0.3804,  ..., 0.3216, 0.3098, 0.3059],
         [0.4157, 0.4431, 0.4471,  ..., 0.2902, 0.2745, 0.3176]]])
candle
watermelon
My mistake
small
[ImagePatch(16, 249, 136, 437), ImagePatch(0, 230, 375, 500)]
vertical arg 661.0
left arg 16
num_clusters 375
Error in blip model: Unsupported number of image dimensions: 2
outdoors
Distance between plane and crop center: 88.0
man
ImagePatch(24, 0, 496, 422) ImagePatch(247, 253, 309, 331)
monkey, boy, rider from bottom right to top
left has -58.0 pixels out of a total of 57.0 pixelsreak
ImagePatch(0, 0, 500, 375)
航班号：(a cat)
What object is this?: ImagePatch(55, 0, 283, 143)
ImagePatch(58, 308, 166, 458)
ImagePatch(227, 39, 332, 200)
ImagePatch(58, 308, 166, 458)
ImagePatch(0, 89, 81, 211)
ImagePatch(58, 308, 166, 458)
ImagePatch(108, 104, 233, 181)
ImagePatch(58, 308, 166, 458)
ImagePatch(214, 110, 268, 180)
ImagePatch(58, 308, 166, 458)
ImagePatch(55, 0, 283, 143)
ImagePatch(104, 9, 232, 98)
ImagePatch(227, 39, 332, 200)
ImagePatch(104, 9, 232, 98)
ImagePatch(0, 89, 81, 211)
ImagePatch(104, 9, 232, 98)
ImagePatch(108, 104, 233, 181)
ImagePatch(104, 9, 232, 98)
ImagePatch(214, 110, 268, 180)
ImagePatch(104, 9, 232, 98)
you
image_patch羧อ comer image_patch: ImagePatch(0, 0, 500, 374)
white
3
True
True
True
Error in blip model: mean must have 1 elements if it is an iterable, got 3
Error in glip model: index is out of bounds for dimension with size 0
Isn't this there? 
the man
hooku 2.jpg?
column:  217   91
Zooming back in to see the details of the man reading
a game
beach369.0
369.0
117.5
282
0.4166666666666667
28.200000000000003
Which place is it?No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
No answer is a number, so this will be wrong
Final accuracy: 0.276031746031746
