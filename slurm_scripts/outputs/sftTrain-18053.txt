ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
ü¶• Unsloth Zoo will now patch everything to make training faster!
INFO 06-04 20:11:35 __init__.py:183] Automatically detected platform cuda.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbarrutia006 (jbarrutia006-upv-ehu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /sorgin1/users/jbarrutia006/viper/wandb/run-20250604_201138-rwhfonih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run codellama
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jbarrutia006-upv-ehu/viperSFT
wandb: üöÄ View run at https://wandb.ai/jbarrutia006-upv-ehu/viperSFT/runs/rwhfonih
2025-06-04 20:11:41,860 - INFO - Results will be saved to: ./sft_trained_models/06-04_20-11-41
2025-06-04 20:11:41,861 - INFO - Loading model and tokenizer...
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.151 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.60s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.25s/it]
Unsloth 2025.3.14 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2025-06-04 20:11:56,101 - INFO - Loading SFT train and dev datasets...
codellama/CodeLlama-7b-Instruct-hf does not have a padding token! Will use pad_token = <unk>.
trainable params: 159,907,840 || all params: 6,898,454,528 || trainable%: 2.3180
Formateando train SFT:   0%|          | 0/7824 [00:00<?, ? examples/s]2025-06-04 20:11:56,416 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are there men to the left of the guy that is wearing sneakers?
def execute_command(image)->str:

    image_patch = ImagePatch(image)
    guy_patches = image_patch.find("guy")
    if len(guy_patches) == 0:
        return image_patch.simple_query("Are there men to the left of the guy that is wearing sneakers?")
    guy_patch = guy_patches[0]
    if not guy_patch.verify_property("guy", "wearing sneakers"):
        return "no"
    man_patches = image_patch.find("man")
    if len(man_patches) == 0:
        return "no"
    man_patch = man_patches[0]
    if man_patch.horizontal_center < guy_patch.horizontal_center:
        return "yes"
    return "no"

2025-06-04 20:11:56,481 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the tennis racket to the right or to the left of the player?
def execute_command(image)->str:

    image_patch = ImagePatch(image)
    tennis_racket_patches = image_patch.find("tennis racket")
    # Question assumes only one tennis racket patch
    if len(tennis_racket_patches) == 0:
        return image_patch.simple_query("Is the tennis racket to the right or to the left of the player?")
    for tennis_racket_patch in tennis_racket_patches:
        player_patches = image_patch.find("player")
        # Question assumes only one player patch
        if len(player_patches) == 0:
            return tennis_racket_patch.simple_query("Is the tennis racket to the right or to the left of the player?")
        if player_patches[0].horizontal_center < tennis_racket_patch.horizontal_center:
            return "right"
        else:
            return "left"
2025-06-04 20:11:56,499 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Who is wearing a shirt?
def execute_command(image)->str:

    image_patch = ImagePatch(image)
    shirts = image_patch.find("shirt")
    
    for shirt in shirts:
        wearing_person = shirt.simple_query("Is the shirt wearing a shirt?")
        if wearing_person == "yes":
            person = shirt.simple_query("Who is the person wearing the shirt?")
            return person
    return image_patch.simple_query("Who is wearing a shirt?")

2025-06-04 20:11:56,518 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are there cars to the right of the vehicle on the right side?
def execute_command(image)->str:
 # doesn't work because there is no right visual aspect
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("Are there cars to the right of the vehicle on the right side?")
Formateando train SFT:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4000/7824 [00:00<00:00, 31219.47 examples/s]2025-06-04 20:11:56,540 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the white sign in front of the house below the wire?
def execute_command(image)->str:

    image_patch = ImagePatch(image)
    white_sign_patches = image_patch.find("white sign")
    # Question assumes only one white sign patch
    if len(white_sign_patches) == 0:
        # If no white sign is found, query the image directly
        return image_patch.simple_query("Is the white sign in front of the house below the wire?")
    for white_sign_patch in white_sign_patches:
        house_patches = image_patch.find("house")
        for house_patch in house_patches:
            if house_patch.horizontal_center > white_sign_patch.horizontal_center:
                if white_sign_patch.upper > house_patch.lower:
                    return "yes"
    return "no"
2025-06-04 20:11:56,558 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Do you see both windows and doors?
def execute_command(image)->str:

    image_patch = ImagePatch(image)
    windows_patches = image_patch.find("window")
    doors_patches = image_patch.find("door")
    return bool_to_yesno(len(windows_patches) > 0 and len(doors_patches) > 0)
2025-06-04 20:11:56,574 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Do the shelf and the floor have a different colors?
def execute_command(image)->str:

    image_patch = ImagePatch(image)
    shelf_patches = image_patch.find("shelf")
    # Question assumes only one shelf patch
    if len(shelf_patches) == 0:
        # If no shelf is found, query the image directly
        return image_patch.simple_query("Do the shelf and the floor have a different colors?")
    floor_patches = image_patch.find("floor")
    # Question assumes only one floor patch
    if len(floor_patches) == 0:
        return "no"
2025-06-04 20:11:56,591 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Is the statue brown and small?
def execute_command(image)->str:
 # if no statue is found, ask the image directly
    image_patch = ImagePatch(image)
    is_small = image_patch.verify_property("statue", "small")
    is_brown = image_patch.verify_property("statue", "bROWN")
    return bool_to_yesno(is_small and is_brown)
Formateando train SFT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7824/7824 [00:01<00:00, 5982.41 examples/s] Formateando train SFT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7824/7824 [00:01<00:00, 6369.34 examples/s]
Formateando dev SFT:   0%|          | 0/1000 [00:00<?, ? examples/s]2025-06-04 20:11:57,666 - INFO - from PIL import Image
from vision_functions import find_in_image, simple_qa, verify_property, best_text_match

def bool_to_yesno(bool_answer: bool)->str:
    return "yes" if bool_answer else "no"

class ImagePatch:
    """A Python class containing a crop of an image centered around a particular object, as well as relevant information.
    Attributes
    ----------
    cropped_image : array_like
        An array-like of the cropped image taken from the original image.
    left : int
        An int describing the position of the left border of the crop's bounding box in the original image.
    lower : int
        An int describing the position of the bottom border of the crop's bounding box in the original image.
    right : int
        An int describing the position of the right border of the crop's bounding box in the original image.
    upper : int
        An int describing the position of the top border of the crop's bounding box in the original image.

    Methods
    -------
    find(object_name: str)->List[ImagePatch]
        Returns a list of new ImagePatch objects containing crops of the image centered around any objects found in the image matching the object_name.
    simple_query(question: str=None)->str
        Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
    exists(object_name: str)->bool
        Returns True if the object specified by object_name is found in the image, and False otherwise.
    verify_property(property: str)->bool
        Returns True if the property is met, and False otherwise.
    best_text_match(string1: str, string2: str)->str
        Returns the string that best matches the image.
    crop(left: int, lower: int, right: int, upper: int)->ImagePatch
        Returns a new ImagePatch object containing a crop of the image at the given coordinates.
        """

    def __init__(self, image, left: int=None, lower: int=None, right: int=None, upper: int=None):
        """Initializes an ImagePatch object by cropping the image at the given coordinates and stores the coordinates as attributes.
        If no coordinates are provided, the image is left unmodified, and the coordinates are set to the dimensions of the image.
        Parameters
        -------
        image : array_like
            An array-like of the original image.
        left : int
            An int describing the position of the left border of the crop's bounding box in the original image.
        lower : int
            An int describing the position of the bottom border of the crop's bounding box in the original image.
        right : int
            An int describing the position of the right border of the crop's bounding box in the original image.
        upper : int
            An int describing the position of the top border of the crop's bounding box in the original image.

        """
        if left is None and right is None and upper is None and lower is None:
            self.cropped_image = image
            self.left = 0
            self.lower = 0
            self.right = image.shape[2]  # width
            self.upper = image.shape[1]  # height
        else:
            self.cropped_image = image[:, lower:upper, left:right]
            self.left = left
            self.upper = upper
            self.right = right
            self.lower = lower

        self.width = self.cropped_image.shape[2]
        self.height = self.cropped_image.shape[1]

        self.horizontal_center = (self.left + self.right) / 2
        self.vertical_center = (self.lower + self.upper) / 2

    def find(self, object_name: str)->List["ImagePatch"]:
        """Returns a new ImagePatch object containing the crop of the image centered around the object specified by object_name.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        """
        return find_in_image(self.cropped_image, object_name)

    def simple_query(self, question: str=None)->str:
        """Returns the answer to a basic question asked about the image. If no question is provided, returns the answer to "What is this?".
        Parameters
        -------
        question : str
            A string describing the question to be asked.

        Examples
        -------

        >>> # Which kind of animal is not eating?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     animal_patches = image_patch.find("animal")
        >>>     for animal_patch in animal_patches:
        >>>         if not animal_patch.verify_property("animal", "eating"):
        >>>             return animal_patch.simple_query("What kind of animal is eating?") # crop would include eating so keep it in the query
        >>>     # If no animal is not eating, query the image directly
        >>>     return image_patch.simple_query("Which kind of animal is not eating?")

        >>> # What is in front of the horse?
        >>> # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
        >>> return image_patch.simple_query("What is in front of the horse?")
        >>>
        """
        return simple_qa(self.cropped_image, question)

    def exists(self, object_name: str)->bool:
        """Returns True if the object specified by object_name is found in the image, and False otherwise.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.

        Examples
        -------
        >>> # Are there both cakes and gummy bears in the photo?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     is_cake = image_patch.exists("cake")
        >>>     is_gummy_bear = image_patch.exists("gummy bear")
        >>>     return bool_to_yesno(is_cake and is_gummy_bear)
        """
        return len(self.find(object_name)) > 0

    def verify_property(self, object_name: str, property: str)->bool:
        """Returns True if the object possesses the property, and False otherwise.
        Differs from 'exists' in that it presupposes the existence of the object specified by object_name, instead checking whether the object possesses the property.
        Parameters
        -------
        object_name : str
            A string describing the name of the object to be found in the image.
        property : str
            A string describing the property to be checked.

        Examples
        -------
        >>> # Do the letters have blue color?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     letters_patches = image_patch.find("letters")
        >>>     # Question assumes only one letter patch
        >>>     if len(letters_patches) == 0:
        >>>         # If no letters are found, query the image directly
        >>>         return image_patch.simple_query("Do the letters have blue color?")
        >>>     return bool_to_yesno(letters_patches[0].verify_property("letters", "blue"))
        """
        return verify_property(self.cropped_image, object_name, property)

    def best_text_match(self, option_list: List[str]) -> str:
        """Returns the string that best matches the image.
        Parameters
        -------
        option_list : str
            A list with the names of the different options
        prefix : str
            A string with the prefixes to append to the options

        Examples
        -------
        >>> # Is the cap gold or white?
        >>> def execute_command(image)->str:
        >>>     image_patch = ImagePatch(image)
        >>>     cap_patches = image_patch.find("cap")
        >>>     # Question assumes one cap patch
        >>>     if len(cap_patches) == 0:
        >>>         # If no cap is found, query the image directly
        >>>         return image_patch.simple_query("Is the cap gold or white?")
        >>>     return cap_patches[0].best_text_match(["gold", "white"])
        """
        return best_text_match(self.cropped_image, option_list)

    def crop(self, left: int, lower: int, right: int, upper: int)->"ImagePatch":
        """Returns a new ImagePatch cropped from the current ImagePatch.
        Parameters
        -------
        left : int
            The leftmost pixel of the cropped image.
        lower : int
            The lowest pixel of the cropped image.
        right : int
            The rightmost pixel of the cropped image.
        upper : int
            The uppermost pixel of the cropped image.
        -------
        """
        return ImagePatch(self.cropped_image, left, lower, right, upper)

# Examples of using ImagePatch
# Is there a backpack to the right of the man?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    man_patches = image_patch.find("man")
    # Question assumes one man patch
    if len(man_patches) == 0:
        # If no man is found, query the image directly
        return image_patch.simple_query("Is there a backpack to the right of the man?")
    man_patch = man_patches[0]
    backpack_patches = image_patch.find("backpack")
    # Question assumes one backpack patch
    if len(backpack_patches) == 0:
        return "no"
    for backpack_patch in backpack_patches:
        if backpack_patch.horizontal_center > man_patch.horizontal_center:
            return "yes"
    return "no"

# In which part is the bread, the bottom or the top?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    bread_patches = image_patch.find("bread")
    # Question assumes only one bread patch
    if len(bread_patches) == 0:
        # If no bread is found, query the image directly
        return image_patch.simple_query("In which part is the bread, the bottom or the top?")
    if bread_patches[0].vertical_center < image_patch.vertical_center:
        return "bottom"
    else:
        return "top"

# What type of weather do you see in the photograph?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    return image_patch.simple_query("What type of weather do you see in the photograph?")

# Who is the man staring at?
def execute_command(image)->str:
    # asks for the predicate of a relational verb (staring at), so ask directly
    image_patch = ImagePatch(image)
    return image_patch.simple_query("Who is the man staring at?")

# What toy is wearing a shirt?
def execute_command(image)->str:
    # not a relational verb so go step by step
    image_patch = ImagePatch(image)
    toy_patches = image_patch.find("toy")
    # Question assumes only one toy patch
    if len(toy_patches) == 0:
        # If no toy is found, query the image directly
        return image_patch.simple_query("What toy is wearing a shirt?")
    for toy_patch in toy_patches:
        is_wearing_shirt = (toy_patch.simple_query("Is the toy wearing a shirt?") == "yes")
        if is_wearing_shirt:
            return toy_patch.simple_query("What toy is wearing a shirt?") # crop would include the shirt so keep it in the query
    # If no toy is wearing a shirt, pick the first toy
    return toy_patches[0].simple_query("What toy is wearing a shirt?")

# What is behind the pole?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    # contains a relation (around, next to, on, near, on top of, in front of, behind, etc), so ask directly
    return image_patch.simple_query("What is behind the pole?")

# Are there bagels or lemons?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    is_bagel = image_patch.exists("bagel")
    is_lemon = image_patch.exists("lemon")
    return bool_to_yesno(is_bagel or is_lemon)

# Is that blanket to the right of a pillow?
def execute_command(image)->str:
    image_patch = ImagePatch(image)
    blanket_patches = image_patch.find("blanket")
    # Question assumes only one blanket patch
    if len(blanket_patches) == 0:
        # If no blanket is found, query the image directly
        return image_patch.simple_query("Is that blanket to the right of a pillow?")
    for blanket_patch in blanket_patches:
        pillow_patches = image_patch.find("pillow")
        for pillow_patch in pillow_patches:
            if pillow_patch.horizontal_center > blanket_patch.horizontal_center:
                return "yes"
    return "no"

# Are the white blinds to the right of a clock?
def execute_command(image)->str:
 # assumes one clock and one white blind
    image_patch = ImagePatch(image)
    white_blinds_patches = image_patch.find("white blind")
    for white_blind_patch in white_blinds_patches:
        if white_blind_patch.horizontal_center > image_patch.horizontal_center:
            return "yes"
    return "no"
Formateando dev SFT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 3342.54 examples/s]Formateando dev SFT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 3044.14 examples/s]
/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Unsloth: Tokenizing ["text"] (num_proc=128):   0%|          | 0/7824 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   1%|          | 62/7824 [00:00<01:37, 79.57 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   9%|‚ñä         | 682/7824 [00:00<00:07, 947.43 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  12%|‚ñà‚ñè        | 929/7824 [00:01<00:10, 671.95 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  22%|‚ñà‚ñà‚ñè       | 1724/7824 [00:01<00:04, 1249.15 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  25%|‚ñà‚ñà‚ñå       | 1968/7824 [00:02<00:06, 892.60 examples/s] Unsloth: Tokenizing ["text"] (num_proc=128):  41%|‚ñà‚ñà‚ñà‚ñà      | 3188/7824 [00:02<00:02, 2007.05 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3676/7824 [00:03<00:02, 1525.44 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 4652/7824 [00:03<00:01, 2313.56 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5201/7824 [00:03<00:01, 2175.10 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5628/7824 [00:03<00:01, 2059.17 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6055/7824 [00:03<00:00, 2334.91 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 6604/7824 [00:03<00:00, 2748.75 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 7031/7824 [00:04<00:00, 2614.97 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 7397/7824 [00:04<00:00, 2048.84 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 7702/7824 [00:04<00:00, 1696.68 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7824/7824 [00:04<00:00, 1602.39 examples/s]
Unsloth: Tokenizing ["text"] (num_proc=128):   0%|          | 0/1000 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   1%|          | 8/1000 [00:00<00:28, 35.07 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):   5%|‚ñç         | 48/1000 [00:00<00:05, 166.83 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  10%|‚ñâ         | 96/1000 [00:00<00:03, 265.94 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  14%|‚ñà‚ñé        | 136/1000 [00:00<00:02, 298.07 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  18%|‚ñà‚ñä        | 176/1000 [00:00<00:02, 316.39 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  22%|‚ñà‚ñà‚ñè       | 224/1000 [00:00<00:02, 356.56 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  26%|‚ñà‚ñà‚ñã       | 264/1000 [00:00<00:02, 353.31 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  30%|‚ñà‚ñà‚ñà       | 304/1000 [00:00<00:01, 366.07 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  34%|‚ñà‚ñà‚ñà‚ñç      | 344/1000 [00:01<00:01, 338.92 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  39%|‚ñà‚ñà‚ñà‚ñâ      | 392/1000 [00:01<00:01, 368.26 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 432/1000 [00:01<00:01, 366.13 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 472/1000 [00:01<00:01, 350.06 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 512/1000 [00:01<00:01, 339.08 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 552/1000 [00:01<00:01, 330.08 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 600/1000 [00:01<00:01, 355.02 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 640/1000 [00:01<00:00, 361.66 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 680/1000 [00:02<00:00, 368.88 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 728/1000 [00:02<00:00, 374.75 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 768/1000 [00:02<00:00, 359.17 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 808/1000 [00:02<00:00, 356.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 846/1000 [00:02<00:00, 340.46 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 958/1000 [00:02<00:00, 531.78 examples/s]Unsloth: Tokenizing ["text"] (num_proc=128): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:02<00:00, 347.41 examples/s]
2025-06-04 20:12:12,028 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-06-04 20:12:12,034 - INFO - Performing an initial evaluation on the dev_sft dataset...
  0%|          | 0/250 [00:00<?, ?it/s]  1%|          | 2/250 [00:01<02:31,  1.63it/s]  1%|          | 3/250 [00:02<03:56,  1.05it/s]  2%|‚ñè         | 4/250 [00:03<04:22,  1.07s/it]  2%|‚ñè         | 5/250 [00:05<04:49,  1.18s/it]  2%|‚ñè         | 6/250 [00:06<04:50,  1.19s/it]  3%|‚ñé         | 7/250 [00:08<05:15,  1.30s/it]  3%|‚ñé         | 8/250 [00:09<05:12,  1.29s/it]  4%|‚ñé         | 9/250 [00:10<05:16,  1.31s/it]  4%|‚ñç         | 10/250 [00:11<05:12,  1.30s/it]  4%|‚ñç         | 11/250 [00:13<05:21,  1.34s/it]  5%|‚ñç         | 12/250 [00:14<05:12,  1.31s/it]  5%|‚ñå         | 13/250 [00:16<05:18,  1.35s/it]  6%|‚ñå         | 14/250 [00:17<05:07,  1.30s/it]  6%|‚ñå         | 15/250 [00:18<05:12,  1.33s/it]  6%|‚ñã         | 16/250 [00:19<05:01,  1.29s/it]  7%|‚ñã         | 17/250 [00:21<05:07,  1.32s/it]  7%|‚ñã         | 18/250 [00:22<05:04,  1.31s/it]  8%|‚ñä         | 19/250 [00:23<05:08,  1.33s/it]  8%|‚ñä         | 20/250 [00:25<04:58,  1.30s/it]  8%|‚ñä         | 21/250 [00:26<05:07,  1.34s/it]  9%|‚ñâ         | 22/250 [00:27<05:00,  1.32s/it]  9%|‚ñâ         | 23/250 [00:29<05:09,  1.36s/it] 10%|‚ñâ         | 24/250 [00:30<04:59,  1.32s/it] 10%|‚ñà         | 25/250 [00:31<05:05,  1.36s/it] 10%|‚ñà         | 26/250 [00:33<04:56,  1.32s/it] 11%|‚ñà         | 27/250 [00:34<05:01,  1.35s/it] 11%|‚ñà         | 28/250 [00:35<04:53,  1.32s/it] 12%|‚ñà‚ñè        | 29/250 [00:37<04:58,  1.35s/it] 12%|‚ñà‚ñè        | 30/250 [00:38<04:50,  1.32s/it] 12%|‚ñà‚ñè        | 31/250 [00:39<04:54,  1.34s/it] 13%|‚ñà‚ñé        | 32/250 [00:41<04:46,  1.32s/it] 13%|‚ñà‚ñé        | 33/250 [00:42<04:52,  1.35s/it] 14%|‚ñà‚ñé        | 34/250 [00:43<04:41,  1.31s/it] 14%|‚ñà‚ñç        | 35/250 [00:45<04:51,  1.36s/it] 14%|‚ñà‚ñç        | 36/250 [00:53<12:25,  3.48s/it] 15%|‚ñà‚ñç        | 37/250 [00:55<10:13,  2.88s/it] 15%|‚ñà‚ñå        | 38/250 [00:56<08:26,  2.39s/it] 16%|‚ñà‚ñå        | 39/250 [00:57<07:23,  2.10s/it] 16%|‚ñà‚ñå        | 40/250 [00:59<06:27,  1.84s/it] 16%|‚ñà‚ñã        | 41/250 [01:00<05:59,  1.72s/it] 17%|‚ñà‚ñã        | 42/250 [01:01<05:29,  1.58s/it] 17%|‚ñà‚ñã        | 43/250 [01:03<05:18,  1.54s/it] 18%|‚ñà‚ñä        | 44/250 [01:04<04:58,  1.45s/it] 18%|‚ñà‚ñä        | 45/250 [01:05<04:53,  1.43s/it] 18%|‚ñà‚ñä        | 46/250 [01:07<04:41,  1.38s/it] 19%|‚ñà‚ñâ        | 47/250 [01:08<04:40,  1.38s/it] 19%|‚ñà‚ñâ        | 48/250 [01:09<04:31,  1.34s/it] 20%|‚ñà‚ñâ        | 49/250 [01:11<04:32,  1.36s/it] 20%|‚ñà‚ñà        | 50/250 [01:12<04:24,  1.32s/it] 20%|‚ñà‚ñà        | 51/250 [01:13<04:32,  1.37s/it] 21%|‚ñà‚ñà        | 52/250 [01:15<04:21,  1.32s/it] 21%|‚ñà‚ñà        | 53/250 [01:16<04:27,  1.36s/it] 22%|‚ñà‚ñà‚ñè       | 54/250 [01:17<04:20,  1.33s/it] 22%|‚ñà‚ñà‚ñè       | 55/250 [01:19<04:22,  1.35s/it] 22%|‚ñà‚ñà‚ñè       | 56/250 [01:20<04:16,  1.32s/it] 23%|‚ñà‚ñà‚ñé       | 57/250 [01:21<04:23,  1.37s/it] 23%|‚ñà‚ñà‚ñé       | 58/250 [01:23<04:15,  1.33s/it] 24%|‚ñà‚ñà‚ñé       | 59/250 [01:24<04:20,  1.36s/it] 24%|‚ñà‚ñà‚ñç       | 60/250 [01:25<04:12,  1.33s/it] 24%|‚ñà‚ñà‚ñç       | 61/250 [01:27<04:18,  1.37s/it] 25%|‚ñà‚ñà‚ñç       | 62/250 [01:28<04:08,  1.32s/it] 25%|‚ñà‚ñà‚ñå       | 63/250 [01:30<04:15,  1.37s/it] 26%|‚ñà‚ñà‚ñå       | 64/250 [01:31<04:08,  1.34s/it] 26%|‚ñà‚ñà‚ñå       | 65/250 [01:32<04:12,  1.37s/it] 26%|‚ñà‚ñà‚ñã       | 66/250 [01:33<04:02,  1.32s/it] 27%|‚ñà‚ñà‚ñã       | 67/250 [01:35<04:08,  1.36s/it] 27%|‚ñà‚ñà‚ñã       | 68/250 [01:36<04:03,  1.34s/it] 28%|‚ñà‚ñà‚ñä       | 69/250 [01:38<04:07,  1.37s/it] 28%|‚ñà‚ñà‚ñä       | 70/250 [01:39<03:57,  1.32s/it] 28%|‚ñà‚ñà‚ñä       | 71/250 [01:40<04:03,  1.36s/it] 29%|‚ñà‚ñà‚ñâ       | 72/250 [01:42<03:56,  1.33s/it] 29%|‚ñà‚ñà‚ñâ       | 73/250 [01:43<04:04,  1.38s/it] 30%|‚ñà‚ñà‚ñâ       | 74/250 [01:44<03:57,  1.35s/it] 30%|‚ñà‚ñà‚ñà       | 75/250 [01:46<04:00,  1.38s/it] 30%|‚ñà‚ñà‚ñà       | 76/250 [01:47<03:52,  1.34s/it] 31%|‚ñà‚ñà‚ñà       | 77/250 [01:48<04:00,  1.39s/it] 31%|‚ñà‚ñà‚ñà       | 78/250 [01:50<03:51,  1.35s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 79/250 [01:51<03:53,  1.36s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 80/250 [01:52<03:45,  1.33s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 81/250 [01:54<03:47,  1.35s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 82/250 [01:55<03:43,  1.33s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 83/250 [01:57<03:48,  1.37s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 84/250 [01:58<03:38,  1.31s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 85/250 [01:59<03:40,  1.33s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 86/250 [02:00<03:35,  1.31s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 87/250 [02:02<03:40,  1.35s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 88/250 [02:03<03:35,  1.33s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 89/250 [02:05<03:38,  1.36s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 90/250 [02:06<03:29,  1.31s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 91/250 [02:07<03:33,  1.35s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 92/250 [02:08<03:28,  1.32s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 93/250 [02:10<03:30,  1.34s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 94/250 [02:11<03:29,  1.34s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 95/250 [02:13<03:36,  1.39s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 96/250 [02:14<03:29,  1.36s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 97/250 [02:15<03:32,  1.39s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 98/250 [02:17<03:25,  1.35s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 99/250 [02:18<03:26,  1.36s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 100/250 [02:19<03:17,  1.32s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 101/250 [02:21<03:22,  1.36s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 102/250 [02:22<03:16,  1.32s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 103/250 [02:23<03:17,  1.34s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 104/250 [02:25<03:12,  1.32s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 105/250 [02:26<03:18,  1.37s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 106/250 [02:27<03:12,  1.34s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 107/250 [02:29<03:15,  1.37s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 108/250 [02:30<03:07,  1.32s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 109/250 [02:31<03:09,  1.34s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 110/250 [02:33<03:04,  1.32s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 111/250 [02:34<03:07,  1.35s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 112/250 [02:35<03:02,  1.32s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 113/250 [02:37<03:06,  1.36s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 114/250 [02:38<03:01,  1.33s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 115/250 [02:39<03:03,  1.36s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 116/250 [02:41<02:56,  1.32s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 117/250 [02:42<02:59,  1.35s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 118/250 [02:43<02:54,  1.32s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 119/250 [02:45<02:54,  1.33s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 120/250 [02:46<02:48,  1.30s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 121/250 [02:47<02:52,  1.34s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 122/250 [02:49<02:47,  1.31s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 123/250 [02:50<02:50,  1.34s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 124/250 [02:51<02:45,  1.32s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 125/250 [02:53<02:49,  1.36s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 126/250 [02:54<02:43,  1.32s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 127/250 [02:55<02:46,  1.35s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 128/250 [02:57<02:39,  1.31s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 129/250 [02:58<02:43,  1.35s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 130/250 [02:59<02:36,  1.31s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 131/250 [03:01<02:40,  1.35s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 132/250 [03:02<02:35,  1.32s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 133/250 [03:03<02:36,  1.34s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 134/250 [03:05<02:31,  1.30s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 135/250 [03:06<02:35,  1.35s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 136/250 [03:07<02:30,  1.32s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 137/250 [03:09<02:33,  1.36s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 138/250 [03:10<02:27,  1.32s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 139/250 [03:11<02:30,  1.35s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 140/250 [03:13<02:25,  1.32s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 141/250 [03:14<02:27,  1.36s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 142/250 [03:15<02:22,  1.32s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 143/250 [03:17<02:25,  1.36s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 144/250 [03:18<02:21,  1.33s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 145/250 [03:19<02:21,  1.35s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 146/250 [03:21<02:17,  1.33s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 147/250 [03:22<02:20,  1.36s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 148/250 [03:23<02:16,  1.33s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 149/250 [03:25<02:17,  1.36s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 150/250 [03:26<02:13,  1.34s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 151/250 [03:28<02:16,  1.37s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 152/250 [03:29<02:11,  1.34s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 153/250 [03:30<02:13,  1.37s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 154/250 [03:32<02:08,  1.33s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 155/250 [03:33<02:08,  1.35s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 156/250 [03:34<02:04,  1.33s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 157/250 [03:36<02:06,  1.36s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 158/250 [03:37<02:03,  1.34s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 159/250 [03:38<02:04,  1.36s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 160/250 [03:40<01:58,  1.32s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 161/250 [03:41<02:03,  1.38s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 162/250 [03:42<01:56,  1.33s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 163/250 [03:44<02:00,  1.38s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 164/250 [03:45<01:55,  1.35s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 165/250 [03:47<01:57,  1.38s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 166/250 [03:48<01:51,  1.33s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 167/250 [03:49<01:51,  1.34s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 168/250 [03:50<01:46,  1.30s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 169/250 [03:52<01:47,  1.32s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 170/250 [03:53<01:43,  1.29s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 171/250 [03:54<01:46,  1.35s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 172/250 [03:56<01:42,  1.32s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 173/250 [03:57<01:44,  1.35s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 174/250 [03:58<01:39,  1.31s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 175/250 [04:00<01:40,  1.34s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 176/250 [04:01<01:39,  1.34s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 177/250 [04:03<01:40,  1.38s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 178/250 [04:04<01:36,  1.34s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 179/250 [04:05<01:38,  1.38s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 180/250 [04:07<01:33,  1.34s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 181/250 [04:08<01:33,  1.36s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 182/250 [04:09<01:29,  1.32s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 183/250 [04:11<01:30,  1.36s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 184/250 [04:12<01:27,  1.33s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 185/250 [04:13<01:29,  1.37s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 186/250 [04:15<01:25,  1.34s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 187/250 [04:16<01:26,  1.37s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 188/250 [04:17<01:22,  1.32s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 189/250 [04:19<01:22,  1.35s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 190/250 [04:20<01:19,  1.32s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 191/250 [04:21<01:18,  1.33s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 192/250 [04:22<01:15,  1.31s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 193/250 [04:24<01:15,  1.33s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 194/250 [04:25<01:12,  1.30s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 195/250 [04:27<01:12,  1.33s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 196/250 [04:28<01:09,  1.29s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 197/250 [04:29<01:10,  1.32s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 198/250 [04:30<01:07,  1.29s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 199/250 [04:32<01:07,  1.32s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 200/250 [04:33<01:04,  1.30s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 201/250 [04:34<01:06,  1.35s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 202/250 [04:36<01:03,  1.32s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 203/250 [04:37<01:04,  1.37s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 204/250 [04:38<01:00,  1.32s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 205/250 [04:40<01:00,  1.35s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 206/250 [04:41<00:58,  1.32s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 207/250 [04:43<00:58,  1.36s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 208/250 [04:44<00:55,  1.32s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 209/250 [04:45<00:55,  1.36s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 210/250 [04:46<00:52,  1.32s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 211/250 [04:48<00:52,  1.34s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 212/250 [04:49<00:49,  1.30s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 213/250 [04:50<00:49,  1.34s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 214/250 [04:52<00:47,  1.31s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 215/250 [04:53<00:46,  1.33s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 216/250 [04:54<00:44,  1.31s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 217/250 [04:56<00:44,  1.34s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 218/250 [04:57<00:42,  1.33s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 219/250 [04:59<00:42,  1.37s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 220/250 [05:00<00:40,  1.34s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 221/250 [05:01<00:39,  1.37s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 222/250 [05:02<00:37,  1.34s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 223/250 [05:04<00:36,  1.35s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 224/250 [05:05<00:33,  1.31s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 225/250 [05:06<00:33,  1.34s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 226/250 [05:08<00:31,  1.32s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 227/250 [05:09<00:30,  1.34s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 228/250 [05:10<00:28,  1.30s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 229/250 [05:12<00:28,  1.35s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 230/250 [05:13<00:26,  1.33s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 231/250 [05:15<00:26,  1.37s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 232/250 [05:16<00:24,  1.36s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 233/250 [05:17<00:23,  1.39s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 234/250 [05:19<00:21,  1.33s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 235/250 [05:20<00:20,  1.36s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 236/250 [05:21<00:18,  1.33s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 237/250 [05:23<00:17,  1.36s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 238/250 [05:24<00:16,  1.34s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 239/250 [05:25<00:15,  1.36s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 240/250 [05:27<00:13,  1.32s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 241/250 [05:28<00:12,  1.35s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 242/250 [05:29<00:10,  1.32s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 243/250 [05:31<00:09,  1.35s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 244/250 [05:32<00:07,  1.32s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 245/250 [05:33<00:06,  1.34s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 246/250 [05:35<00:05,  1.30s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 247/250 [05:36<00:03,  1.33s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 248/250 [05:37<00:02,  1.29s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 249/250 [05:39<00:01,  1.33s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:40<00:00,  1.30s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:40<00:00,  1.36s/it]
2025-06-04 20:17:54,965 - INFO - Initial SFT dev set evaluation results: {'eval_loss': 5.923372745513916, 'eval_model_preparation_time': 0.0089, 'eval_runtime': 342.8711, 'eval_samples_per_second': 2.917, 'eval_steps_per_second': 0.729}
2025-06-04 20:17:54,966 - INFO - Starting SFT training...
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,824 | Num Epochs = 4 | Total steps = 980
O^O/ \_/ \    Batch size per device = 32 | Gradient accumulation steps = 1
\        /    Data Parallel GPUs = 1 | Total batch size (32 x 1 x 1) = 32
 "-____-"     Trainable parameters = 159,907,840/6,898,454,528 (2.32% trained)
  0%|          | 0/980 [00:00<?, ?it/s]  0%|          | 1/980 [01:20<21:58:07, 80.78s/it]  0%|          | 2/980 [01:41<12:24:03, 45.65s/it]  0%|          | 3/980 [02:08<10:01:55, 36.97s/it]  0%|          | 4/980 [02:35<8:57:26, 33.04s/it]   1%|          | 5/980 [03:04<8:32:01, 31.51s/it]  1%|          | 6/980 [03:31<8:06:16, 29.96s/it]  1%|          | 7/980 [04:00<8:00:47, 29.65s/it]  1%|          | 8/980 [04:26<7:42:23, 28.54s/it]  1%|          | 9/980 [04:52<7:31:31, 27.90s/it]  1%|          | 10/980 [05:19<7:23:57, 27.46s/it]  1%|          | 11/980 [05:52<7:53:45, 29.34s/it]  1%|          | 12/980 [06:26<8:16:02, 30.75s/it]  1%|‚ñè         | 13/980 [06:54<7:59:13, 29.74s/it]  1%|‚ñè         | 14/980 [07:23<7:54:23, 29.47s/it]  2%|‚ñè         | 15/980 [07:50<7:41:18, 28.68s/it]  2%|‚ñè         | 16/980 [08:17<7:34:13, 28.27s/it]  2%|‚ñè         | 17/980 [08:50<7:55:10, 29.61s/it]  2%|‚ñè         | 18/980 [09:17<7:43:49, 28.93s/it]  2%|‚ñè         | 19/980 [09:44<7:33:23, 28.31s/it]  2%|‚ñè         | 20/980 [10:11<7:25:34, 27.85s/it]                                                    2%|‚ñè         | 20/980 [10:16<7:25:34, 27.85s/it]  2%|‚ñè         | 21/980 [10:37<7:19:17, 27.48s/it]  2%|‚ñè         | 22/980 [11:11<7:47:19, 29.27s/it]  2%|‚ñè         | 23/980 [11:38<7:36:21, 28.61s/it]  2%|‚ñè         | 24/980 [12:06<7:33:35, 28.47s/it]  3%|‚ñé         | 25/980 [12:33<7:24:48, 27.95s/it]  3%|‚ñé         | 26/980 [13:10<8:11:24, 30.91s/it]  3%|‚ñé         | 27/980 [13:37<7:52:27, 29.75s/it]  3%|‚ñé         | 28/980 [14:04<7:39:04, 28.93s/it]  3%|‚ñé         | 29/980 [14:32<7:34:01, 28.65s/it]  3%|‚ñé         | 30/980 [15:00<7:26:38, 28.21s/it]  3%|‚ñé         | 31/980 [15:31<7:38:54, 29.01s/it]  3%|‚ñé         | 32/980 [15:59<7:33:30, 28.70s/it]  3%|‚ñé         | 33/980 [16:25<7:23:48, 28.12s/it]  3%|‚ñé         | 34/980 [16:55<7:31:43, 28.65s/it]  4%|‚ñé         | 35/980 [17:25<7:36:38, 28.99s/it]  4%|‚ñé         | 36/980 [17:52<7:27:26, 28.44s/it]  4%|‚ñç         | 37/9Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.318, 'grad_norm': 0.15234375, 'learning_rate': 2.0408163265306123e-05, 'epoch': 0.08}
{'loss': 0.1866, 'grad_norm': 0.046875, 'learning_rate': 4.0816326530612245e-05, 'epoch': 0.16}
80 [18:19<7:20:21, 28.02s/it]  4%|‚ñç         | 38/980 [18:46<7:13:00, 27.58s/it]  4%|‚ñç         | 39/980 [19:12<7:05:36, 27.14s/it]  4%|‚ñç         | 40/980 [19:38<7:02:40, 26.98s/it]                                                    4%|‚ñç         | 40/980 [19:44<7:02:40, 26.98s/it]  4%|‚ñç         | 41/980 [20:07<7:09:01, 27.41s/it]  4%|‚ñç         | 42/980 [20:34<7:05:08, 27.19s/it]  4%|‚ñç         | 43/980 [21:00<7:01:01, 26.96s/it]  4%|‚ñç         | 44/980 [21:27<7:00:16, 26.94s/it]  5%|‚ñç         | 45/980 [21:58<7:19:44, 28.22s/it]  5%|‚ñç         | 46/980 [22:25<7:12:47, 27.80s/it]  5%|‚ñç         | 47/980 [22:51<7:05:12, 27.34s/it]  5%|‚ñç         | 48/980 [23:18<7:02:51, 27.22s/it]  5%|‚ñå         | 49/980 [23:45<6:58:49, 26.99s/it]  5%|‚ñå         | 50/980 [24:14<7:08:11, 27.63s/it]
  0%|          | 0/250 [00:00<?, ?it/s][A
  1%|          | 2/250 [00:01<02:33,  1.62it/s][A
  1%|          | 3/250 [00:02<04:11,  1.02s/it][A
  2%|‚ñè         | 4/250 [00:04<04:33,  1.11s/it][A
  2%|‚ñè         | 5/250 [00:05<04:56,  1.21s/it][A
  2%|‚ñè         | 6/250 [00:06<04:55,  1.21s/it][A
  3%|‚ñé         | 7/250 [00:08<05:10,  1.28s/it][A
  3%|‚ñé         | 8/250 [00:09<05:10,  1.28s/it][A
  4%|‚ñé         | 9/250 [00:10<05:15,  1.31s/it][A
  4%|‚ñç         | 10/250 [00:12<05:12,  1.30s/it][A
  4%|‚ñç         | 11/250 [00:13<05:21,  1.35s/it][A
  5%|‚ñç         | 12/250 [00:14<05:13,  1.32s/it][A
  5%|‚ñå         | 13/250 [00:16<05:20,  1.35s/it][A
  6%|‚ñå         | 14/250 [00:17<05:09,  1.31s/it][A
  6%|‚ñå         | 15/250 [00:18<05:14,  1.34s/it][A
  6%|‚ñã         | 16/250 [00:20<05:03,  1.30s/it][A
  7%|‚ñã         | 17/250 [00:21<05:09,  1.33s/it][A
  7%|‚ñã         | 18/250 [00:22<05:08,  1.33s/it][A
  8%|‚ñä         | 19/250 [00:24<05:10,  1.34s/it][A
  8%|‚ñä         | 20/250 [00:25<05:00,  1.31s/it][A
  8%|‚ñä         | 21/250 [00:26<05:06,  1.34s/it][A
  9%|‚ñâ         | 22/250 [00:28<05:00,  1.32s/it][A
  9%|‚ñâ         | 23/250 [00:29<05:09,  1.36s/it][A
 10%|‚ñâ         | 24/250 [00:30<04:59,  1.33s/it][A
 10%|‚ñà         | 25/250 [00:32<05:05,  1.36s/it][A
 10%|‚ñà         | 26/250 [00:33<04:58,  1.33s/it][A
 11%|‚ñà         | 27/250 [00:34<05:05,  1.37s/it][A
 11%|‚ñà         | 28/250 [00:36<04:56,  1.33s/it][A
 12%|‚ñà‚ñè        | 29/250 [00:37<05:01,  1.36s/it][A
 12%|‚ñà‚ñè        | 30/250 [00:38<04:52,  1.33s/it][A
 12%|‚ñà‚ñè        | 31/250 [00:40<04:56,  1.35s/it][A
 13%|‚ñà‚ñé        | 32/250 [00:41<04:48,  1.32s/it][A
 13%|‚ñà‚ñé        | 33/250 [00:42<04:53,  1.35s/it][A
 14%|‚ñà‚ñé        | 34/250 [00:44<04:43,  1.31s/it][A
 14%|‚ñà‚ñç        | 35/250 [00:45<04:52,  1.36s/it][A
 14%|‚ñà‚ñç        | 36/250 [00:46<04:44,  1.33s/it][A
 15%|‚ñà‚ñç        | 37/250 [00:48<04:49,  1.36s/it][A
 15%|‚ñà‚ñå        | 38/250 [00:49<04:41,  1.33s/it][A
 16%|‚ñà‚ñå        | 39/250 [00:50<04:46,  1.36s/it][A
 16%|‚ñà‚ñå        | 40/250 [00:52<04:38,  1.33s/it][A
 16%|‚ñà‚ñã        | 41/250 [00:53<04:43,  1.36s/it][A
 17%|‚ñà‚ñã        | 42/250 [00:54<04:37,  1.33s/it][A
 17%|‚ñà‚ñã        | 43/250 [00:56<04:42,  1.36s/it][A
 18%|‚ñà‚ñä        | 44/250 [00:57<04:33,  1.33s/it][A
 18%|‚ñà‚ñä        | 45/250 [00:58<04:36,  1.35s/it][A
 18%|‚ñà‚ñä        | 46/250 [01:00<04:30,  1.33s/it][A
 19%|‚ñà‚ñâ        | 47/250 [01:01<04:33,  1.35s/it][A
 19%|‚ñà‚ñâ        | 48/250 [01:02<04:26,  1.32s/it][A
 20%|‚ñà‚ñâ        | 49/250 [01:04<04:29,  1.34s/it][A
 20%|‚ñà‚ñà        | 50/250 [01:05<04:23,  1.32s/it][A
 20%|‚ñà‚ñà        | 51/250 [01:07<04:31,  1.36s/it][A
 21%|‚ñà‚ñà        | 52/250 [01:08<04:59,  1.52s/it][A
 21%|‚ñà‚ñà        | 53/250 [01:10<04:55,  1.50s/it][A
 22%|‚ñà‚ñà‚ñè       | 54/250 [01:11<04:39,  1.43s/it][A
 22%|‚ñà‚ñà‚ñè       | 55/250 [01:13<04:36,  1.42s/it][A
 22%|‚ñà‚ñà‚ñè       | 56/250 [01:14<04:26,  1.37s/it][A
 23%|‚ñà‚ñà‚ñé       | 57/250 [01:15<04:30,  1.40s/it][A
 23%|‚ñà‚ñà‚ñé       | 58/250 [01:17<04:49,  1.51s/it][A
 24%|‚ñà‚ñà‚ñé       | 59/250 [01:18<04:44,  1.49s/it][A
 24%|‚ñà‚ñà‚ñç       | 60/250 [01:20<04:45,  1.50s/it][A
 24%|‚ñà‚ñà‚ñç       | 61/250 [01:21<04:41,  1.49s/it][A
 25%|‚ñà‚ñà‚ñç       | 62/250 [01:23<04:24,  1.41s/it][A
 25%|‚ñà‚ñà‚ñå       | 63/250 [01:24<04:27,  1.43s/it][A
 26%|‚ñà‚ñà‚ñå       | 64/250 [01:25<04:16,  1.38s/it][A
 26%|‚ñà‚ñà‚ñå       | 65/250 [01:27<04:18,  1.40s/it][A
 26%|‚ñà‚ñà‚ñã       | 66/250 [01:28<04:07,  1.34s/it][A
 27%|‚ñà‚ñà‚ñã       | 67/250 [01:30<04:10,  1.37s/it][A
 27%|‚ñà‚ñà‚ñã       | 68/250 [01:31<04:05,  1.35s/it][A
 28%|‚ñà‚ñà‚ñä       | 69/250 [01:32<04:08,  1.37s/it][A
 28%|‚ñà‚ñà‚ñä       | 70/250 [01:33<03:59,  1.33s/it][A
 28%|‚ñà‚ñà‚ñä       | 71/250 [01:35<04:04,  1.37s/it][A
 29%|‚ñà‚ñà‚ñâ       | 72/250 [01:36<03:58,  1.34s/it][A
 29%|‚ñà‚ñà‚ñâ       | 73/250 [01:38<04:05,  1.39s/it][A
 30%|‚ñà‚ñà‚ñâ       | 74/250 [01:39<03:59,  1.36s/it][A
 30%|‚ñà‚ñà‚ñà       | 75/250 [01:40<04:02,  1.39s/it][A
 30%|‚ñà‚ñà‚ñà       | 76/250 [01:42<03:58,  1.37s/it][A
 31%|‚ñà‚ñà‚ñà       | 77/250 [01:43<04:04,  1.41s/it][A
 31%|‚ñà‚ñà‚ñà       | 78/250 [01:45<03:54,  1.36s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 79/250 [01:46<03:55,  1.38s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 80/250 [01:47<03:49,  1.35s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 81/250 [01:49<03:50,  1.36s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 82/250 [01:50<03:45,  1.34s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 83/250 [01:51<03:49,  1.38s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 84/250 [01:53<03:39,  1.32s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 85/250 [01:54<03:41,  1.34s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 86/250 [01:55<03:37,  1.33s/it][A
 35%|‚ñà‚ñà‚ñà‚ñç      | 87/250 [01:57<03:42,  1.36s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 88/250 [01:58<03:36,  1.34s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 89/250 [01:59<03:39,  1.36s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 90/250 [02:01<03:30,  1.32s/it][A
 36%|‚ñà‚ñà‚ñà‚ñã      | 91/250 [02:02<03:34,  1.35s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 92/250 [02:03<03:28,  1.32s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 93/250 [02:05<03:31,  1.35s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 94/250 [02:06<03:30,  1.35s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 95/250 [02:08<03:36,  1.40s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 96/250 [02:09<03:30,  1.37s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 97/250 [02:10<03:33,  1.40s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 98/250 [02:12<03:26,  1.36s/it][A
 40%|‚ñà‚ñà‚ñà‚ñâ      | 99/250 [02:13<03:27,  1.37s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 100/250 [02:14<03:18,  1.32s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 101/250 [02:16<03:23,  1.36s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 102/250 [02:17<03:17,  1.33s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 103/250 [02:18<03:18,  1.35s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 104/250 [02:20<03:12,  1.32s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 105/250 [02:21<03:17,  1.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 106/250 [02:22<03:12,  1.33s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 107/250 [02:24<03:16,  1.37s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 108/250 [02:25<03:08,  1.32s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 109/250 [02:26<03:09,  1.35s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 110/250 [02:28<03:04,  1.32s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 111/250 [02:29<03:07,  1.35s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 112/250 [02:30<03:03,  1.33s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 113/250 [02:32<03:06,  1.36s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 114/250 [02:33<03:01,  1.34s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 115/250 [02:34<03:04,  1.37s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 116/250 [02:36<02:56,  1.32s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 117/250 [02:37<03:00,  1.35s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 118/250 [02:38<02:54,  1.32s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 119/250 [02:40<02:55,  1.34s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 120/250 [02:41<02:48,  1.30s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 121/250 [02:42<02:53,  1.34s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 122/250 [02:44<02:48,  1.32s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 123/250 [02:45<02:51,  1.35s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 124/250 [02:46<02:46,  1.32s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 125/250 [02:48<02:49,  1.36s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 126/250 [02:49<02:44,  1.32s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 127/250 [02:50<02:46,  1.36s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 128/250 [02:52<02:40,  1.32s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 129/250 [02:53<02:44,  1.36s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 130/250 [02:55<03:13,  1.61s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 131/250 [02:57<03:05,  1.56s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 132/250 [02:58<02:53,  1.47s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 133/250 [02:59<02:49,  1.45s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 134/250 [03:01<02:39,  1.38s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 135/250 [03:02<02:41,  1.41s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 136/250 [03:03<02:35,  1.36s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 137/250 [03:05<02:37,  1.39s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 138/250 [03:07<02:55,  1.56s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 139/250 [03:08<02:49,  1.53s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 140/250 [03:10<02:44,  1.50s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 141/250 [03:11<02:41,  1.48s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 142/250 [03:13<02:50,  1.58s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 143/250 [03:14<02:44,  1.54s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 144/250 [03:16<02:34,  1.46s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 145/250 [03:17<02:31,  1.44s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 146/250 [03:18<02:24,  1.39s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 147/250 [03:20<02:24,  1.41s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 148/250 [03:21<02:21,  1.38s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 149/250 [03:23<02:21,  1.40s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 150/250 [03:24<02:16,  1.36s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 151/250 [03:25<02:17,  1.39s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 152/250 [03:27<02:12,  1.36s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 153/250 [03:28<02:13,  1.38s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 154/250 [03:29<02:08,  1.34s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 155/250 [03:31<02:08,  1.36s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 156/250 [03:32<02:05,  1.33s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 157/250 [03:33<02:07,  1.37s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 158/250 [03:35<02:03,  1.34s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 159/250 [03:36<02:04,  1.37s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 160/250 [03:37<01:59,  1.32s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 161/250 [03:39<02:00,  1.36s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 162/250 [03:40<01:55,  1.31s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 163/250 [03:41<01:59,  1.37s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 164/250 [03:43<01:55,  1.34s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 165/250 [03:44<01:56,  1.38s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 166/250 [03:45<01:51,  1.33s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 167/250 [03:47<01:51,  1.34s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 168/250 [03:48<01:48,  1.32s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 169/250 [03:49<01:48,  1.34s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 170/250 [03:51<01:44,  1.30s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 171/250 [03:52<01:47,  1.35s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 172/250 [03:53<01:43,  1.33s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 173/250 [03:55<01:44,  1.36s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 174/250 [03:56<01:40,  1.32s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 175/250 [03:57<01:41,  1.35s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 176/250 [03:59<01:40,  1.35s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 177/250 [04:00<01:41,  1.39s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 178/250 [04:02<01:37,  1.35s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 179/250 [04:03<01:38,  1.39s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 180/250 [04:04<01:34,  1.35s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 181/250 [04:06<01:34,  1.36s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 182/250 [04:07<01:29,  1.32s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 183/250 [04:08<01:31,  1.36s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 184/250 [04:10<01:27,  1.33s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 185/250 [04:11<01:28,  1.37s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 186/250 [04:12<01:25,  1.33s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 187/250 [04:14<01:26,  1.37s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 188/250 [04:15<01:22,  1.32s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 189/250 [04:16<01:22,  1.35s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 190/250 [04:18<01:19,  1.32s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 191/250 [04:19<01:18,  1.34s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 192/250 [04:20<01:15,  1.31s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 193/250 [04:22<01:16,  1.34s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 194/250 [04:23<01:12,  1.30s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 195/250 [04:24<01:13,  1.33s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 196/250 [04:25<01:10,  1.30s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 197/250 [04:27<01:10,  1.32s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 198/250 [04:28<01:07,  1.30s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 199/250 [04:29<01:07,  1.33s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 200/250 [04:31<01:05,  1.30s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 201/250 [04:32<01:06,  1.36s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 202/250 [04:33<01:03,  1.33s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 203/250 [04:35<01:04,  1.37s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 204/250 [04:36<01:00,  1.32s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 205/250 [04:38<01:01,  1.36s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 206/250 [04:39<00:58,  1.33s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 207/250 [04:40<00:58,  1.36s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 208/250 [04:42<00:55,  1.32s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 209/250 [04:43<00:56,  1.37s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 210/250 [04:44<00:52,  1.32s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 211/250 [04:46<00:52,  1.34s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 212/250 [04:47<00:49,  1.30s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 213/250 [04:48<00:49,  1.34s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 214/250 [04:50<00:47,  1.32s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 215/250 [04:51<00:46,  1.34s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 216/250 [04:52<00:44,  1.31s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 217/250 [04:54<00:44,  1.36s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 218/250 [04:55<00:42,  1.34s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 219/250 [04:56<00:42,  1.38s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 220/250 [04:58<00:40,  1.35s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 221/250 [04:59<00:39,  1.38s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 222/250 [05:00<00:37,  1.34s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 223/250 [05:02<00:36,  1.35s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 224/250 [05:03<00:34,  1.31s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 225/250 [05:04<00:33,  1.35s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 226/250 [05:06<00:31,  1.32s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 227/250 [05:07<00:30,  1.35s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 228/250 [05:08<00:28,  1.31s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 229/250 [05:10<00:28,  1.36s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 230/250 [05:11<00:26,  1.34s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 231/250 [05:13<00:26,  1.38s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 232/250 [05:14<00:24,  1.37s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 233/250 [05:15<00:23,  1.40s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 234/250 [05:17<00:21,  1.34s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 235/250 [05:18<00:20,  1.37s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 236/250 [05:20<00:19,  1.42s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 237/250 [05:21<00:18,  1.43s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 238/250 [05:22<00:16,  1.38s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 239/250 [05:24<00:15,  1.39s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 240/250 [05:25<00:13,  1.34s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 241/250 [05:27<00:13,  1.45s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 242/250 [05:28<00:11,  1.39s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 243/250 [05:29<00:09,  1.40s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 244/250 [05:30<00:08,  1.36s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 245/250 [05:32<00:06,  1.37s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 246/250 [05:33<00:05,  1.32s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 247/250 [05:35<00:04,  1.34s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 248/250 [05:36<00:02,  1.30s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 249/250 [05:37<00:01,  1.34s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:38<00:00,  1.31s/it][A                                                  
                                                 [A  5%|‚ñå         | 50/980 [29:59<7:08:11, 27.63s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:38<00:00,  1.31s/it][A
                                                 [A  5%|‚ñå         | 51/980 [30:47<35:25:12, 137.26s/it]  5%|‚ñå         | 52/980 [31:14<26:51:56, 104.22s/it]  5%|‚ñå         | 53/980 [31:40<20:49:37, 80.88s/it]   6%|‚ñå         | 54/980 [32:07<16:37:02, 64.60s/it]  6%|‚ñå         | 55/980 [32:36<13:50:59, 53.90s/it]  6%|‚ñå         | 56/980 [33:03<11:44:28, 45.75s/it]  6%|‚ñå         | 57/980 [33:29<10:15:29, 40.01s/it]  6%|‚ñå         | 58/980 [33:56<9:15:27, 36.15s/it]   6%|‚ñå         | 59/980 [34:23<8:33:04, 33.42s/it]  6%|‚ñå         | 60/980 [34:50<8:00:07, 31.31s/it]                                                    6%|‚ñå         | 60/980 [34:55<8:00:07, 31.31s/it]  6%|‚ñå         | 61/980 [35:17<7:41:51, 30.15s/it]  6%|‚ñã         | 62/980 [35:45<7:28:25, 29.31s/it]  6%|‚ñã         | 63/980 [36:13<7:22:29, 28.95s/it]  7%|‚ñã         | 64/980 [36:39<7:12:06, 28.30s/it]  7%|‚ñã         | 65/980 [37:06<7:02:30, 27.70s/it]  7%|‚ñã         | 66/980 [37:32<6:57:11, 27.39s/it]  7%|‚ñã         | 67/980 [37:59<6:52:48, 27.13s/it]  7%|‚ñã         | 68/980 [38:26<6:51:35, 27.08s/it]  7%|‚ñã         | 69/980 [38:53<6:49:32, 26.97s/it]  7%|‚ñã         | 70/980 [39:19<6:45:37, 26.74s/it]  7%|‚ñã         | 71/980 [39:46<6:45:36, 26.77s/it]  7%|‚ñã         | 72/980 [40:12<6:44:25, 26.72s/it]  7%|‚ñã         | 73/980 [40:39<6:43:53, 26.72s/it]  8%|‚ñä         | 74/980 [41:06<6:44:56, 26.82s/it]  8%|‚ñä         | 75/980 [41:33<6:44:05, 26.79s/it]  8%|‚ñä         | 76/980 [41:59<6:42:47, 26.73s/it]  8%|‚ñä         | 77/980 [42:26<6:43:30, 26.81s/it]  8%|‚ñä         | 78/980 [42:53<6:42:37, 26.78s/it]  8%|‚ñä         | 79/980 [43:19<6:40:29, 26.67s/it]  8%|‚ñä         | 80/980 [43:46<6:39:17, 26.62s/it]                                                    8%|‚ñä         | 80/980 [43:51<6:39:17, 26.62s/it]  8%|‚ñä         | 81/980 [44:12<6:37:36, 26.54s/it]  8%|‚ñä         | 82/980 [44:39<6:38:48, 26.65s/it]  8%|‚ñä         | 83/980 [45:06<6:37:34, 26.59s/it]  9%|‚ñä         | 84/98{'eval_loss': 0.19631871581077576, 'eval_model_preparation_time': 0.0089, 'eval_runtime': 345.691, 'eval_samples_per_second': 2.893, 'eval_steps_per_second': 0.723, 'epoch': 0.2}
{'loss': 0.1351, 'grad_norm': 0.061767578125, 'learning_rate': 6.122448979591838e-05, 'epoch': 0.24}
{'loss': 0.1158, 'grad_norm': 0.037109375, 'learning_rate': 8.163265306122449e-05, 'epoch': 0.33}
{'loss': 0.1154, 'grad_norm': 0.038330078125, 'learning_rate': 9.999873129474573e-05, 'epoch': 0.41}
0 [45:33<6:39:33, 26.76s/it]  9%|‚ñä         | 85/980 [46:00<6:39:27, 26.78s/it]  9%|‚ñâ         | 86/980 [46:26<6:37:31, 26.68s/it]  9%|‚ñâ         | 87/980 [46:53<6:38:19, 26.76s/it]  9%|‚ñâ         | 88/980 [47:20<6:37:10, 26.72s/it]  9%|‚ñâ         | 89/980 [47:47<6:38:47, 26.85s/it]  9%|‚ñâ         | 90/980 [48:13<6:35:52, 26.69s/it]  9%|‚ñâ         | 91/980 [48:40<6:34:22, 26.62s/it]  9%|‚ñâ         | 92/980 [49:06<6:32:50, 26.54s/it]  9%|‚ñâ         | 93/980 [49:33<6:32:49, 26.57s/it] 10%|‚ñâ         | 94/980 [50:00<6:34:52, 26.74s/it] 10%|‚ñâ         | 95/980 [50:26<6:34:12, 26.73s/it] 10%|‚ñâ         | 96/980 [50:53<6:33:08, 26.68s/it] 10%|‚ñâ         | 97/980 [51:19<6:31:26, 26.60s/it] 10%|‚ñà         | 98/980 [51:46<6:29:07, 26.47s/it] 10%|‚ñà         | 99/980 [52:12<6:29:18, 26.51s/it] 10%|‚ñà         | 100/980 [52:39<6:28:34, 26.49s/it]                                                    10%|‚ñà         | 100/980 [52:44<6:28:34, 26.49s/it]
  0%|          | 0/250 [00:00<?, ?it/s][A
  1%|          | 2/250 [00:01<02:32,  1.63it/s][A
  1%|          | 3/250 [00:02<03:59,  1.03it/s][A
  2%|‚ñè         | 4/250 [00:03<04:25,  1.08s/it][A
  2%|‚ñè         | 5/250 [00:05<04:51,  1.19s/it][A
  2%|‚ñè         | 6/250 [00:06<04:52,  1.20s/it][A
  3%|‚ñé         | 7/250 [00:07<05:08,  1.27s/it][A
  3%|‚ñé         | 8/250 [00:09<05:09,  1.28s/it][A
  4%|‚ñé         | 9/250 [00:10<05:14,  1.31s/it][A
  4%|‚ñç         | 10/250 [00:11<05:12,  1.30s/it][A
  4%|‚ñç         | 11/250 [00:13<05:21,  1.35s/it][A
  5%|‚ñç         | 12/250 [00:14<05:13,  1.32s/it][A
  5%|‚ñå         | 13/250 [00:16<05:20,  1.35s/it][A
  6%|‚ñå         | 14/250 [00:17<05:09,  1.31s/it][A
  6%|‚ñå         | 15/250 [00:18<05:14,  1.34s/it][A
  6%|‚ñã         | 16/250 [00:19<05:03,  1.30s/it][A
  7%|‚ñã         | 17/250 [00:21<05:09,  1.33s/it][A
  7%|‚ñã         | 18/250 [00:22<05:06,  1.32s/it][A
  8%|‚ñä         | 19/250 [00:23<05:10,  1.34s/it][A
  8%|‚ñä         | 20/250 [00:25<04:59,  1.30s/it][A
  8%|‚ñä         | 21/250 [00:26<05:06,  1.34s/it][A
  9%|‚ñâ         | 22/250 [00:27<05:00,  1.32s/it][A
  9%|‚ñâ         | 23/250 [00:29<05:09,  1.36s/it][A
 10%|‚ñâ         | 24/250 [00:30<04:59,  1.33s/it][A
 10%|‚ñà         | 25/250 [00:32<05:05,  1.36s/it][A
 10%|‚ñà         | 26/250 [00:33<04:57,  1.33s/it][A
 11%|‚ñà         | 27/250 [00:34<05:03,  1.36s/it][A
 11%|‚ñà         | 28/250 [00:35<04:54,  1.33s/it][A
 12%|‚ñà‚ñè        | 29/250 [00:37<05:00,  1.36s/it][A
 12%|‚ñà‚ñè        | 30/250 [00:38<04:52,  1.33s/it][A
 12%|‚ñà‚ñè        | 31/250 [00:40<04:55,  1.35s/it][A
 13%|‚ñà‚ñé        | 32/250 [00:41<04:47,  1.32s/it][A
 13%|‚ñà‚ñé        | 33/250 [00:42<04:53,  1.35s/it][A
 14%|‚ñà‚ñé        | 34/250 [00:43<04:43,  1.31s/it][A
 14%|‚ñà‚ñç        | 35/250 [00:45<04:52,  1.36s/it][A
 14%|‚ñà‚ñç        | 36/250 [00:46<04:44,  1.33s/it][A
 15%|‚ñà‚ñç        | 37/250 [00:48<04:49,  1.36s/it][A
 15%|‚ñà‚ñå        | 38/250 [00:49<04:41,  1.33s/it][A
 16%|‚ñà‚ñå        | 39/250 [00:50<04:47,  1.36s/it][A
 16%|‚ñà‚ñå        | 40/250 [00:52<04:38,  1.33s/it][A
 16%|‚ñà‚ñã        | 41/250 [00:53<04:44,  1.36s/it][A
 17%|‚ñà‚ñã        | 42/250 [00:54<04:37,  1.33s/it][A
 17%|‚ñà‚ñã        | 43/250 [00:56<04:42,  1.37s/it][A
 18%|‚ñà‚ñä        | 44/250 [00:57<04:34,  1.33s/it][A
 18%|‚ñà‚ñä        | 45/250 [00:58<04:36,  1.35s/it][A
 18%|‚ñà‚ñä        | 46/250 [01:00<04:30,  1.33s/it][A
 19%|‚ñà‚ñâ        | 47/250 [01:01<04:33,  1.35s/it][A
 19%|‚ñà‚ñâ        | 48/250 [01:02<04:26,  1.32s/it][A
 20%|‚ñà‚ñâ        | 49/250 [01:04<04:29,  1.34s/it][A
 20%|‚ñà‚ñà        | 50/250 [01:05<04:23,  1.32s/it][A
 20%|‚ñà‚ñà        | 51/250 [01:06<04:31,  1.36s/it][A
 21%|‚ñà‚ñà        | 52/250 [01:08<04:21,  1.32s/it][A
 21%|‚ñà‚ñà        | 53/250 [01:09<04:28,  1.36s/it][A
 22%|‚ñà‚ñà‚ñè       | 54/250 [01:10<04:20,  1.33s/it][A
 22%|‚ñà‚ñà‚ñè       | 55/250 [01:12<04:23,  1.35s/it][A
 22%|‚ñà‚ñà‚ñè       | 56/250 [01:13<04:17,  1.33s/it][A
 23%|‚ñà‚ñà‚ñé       | 57/250 [01:14<04:24,  1.37s/it][A
 23%|‚ñà‚ñà‚ñé       | 58/250 [01:16<04:16,  1.33s/it][A
 24%|‚ñà‚ñà‚ñé       | 59/250 [01:17<04:20,  1.37s/it][A
 24%|‚ñà‚ñà‚ñç       | 60/250 [01:18<04:12,  1.33s/it][A
 24%|‚ñà‚ñà‚ñç       | 61/250 [01:20<04:18,  1.37s/it][A
 25%|‚ñà‚ñà‚ñç       | 62/250 [01:21<04:08,  1.32s/it][A
 25%|‚ñà‚ñà‚ñå       | 63/250 [01:23<04:16,  1.37s/it][A
 26%|‚ñà‚ñà‚ñå       | 64/250 [01:24<04:09,  1.34s/it][A
 26%|‚ñà‚ñà‚ñå       | 65/250 [01:25<04:13,  1.37s/it][A
 26%|‚ñà‚ñà‚ñã       | 66/250 [01:26<04:03,  1.32s/it][A
 27%|‚ñà‚ñà‚ñã       | 67/250 [01:28<04:08,  1.36s/it][A
 27%|‚ñà‚ñà‚ñã       | 68/250 [01:29<04:03,  1.34s/it][A
 28%|‚ñà‚ñà‚ñä       | 69/250 [01:31<04:07,  1.37s/it][A
 28%|‚ñà‚ñà‚ñä       | 70/250 [01:32<03:57,  1.32s/it][A
 28%|‚ñà‚ñà‚ñä       | 71/250 [01:33<04:03,  1.36s/it][A
 29%|‚ñà‚ñà‚ñâ       | 72/250 [01:35<03:57,  1.33s/it][A
 29%|‚ñà‚ñà‚ñâ       | 73/250 [01:36<04:05,  1.39s/it][A
 30%|‚ñà‚ñà‚ñâ       | 74/250 [01:37<03:57,  1.35s/it][A
 30%|‚ñà‚ñà‚ñà       | 75/250 [01:39<04:01,  1.38s/it][A
 30%|‚ñà‚ñà‚ñà       | 76/250 [01:40<03:53,  1.34s/it][A
 31%|‚ñà‚ñà‚ñà       | 77/250 [01:42<04:01,  1.39s/it][A
 31%|‚ñà‚ñà‚ñà       | 78/250 [01:43<03:52,  1.35s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 79/250 [01:44<03:53,  1.37s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 80/250 [01:46<03:46,  1.33s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 81/250 [01:47<03:48,  1.35s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 82/250 [01:48<03:44,  1.34s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 83/250 [01:50<03:49,  1.37s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 84/250 [01:51<03:38,  1.32s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 85/250 [01:52<03:40,  1.34s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 86/250 [01:54<03:36,  1.32s/it][A
 35%|‚ñà‚ñà‚ñà‚ñç      | 87/250 [01:55<03:41,  1.36s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 88/250 [01:56<03:36,  1.33s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 89/250 [01:58<03:39,  1.36s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 90/250 [01:59<03:30,  1.32s/it][A
 36%|‚ñà‚ñà‚ñà‚ñã      | 91/250 [02:00<03:34,  1.35s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 92/250 [02:02<03:28,  1.32s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 93/250 [02:03<03:31,  1.35s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 94/250 [02:04<03:30,  1.35s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 95/250 [02:06<03:36,  1.40s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 96/250 [02:07<03:29,  1.36s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 97/250 [02:09<03:33,  1.39s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 98/250 [02:10<03:26,  1.36s/it][A
 40%|‚ñà‚ñà‚ñà‚ñâ      | 99/250 [02:11<03:26,  1.37s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 100/250 [02:12<03:18,  1.32s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 101/250 [02:14<03:22,  1.36s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 102/250 [02:15<03:16,  1.33s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 103/250 [02:17<03:18,  1.35s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 104/250 [02:18<03:12,  1.32s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 105/250 [02:19<03:17,  1.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 106/250 [02:21<03:12,  1.33s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 107/250 [02:22<03:16,  1.37s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 108/250 [02:23<03:08,  1.32s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 109/250 [02:25<03:09,  1.35s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 110/250 [02:26<03:04,  1.32s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 111/250 [02:27<03:09,  1.36s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 112/250 [02:29<03:04,  1.33s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 113/250 [02:30<03:07,  1.37s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 114/250 [02:31<03:02,  1.34s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 115/250 [02:33<03:04,  1.37s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 116/250 [02:34<02:57,  1.32s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 117/250 [02:35<03:00,  1.36s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 118/250 [02:37<02:55,  1.33s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 119/250 [02:38<02:55,  1.34s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 120/250 [02:39<02:49,  1.30s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 121/250 [02:41<02:53,  1.35s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 122/250 [02:42<02:48,  1.32s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 123/250 [02:43<02:51,  1.35s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 124/250 [02:45<02:46,  1.32s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 125/250 [02:46<02:50,  1.36s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 126/250 [02:47<02:44,  1.32s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 127/250 [02:49<02:46,  1.36s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 128/250 [02:50<02:40,  1.31s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 129/250 [02:51<02:44,  1.36s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 130/250 [02:53<02:36,  1.31s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 131/250 [02:54<02:40,  1.35s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 132/250 [02:55<02:36,  1.32s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 133/250 [02:57<02:37,  1.34s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 134/250 [02:58<02:31,  1.31s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 135/250 [02:59<02:36,  1.36s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 136/250 [03:01<02:31,  1.33s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 137/250 [03:02<02:34,  1.37s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 138/250 [03:03<02:27,  1.32s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 139/250 [03:05<02:30,  1.36s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 140/250 [03:06<02:25,  1.33s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 141/250 [03:07<02:28,  1.36s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 142/250 [03:09<02:23,  1.33s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 143/250 [03:10<02:25,  1.36s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 144/250 [03:11<02:21,  1.33s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 145/250 [03:13<02:22,  1.35s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 146/250 [03:14<02:18,  1.33s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 147/250 [03:16<02:20,  1.37s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 148/250 [03:17<02:16,  1.34s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 149/250 [03:18<02:18,  1.37s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 150/250 [03:20<02:14,  1.34s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 151/250 [03:21<02:16,  1.38s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 152/250 [03:22<02:12,  1.35s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 153/250 [03:24<02:13,  1.38s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 154/250 [03:25<02:08,  1.34s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 155/250 [03:26<02:08,  1.36s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 156/250 [03:28<02:05,  1.33s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 157/250 [03:29<02:07,  1.37s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 158/250 [03:30<02:03,  1.35s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 159/250 [03:32<02:04,  1.37s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 160/250 [03:33<01:59,  1.32s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 161/250 [03:34<02:01,  1.36s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 162/250 [03:36<01:55,  1.31s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 163/250 [03:37<01:59,  1.37s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 164/250 [03:38<01:55,  1.34s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 165/250 [03:40<01:57,  1.38s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 166/250 [03:41<01:51,  1.33s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 167/250 [03:43<01:51,  1.34s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 168/250 [03:44<01:47,  1.31s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 169/250 [03:45<01:47,  1.32s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 170/250 [03:46<01:43,  1.29s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 171/250 [03:48<01:46,  1.35s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 172/250 [03:49<01:43,  1.32s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 173/250 [03:51<01:44,  1.36s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 174/250 [03:52<01:39,  1.31s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 175/250 [03:53<01:41,  1.35s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 176/250 [03:54<01:39,  1.35s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 177/250 [03:56<01:41,  1.39s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 178/250 [03:57<01:36,  1.35s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 179/250 [03:59<01:40,  1.41s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 180/250 [04:00<01:35,  1.37s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 181/250 [04:01<01:35,  1.38s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 182/250 [04:03<01:30,  1.33s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 183/250 [04:04<01:31,  1.37s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 184/250 [04:05<01:28,  1.33s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 185/250 [04:07<01:29,  1.37s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 186/250 [04:08<01:25,  1.34s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 187/250 [04:10<01:26,  1.37s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 188/250 [04:11<01:22,  1.32s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 189/250 [04:12<01:22,  1.35s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 190/250 [04:13<01:19,  1.33s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 191/250 [04:15<01:19,  1.34s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 192/250 [04:16<01:16,  1.31s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 193/250 [04:17<01:16,  1.34s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 194/250 [04:19<01:12,  1.30s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 195/250 [04:20<01:13,  1.33s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 196/250 [04:21<01:10,  1.30s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 197/250 [04:23<01:10,  1.33s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 198/250 [04:24<01:07,  1.29s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 199/250 [04:25<01:07,  1.32s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 200/250 [04:27<01:05,  1.30s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 201/250 [04:28<01:06,  1.36s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 202/250 [04:29<01:03,  1.32s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 203/250 [04:31<01:04,  1.37s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 204/250 [04:32<01:00,  1.32s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 205/250 [04:33<01:01,  1.36s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 206/250 [04:35<00:58,  1.33s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 207/250 [04:36<00:58,  1.36s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 208/250 [04:37<00:55,  1.32s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 209/250 [04:39<00:56,  1.37s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 210/250 [04:40<00:52,  1.32s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 211/250 [04:41<00:52,  1.34s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 212/250 [04:43<00:49,  1.30s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 213/250 [04:44<00:49,  1.34s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 214/250 [04:45<00:47,  1.32s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 215/250 [04:47<00:46,  1.34s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 216/250 [04:48<00:44,  1.31s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 217/250 [04:49<00:44,  1.35s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 218/250 [04:51<00:42,  1.33s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 219/250 [04:52<00:42,  1.38s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 220/250 [04:53<00:40,  1.34s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 221/250 [04:55<00:39,  1.37s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 222/250 [04:56<00:37,  1.34s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 223/250 [04:58<00:36,  1.35s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 224/250 [04:59<00:34,  1.31s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 225/250 [05:00<00:33,  1.35s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 226/250 [05:01<00:31,  1.32s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 227/250 [05:03<00:30,  1.34s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 228/250 [05:04<00:28,  1.30s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 229/250 [05:06<00:28,  1.36s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 230/250 [05:07<00:26,  1.33s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 231/250 [05:08<00:26,  1.38s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 232/250 [05:10<00:24,  1.36s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 233/250 [05:11<00:23,  1.39s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 234/250 [05:12<00:21,  1.34s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 235/250 [05:14<00:20,  1.37s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 236/250 [05:15<00:18,  1.34s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 237/250 [05:16<00:17,  1.37s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 238/250 [05:18<00:16,  1.35s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 239/250 [05:19<00:15,  1.38s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 240/250 [05:20<00:13,  1.33s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 241/250 [05:22<00:12,  1.36s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 242/250 [05:23<00:10,  1.33s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 243/250 [05:25<00:09,  1.36s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 244/250 [05:26<00:07,  1.33s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 245/250 [05:27<00:06,  1.35s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 246/250 [05:28<00:05,  1.31s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 247/250 [05:30<00:04,  1.34s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 248/250 [05:31<00:02,  1.29s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 249/250 [05:32<00:01,  1.34s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:34<00:00,  1.30s/it][A                                                   
                                                 [A 10%|‚ñà         | 100/980 [58:20<6:28:34, 26.49s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:34<00:00,  1.30s/it][A
                                                 [A 10%|‚ñà         | 101/980 [58:52<31:54:33, 130.69s/it] 10%|‚ñà         | 102/980 [59:19<24:17:22, 99.59s/it]  11%|‚ñà         | 103/980 [59:46<18:55:26, 77.68s/it] 11%|‚ñà         | 104/980 [1:00:13<15:10:38, 62.37s/it] 11%|‚ñà         | 105/980 [1:00:40<12:34:53, 51.76s/it] 11%|‚ñà         | 106/980 [1:01:07<10:46:59, 44.42s/it] 11%|‚ñà         | 107/980 [1:01:33<9:27:41, 39.02s/it]  11%|‚ñà         | 108/980 [1:02:00<8:30:49, 35.15s/it] 11%|‚ñà         | 109/980 [1:02:26<7:51:49, 32.50s/it] 11%|‚ñà         | 110/980 [1:02:52<7:25:32, 30.73s/it] 11%|‚ñà‚ñè        | 111/980 [1:03:20<7:10:44, 29.74s/it] 11%|‚ñà‚ñè        | 112/980 [1:03:46<6:56:38, 28.80s/it] 12%|‚ñà‚ñè        | 113/980 [1:04:13<6:47:13, 28.18s/it] 12%|‚ñà‚ñè        | 114/980 [1:04:40<6:40:36, 27.76s/it] 12%|‚ñà‚ñè        | 115/980 [1:05:07<6:36:06, 27.48s/it] 12%|‚ñà‚ñè        | 116/980 [1:05:33<6:28:38, 26.99s/it] 12%|‚ñà‚ñè        | 117/980 [1:06:00<6:28:04, 26.98s/it] 12%|‚ñà‚ñè        | 118/980 [1:06:26<6:26:55, 26.93s/it] 12%|‚ñà‚ñè        | 119/980 [1:06:54<6:27:24, 27.00s/it] 12%|‚ñà‚ñè        | 120/980 [1:07:20<6:25:52, 26.92s/it]                                                      12%|‚ñà‚ñè        | 120/980 [1:07:26<6:25:52, 26.92s/it] 12%|‚ñà‚ñè        | 121/980 [1:07:48<6:26:57, 27.03s/it] 12%|‚ñà‚ñè        | 122/980 [1:08:14<6:24:54, 26.92s/it] 13%|‚ñà‚ñé        | 123/980 [1:08:41<6:22:44, 26.80s/it] 13%|‚ñà‚ñé        | 124/980 [1:09:09<6:27:04, 27.13s/it] 13%|‚ñà‚ñé        | 125/980 [1:09:36<6:25:45, 27.07s/it] 13%|‚ñà‚ñé        | 126/980 [1:10:02<6:21:50, 26.83s/it] 13%|‚ñà‚ñé        | 127/980 [1:10:28<6:20:03, 26.73s/it] 13%|‚ñà‚ñé        | 128/980 [1:10:55<6:18:47, 26.68s/it] 13%|‚ñà‚ñé        | 129/980 [1:11:21<6:17:10, 26.59s/it] 13%|‚ñà‚ñé        | 130/980 [1:11:48<6:16:54, 26.61s/it] 13%|‚ñà‚ñé        | 131/980 [1:12:14<6:15:13, 26.52s/it] 13%|‚ñà‚ñé        | 132/980 [1:12:41<6:14:58, 26.53s/it] 14%|‚ñà‚ñé        | 133/980 [1:13:07<6:13:43, 26.47s/it] 14%|‚ñà‚ñé        | 134/980 [1:13:33<6:10:39, 26.29s/it] 14%|‚ñà‚ñç        | 135/980 [1:14:00<6:11:12, 26.36s/it] 14%|‚ñà‚ñç        | 136/980 [1:14:26<6:12:17, 26.47s/it] 14%|‚ñà‚ñç        | 137/980 [1:14:53<6:14:25, 26.65s/it] 14%|‚ñà‚ñç        | 138/980 [1:15:20<6:14:33, 26.69s/it] 14%|‚ñà‚ñç        | 139/980 [1:15:47<6:13:38, 26.66s/it] 14%|‚ñà‚ñç        | 140/980 [1:16:13<6:11:54, 26.56s/it]                                                      14%|‚ñà‚ñç        | 140/980 [1:16:18<6:11:54, 26.56s/it] 14%|‚ñà‚ñç        | 141/980 [1:16:40<6:11:23, 26.56s/it] 14%|‚ñà‚ñç        | 142/980 [1:17:06<6:08:25, 26.38s/it] 15%|‚ñà‚ñç        | 143/980 [1:17:32<6:08:11, 26.39s/it] 15%|‚ñà‚ñç        | 144/980 [1:17:59<6:08:57, 26.48s/it] 15%|‚ñà‚ñç        | 145/980 [1:18:25<6:08:02, 26.45s/it] 15%|‚ñà‚ñç        | 146/980 [1:18:51<6:06:51, 26.39s/it] 15%|‚ñà‚ñå        | 147/980 [1:19:18<6:07:35, 26.48s/it] 15%|‚ñà‚ñå        | 148/980 [1:19:44<6:06:11, 26.41s/it] 15%|‚ñà‚ñå        | 149/{'eval_loss': 0.15585429966449738, 'eval_model_preparation_time': 0.0089, 'eval_runtime': 335.5736, 'eval_samples_per_second': 2.98, 'eval_steps_per_second': 0.745, 'epoch': 0.41}
{'loss': 0.1164, 'grad_norm': 0.033203125, 'learning_rate': 9.984656455408591e-05, 'epoch': 0.49}
{'loss': 0.1029, 'grad_norm': 0.038818359375, 'learning_rate': 9.944154131125642e-05, 'epoch': 0.57}
980 [1:20:11<6:06:28, 26.46s/it] 15%|‚ñà‚ñå        | 150/980 [1:20:38<6:07:00, 26.53s/it]
  0%|          | 0/250 [00:00<?, ?it/s][A
  1%|          | 2/250 [00:01<02:31,  1.63it/s][A
  1%|          | 3/250 [00:02<03:59,  1.03it/s][A
  2%|‚ñè         | 4/250 [00:03<04:25,  1.08s/it][A
  2%|‚ñè         | 5/250 [00:05<04:51,  1.19s/it][A
  2%|‚ñè         | 6/250 [00:06<04:52,  1.20s/it][A
  3%|‚ñé         | 7/250 [00:07<05:08,  1.27s/it][A
  3%|‚ñé         | 8/250 [00:09<05:09,  1.28s/it][A
  4%|‚ñé         | 9/250 [00:10<05:14,  1.31s/it][A
  4%|‚ñç         | 10/250 [00:11<05:12,  1.30s/it][A
  4%|‚ñç         | 11/250 [00:13<05:21,  1.35s/it][A
  5%|‚ñç         | 12/250 [00:14<05:13,  1.32s/it][A
  5%|‚ñå         | 13/250 [00:16<05:20,  1.35s/it][A
  6%|‚ñå         | 14/250 [00:17<05:09,  1.31s/it][A
  6%|‚ñå         | 15/250 [00:18<05:14,  1.34s/it][A
  6%|‚ñã         | 16/250 [00:19<05:03,  1.30s/it][A
  7%|‚ñã         | 17/250 [00:21<05:09,  1.33s/it][A
  7%|‚ñã         | 18/250 [00:22<05:05,  1.32s/it][A
  8%|‚ñä         | 19/250 [00:23<05:10,  1.34s/it][A
  8%|‚ñä         | 20/250 [00:25<04:59,  1.30s/it][A
  8%|‚ñä         | 21/250 [00:26<05:06,  1.34s/it][A
  9%|‚ñâ         | 22/250 [00:27<05:00,  1.32s/it][A
  9%|‚ñâ         | 23/250 [00:29<05:09,  1.36s/it][A
 10%|‚ñâ         | 24/250 [00:30<04:59,  1.33s/it][A
 10%|‚ñà         | 25/250 [00:32<05:06,  1.36s/it][A
 10%|‚ñà         | 26/250 [00:33<04:57,  1.33s/it][A
 11%|‚ñà         | 27/250 [00:34<05:03,  1.36s/it][A
 11%|‚ñà         | 28/250 [00:35<04:54,  1.33s/it][A
 12%|‚ñà‚ñè        | 29/250 [00:37<05:00,  1.36s/it][A
 12%|‚ñà‚ñè        | 30/250 [00:38<04:52,  1.33s/it][A
 12%|‚ñà‚ñè        | 31/250 [00:40<04:55,  1.35s/it][A
 13%|‚ñà‚ñé        | 32/250 [00:41<04:47,  1.32s/it][A
 13%|‚ñà‚ñé        | 33/250 [00:42<04:53,  1.35s/it][A
 14%|‚ñà‚ñé        | 34/250 [00:43<04:43,  1.31s/it][A
 14%|‚ñà‚ñç        | 35/250 [00:45<04:52,  1.36s/it][A
 14%|‚ñà‚ñç        | 36/250 [00:46<04:44,  1.33s/it][A
 15%|‚ñà‚ñç        | 37/250 [00:48<04:49,  1.36s/it][A
 15%|‚ñà‚ñå        | 38/250 [00:49<04:41,  1.33s/it][A
 16%|‚ñà‚ñå        | 39/250 [00:50<04:47,  1.36s/it][A
 16%|‚ñà‚ñå        | 40/250 [00:52<04:38,  1.33s/it][A
 16%|‚ñà‚ñã        | 41/250 [00:53<04:44,  1.36s/it][A
 17%|‚ñà‚ñã        | 42/250 [00:54<04:37,  1.33s/it][A
 17%|‚ñà‚ñã        | 43/250 [00:56<04:42,  1.36s/it][A
 18%|‚ñà‚ñä        | 44/250 [00:57<04:33,  1.33s/it][A
 18%|‚ñà‚ñä        | 45/250 [00:58<04:36,  1.35s/it][A
 18%|‚ñà‚ñä        | 46/250 [01:00<04:30,  1.33s/it][A
 19%|‚ñà‚ñâ        | 47/250 [01:01<04:33,  1.35s/it][A
 19%|‚ñà‚ñâ        | 48/250 [01:02<04:26,  1.32s/it][A
 20%|‚ñà‚ñâ        | 49/250 [01:04<04:29,  1.34s/it][A
 20%|‚ñà‚ñà        | 50/250 [01:05<04:23,  1.32s/it][A
 20%|‚ñà‚ñà        | 51/250 [01:06<04:31,  1.36s/it][A
 21%|‚ñà‚ñà        | 52/250 [01:08<04:21,  1.32s/it][A
 21%|‚ñà‚ñà        | 53/250 [01:09<04:28,  1.36s/it][A
 22%|‚ñà‚ñà‚ñè       | 54/250 [01:10<04:20,  1.33s/it][A
 22%|‚ñà‚ñà‚ñè       | 55/250 [01:12<04:23,  1.35s/it][A
 22%|‚ñà‚ñà‚ñè       | 56/250 [01:13<04:16,  1.32s/it][A
 23%|‚ñà‚ñà‚ñé       | 57/250 [01:14<04:24,  1.37s/it][A
 23%|‚ñà‚ñà‚ñé       | 58/250 [01:16<04:15,  1.33s/it][A
 24%|‚ñà‚ñà‚ñé       | 59/250 [01:17<04:20,  1.37s/it][A
 24%|‚ñà‚ñà‚ñç       | 60/250 [01:18<04:12,  1.33s/it][A
 24%|‚ñà‚ñà‚ñç       | 61/250 [01:20<04:18,  1.37s/it][A
 25%|‚ñà‚ñà‚ñç       | 62/250 [01:21<04:08,  1.32s/it][A
 25%|‚ñà‚ñà‚ñå       | 63/250 [01:23<04:16,  1.37s/it][A
 26%|‚ñà‚ñà‚ñå       | 64/250 [01:24<04:09,  1.34s/it][A
 26%|‚ñà‚ñà‚ñå       | 65/250 [01:25<04:13,  1.37s/it][A
 26%|‚ñà‚ñà‚ñã       | 66/250 [01:26<04:03,  1.32s/it][A
 27%|‚ñà‚ñà‚ñã       | 67/250 [01:28<04:08,  1.36s/it][A
 27%|‚ñà‚ñà‚ñã       | 68/250 [01:29<04:03,  1.34s/it][A
 28%|‚ñà‚ñà‚ñä       | 69/250 [01:31<04:07,  1.37s/it][A
 28%|‚ñà‚ñà‚ñä       | 70/250 [01:32<03:58,  1.32s/it][A
 28%|‚ñà‚ñà‚ñä       | 71/250 [01:33<04:03,  1.36s/it][A
 29%|‚ñà‚ñà‚ñâ       | 72/250 [01:35<03:57,  1.33s/it][A
 29%|‚ñà‚ñà‚ñâ       | 73/250 [01:36<04:05,  1.39s/it][A
 30%|‚ñà‚ñà‚ñâ       | 74/250 [01:37<03:57,  1.35s/it][A
 30%|‚ñà‚ñà‚ñà       | 75/250 [01:39<04:01,  1.38s/it][A
 30%|‚ñà‚ñà‚ñà       | 76/250 [01:40<03:53,  1.34s/it][A
 31%|‚ñà‚ñà‚ñà       | 77/250 [01:42<04:01,  1.39s/it][A
 31%|‚ñà‚ñà‚ñà       | 78/250 [01:43<03:52,  1.35s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 79/250 [01:44<03:53,  1.37s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 80/250 [01:45<03:46,  1.33s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 81/250 [01:47<03:48,  1.35s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 82/250 [01:48<03:44,  1.34s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 83/250 [01:50<03:48,  1.37s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 84/250 [01:51<03:38,  1.32s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 85/250 [01:52<03:40,  1.34s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 86/250 [01:53<03:36,  1.32s/it][A
 35%|‚ñà‚ñà‚ñà‚ñç      | 87/250 [01:55<03:41,  1.36s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 88/250 [01:56<03:35,  1.33s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 89/250 [01:58<03:39,  1.36s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 90/250 [01:59<03:30,  1.32s/it][A
 36%|‚ñà‚ñà‚ñà‚ñã      | 91/250 [02:00<03:34,  1.35s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 92/250 [02:02<03:28,  1.32s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 93/250 [02:03<03:31,  1.35s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 94/250 [02:04<03:29,  1.35s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 95/250 [02:06<03:36,  1.40s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 96/250 [02:07<03:29,  1.36s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 97/250 [02:09<03:33,  1.39s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 98/250 [02:10<03:25,  1.35s/it][A
 40%|‚ñà‚ñà‚ñà‚ñâ      | 99/250 [02:11<03:26,  1.37s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 100/250 [02:12<03:18,  1.32s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 101/250 [02:14<03:22,  1.36s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 102/250 [02:15<03:16,  1.33s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 103/250 [02:17<03:18,  1.35s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 104/250 [02:18<03:12,  1.32s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 105/250 [02:19<03:17,  1.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 106/250 [02:21<03:11,  1.33s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 107/250 [02:22<03:15,  1.37s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 108/250 [02:23<03:08,  1.33s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 109/250 [02:25<03:09,  1.35s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 110/250 [02:26<03:04,  1.32s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 111/250 [02:27<03:07,  1.35s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 112/250 [02:29<03:02,  1.33s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 113/250 [02:30<03:06,  1.36s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 114/250 [02:31<03:01,  1.33s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 115/250 [02:33<03:04,  1.37s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 116/250 [02:34<02:56,  1.32s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 117/250 [02:35<03:00,  1.36s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 118/250 [02:37<02:54,  1.32s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 119/250 [02:38<02:55,  1.34s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 120/250 [02:39<02:48,  1.30s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 121/250 [02:41<02:53,  1.34s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 122/250 [02:42<02:48,  1.32s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 123/250 [02:43<02:51,  1.35s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 124/250 [02:45<02:46,  1.32s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 125/250 [02:46<02:50,  1.36s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 126/250 [02:47<02:44,  1.32s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 127/250 [02:49<02:47,  1.36s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 128/250 [02:50<02:40,  1.31s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 129/250 [02:51<02:44,  1.36s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 130/250 [02:53<02:37,  1.31s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 131/250 [02:54<02:41,  1.35s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 132/250 [02:55<02:36,  1.32s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 133/250 [02:57<02:37,  1.35s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 134/250 [02:58<02:31,  1.31s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 135/250 [02:59<02:36,  1.36s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 136/250 [03:01<02:31,  1.33s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 137/250 [03:02<02:34,  1.37s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 138/250 [03:03<02:28,  1.32s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 139/250 [03:05<02:30,  1.36s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 140/250 [03:06<02:25,  1.33s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 141/250 [03:07<02:28,  1.36s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 142/250 [03:09<02:23,  1.33s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 143/250 [03:10<02:25,  1.36s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 144/250 [03:11<02:21,  1.33s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 145/250 [03:13<02:22,  1.35s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 146/250 [03:14<02:18,  1.33s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 147/250 [03:15<02:20,  1.37s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 148/250 [03:17<02:16,  1.34s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 149/250 [03:18<02:18,  1.37s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 150/250 [03:19<02:14,  1.34s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 151/250 [03:21<02:16,  1.38s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 152/250 [03:22<02:11,  1.35s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 153/250 [03:24<02:13,  1.37s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 154/250 [03:25<02:08,  1.34s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 155/250 [03:26<02:08,  1.36s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 156/250 [03:28<02:05,  1.33s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 157/250 [03:29<02:07,  1.37s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 158/250 [03:30<02:03,  1.34s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 159/250 [03:32<02:04,  1.37s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 160/250 [03:33<01:59,  1.32s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 161/250 [03:34<02:00,  1.36s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 162/250 [03:36<01:55,  1.31s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 163/250 [03:37<01:59,  1.37s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 164/250 [03:38<01:55,  1.34s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 165/250 [03:40<01:56,  1.38s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 166/250 [03:41<01:51,  1.33s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 167/250 [03:42<01:51,  1.34s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 168/250 [03:44<01:46,  1.30s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 169/250 [03:45<01:47,  1.32s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 170/250 [03:46<01:43,  1.29s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 171/250 [03:48<01:46,  1.35s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 172/250 [03:49<01:43,  1.32s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 173/250 [03:50<01:44,  1.36s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 174/250 [03:52<01:39,  1.31s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 175/250 [03:53<01:41,  1.35s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 176/250 [03:54<01:39,  1.35s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 177/250 [03:56<01:41,  1.39s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 178/250 [03:57<01:36,  1.35s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 179/250 [03:59<01:38,  1.39s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 180/250 [04:00<01:34,  1.35s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 181/250 [04:01<01:34,  1.36s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 182/250 [04:02<01:29,  1.32s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 183/250 [04:04<01:31,  1.36s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 184/250 [04:05<01:27,  1.33s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 185/250 [04:07<01:28,  1.37s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 186/250 [04:08<01:25,  1.33s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 187/250 [04:09<01:26,  1.37s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 188/250 [04:11<01:21,  1.32s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 189/250 [04:12<01:22,  1.35s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 190/250 [04:13<01:19,  1.32s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 191/250 [04:15<01:20,  1.36s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 192/250 [04:16<01:16,  1.33s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 193/250 [04:17<01:16,  1.35s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 194/250 [04:19<01:13,  1.31s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 195/250 [04:20<01:13,  1.34s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 196/250 [04:21<01:10,  1.30s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 197/250 [04:23<01:10,  1.33s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 198/250 [04:24<01:07,  1.29s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 199/250 [04:25<01:07,  1.33s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 200/250 [04:26<01:05,  1.30s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 201/250 [04:28<01:06,  1.36s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 202/250 [04:29<01:03,  1.32s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 203/250 [04:31<01:04,  1.37s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 204/250 [04:32<01:00,  1.32s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 205/250 [04:33<01:01,  1.36s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 206/250 [04:35<00:58,  1.33s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 207/250 [04:36<00:58,  1.36s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 208/250 [04:37<00:55,  1.32s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 209/250 [04:39<00:56,  1.37s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 210/250 [04:40<00:52,  1.32s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 211/250 [04:41<00:52,  1.34s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 212/250 [04:43<00:49,  1.30s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 213/250 [04:44<00:49,  1.34s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 214/250 [04:45<00:47,  1.31s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 215/250 [04:47<00:46,  1.34s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 216/250 [04:48<00:44,  1.31s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 217/250 [04:49<00:44,  1.35s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 218/250 [04:51<00:42,  1.33s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 219/250 [04:52<00:42,  1.38s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 220/250 [04:53<00:40,  1.34s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 221/250 [04:55<00:39,  1.37s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 222/250 [04:56<00:37,  1.34s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 223/250 [04:57<00:36,  1.35s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 224/250 [04:59<00:34,  1.31s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 225/250 [05:00<00:33,  1.35s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 226/250 [05:01<00:31,  1.32s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 227/250 [05:03<00:30,  1.34s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 228/250 [05:04<00:28,  1.30s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 229/250 [05:05<00:28,  1.36s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 230/250 [05:07<00:26,  1.33s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 231/250 [05:08<00:26,  1.38s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 232/250 [05:09<00:24,  1.36s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 233/250 [05:11<00:23,  1.39s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 234/250 [05:12<00:21,  1.34s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 235/250 [05:14<00:20,  1.37s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 236/250 [05:15<00:18,  1.34s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 237/250 [05:16<00:17,  1.37s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 238/250 [05:18<00:16,  1.34s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 239/250 [05:19<00:15,  1.37s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 240/250 [05:20<00:13,  1.32s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 241/250 [05:22<00:12,  1.36s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 242/250 [05:23<00:10,  1.32s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 243/250 [05:24<00:09,  1.36s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 244/250 [05:26<00:07,  1.33s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 245/250 [05:27<00:06,  1.35s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 246/250 [05:28<00:05,  1.31s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 247/250 [05:30<00:04,  1.33s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 248/250 [05:31<00:02,  1.29s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 249/250 [05:32<00:01,  1.34s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:33<00:00,  1.30s/it][A                                                     
                                                 [A 15%|‚ñà‚ñå        | 150/980 [1:26:18<6:07:00, 26.53s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:34<00:00,  1.30s/it][A
                                                 [A 15%|‚ñà‚ñå        | 151/980 [1:26:52<30:09:13, 130.95s/it] 16%|‚ñà‚ñå        | 152/980 [1:27:19<22:56:57, 99.78s/it]  16%|‚ñà‚ñå        | 153/980 [1:27:46<17:52:03, 77.78s/it] 16%|‚ñà‚ñå        | 154/980 [1:28:12<14:20:32, 62.51s/it] 16%|‚ñà‚ñå        | 155/980 [1:28:39<11:50:26, 51.67s/it] 16%|‚ñà‚ñå        | 156/980 [1:29:05<10:06:07, 44.13s/it] 16%|‚ñà‚ñå        | 157/980 [1:29:32<8:55:00, 39.00s/it]  16%|‚ñà‚ñå        | 158/980 [1:29:59<8:03:17, 35.28s/it] 16%|‚ñà‚ñå        | 159/980 [1:30:25<7:25:55, 32.59s/it] 16%|‚ñà‚ñã        | 160/980 [1:30:52<6:59:47, 30.72s/it]                                                      16%|‚ñà‚ñã        | 160/980 [1:30:57<6:59:47, 30.72s/it] 16%|‚ñà‚ñã        | 161/980 [1:31:18<6:41:27, 29.41s/it] 17%|‚ñà‚ñã        | 162/980 [1:31:45<6:29:47, 28.59s/it] 17%|‚ñà‚ñã        | 163/980 [1:32:12<6:24:24, 28.23s/it] 17%|‚ñà‚ñã        | 164/980 [1:32:39<6:16:43, 27.70s/it] 17%|‚ñà‚ñã        | 165/980 [1:33:06<6:15:16, 27.63s/it] 17%|‚ñà‚ñã        | 166/980 [1:33:34<6:14:49, 27.63s/it] 17%|‚ñà‚ñã        | 167/980 [1:34:00<6:09:12, 27.25s/it] 17%|‚ñà‚ñã        | 168/980 [1:34:26<6:04:50, 26.96s/it] 17%|‚ñà‚ñã        | 169/980 [1:34:53<6:04:33, 26.97s/it] 17%|‚ñà‚ñã        | 170/980 [1:35:21<6:05:29, 27.07s/it] 17%|‚ñà‚ñã        | 171/980 [1:35:47<6:02:34, 26.89s/it] 18%|‚ñà‚ñä        | 172/980 [1:36:13<5:59:18, 26.68s/it] 18%|‚ñà‚ñä        | 173/980 [1:36:41<6:03:48, 27.05s/it] 18%|‚ñà‚ñä        | 174/980 [1:37:08<6:02:11, 26.96s/it] 18%|‚ñà‚ñä        | 175/980 [1:37:34<5:59:06, 26.77s/it] 18%|‚ñà‚ñä        | 176/980 [1:38:01<5:59:19, 26.81s/it] 18%|‚ñà‚ñä        | 177/980 [1:38:28<5:57:22, 26.70s/it] 18%|‚ñà‚ñä        | 178/980 [1:38:54<5:56:59, 26.71s/it] 18%|‚ñà‚ñä        | 179/980 [1:39:21<5:57:51, 26.81s/it] 18%|‚ñà‚ñä        | 180/980 [1:39:48<5:58:29, 26.89s/it]                                                      18%|‚ñà‚ñä        | 180/980 [1:39:54<5:58:29, 26.89s/it] 18%|‚ñà‚ñä        | 181/980 [1:40:15<5:57:35, 26.85s/it] 19%|‚ñà‚ñä        | 182/980 [1:40:41<5:54:00, 26.62s/it] 19%|‚ñà‚ñä        | 183/980 [1:41:07<5:51:22, 26.45s/it] 19%|‚ñà‚ñâ        | 184/980 [1:41:34<5:50:00, 26.38s/it] 19%|‚ñà‚ñâ        | 185/980 [1:42:01<5:52:13, 26.58s/it] 19%|‚ñà‚ñâ        | 186/980 [1:42:28<5:54:25, 26.78s/it] 19%|‚ñà‚ñâ        | 187/980 [1:42:55<5:55:52, 26.93s/it] 19%|‚ñà‚ñâ        | 188/980 [1:43:22<5:54:01, 26.82s/it] 19%|‚ñà‚ñâ        | 189/980 [1:43:48<5:52:40, 26.75s/it] 19%|‚ñà‚ñâ        | 190/980 [1:44:15<5:51:50, 26.72s/it] 19%|‚ñà‚ñâ        | 191/980 [1:44:42<5:50:42, 26.67s/it] 20%|‚ñà‚ñâ        | 192/980 [1:45:08<5:50:01, 26.65s/it] 20%|‚ñà‚ñâ        | 193/980 [1:45:35<5:49:41, 26.66s/it] 20%|‚ñà‚ñâ        | 194/980 [1:46:01<5:49:18, 26.67s/it] 20%|‚ñà‚ñâ        | 195/980 [1:46:28<5:48:49, 26.66s/it] 20%|‚ñà‚ñà        | 196/980 [1:46:55<5:50:20, 26.81s/it] 20%|‚ñà‚ñà        | 197/980 [1:47:22<5:50:05, 26.83s/it] 20%|‚ñà‚ñà        | 198/980 [1:47:50<5:51:47, 26.99s/it]{'eval_loss': 0.15094678103923798, 'eval_model_preparation_time': 0.0089, 'eval_runtime': 340.6848, 'eval_samples_per_second': 2.935, 'eval_steps_per_second': 0.734, 'epoch': 0.61}
{'loss': 0.1018, 'grad_norm': 0.039794921875, 'learning_rate': 9.878571612631364e-05, 'epoch': 0.65}
{'loss': 0.0931, 'grad_norm': 0.0322265625, 'learning_rate': 9.788241580149123e-05, 'epoch': 0.73}
{'loss': 0.0958, 'grad_norm': 0.031494140625, 'learning_rate': 9.673622250534156e-05, 'epoch': 0.82}
 20%|‚ñà‚ñà        | 199/980 [1:48:16<5:50:58, 26.96s/it] 20%|‚ñà‚ñà        | 200/980 [1:48:43<5:49:10, 26.86s/it]                                                      20%|‚ñà‚ñà        | 200/980 [1:48:48<5:49:10, 26.86s/it]
  0%|          | 0/250 [00:00<?, ?it/s][A
  1%|          | 2/250 [00:01<02:32,  1.63it/s][A
  1%|          | 3/250 [00:02<03:59,  1.03it/s][A
  2%|‚ñè         | 4/250 [00:03<04:25,  1.08s/it][A
  2%|‚ñè         | 5/250 [00:05<04:51,  1.19s/it][A
  2%|‚ñè         | 6/250 [00:06<04:52,  1.20s/it][A
  3%|‚ñé         | 7/250 [00:07<05:08,  1.27s/it][A
  3%|‚ñé         | 8/250 [00:09<05:09,  1.28s/it][A
  4%|‚ñé         | 9/250 [00:10<05:14,  1.31s/it][A
  4%|‚ñç         | 10/250 [00:11<05:12,  1.30s/it][A
  4%|‚ñç         | 11/250 [00:13<05:21,  1.35s/it][A
  5%|‚ñç         | 12/250 [00:14<05:13,  1.32s/it][A
  5%|‚ñå         | 13/250 [00:16<05:20,  1.35s/it][A
  6%|‚ñå         | 14/250 [00:17<05:09,  1.31s/it][A
  6%|‚ñå         | 15/250 [00:18<05:14,  1.34s/it][A
  6%|‚ñã         | 16/250 [00:19<05:03,  1.30s/it][A
  7%|‚ñã         | 17/250 [00:21<05:08,  1.33s/it][A
  7%|‚ñã         | 18/250 [00:22<05:05,  1.32s/it][A
  8%|‚ñä         | 19/250 [00:23<05:09,  1.34s/it][A
  8%|‚ñä         | 20/250 [00:25<04:59,  1.30s/it][A
  8%|‚ñä         | 21/250 [00:26<05:06,  1.34s/it][A
  9%|‚ñâ         | 22/250 [00:27<05:00,  1.32s/it][A
  9%|‚ñâ         | 23/250 [00:29<05:09,  1.36s/it][A
 10%|‚ñâ         | 24/250 [00:30<04:59,  1.33s/it][A
 10%|‚ñà         | 25/250 [00:32<05:05,  1.36s/it][A
 10%|‚ñà         | 26/250 [00:33<04:56,  1.33s/it][A
 11%|‚ñà         | 27/250 [00:34<05:03,  1.36s/it][A
 11%|‚ñà         | 28/250 [00:35<04:54,  1.33s/it][A
 12%|‚ñà‚ñè        | 29/250 [00:37<05:00,  1.36s/it][A
 12%|‚ñà‚ñè        | 30/250 [00:38<04:51,  1.33s/it][A
 12%|‚ñà‚ñè        | 31/250 [00:40<04:55,  1.35s/it][A
 13%|‚ñà‚ñé        | 32/250 [00:41<04:47,  1.32s/it][A
 13%|‚ñà‚ñé        | 33/250 [00:42<04:53,  1.35s/it][A
 14%|‚ñà‚ñé        | 34/250 [00:43<04:42,  1.31s/it][A
 14%|‚ñà‚ñç        | 35/250 [00:45<04:52,  1.36s/it][A
 14%|‚ñà‚ñç        | 36/250 [00:46<04:43,  1.33s/it][A
 15%|‚ñà‚ñç        | 37/250 [00:48<04:49,  1.36s/it][A
 15%|‚ñà‚ñå        | 38/250 [00:49<04:41,  1.33s/it][A
 16%|‚ñà‚ñå        | 39/250 [00:50<04:46,  1.36s/it][A
 16%|‚ñà‚ñå        | 40/250 [00:52<04:38,  1.33s/it][A
 16%|‚ñà‚ñã        | 41/250 [00:53<04:44,  1.36s/it][A
 17%|‚ñà‚ñã        | 42/250 [00:54<04:37,  1.33s/it][A
 17%|‚ñà‚ñã        | 43/250 [00:56<04:42,  1.36s/it][A
 18%|‚ñà‚ñä        | 44/250 [00:57<04:33,  1.33s/it][A
 18%|‚ñà‚ñä        | 45/250 [00:58<04:36,  1.35s/it][A
 18%|‚ñà‚ñä        | 46/250 [01:00<04:30,  1.33s/it][A
 19%|‚ñà‚ñâ        | 47/250 [01:01<04:32,  1.34s/it][A
 19%|‚ñà‚ñâ        | 48/250 [01:02<04:26,  1.32s/it][A
 20%|‚ñà‚ñâ        | 49/250 [01:04<04:29,  1.34s/it][A
 20%|‚ñà‚ñà        | 50/250 [01:05<04:23,  1.32s/it][A
 20%|‚ñà‚ñà        | 51/250 [01:06<04:31,  1.36s/it][A
 21%|‚ñà‚ñà        | 52/250 [01:08<04:21,  1.32s/it][A
 21%|‚ñà‚ñà        | 53/250 [01:09<04:28,  1.36s/it][A
 22%|‚ñà‚ñà‚ñè       | 54/250 [01:10<04:20,  1.33s/it][A
 22%|‚ñà‚ñà‚ñè       | 55/250 [01:12<04:23,  1.35s/it][A
 22%|‚ñà‚ñà‚ñè       | 56/250 [01:13<04:16,  1.32s/it][A
 23%|‚ñà‚ñà‚ñé       | 57/250 [01:14<04:24,  1.37s/it][A
 23%|‚ñà‚ñà‚ñé       | 58/250 [01:16<04:15,  1.33s/it][A
 24%|‚ñà‚ñà‚ñé       | 59/250 [01:17<04:20,  1.36s/it][A
 24%|‚ñà‚ñà‚ñç       | 60/250 [01:18<04:12,  1.33s/it][A
 24%|‚ñà‚ñà‚ñç       | 61/250 [01:20<04:18,  1.37s/it][A
 25%|‚ñà‚ñà‚ñç       | 62/250 [01:21<04:08,  1.32s/it][A
 25%|‚ñà‚ñà‚ñå       | 63/250 [01:23<04:15,  1.37s/it][A
 26%|‚ñà‚ñà‚ñå       | 64/250 [01:24<04:08,  1.34s/it][A
 26%|‚ñà‚ñà‚ñå       | 65/250 [01:25<04:13,  1.37s/it][A
 26%|‚ñà‚ñà‚ñã       | 66/250 [01:26<04:03,  1.32s/it][A
 27%|‚ñà‚ñà‚ñã       | 67/250 [01:28<04:08,  1.36s/it][A
 27%|‚ñà‚ñà‚ñã       | 68/250 [01:29<04:03,  1.34s/it][A
 28%|‚ñà‚ñà‚ñä       | 69/250 [01:31<04:07,  1.37s/it][A
 28%|‚ñà‚ñà‚ñä       | 70/250 [01:32<03:57,  1.32s/it][A
 28%|‚ñà‚ñà‚ñä       | 71/250 [01:33<04:03,  1.36s/it][A
 29%|‚ñà‚ñà‚ñâ       | 72/250 [01:35<03:57,  1.33s/it][A
 29%|‚ñà‚ñà‚ñâ       | 73/250 [01:36<04:05,  1.38s/it][A
 30%|‚ñà‚ñà‚ñâ       | 74/250 [01:37<03:57,  1.35s/it][A
 30%|‚ñà‚ñà‚ñà       | 75/250 [01:39<04:01,  1.38s/it][A
 30%|‚ñà‚ñà‚ñà       | 76/250 [01:40<03:53,  1.34s/it][A
 31%|‚ñà‚ñà‚ñà       | 77/250 [01:42<04:00,  1.39s/it][A
 31%|‚ñà‚ñà‚ñà       | 78/250 [01:43<03:51,  1.35s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 79/250 [01:44<03:53,  1.37s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 80/250 [01:45<03:46,  1.33s/it][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 81/250 [01:47<03:48,  1.35s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 82/250 [01:48<03:44,  1.34s/it][A
 33%|‚ñà‚ñà‚ñà‚ñé      | 83/250 [01:50<03:49,  1.37s/it][A
 34%|‚ñà‚ñà‚ñà‚ñé      | 84/250 [01:51<03:38,  1.32s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 85/250 [01:52<03:42,  1.35s/it][A
 34%|‚ñà‚ñà‚ñà‚ñç      | 86/250 [01:53<03:37,  1.32s/it][A
 35%|‚ñà‚ñà‚ñà‚ñç      | 87/250 [01:55<03:41,  1.36s/it][A
 35%|‚ñà‚ñà‚ñà‚ñå      | 88/250 [01:56<03:36,  1.34s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 89/250 [01:58<03:39,  1.36s/it][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 90/250 [01:59<03:30,  1.32s/it][A
 36%|‚ñà‚ñà‚ñà‚ñã      | 91/250 [02:00<03:34,  1.35s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 92/250 [02:02<03:28,  1.32s/it][A
 37%|‚ñà‚ñà‚ñà‚ñã      | 93/250 [02:03<03:31,  1.35s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 94/250 [02:04<03:29,  1.34s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 95/250 [02:06<03:36,  1.39s/it][A
 38%|‚ñà‚ñà‚ñà‚ñä      | 96/250 [02:07<03:29,  1.36s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 97/250 [02:08<03:32,  1.39s/it][A
 39%|‚ñà‚ñà‚ñà‚ñâ      | 98/250 [02:10<03:25,  1.35s/it][A
 40%|‚ñà‚ñà‚ñà‚ñâ      | 99/250 [02:11<03:26,  1.37s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 100/250 [02:12<03:18,  1.32s/it][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 101/250 [02:14<03:22,  1.36s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 102/250 [02:15<03:16,  1.33s/it][A
 41%|‚ñà‚ñà‚ñà‚ñà      | 103/250 [02:16<03:17,  1.35s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 104/250 [02:18<03:12,  1.32s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 105/250 [02:19<03:17,  1.36s/it][A
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 106/250 [02:20<03:11,  1.33s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 107/250 [02:22<03:15,  1.37s/it][A
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 108/250 [02:23<03:07,  1.32s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 109/250 [02:25<03:09,  1.35s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 110/250 [02:26<03:04,  1.32s/it][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 111/250 [02:27<03:07,  1.35s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 112/250 [02:28<03:02,  1.33s/it][A
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 113/250 [02:30<03:06,  1.36s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 114/250 [02:31<03:01,  1.33s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 115/250 [02:33<03:04,  1.37s/it][A
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 116/250 [02:34<02:56,  1.32s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 117/250 [02:35<03:00,  1.35s/it][A
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 118/250 [02:37<02:54,  1.32s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 119/250 [02:38<02:56,  1.35s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 120/250 [02:39<02:50,  1.31s/it][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 121/250 [02:41<02:54,  1.35s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 122/250 [02:42<02:48,  1.32s/it][A
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 123/250 [02:43<02:51,  1.35s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 124/250 [02:45<02:46,  1.32s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 125/250 [02:46<02:50,  1.36s/it][A
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 126/250 [02:47<02:44,  1.32s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 127/250 [02:49<02:47,  1.36s/it][A
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 128/250 [02:50<02:40,  1.31s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 129/250 [02:51<02:44,  1.36s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 130/250 [02:53<02:36,  1.31s/it][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 131/250 [02:54<02:40,  1.35s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 132/250 [02:55<02:35,  1.32s/it][A
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 133/250 [02:57<02:37,  1.35s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 134/250 [02:58<02:31,  1.31s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 135/250 [02:59<02:35,  1.36s/it][A
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 136/250 [03:01<02:31,  1.33s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 137/250 [03:02<02:34,  1.37s/it][A
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 138/250 [03:03<02:27,  1.32s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 139/250 [03:05<02:30,  1.36s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 140/250 [03:06<02:25,  1.33s/it][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 141/250 [03:07<02:28,  1.36s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 142/250 [03:09<02:23,  1.33s/it][A
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 143/250 [03:10<02:25,  1.36s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 144/250 [03:11<02:21,  1.33s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 145/250 [03:13<02:21,  1.35s/it][A
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 146/250 [03:14<02:18,  1.33s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 147/250 [03:15<02:20,  1.36s/it][A
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 148/250 [03:17<02:16,  1.34s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 149/250 [03:18<02:18,  1.37s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 150/250 [03:19<02:13,  1.34s/it][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 151/250 [03:21<02:16,  1.38s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 152/250 [03:22<02:11,  1.35s/it][A
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 153/250 [03:24<02:13,  1.38s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 154/250 [03:25<02:08,  1.34s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 155/250 [03:26<02:08,  1.36s/it][A
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 156/250 [03:28<02:04,  1.33s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 157/250 [03:29<02:07,  1.37s/it][A
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 158/250 [03:30<02:03,  1.34s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 159/250 [03:32<02:04,  1.37s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 160/250 [03:33<01:59,  1.32s/it][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 161/250 [03:34<02:00,  1.36s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 162/250 [03:36<01:55,  1.31s/it][A
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 163/250 [03:37<01:59,  1.37s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 164/250 [03:38<01:55,  1.34s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 165/250 [03:40<01:56,  1.38s/it][A
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 166/250 [03:41<01:51,  1.33s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 167/250 [03:42<01:51,  1.34s/it][A
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 168/250 [03:44<01:46,  1.30s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 169/250 [03:45<01:47,  1.32s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 170/250 [03:46<01:43,  1.29s/it][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 171/250 [03:48<01:46,  1.35s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 172/250 [03:49<01:43,  1.32s/it][A
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 173/250 [03:50<01:44,  1.36s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 174/250 [03:52<01:39,  1.31s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 175/250 [03:53<01:41,  1.35s/it][A
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 176/250 [03:54<01:39,  1.34s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 177/250 [03:56<01:41,  1.39s/it][A
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 178/250 [03:57<01:36,  1.34s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 179/250 [03:59<01:38,  1.39s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 180/250 [04:00<01:34,  1.35s/it][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 181/250 [04:01<01:34,  1.36s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 182/250 [04:02<01:29,  1.32s/it][A
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 183/250 [04:04<01:31,  1.36s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 184/250 [04:05<01:27,  1.33s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 185/250 [04:07<01:28,  1.37s/it][A
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 186/250 [04:08<01:25,  1.33s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 187/250 [04:09<01:26,  1.37s/it][A
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 188/250 [04:11<01:22,  1.32s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 189/250 [04:12<01:22,  1.35s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 190/250 [04:13<01:19,  1.32s/it][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 191/250 [04:15<01:18,  1.34s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 192/250 [04:16<01:15,  1.31s/it][A
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 193/250 [04:17<01:16,  1.34s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 194/250 [04:18<01:12,  1.30s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 195/250 [04:20<01:13,  1.33s/it][A
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 196/250 [04:21<01:09,  1.30s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 197/250 [04:22<01:10,  1.33s/it][A
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 198/250 [04:24<01:07,  1.29s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 199/250 [04:25<01:07,  1.33s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 200/250 [04:26<01:05,  1.30s/it][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 201/250 [04:28<01:06,  1.36s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 202/250 [04:29<01:03,  1.33s/it][A
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 203/250 [04:31<01:04,  1.37s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 204/250 [04:32<01:00,  1.32s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 205/250 [04:33<01:01,  1.36s/it][A
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 206/250 [04:34<00:58,  1.33s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 207/250 [04:36<00:58,  1.36s/it][A
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 208/250 [04:37<00:55,  1.32s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 209/250 [04:39<00:56,  1.37s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 210/250 [04:40<00:52,  1.32s/it][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 211/250 [04:41<00:52,  1.34s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 212/250 [04:42<00:49,  1.30s/it][A
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 213/250 [04:44<00:49,  1.34s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 214/250 [04:45<00:47,  1.32s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 215/250 [04:46<00:46,  1.34s/it][A
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 216/250 [04:48<00:44,  1.31s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 217/250 [04:49<00:44,  1.35s/it][A
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 218/250 [04:50<00:42,  1.33s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 219/250 [04:52<00:42,  1.38s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 220/250 [04:53<00:40,  1.34s/it][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 221/250 [04:55<00:39,  1.37s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 222/250 [04:56<00:37,  1.34s/it][A
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 223/250 [04:57<00:36,  1.35s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 224/250 [04:58<00:34,  1.31s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 225/250 [05:00<00:33,  1.35s/it][A
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 226/250 [05:01<00:31,  1.32s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 227/250 [05:03<00:30,  1.34s/it][A
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 228/250 [05:04<00:28,  1.30s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 229/250 [05:05<00:28,  1.36s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 230/250 [05:07<00:26,  1.33s/it][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 231/250 [05:08<00:26,  1.38s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 232/250 [05:09<00:24,  1.36s/it][A
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 233/250 [05:11<00:23,  1.39s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 234/250 [05:12<00:21,  1.34s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 235/250 [05:13<00:20,  1.37s/it][A
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 236/250 [05:15<00:18,  1.34s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 237/250 [05:16<00:17,  1.37s/it][A
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 238/250 [05:17<00:16,  1.34s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 239/250 [05:19<00:15,  1.37s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 240/250 [05:20<00:13,  1.32s/it][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 241/250 [05:21<00:12,  1.35s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 242/250 [05:23<00:10,  1.32s/it][A
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 243/250 [05:24<00:09,  1.39s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 244/250 [05:26<00:08,  1.35s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 245/250 [05:27<00:06,  1.36s/it][A
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 246/250 [05:28<00:05,  1.32s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 247/250 [05:30<00:04,  1.34s/it][A
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 248/250 [05:31<00:02,  1.30s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 249/250 [05:32<00:01,  1.34s/it][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:33<00:00,  1.30s/it][A                                                     
                                                 [A 20%|‚ñà‚ñà        | 200/980 [1:54:24<5:49:10, 26.86s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [05:34<00:00,  1.30s/it][A
                                                 [A 21%|‚ñà‚ñà        | 201/980 [1:54:57<28:22:11, 131.11s/it] 21%|‚ñà‚ñà        | 202/980 [1:55:24<21:32:35, 99.69s/it]  21%|‚ñà‚ñà        | 203/980 [1:55:51<16:50:10, 78.01s/it] 21%|‚ñà‚ñà        | 204/980 [1:56:18<13:28:54, 62.54s/it] 21%|‚ñà‚ñà        | 205/980 [1:56:44<11:08:31, 51.76s/it] 21%|‚ñà‚ñà        | 206/980 [1:57:11<9:31:47, 44.32s/it]  21%|‚ñà‚ñà        | 207/980 [1:57:37<8:21:06, 38.90s/it] 21%|‚ñà‚ñà        | 208/980 [1:58:04<7:33:16, 35.23s/it] 21%|‚ñà‚ñà‚ñè       | 209/980 [1:58:31<7:01:20, 32.79s/it] 21%|‚ñà‚ñà‚ñè       | 210/980 [1:58:58<6:37:41, 30.99s/it] 22%|‚ñà‚ñà‚ñè       | 211/980 [1:59:26<6:25:12, 30.05s/it] 22%|‚ñà‚ñà‚ñè       | 212/980 [1:59:53<6:12:08, 29.07s/it] 22%|‚ñà‚ñà‚ñè       | 213/980 [2:00:19<6:00:41, 28.22s/it] 22%|‚ñà‚ñà‚ñè       | 214/980 [2:00:45<5:51:45, 27.55s/it] 22%|‚ñà‚ñà‚ñè       | 215/980 [2:01:11<5:45:49, 27.12s/it] 22%|‚ñà‚ñà‚ñè       | 216/980 [2:01:40<5:53:09, 27.73s/it] 22%|‚ñà‚ñà‚ñè       | 217/980 [2:02:07<5:50:25, 27.56s/it] 22%|‚ñà‚ñà‚ñè       | 218/980 [2:02:34<5:45:30, 27.21s/it] 22%|‚ñà‚ñà‚ñè       | 219/980 [2:03:00<5:42:23, 27.00s/it] 22%|‚ñà‚ñà‚ñè       | 220/980 [2:03:27<5:39:47, 26.83s/it]                                                      22%|‚ñà‚ñà‚ñè       | 220/980 [2:03:32<5:39:47, 26.83s/it] 23%|‚ñà‚ñà‚ñé       | 221/980 [2:03:54<5:39:48, 26.86s/it] 23%|‚ñà‚ñà‚ñé       | 222/980 [2:04:20<5:37:07, 26.69s/it] 23%|‚ñà‚ñà‚ñé       | 223/980 [2:04:47<5:39:00, 26.87s/it] 23%|‚ñà‚ñà‚ñé       | 224/980 [2:05:15<5:41:12, 27.08s/it] 23%|‚ñà‚ñà‚ñé       | 225/980 [2:05:42<5:40:34, 27.07s/it] 23%|‚ñà‚ñà‚ñé       | 226/980 [2:06:09<5:40:32, 27.10s/it] 23%|‚ñà‚ñà‚ñé       | 227/980 [2:06:36<5:39:20, 27.04s/it] 23%|‚ñà‚ñà‚ñé       | 228/980 [2:07:03<5:37:40, 26.94s/it] 23%|‚ñà‚ñà‚ñé       | 229/980 [2:07:30<5:39:18, 27.11s/it] 23%|‚ñà‚ñà‚ñé       | 230/980 [2:07:57<5:39:09, 27.13s/it] 24%|‚ñà‚ñà‚ñé       | 231/980 [2:08:24<5:37:01, 27.00s/it] 24%|‚ñà‚ñà‚ñé       | 232/