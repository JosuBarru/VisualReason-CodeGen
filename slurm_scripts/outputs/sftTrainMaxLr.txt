ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 05-25 22:53:08 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.325 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
trainable params: 167,772,160 || all params: 8,198,033,408 || trainable%: 2.0465
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: We found double BOS tokens - we shall remove one automatically.
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 5.7821, 'grad_norm': 0.6875, 'learning_rate': 0.0010204081632653062, 'epoch': 0.08}
{'loss': 7.5546, 'grad_norm': 31.125, 'learning_rate': 0.0020408163265306124, 'epoch': 0.16}
{'eval_loss': 9.787104606628418, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 886.6626, 'eval_samples_per_second': 1.128, 'eval_steps_per_second': 0.282, 'epoch': 0.2}
{'loss': 12.9606, 'grad_norm': 51.5, 'learning_rate': 0.0030612244897959186, 'epoch': 0.24}
{'loss': 8.3361, 'grad_norm': 1.0625, 'learning_rate': 0.004081632653061225, 'epoch': 0.33}
{'loss': 6.4748, 'grad_norm': 0.265625, 'learning_rate': 0.004999936564737286, 'epoch': 0.41}
{'eval_loss': 6.168547630310059, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 881.4518, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.284, 'epoch': 0.41}
{'loss': 6.0964, 'grad_norm': 0.1259765625, 'learning_rate': 0.004992328227704295, 'epoch': 0.49}
{'loss': 6.0306, 'grad_norm': 0.15625, 'learning_rate': 0.004972077065562821, 'epoch': 0.57}
{'eval_loss': 5.914846420288086, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 885.9062, 'eval_samples_per_second': 1.129, 'eval_steps_per_second': 0.282, 'epoch': 0.61}
{'loss': 5.9917, 'grad_norm': 0.2001953125, 'learning_rate': 0.004939285806315682, 'epoch': 0.65}
{'loss': 6.0149, 'grad_norm': 0.09765625, 'learning_rate': 0.004894120790074561, 'epoch': 0.73}
{'loss': 6.0116, 'grad_norm': 0.125, 'learning_rate': 0.004836811125267078, 'epoch': 0.82}
{'eval_loss': 5.938643455505371, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 880.8723, 'eval_samples_per_second': 1.135, 'eval_steps_per_second': 0.284, 'epoch': 0.82}
{'loss': 6.0334, 'grad_norm': 0.2333984375, 'learning_rate': 0.0047676475264392245, 'epoch': 0.9}
{'loss': 6.059, 'grad_norm': 0.1708984375, 'learning_rate': 0.004686980839548665, 'epoch': 0.98}
{'eval_loss': 5.942956924438477, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 881.4806, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.284, 'epoch': 1.02}
{'loss': 6.0248, 'grad_norm': 0.1591796875, 'learning_rate': 0.0045952202622296014, 'epoch': 1.06}
{'loss': 6.0219, 'grad_norm': 0.10693359375, 'learning_rate': 0.0044928312680573065, 'epoch': 1.14}
{'loss': 6.0253, 'grad_norm': 0.16015625, 'learning_rate': 0.00438033324534186, 'epoch': 1.22}
{'eval_loss': 5.925880432128906, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 876.6909, 'eval_samples_per_second': 1.141, 'eval_steps_per_second': 0.285, 'epoch': 1.22}
{'loss': 6.0269, 'grad_norm': 0.154296875, 'learning_rate': 0.0042582968624287985, 'epoch': 1.31}
{'loss': 6.0168, 'grad_norm': 0.201171875, 'learning_rate': 0.004127341172871703, 'epoch': 1.39}
{'eval_loss': 5.941459655761719, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 882.0718, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.283, 'epoch': 1.43}
{'loss': 6.0065, 'grad_norm': 0.232421875, 'learning_rate': 0.003988130475161286, 'epoch': 1.47}
{'loss': 6.0332, 'grad_norm': 0.076171875, 'learning_rate': 0.003841370942940657, 'epoch': 1.55}
{'loss': 6.0179, 'grad_norm': 0.1259765625, 'learning_rate': 0.0036878070428006324, 'epoch': 1.63}
{'eval_loss': 5.925209045410156, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 876.116, 'eval_samples_per_second': 1.141, 'eval_steps_per_second': 0.285, 'epoch': 1.63}
{'loss': 6.019, 'grad_norm': 0.1533203125, 'learning_rate': 0.0035282177578265296, 'epoch': 1.71}
{'loss': 6.0281, 'grad_norm': 0.1103515625, 'learning_rate': 0.003363412636053269, 'epoch': 1.8}
{'eval_loss': 5.983621597290039, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 877.5897, 'eval_samples_per_second': 1.139, 'eval_steps_per_second': 0.285, 'epoch': 1.84}
{'loss': 6.0354, 'grad_norm': 0.08984375, 'learning_rate': 0.003194227683873751, 'epoch': 1.88}
{'loss': 6.0188, 'grad_norm': 0.09326171875, 'learning_rate': 0.0030215211252320024, 'epoch': 1.96}
{'loss': 6.012, 'grad_norm': 0.11181640625, 'learning_rate': 0.002846169048113435, 'epoch': 2.04}
{'eval_loss': 5.924254894256592, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 873.7363, 'eval_samples_per_second': 1.145, 'eval_steps_per_second': 0.286, 'epoch': 2.04}
{'loss': 6.0071, 'grad_norm': 0.08349609375, 'learning_rate': 0.0026690609604162374, 'epoch': 2.12}
{'loss': 6.0488, 'grad_norm': 0.15234375, 'learning_rate': 0.0024910952777476175, 'epoch': 2.2}
{'eval_loss': 5.978638172149658, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 877.8577, 'eval_samples_per_second': 1.139, 'eval_steps_per_second': 0.285, 'epoch': 2.24}
{'loss': 6.0559, 'grad_norm': 0.1083984375, 'learning_rate': 0.0023131747660339393, 'epoch': 2.29}
{'loss': 6.0349, 'grad_norm': 0.27734375, 'learning_rate': 0.0021362019620630177, 'epoch': 2.37}
{'loss': 6.0052, 'grad_norm': 0.095703125, 'learning_rate': 0.001961074595188751, 'epoch': 2.45}
{'eval_loss': 5.95515251159668, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 873.4419, 'eval_samples_per_second': 1.145, 'eval_steps_per_second': 0.286, 'epoch': 2.45}
{'loss': 6.0055, 'grad_norm': 0.14453125, 'learning_rate': 0.001788681033422419, 'epoch': 2.53}
{'loss': 6.0097, 'grad_norm': 0.1318359375, 'learning_rate': 0.0016198957770112246, 'epoch': 2.61}
{'eval_loss': 5.918540000915527, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 877.6129, 'eval_samples_per_second': 1.139, 'eval_steps_per_second': 0.285, 'epoch': 2.65}
{'loss': 6.0153, 'grad_norm': 0.11474609375, 'learning_rate': 0.0014555750223638026, 'epoch': 2.69}
{'loss': 6.0199, 'grad_norm': 0.107421875, 'learning_rate': 0.0012965523188255437, 'epoch': 2.78}
{'loss': 6.0268, 'grad_norm': 0.125, 'learning_rate': 0.0011436343403356016, 'epoch': 2.86}
{'eval_loss': 5.935455799102783, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 873.1338, 'eval_samples_per_second': 1.145, 'eval_steps_per_second': 0.286, 'epoch': 2.86}
{'loss': 6.0212, 'grad_norm': 0.1220703125, 'learning_rate': 0.0009975967934146934, 'epoch': 2.94}
{'loss': 6.0575, 'grad_norm': 0.07958984375, 'learning_rate': 0.0008591804822412047, 'epoch': 3.02}
{'eval_loss': 5.9355082511901855, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 877.837, 'eval_samples_per_second': 1.139, 'eval_steps_per_second': 0.285, 'epoch': 3.06}
{'loss': 6.0275, 'grad_norm': 0.07958984375, 'learning_rate': 0.0007290875507763017, 'epoch': 3.1}
{'loss': 6.0466, 'grad_norm': 0.078125, 'learning_rate': 0.0006079779210005953, 'epoch': 3.18}
{'loss': 6.0219, 'grad_norm': 0.1337890625, 'learning_rate': 0.0004964659453301088, 'epoch': 3.27}
{'eval_loss': 5.9426798820495605, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 873.7343, 'eval_samples_per_second': 1.145, 'eval_steps_per_second': 0.286, 'epoch': 3.27}
{'loss': 6.0146, 'grad_norm': 0.10546875, 'learning_rate': 0.00039511729019281325, 'epoch': 3.35}
{'loss': 6.0342, 'grad_norm': 0.0771484375, 'learning_rate': 0.00030444606657442836, 'epoch': 3.43}
{'eval_loss': 5.934549808502197, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 878.1771, 'eval_samples_per_second': 1.139, 'eval_steps_per_second': 0.285, 'epoch': 3.47}
{'loss': 6.009, 'grad_norm': 0.076171875, 'learning_rate': 0.00022491222208933376, 'epoch': 3.51}
{'loss': 6.0122, 'grad_norm': 0.0751953125, 'learning_rate': 0.0001569192078058307, 'epoch': 3.59}
{'loss': 6.0213, 'grad_norm': 0.06689453125, 'learning_rate': 0.00010081193166125824, 'epoch': 3.67}
{'eval_loss': 5.931304454803467, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 875.2968, 'eval_samples_per_second': 1.142, 'eval_steps_per_second': 0.286, 'epoch': 3.67}
{'loss': 6.0236, 'grad_norm': 0.07568359375, 'learning_rate': 5.6875008848639994e-05, 'epoch': 3.76}
{'loss': 6.0106, 'grad_norm': 0.08544921875, 'learning_rate': 2.5331318050146046e-05, 'epoch': 3.84}
{'eval_loss': 5.931417942047119, 'eval_model_preparation_time': 0.0062, 'eval_runtime': 878.9184, 'eval_samples_per_second': 1.138, 'eval_steps_per_second': 0.284, 'epoch': 3.88}
{'loss': 5.9888, 'grad_norm': 0.0771484375, 'learning_rate': 6.3408708411413776e-06, 'epoch': 3.92}
{'loss': 6.0272, 'grad_norm': 0.13671875, 'learning_rate': 0.0, 'epoch': 4.0}
{'train_runtime': 40285.7167, 'train_samples_per_second': 0.777, 'train_steps_per_second': 0.024, 'train_loss': 6.248519547131597, 'epoch': 4.0}
