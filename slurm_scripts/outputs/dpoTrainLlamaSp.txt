ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 03-31 16:14:12 __init__.py:183] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.2. vLLM: 0.7.1.
   \\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.15 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.6438, 'grad_norm': 3.25, 'learning_rate': 4.102564102564103e-06, 'rewards/chosen': 0.036142926663160324, 'rewards/rejected': -0.07153067737817764, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.10767360031604767, 'logps/chosen': -178.70330810546875, 'logps/rejected': -193.1033935546875, 'logits/chosen': -0.6650648713111877, 'logits/rejected': -0.8062074780464172, 'epoch': 0.12}
{'loss': 0.2291, 'grad_norm': 1.21875, 'learning_rate': 8.205128205128205e-06, 'rewards/chosen': 0.725608229637146, 'rewards/rejected': -1.1521131992340088, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 1.8777215480804443, 'logps/chosen': -178.56878662109375, 'logps/rejected': -202.31666564941406, 'logits/chosen': -0.6121434569358826, 'logits/rejected': -0.815960705280304, 'epoch': 0.25}
{'eval_loss': 1.8581486940383911, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 230.7385, 'eval_samples_per_second': 4.334, 'eval_steps_per_second': 1.083, 'eval_rewards/chosen': 0.6955386996269226, 'eval_rewards/rejected': 1.135413646697998, 'eval_rewards/accuracies': 0.45100000500679016, 'eval_rewards/margins': -0.4398750066757202, 'eval_logps/chosen': -172.87921142578125, 'eval_logps/rejected': -195.7686767578125, 'eval_logits/chosen': -0.6401463747024536, 'eval_logits/rejected': -0.5970786213874817, 'epoch': 0.31}
{'loss': 0.0352, 'grad_norm': 1.03125, 'learning_rate': 1.230769230769231e-05, 'rewards/chosen': 2.0101981163024902, 'rewards/rejected': -3.4781856536865234, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 5.488383769989014, 'logps/chosen': -167.93405151367188, 'logps/rejected': -224.5864715576172, 'logits/chosen': -0.504182755947113, 'logits/rejected': -0.7983534932136536, 'epoch': 0.37}
{'loss': 0.0305, 'grad_norm': 0.1064453125, 'learning_rate': 1.641025641025641e-05, 'rewards/chosen': 2.280395030975342, 'rewards/rejected': -5.043667793273926, 'rewards/accuracies': 0.9859374761581421, 'rewards/margins': 7.324063301086426, 'logps/chosen': -162.089599609375, 'logps/rejected': -241.72286987304688, 'logits/chosen': -0.5054978728294373, 'logits/rejected': -0.8190523386001587, 'epoch': 0.49}
{'loss': 0.0193, 'grad_norm': 0.0103759765625, 'learning_rate': 1.9999599453798523e-05, 'rewards/chosen': 1.500471830368042, 'rewards/rejected': -7.636732578277588, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 9.13720417022705, 'logps/chosen': -166.58670043945312, 'logps/rejected': -268.8422546386719, 'logits/chosen': -0.5107287168502808, 'logits/rejected': -0.825118362903595, 'epoch': 0.62}
{'eval_loss': 2.7929649353027344, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 224.2472, 'eval_samples_per_second': 4.459, 'eval_steps_per_second': 1.115, 'eval_rewards/chosen': -0.2876909077167511, 'eval_rewards/rejected': 0.5570648908615112, 'eval_rewards/accuracies': 0.46299999952316284, 'eval_rewards/margins': -0.8447558879852295, 'eval_logps/chosen': -182.7115020751953, 'eval_logps/rejected': -201.55213928222656, 'eval_logits/chosen': -0.580441951751709, 'eval_logits/rejected': -0.53642737865448, 'epoch': 0.62}
{'loss': 0.0134, 'grad_norm': 0.041748046875, 'learning_rate': 1.9967573081342103e-05, 'rewards/chosen': 2.0052132606506348, 'rewards/rejected': -7.62496280670166, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 9.630175590515137, 'logps/chosen': -167.59742736816406, 'logps/rejected': -267.0489196777344, 'logits/chosen': -0.44195953011512756, 'logits/rejected': -0.7441695332527161, 'epoch': 0.74}
{'loss': 0.0124, 'grad_norm': 0.8046875, 'learning_rate': 1.9884464537032103e-05, 'rewards/chosen': 3.1012051105499268, 'rewards/rejected': -6.7541656494140625, 'rewards/accuracies': 0.995312511920929, 'rewards/margins': 9.855371475219727, 'logps/chosen': -152.20828247070312, 'logps/rejected': -253.90097045898438, 'logits/chosen': -0.27915969491004944, 'logits/rejected': -0.6268520355224609, 'epoch': 0.86}
{'eval_loss': 2.941253900527954, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 230.4023, 'eval_samples_per_second': 4.34, 'eval_steps_per_second': 1.085, 'eval_rewards/chosen': -1.3165353536605835, 'eval_rewards/rejected': -0.30148524045944214, 'eval_rewards/accuracies': 0.4560000002384186, 'eval_rewards/margins': -1.0150501728057861, 'eval_logps/chosen': -192.9999542236328, 'eval_logps/rejected': -210.1376495361328, 'eval_logits/chosen': -0.5841412544250488, 'eval_logits/rejected': -0.5356338024139404, 'epoch': 0.92}
{'loss': 0.0199, 'grad_norm': 0.17578125, 'learning_rate': 1.9750699738482403e-05, 'rewards/chosen': 1.443946361541748, 'rewards/rejected': -8.871118545532227, 'rewards/accuracies': 0.989062488079071, 'rewards/margins': 10.315064430236816, 'logps/chosen': -172.1519012451172, 'logps/rejected': -273.673828125, 'logits/chosen': -0.4231323301792145, 'logits/rejected': -0.7232353687286377, 'epoch': 0.98}
{'loss': 0.0047, 'grad_norm': 0.1708984375, 'learning_rate': 1.9566964208274254e-05, 'rewards/chosen': 2.4813761711120605, 'rewards/rejected': -8.237336158752441, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 10.718711853027344, 'logps/chosen': -157.83145141601562, 'logps/rejected': -271.59375, 'logits/chosen': -0.3747785985469818, 'logits/rejected': -0.6129716634750366, 'epoch': 1.11}
{'loss': 0.0017, 'grad_norm': 0.0018310546875, 'learning_rate': 1.933419956076584e-05, 'rewards/chosen': 2.0468027591705322, 'rewards/rejected': -10.424903869628906, 'rewards/accuracies': 1.0, 'rewards/margins': 12.47170639038086, 'logps/chosen': -163.29257202148438, 'logps/rejected': -296.86871337890625, 'logits/chosen': -0.3143627941608429, 'logits/rejected': -0.5628305673599243, 'epoch': 1.23}
{'eval_loss': 3.4131288528442383, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 225.3732, 'eval_samples_per_second': 4.437, 'eval_steps_per_second': 1.109, 'eval_rewards/chosen': -0.6043259501457214, 'eval_rewards/rejected': 0.6268393993377686, 'eval_rewards/accuracies': 0.4650000035762787, 'eval_rewards/margins': -1.2311652898788452, 'eval_logps/chosen': -185.87786865234375, 'eval_logps/rejected': -200.85438537597656, 'eval_logits/chosen': -0.4135911762714386, 'eval_logits/rejected': -0.3780379891395569, 'epoch': 1.23}
{'loss': 0.002, 'grad_norm': 0.0228271484375, 'learning_rate': 1.9053598676473656e-05, 'rewards/chosen': 2.2406675815582275, 'rewards/rejected': -10.807510375976562, 'rewards/accuracies': 1.0, 'rewards/margins': 13.048177719116211, 'logps/chosen': -160.778564453125, 'logps/rejected': -300.87579345703125, 'logits/chosen': -0.2786148488521576, 'logits/rejected': -0.5286996960639954, 'epoch': 1.35}
{'loss': 0.0056, 'grad_norm': 0.01226806640625, 'learning_rate': 1.8726599588756144e-05, 'rewards/chosen': 1.9864877462387085, 'rewards/rejected': -12.436178207397461, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 14.4226655960083, 'logps/chosen': -163.13150024414062, 'logps/rejected': -311.2897033691406, 'logits/chosen': -0.21809092164039612, 'logits/rejected': -0.4709160327911377, 'epoch': 1.48}
{'eval_loss': 3.973567008972168, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 240.4713, 'eval_samples_per_second': 4.159, 'eval_steps_per_second': 1.04, 'eval_rewards/chosen': -1.0226036310195923, 'eval_rewards/rejected': 0.5049368739128113, 'eval_rewards/accuracies': 0.45100000500679016, 'eval_rewards/margins': -1.5275405645370483, 'eval_logps/chosen': -190.0606231689453, 'eval_logps/rejected': -202.0734405517578, 'eval_logits/chosen': -0.3305374085903168, 'eval_logits/rejected': -0.3003832995891571, 'epoch': 1.54}
{'loss': 0.0011, 'grad_norm': 0.0015106201171875, 'learning_rate': 1.8354878114129368e-05, 'rewards/chosen': 2.2772955894470215, 'rewards/rejected': -12.354827880859375, 'rewards/accuracies': 1.0, 'rewards/margins': 14.632123947143555, 'logps/chosen': -161.23670959472656, 'logps/rejected': -314.4676208496094, 'logits/chosen': -0.22284793853759766, 'logits/rejected': -0.4768451154232025, 'epoch': 1.6}
{'loss': 0.0066, 'grad_norm': 0.01068115234375, 'learning_rate': 1.7940339263983112e-05, 'rewards/chosen': 2.0082459449768066, 'rewards/rejected': -11.391351699829102, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 13.39959716796875, 'logps/chosen': -165.8925323486328, 'logps/rejected': -305.60699462890625, 'logits/chosen': -0.24202771484851837, 'logits/rejected': -0.4610878527164459, 'epoch': 1.72}
{'loss': 0.0025, 'grad_norm': 0.00775146484375, 'learning_rate': 1.7485107481711014e-05, 'rewards/chosen': 2.4531898498535156, 'rewards/rejected': -10.18152141571045, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 12.634710311889648, 'logps/chosen': -162.4517364501953, 'logps/rejected': -288.78399658203125, 'logits/chosen': -0.23870384693145752, 'logits/rejected': -0.498605340719223, 'epoch': 1.85}
{'eval_loss': 3.4664735794067383, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 236.6135, 'eval_samples_per_second': 4.226, 'eval_steps_per_second': 1.057, 'eval_rewards/chosen': -0.39714792370796204, 'eval_rewards/rejected': 0.8594974875450134, 'eval_rewards/accuracies': 0.4560000002384186, 'eval_rewards/margins': -1.2566455602645874, 'eval_logps/chosen': -183.80609130859375, 'eval_logps/rejected': -198.52783203125, 'eval_logits/chosen': -0.33261528611183167, 'eval_logits/rejected': -0.300388365983963, 'epoch': 1.85}
{'loss': 0.0161, 'grad_norm': 1.1640625, 'learning_rate': 1.6991515755287715e-05, 'rewards/chosen': 2.218151569366455, 'rewards/rejected': -11.05924129486084, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 13.277392387390137, 'logps/chosen': -166.1291046142578, 'logps/rejected': -300.5863342285156, 'logits/chosen': -0.22420033812522888, 'logits/rejected': -0.4442855417728424, 'epoch': 1.97}
{'loss': 0.0036, 'grad_norm': 0.00469970703125, 'learning_rate': 1.6462093661089432e-05, 'rewards/chosen': 2.685549259185791, 'rewards/rejected': -9.138436317443848, 'rewards/accuracies': 0.9984375238418579, 'rewards/margins': 11.82398509979248, 'logps/chosen': -156.94607543945312, 'logps/rejected': -279.7315979003906, 'logits/chosen': -0.21887776255607605, 'logits/rejected': -0.48819082975387573, 'epoch': 2.09}
{'eval_loss': 3.383981943130493, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 237.4979, 'eval_samples_per_second': 4.211, 'eval_steps_per_second': 1.053, 'eval_rewards/chosen': -0.17126834392547607, 'eval_rewards/rejected': 1.0877366065979004, 'eval_rewards/accuracies': 0.4449999928474426, 'eval_rewards/margins': -1.2590049505233765, 'eval_logps/chosen': -181.54730224609375, 'eval_logps/rejected': -196.2454376220703, 'eval_logits/chosen': -0.33820831775665283, 'eval_logits/rejected': -0.30470138788223267, 'epoch': 2.15}
{'loss': 0.0016, 'grad_norm': 0.021240234375, 'learning_rate': 1.5899554400231233e-05, 'rewards/chosen': 2.6060791015625, 'rewards/rejected': -9.77400016784668, 'rewards/accuracies': 1.0, 'rewards/margins': 12.38007926940918, 'logps/chosen': -155.7150115966797, 'logps/rejected': -284.8780822753906, 'logits/chosen': -0.2382727563381195, 'logits/rejected': -0.4863353371620178, 'epoch': 2.22}
{'loss': 0.0005, 'grad_norm': 0.0005950927734375, 'learning_rate': 1.530678089385782e-05, 'rewards/chosen': 2.487919569015503, 'rewards/rejected': -10.413464546203613, 'rewards/accuracies': 1.0, 'rewards/margins': 12.901382446289062, 'logps/chosen': -158.46359252929688, 'logps/rejected': -293.6593017578125, 'logits/chosen': -0.23191173374652863, 'logits/rejected': -0.47957247495651245, 'epoch': 2.34}
{'loss': 0.001, 'grad_norm': 0.0023193359375, 'learning_rate': 1.4686811008647037e-05, 'rewards/chosen': 2.3238234519958496, 'rewards/rejected': -10.751132011413574, 'rewards/accuracies': 1.0, 'rewards/margins': 13.074955940246582, 'logps/chosen': -165.52796936035156, 'logps/rejected': -296.8487243652344, 'logits/chosen': -0.2125231921672821, 'logits/rejected': -0.4468306601047516, 'epoch': 2.46}
{'eval_loss': 3.5586812496185303, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 229.5001, 'eval_samples_per_second': 4.357, 'eval_steps_per_second': 1.089, 'eval_rewards/chosen': -0.21619904041290283, 'eval_rewards/rejected': 1.1144435405731201, 'eval_rewards/accuracies': 0.4480000138282776, 'eval_rewards/margins': -1.330642580986023, 'eval_logps/chosen': -181.99661254882812, 'eval_logps/rejected': -195.97837829589844, 'eval_logits/chosen': -0.3043190836906433, 'eval_logits/rejected': -0.27304449677467346, 'epoch': 2.46}
{'loss': 0.0011, 'grad_norm': 0.0034942626953125, 'learning_rate': 1.404282198824305e-05, 'rewards/chosen': 2.5875580310821533, 'rewards/rejected': -10.72315788269043, 'rewards/accuracies': 1.0, 'rewards/margins': 13.310714721679688, 'logps/chosen': -157.350830078125, 'logps/rejected': -295.78363037109375, 'logits/chosen': -0.21309879422187805, 'logits/rejected': -0.4436771869659424, 'epoch': 2.58}
{'loss': 0.0003, 'grad_norm': 0.0006866455078125, 'learning_rate': 1.3378114170405473e-05, 'rewards/chosen': 2.3740274906158447, 'rewards/rejected': -11.331544876098633, 'rewards/accuracies': 1.0, 'rewards/margins': 13.705572128295898, 'logps/chosen': -161.57101440429688, 'logps/rejected': -306.39239501953125, 'logits/chosen': -0.21548466384410858, 'logits/rejected': -0.4756617546081543, 'epoch': 2.71}
{'eval_loss': 3.5980417728424072, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 236.9063, 'eval_samples_per_second': 4.221, 'eval_steps_per_second': 1.055, 'eval_rewards/chosen': -0.2675839364528656, 'eval_rewards/rejected': 1.0689016580581665, 'eval_rewards/accuracies': 0.45100000500679016, 'eval_rewards/margins': -1.336485505104065, 'eval_logps/chosen': -182.51043701171875, 'eval_logps/rejected': -196.43377685546875, 'eval_logits/chosen': -0.31560462713241577, 'eval_logits/rejected': -0.28304001688957214, 'epoch': 2.77}
{'loss': 0.0011, 'grad_norm': 0.2353515625, 'learning_rate': 1.269609407332144e-05, 'rewards/chosen': 2.4939522743225098, 'rewards/rejected': -10.835622787475586, 'rewards/accuracies': 1.0, 'rewards/margins': 13.329574584960938, 'logps/chosen': -159.97439575195312, 'logps/rejected': -299.9468688964844, 'logits/chosen': -0.19053466618061066, 'logits/rejected': -0.4441281259059906, 'epoch': 2.83}
{'loss': 0.0005, 'grad_norm': 0.06982421875, 'learning_rate': 1.2000256937760446e-05, 'rewards/chosen': 2.651401996612549, 'rewards/rejected': -11.138150215148926, 'rewards/accuracies': 1.0, 'rewards/margins': 13.78955078125, 'logps/chosen': -157.85659790039062, 'logps/rejected': -303.19183349609375, 'logits/chosen': -0.22400960326194763, 'logits/rejected': -0.46675819158554077, 'epoch': 2.95}
{'loss': 0.0002, 'grad_norm': 5.173683166503906e-05, 'learning_rate': 1.1294168814540554e-05, 'rewards/chosen': 2.741525173187256, 'rewards/rejected': -11.753440856933594, 'rewards/accuracies': 1.0, 'rewards/margins': 14.494966506958008, 'logps/chosen': -153.1564178466797, 'logps/rejected': -305.53369140625, 'logits/chosen': -0.1865626722574234, 'logits/rejected': -0.42751026153564453, 'epoch': 3.08}
{'eval_loss': 3.830491542816162, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 230.1817, 'eval_samples_per_second': 4.344, 'eval_steps_per_second': 1.086, 'eval_rewards/chosen': -0.5872271060943604, 'eval_rewards/rejected': 0.8611528873443604, 'eval_rewards/accuracies': 0.44600000977516174, 'eval_rewards/margins': -1.4483799934387207, 'eval_logps/chosen': -185.70687866210938, 'eval_logps/rejected': -198.51126098632812, 'eval_logits/chosen': -0.3077828288078308, 'eval_logits/rejected': -0.27628782391548157, 'epoch': 3.08}
{'loss': 0.0002, 'grad_norm': 0.000423431396484375, 'learning_rate': 1.0581448289104759e-05, 'rewards/chosen': 2.5919971466064453, 'rewards/rejected': -11.628560066223145, 'rewards/accuracies': 1.0, 'rewards/margins': 14.220556259155273, 'logps/chosen': -157.2519989013672, 'logps/rejected': -305.87835693359375, 'logits/chosen': -0.20965632796287537, 'logits/rejected': -0.47493237257003784, 'epoch': 3.2}
{'loss': 0.0002, 'grad_norm': 0.002593994140625, 'learning_rate': 9.865747936866027e-06, 'rewards/chosen': 2.6959385871887207, 'rewards/rejected': -11.688493728637695, 'rewards/accuracies': 1.0, 'rewards/margins': 14.384432792663574, 'logps/chosen': -161.26336669921875, 'logps/rejected': -307.250244140625, 'logits/chosen': -0.17505478858947754, 'logits/rejected': -0.4410879611968994, 'epoch': 3.32}
{'eval_loss': 3.8470966815948486, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 228.0961, 'eval_samples_per_second': 4.384, 'eval_steps_per_second': 1.096, 'eval_rewards/chosen': -0.6029418706893921, 'eval_rewards/rejected': 0.8514650464057922, 'eval_rewards/accuracies': 0.4490000009536743, 'eval_rewards/margins': -1.454406976699829, 'eval_logps/chosen': -185.86402893066406, 'eval_logps/rejected': -198.608154296875, 'eval_logits/chosen': -0.30544278025627136, 'eval_logits/rejected': -0.27407655119895935, 'epoch': 3.38}
{'loss': 0.0002, 'grad_norm': 0.0033111572265625, 'learning_rate': 9.15073560435935e-06, 'rewards/chosen': 2.742284059524536, 'rewards/rejected': -11.69063663482666, 'rewards/accuracies': 1.0, 'rewards/margins': 14.4329195022583, 'logps/chosen': -158.2281036376953, 'logps/rejected': -303.9078063964844, 'logits/chosen': -0.1976395547389984, 'logits/rejected': -0.46096271276474, 'epoch': 3.45}
{'loss': 0.0002, 'grad_norm': 0.0179443359375, 'learning_rate': 8.440075612131823e-06, 'rewards/chosen': 2.6239240169525146, 'rewards/rejected': -11.614709854125977, 'rewards/accuracies': 1.0, 'rewards/margins': 14.23863410949707, 'logps/chosen': -160.89419555664062, 'logps/rejected': -306.5701599121094, 'logits/chosen': -0.20012207329273224, 'logits/rejected': -0.4409509301185608, 'epoch': 3.57}
{'loss': 0.0002, 'grad_norm': 0.01123046875, 'learning_rate': 7.73740997570278e-06, 'rewards/chosen': 2.391951084136963, 'rewards/rejected': -11.864020347595215, 'rewards/accuracies': 1.0, 'rewards/margins': 14.255971908569336, 'logps/chosen': -159.15426635742188, 'logps/rejected': -306.6200256347656, 'logits/chosen': -0.20633383095264435, 'logits/rejected': -0.463162362575531, 'epoch': 3.69}
{'eval_loss': 3.8634393215179443, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 229.7919, 'eval_samples_per_second': 4.352, 'eval_steps_per_second': 1.088, 'eval_rewards/chosen': -0.6242308020591736, 'eval_rewards/rejected': 0.8384616374969482, 'eval_rewards/accuracies': 0.4490000009536743, 'eval_rewards/margins': -1.462692379951477, 'eval_logps/chosen': -186.076904296875, 'eval_logps/rejected': -198.7381591796875, 'eval_logits/chosen': -0.3036387264728546, 'eval_logits/rejected': -0.2724279463291168, 'epoch': 3.69}
{'loss': 0.0002, 'grad_norm': 0.0240478515625, 'learning_rate': 7.04633974083359e-06, 'rewards/chosen': 2.609867572784424, 'rewards/rejected': -11.832639694213867, 'rewards/accuracies': 1.0, 'rewards/margins': 14.442506790161133, 'logps/chosen': -157.9798126220703, 'logps/rejected': -310.6350402832031, 'logits/chosen': -0.20463144779205322, 'logits/rejected': -0.4611344337463379, 'epoch': 3.82}
{'loss': 0.0001, 'grad_norm': 0.00014495849609375, 'learning_rate': 6.370406528760675e-06, 'rewards/chosen': 2.791341781616211, 'rewards/rejected': -11.831768035888672, 'rewards/accuracies': 1.0, 'rewards/margins': 14.6231107711792, 'logps/chosen': -157.7451171875, 'logps/rejected': -309.1911315917969, 'logits/chosen': -0.2065383940935135, 'logits/rejected': -0.44688859581947327, 'epoch': 3.94}
{'eval_loss': 3.8630290031433105, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 229.8336, 'eval_samples_per_second': 4.351, 'eval_steps_per_second': 1.088, 'eval_rewards/chosen': -0.6199008822441101, 'eval_rewards/rejected': 0.841309666633606, 'eval_rewards/accuracies': 0.4480000138282776, 'eval_rewards/margins': -1.4612106084823608, 'eval_logps/chosen': -186.0336151123047, 'eval_logps/rejected': -198.70968627929688, 'eval_logits/chosen': -0.30283603072166443, 'eval_logits/rejected': -0.2717178761959076, 'epoch': 4.0}
{'loss': 0.0001, 'grad_norm': 0.06298828125, 'learning_rate': 5.713074385969457e-06, 'rewards/chosen': 2.7269484996795654, 'rewards/rejected': -11.897852897644043, 'rewards/accuracies': 1.0, 'rewards/margins': 14.62480354309082, 'logps/chosen': -151.78102111816406, 'logps/rejected': -311.44549560546875, 'logits/chosen': -0.188602477312088, 'logits/rejected': -0.45048412680625916, 'epoch': 4.06}
{'loss': 0.0002, 'grad_norm': 0.038330078125, 'learning_rate': 5.077712031526153e-06, 'rewards/chosen': 2.4886717796325684, 'rewards/rejected': -11.813080787658691, 'rewards/accuracies': 1.0, 'rewards/margins': 14.301752090454102, 'logps/chosen': -156.72618103027344, 'logps/rejected': -306.0080261230469, 'logits/chosen': -0.19254377484321594, 'logits/rejected': -0.46217307448387146, 'epoch': 4.18}
{'loss': 0.0001, 'grad_norm': 0.005645751953125, 'learning_rate': 4.467575592946865e-06, 'rewards/chosen': 2.637871742248535, 'rewards/rejected': -11.971010208129883, 'rewards/accuracies': 1.0, 'rewards/margins': 14.608880996704102, 'logps/chosen': -164.4578857421875, 'logps/rejected': -313.1665344238281, 'logits/chosen': -0.19252458214759827, 'logits/rejected': -0.4446956515312195, 'epoch': 4.31}
{'eval_loss': 3.8660342693328857, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 228.6557, 'eval_samples_per_second': 4.373, 'eval_steps_per_second': 1.093, 'eval_rewards/chosen': -0.6236932873725891, 'eval_rewards/rejected': 0.8382666707038879, 'eval_rewards/accuracies': 0.4490000009536743, 'eval_rewards/margins': -1.461959958076477, 'eval_logps/chosen': -186.071533203125, 'eval_logps/rejected': -198.74012756347656, 'eval_logits/chosen': -0.30234232544898987, 'eval_logits/rejected': -0.27112677693367004, 'epoch': 4.31}
{'loss': 0.0001, 'grad_norm': 5.221366882324219e-05, 'learning_rate': 3.885791919079878e-06, 'rewards/chosen': 2.8009912967681885, 'rewards/rejected': -11.836870193481445, 'rewards/accuracies': 1.0, 'rewards/margins': 14.637861251831055, 'logps/chosen': -159.00230407714844, 'logps/rejected': -309.4334716796875, 'logits/chosen': -0.20307886600494385, 'logits/rejected': -0.44979342818260193, 'epoch': 4.43}
{'loss': 0.0002, 'grad_norm': 0.001617431640625, 'learning_rate': 3.335342555519855e-06, 'rewards/chosen': 2.7641727924346924, 'rewards/rejected': -11.817848205566406, 'rewards/accuracies': 1.0, 'rewards/margins': 14.582021713256836, 'logps/chosen': -160.7533416748047, 'logps/rejected': -310.01116943359375, 'logits/chosen': -0.19883494079113007, 'logits/rejected': -0.4634508490562439, 'epoch': 4.55}
{'eval_loss': 3.8671326637268066, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 231.1479, 'eval_samples_per_second': 4.326, 'eval_steps_per_second': 1.082, 'eval_rewards/chosen': -0.6228238344192505, 'eval_rewards/rejected': 0.8408403396606445, 'eval_rewards/accuracies': 0.45100000500679016, 'eval_rewards/margins': -1.4636642932891846, 'eval_logps/chosen': -186.06285095214844, 'eval_logps/rejected': -198.71438598632812, 'eval_logits/chosen': -0.3020201325416565, 'eval_logits/rejected': -0.2709290385246277, 'epoch': 4.62}
{'loss': 0.0002, 'grad_norm': 4.220008850097656e-05, 'learning_rate': 2.819048464677261e-06, 'rewards/chosen': 2.7386908531188965, 'rewards/rejected': -11.777410507202148, 'rewards/accuracies': 1.0, 'rewards/margins': 14.516100883483887, 'logps/chosen': -156.39669799804688, 'logps/rejected': -306.1948547363281, 'logits/chosen': -0.2150609791278839, 'logits/rejected': -0.450381338596344, 'epoch': 4.68}
{'loss': 0.0001, 'grad_norm': 0.006134033203125, 'learning_rate': 2.339555568810221e-06, 'rewards/chosen': 2.5344135761260986, 'rewards/rejected': -11.649456024169922, 'rewards/accuracies': 1.0, 'rewards/margins': 14.183870315551758, 'logps/chosen': -160.87069702148438, 'logps/rejected': -306.84625244140625, 'logits/chosen': -0.20563170313835144, 'logits/rejected': -0.4570973515510559, 'epoch': 4.8}
{'loss': 0.0002, 'grad_norm': 0.0021514892578125, 'learning_rate': 1.8993211901083353e-06, 'rewards/chosen': 2.592599630355835, 'rewards/rejected': -11.809755325317383, 'rewards/accuracies': 1.0, 'rewards/margins': 14.402356147766113, 'logps/chosen': -155.18214416503906, 'logps/rejected': -304.74359130859375, 'logits/chosen': -0.19248025119304657, 'logits/rejected': -0.45675405859947205, 'epoch': 4.92}
{'eval_loss': 3.868522882461548, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 231.6595, 'eval_samples_per_second': 4.317, 'eval_steps_per_second': 1.079, 'eval_rewards/chosen': -0.6225992441177368, 'eval_rewards/rejected': 0.8409093618392944, 'eval_rewards/accuracies': 0.4480000138282776, 'eval_rewards/margins': -1.4635084867477417, 'eval_logps/chosen': -186.0605926513672, 'eval_logps/rejected': -198.71368408203125, 'eval_logits/chosen': -0.30182719230651855, 'eval_logits/rejected': -0.27074775099754333, 'epoch': 4.92}
{'loss': 0.0002, 'grad_norm': 0.00531005859375, 'learning_rate': 1.500601457320814e-06, 'rewards/chosen': 2.618159532546997, 'rewards/rejected': -11.842673301696777, 'rewards/accuracies': 1.0, 'rewards/margins': 14.460832595825195, 'logps/chosen': -155.73556518554688, 'logps/rejected': -307.4529724121094, 'logits/chosen': -0.1964423954486847, 'logits/rejected': -0.43791255354881287, 'epoch': 5.05}
{'loss': 0.0001, 'grad_norm': 0.00017261505126953125, 'learning_rate': 1.1454397434679022e-06, 'rewards/chosen': 2.6715593338012695, 'rewards/rejected': -11.87635326385498, 'rewards/accuracies': 1.0, 'rewards/margins': 14.547914505004883, 'logps/chosen': -159.17684936523438, 'logps/rejected': -308.91546630859375, 'logits/chosen': -0.18255004286766052, 'logits/rejected': -0.4404626786708832, 'epoch': 5.17}
{'eval_loss': 3.868281602859497, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 232.448, 'eval_samples_per_second': 4.302, 'eval_steps_per_second': 1.076, 'eval_rewards/chosen': -0.6227512955665588, 'eval_rewards/rejected': 0.8402934074401855, 'eval_rewards/accuracies': 0.4519999921321869, 'eval_rewards/margins': -1.46304452419281, 'eval_logps/chosen': -186.06211853027344, 'eval_logps/rejected': -198.7198486328125, 'eval_logits/chosen': -0.3017498850822449, 'eval_logits/rejected': -0.27062731981277466, 'epoch': 5.23}
{'loss': 0.0002, 'grad_norm': 0.01239013671875, 'learning_rate': 8.356561938903707e-07, 'rewards/chosen': 2.5082345008850098, 'rewards/rejected': -11.853601455688477, 'rewards/accuracies': 1.0, 'rewards/margins': 14.361837387084961, 'logps/chosen': -162.100830078125, 'logps/rejected': -306.46368408203125, 'logits/chosen': -0.21670477092266083, 'logits/rejected': -0.45102983713150024, 'epoch': 5.29}
{'loss': 0.0002, 'grad_norm': 0.01019287109375, 'learning_rate': 5.728383983041696e-07, 'rewards/chosen': 2.6975045204162598, 'rewards/rejected': -11.641827583312988, 'rewards/accuracies': 1.0, 'rewards/margins': 14.339330673217773, 'logps/chosen': -153.89442443847656, 'logps/rejected': -307.0646667480469, 'logits/chosen': -0.1851019561290741, 'logits/rejected': -0.45509976148605347, 'epoch': 5.42}
{'loss': 0.0002, 'grad_norm': 0.033935546875, 'learning_rate': 3.5833325466437697e-07, 'rewards/chosen': 2.603029727935791, 'rewards/rejected': -11.794305801391602, 'rewards/accuracies': 1.0, 'rewards/margins': 14.397333145141602, 'logps/chosen': -157.7276611328125, 'logps/rejected': -306.7121276855469, 'logits/chosen': -0.20422157645225525, 'logits/rejected': -0.4562655985355377, 'epoch': 5.54}
{'eval_loss': 3.8660998344421387, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 232.5784, 'eval_samples_per_second': 4.3, 'eval_steps_per_second': 1.075, 'eval_rewards/chosen': -0.6224233508110046, 'eval_rewards/rejected': 0.8383621573448181, 'eval_rewards/accuracies': 0.44999998807907104, 'eval_rewards/margins': -1.4607856273651123, 'eval_logps/chosen': -186.058837890625, 'eval_logps/rejected': -198.73916625976562, 'eval_logits/chosen': -0.30183929204940796, 'eval_logits/rejected': -0.2706717848777771, 'epoch': 5.54}
{'loss': 0.0002, 'grad_norm': 0.0003757476806640625, 'learning_rate': 1.9324006653480332e-07, 'rewards/chosen': 2.7949626445770264, 'rewards/rejected': -11.846343040466309, 'rewards/accuracies': 1.0, 'rewards/margins': 14.64130687713623, 'logps/chosen': -161.00656127929688, 'logps/rejected': -312.5505676269531, 'logits/chosen': -0.2106359452009201, 'logits/rejected': -0.4654160141944885, 'epoch': 5.66}
{'loss': 0.0001, 'grad_norm': 0.0311279296875, 'learning_rate': 7.840490933812783e-08, 'rewards/chosen': 2.801837205886841, 'rewards/rejected': -11.798060417175293, 'rewards/accuracies': 1.0, 'rewards/margins': 14.599897384643555, 'logps/chosen': -153.86154174804688, 'logps/rejected': -306.6255798339844, 'logits/chosen': -0.1947731077671051, 'logits/rejected': -0.4756355881690979, 'epoch': 5.78}
{'eval_loss': 3.866610288619995, 'eval_model_preparation_time': 0.0086, 'eval_runtime': 230.4375, 'eval_samples_per_second': 4.34, 'eval_steps_per_second': 1.085, 'eval_rewards/chosen': -0.6222547888755798, 'eval_rewards/rejected': 0.8395420908927917, 'eval_rewards/accuracies': 0.4490000009536743, 'eval_rewards/margins': -1.4617969989776611, 'eval_logps/chosen': -186.05715942382812, 'eval_logps/rejected': -198.7273712158203, 'eval_logits/chosen': -0.30185985565185547, 'eval_logits/rejected': -0.2707975506782532, 'epoch': 5.85}
{'loss': 0.0002, 'grad_norm': 0.056884765625, 'learning_rate': 1.4416294358582383e-08, 'rewards/chosen': 2.4406332969665527, 'rewards/rejected': -11.915578842163086, 'rewards/accuracies': 1.0, 'rewards/margins': 14.35621166229248, 'logps/chosen': -160.87245178222656, 'logps/rejected': -309.59649658203125, 'logits/chosen': -0.19774259626865387, 'logits/rejected': -0.43783384561538696, 'epoch': 5.91}
{'train_runtime': 10343.6136, 'train_samples_per_second': 3.012, 'train_steps_per_second': 0.189, 'train_loss': 0.02170004439062606, 'epoch': 6.0}
