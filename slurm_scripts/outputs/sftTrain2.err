wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbarrutia006 (jbarrutia006-upv-ehu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /sorgin1/users/jbarrutia006/viper/wandb/run-20250416_003149-4oflglab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Llama with SFT dataset. 3 epochs
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jbarrutia006-upv-ehu/viperSFT
wandb: üöÄ View run at https://wandb.ai/jbarrutia006-upv-ehu/viperSFT/runs/4oflglab
2025-04-16 00:31:50,471 - INFO - Results will be saved to: ./sft_trained_models/04-16_00-31-50
2025-04-16 00:31:50,471 - INFO - Loading model and tokenizer...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:45<02:17, 45.87s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [01:31<01:31, 45.79s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [02:15<00:45, 45.03s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [02:16<00:00, 27.55s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [02:16<00:00, 34.12s/it]
Unsloth 2025.3.14 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2025-04-16 00:34:22,474 - INFO - Loading SFT train and dev datasets...
/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/scripts/sft/sftrain.py", line 353, in <module>
    main()
  File "/sorgin1/users/jbarrutia006/viper/scripts/sft/sftrain.py", line 276, in main
    training_args = SFTConfig(
                    ^^^^^^^^^^
  File "/sorgin1/users/jbarrutia006/viper/unsloth_compiled_cache/UnslothSFTTrainer.py", line 253, in __init__
    super().__init__(
  File "<string>", line 145, in __init__
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/trl/trainer/sft_config.py", line 145, in __post_init__
    super().__post_init__()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/training_args.py", line 1662, in __post_init__
    raise ValueError(
ValueError: --load_best_model_at_end requires the saving steps to be a round multiple of the evaluation steps, but found 40, which is not a round multiple of 50.
Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/scripts/sft/sftrain.py", line 353, in <module>
    main()
  File "/sorgin1/users/jbarrutia006/viper/scripts/sft/sftrain.py", line 276, in main
    training_args = SFTConfig(
                    ^^^^^^^^^^
  File "/sorgin1/users/jbarrutia006/viper/unsloth_compiled_cache/UnslothSFTTrainer.py", line 253, in __init__
    super().__init__(
  File "<string>", line 145, in __init__
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/trl/trainer/sft_config.py", line 145, in __post_init__
    super().__post_init__()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/training_args.py", line 1662, in __post_init__
    raise ValueError(
ValueError: --load_best_model_at_end requires the saving steps to be a round multiple of the evaluation steps, but found 40, which is not a round multiple of 50.
srun: error: localhost: task 0: Exited with exit code 1
