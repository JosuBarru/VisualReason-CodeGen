wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jbarrutia006 (jbarrutia006-upv-ehu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /sorgin1/users/jbarrutia006/viper/wandb/run-20250330_225245-k0o87r31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Llama with specific llama dataset all. First go!
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jbarrutia006-upv-ehu/viperDPO
wandb: üöÄ View run at https://wandb.ai/jbarrutia006-upv-ehu/viperDPO/runs/k0o87r31
2025-03-30 22:52:45,963 - INFO - Loading model and tokenizer...
Unsloth 2025.3.14 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2025-03-30 22:55:19,792 - INFO - Loading dataset from /sorgin1/users/jbarrutia006/viper/syntData/PrefDatasets/dpo_dataset_llama_train.arrow as train and /sorgin1/users/jbarrutia006/viper/syntData/PrefDatasets/dpo_dataset_single_dev.arrow as dev
2025-03-30 22:55:19,810 - INFO - Initializing DPOTrainer...
Applying chat template to train dataset (num_proc=48):   0%|          | 0/5192 [00:00<?, ? examples/s]Applying chat template to train dataset (num_proc=48):   2%|‚ñè         | 109/5192 [00:01<00:58, 86.91 examples/s]Applying chat template to train dataset (num_proc=48):   6%|‚ñã         | 327/5192 [00:01<00:20, 239.70 examples/s]Applying chat template to train dataset (num_proc=48):   8%|‚ñä         | 436/5192 [00:01<00:15, 304.77 examples/s]Applying chat template to train dataset (num_proc=48):  10%|‚ñà         | 545/5192 [00:01<00:12, 364.04 examples/s]Applying chat template to train dataset (num_proc=48):  15%|‚ñà‚ñç        | 763/5192 [00:02<00:09, 451.03 examples/s]Applying chat template to train dataset (num_proc=48):  17%|‚ñà‚ñã        | 871/5192 [00:02<00:08, 481.85 examples/s]Applying chat template to train dataset (num_proc=48):  21%|‚ñà‚ñà        | 1088/5192 [00:02<00:07, 521.45 examples/s]Applying chat template to train dataset (num_proc=48):  25%|‚ñà‚ñà‚ñå       | 1304/5192 [00:03<00:07, 537.70 examples/s]Applying chat template to train dataset (num_proc=48):  29%|‚ñà‚ñà‚ñâ       | 1520/5192 [00:03<00:06, 561.89 examples/s]Applying chat template to train dataset (num_proc=48):  33%|‚ñà‚ñà‚ñà‚ñé      | 1736/5192 [00:03<00:05, 577.82 examples/s]Applying chat template to train dataset (num_proc=48):  38%|‚ñà‚ñà‚ñà‚ñä      | 1952/5192 [00:04<00:05, 588.83 examples/s]Applying chat template to train dataset (num_proc=48):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2168/5192 [00:04<00:05, 596.07 examples/s]Applying chat template to train dataset (num_proc=48):  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2276/5192 [00:04<00:04, 600.99 examples/s]Applying chat template to train dataset (num_proc=48):  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2492/5192 [00:05<00:04, 581.55 examples/s]Applying chat template to train dataset (num_proc=48):  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2708/5192 [00:05<00:03, 703.40 examples/s]Applying chat template to train dataset (num_proc=48):  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2816/5192 [00:05<00:03, 665.27 examples/s]Applying chat template to train dataset (num_proc=48):  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3032/5192 [00:06<00:03, 543.72 examples/s]Applying chat template to train dataset (num_proc=48):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3248/5192 [00:06<00:03, 554.43 examples/s]Applying chat template to train dataset (num_proc=48):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3356/5192 [00:06<00:03, 567.35 examples/s]Applying chat template to train dataset (num_proc=48):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3572/5192 [00:06<00:02, 702.08 examples/s]Applying chat template to train dataset (num_proc=48):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3680/5192 [00:07<00:02, 682.11 examples/s]Applying chat template to train dataset (num_proc=48):  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3788/5192 [00:07<00:02, 667.16 examples/s]Applying chat template to train dataset (num_proc=48):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3896/5192 [00:07<00:01, 649.50 examples/s]Applying chat template to train dataset (num_proc=48):  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4004/5192 [00:07<00:02, 501.47 examples/s]Applying chat template to train dataset (num_proc=48):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4220/5192 [00:07<00:01, 670.39 examples/s]Applying chat template to train dataset (num_proc=48):  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4328/5192 [00:08<00:01, 522.37 examples/s]Applying chat template to train dataset (num_proc=48):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4436/5192 [00:08<00:01, 546.09 examples/s]Applying chat template to train dataset (num_proc=48):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 4652/5192 [00:08<00:00, 711.71 examples/s]Applying chat template to train dataset (num_proc=48):  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 4760/5192 [00:08<00:00, 725.42 examples/s]Applying chat template to train dataset (num_proc=48):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 4868/5192 [00:08<00:00, 742.98 examples/s]Applying chat template to train dataset (num_proc=48):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4976/5192 [00:09<00:00, 685.28 examples/s]Applying chat template to train dataset (num_proc=48):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5084/5192 [00:09<00:00, 589.00 examples/s]Applying chat template to train dataset (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5192/5192 [00:09<00:00, 668.21 examples/s]Applying chat template to train dataset (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5192/5192 [00:09<00:00, 544.37 examples/s]
Tokenizing train dataset (num_proc=48):   0%|          | 0/5192 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=48):   1%|          | 34/5192 [00:01<03:19, 25.91 examples/s]Tokenizing train dataset (num_proc=48):   5%|‚ñç         | 258/5192 [00:01<00:21, 225.04 examples/s]Tokenizing train dataset (num_proc=48):   7%|‚ñã         | 357/5192 [00:01<00:20, 240.33 examples/s]Tokenizing train dataset (num_proc=48):  11%|‚ñà‚ñè        | 585/5192 [00:02<00:10, 426.92 examples/s]Tokenizing train dataset (num_proc=48):  13%|‚ñà‚ñé        | 688/5192 [00:02<00:12, 374.01 examples/s]Tokenizing train dataset (num_proc=48):  15%|‚ñà‚ñå        | 794/5192 [00:02<00:10, 412.41 examples/s]Tokenizing train dataset (num_proc=48):  20%|‚ñà‚ñâ        | 1015/5192 [00:02<00:08, 485.19 examples/s]Tokenizing train dataset (num_proc=48):  22%|‚ñà‚ñà‚ñè       | 1117/5192 [00:03<00:08, 497.90 examples/s]Tokenizing train dataset (num_proc=48):  26%|‚ñà‚ñà‚ñå       | 1341/5192 [00:03<00:07, 538.30 examples/s]Tokenizing train dataset (num_proc=48):  30%|‚ñà‚ñà‚ñâ       | 1556/5192 [00:03<00:05, 670.79 examples/s]Tokenizing train dataset (num_proc=48):  32%|‚ñà‚ñà‚ñà‚ñè      | 1660/5192 [00:04<00:06, 521.78 examples/s]Tokenizing train dataset (num_proc=48):  36%|‚ñà‚ñà‚ñà‚ñå      | 1874/5192 [00:04<00:06, 539.73 examples/s]Tokenizing train dataset (num_proc=48):  38%|‚ñà‚ñà‚ñà‚ñä      | 1984/5192 [00:04<00:05, 549.30 examples/s]Tokenizing train dataset (num_proc=48):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2203/5192 [00:04<00:04, 684.84 examples/s]Tokenizing train dataset (num_proc=48):  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2305/5192 [00:05<00:05, 524.32 examples/s]Tokenizing train dataset (num_proc=48):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2416/5192 [00:05<00:05, 532.64 examples/s]Tokenizing train dataset (num_proc=48):  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2521/5192 [00:05<00:04, 537.57 examples/s]Tokenizing train dataset (num_proc=48):  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2748/5192 [00:05<00:03, 705.15 examples/s]Tokenizing train dataset (num_proc=48):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2854/5192 [00:06<00:04, 528.14 examples/s]Tokenizing train dataset (num_proc=48):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2949/5192 [00:06<00:04, 517.89 examples/s]Tokenizing train dataset (num_proc=48):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3066/5192 [00:06<00:03, 542.81 examples/s]Tokenizing train dataset (num_proc=48):  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3220/5192 [00:06<00:03, 613.31 examples/s]Tokenizing train dataset (num_proc=48):  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3316/5192 [00:06<00:03, 580.73 examples/s]Tokenizing train dataset (num_proc=48):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3379/5192 [00:07<00:03, 512.59 examples/s]Tokenizing train dataset (num_proc=48):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3600/5192 [00:07<00:02, 553.35 examples/s]Tokenizing train dataset (num_proc=48):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3709/5192 [00:07<00:02, 565.85 examples/s]Tokenizing train dataset (num_proc=48):  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3804/5192 [00:07<00:02, 552.74 examples/s]Tokenizing train dataset (num_proc=48):  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4044/5192 [00:08<00:01, 755.66 examples/s]Tokenizing train dataset (num_proc=48):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4147/5192 [00:08<00:01, 711.77 examples/s]Tokenizing train dataset (num_proc=48):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4220/5192 [00:08<00:01, 628.55 examples/s]Tokenizing train dataset (num_proc=48):  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4302/5192 [00:08<00:01, 575.77 examples/s]Tokenizing train dataset (num_proc=48):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4414/5192 [00:08<00:01, 593.26 examples/s]Tokenizing train dataset (num_proc=48):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4582/5192 [00:08<00:00, 629.35 examples/s]Tokenizing train dataset (num_proc=48):  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 4737/5192 [00:09<00:00, 760.34 examples/s]Tokenizing train dataset (num_proc=48):  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 4844/5192 [00:09<00:00, 724.82 examples/s]Tokenizing train dataset (num_proc=48):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4954/5192 [00:09<00:00, 596.54 examples/s]Tokenizing train dataset (num_proc=48):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5063/5192 [00:09<00:00, 631.41 examples/s]Tokenizing train dataset (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5192/5192 [00:09<00:00, 747.49 examples/s]Tokenizing train dataset (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5192/5192 [00:09<00:00, 525.09 examples/s]
Applying chat template to eval dataset (num_proc=48):   0%|          | 0/1000 [00:00<?, ? examples/s]Applying chat template to eval dataset (num_proc=48):   2%|‚ñè         | 21/1000 [00:01<00:52, 18.52 examples/s]Applying chat template to eval dataset (num_proc=48):   6%|‚ñã         | 63/1000 [00:01<00:19, 48.93 examples/s]Applying chat template to eval dataset (num_proc=48):  10%|‚ñà         | 105/1000 [00:01<00:12, 69.16 examples/s]Applying chat template to eval dataset (num_proc=48):  13%|‚ñà‚ñé        | 126/1000 [00:02<00:13, 65.30 examples/s]Applying chat template to eval dataset (num_proc=48):  15%|‚ñà‚ñç        | 147/1000 [00:02<00:11, 74.24 examples/s]Applying chat template to eval dataset (num_proc=48):  19%|‚ñà‚ñâ        | 189/1000 [00:02<00:07, 105.45 examples/s]Applying chat template to eval dataset (num_proc=48):  21%|‚ñà‚ñà        | 210/1000 [00:02<00:09, 86.63 examples/s] Applying chat template to eval dataset (num_proc=48):  25%|‚ñà‚ñà‚ñå       | 252/1000 [00:03<00:06, 115.88 examples/s]Applying chat template to eval dataset (num_proc=48):  27%|‚ñà‚ñà‚ñã       | 273/1000 [00:03<00:07, 94.05 examples/s] Applying chat template to eval dataset (num_proc=48):  32%|‚ñà‚ñà‚ñà‚ñè      | 315/1000 [00:03<00:05, 121.14 examples/s]Applying chat template to eval dataset (num_proc=48):  34%|‚ñà‚ñà‚ñà‚ñé      | 336/1000 [00:03<00:05, 119.63 examples/s]Applying chat template to eval dataset (num_proc=48):  36%|‚ñà‚ñà‚ñà‚ñå      | 357/1000 [00:04<00:06, 95.02 examples/s] Applying chat template to eval dataset (num_proc=48):  38%|‚ñà‚ñà‚ñà‚ñä      | 378/1000 [00:04<00:06, 99.03 examples/s]Applying chat template to eval dataset (num_proc=48):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 420/1000 [00:04<00:04, 129.95 examples/s]Applying chat template to eval dataset (num_proc=48):  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 441/1000 [00:04<00:04, 125.51 examples/s]Applying chat template to eval dataset (num_proc=48):  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 462/1000 [00:05<00:05, 97.30 examples/s] Applying chat template to eval dataset (num_proc=48):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 504/1000 [00:05<00:04, 103.61 examples/s]Applying chat template to eval dataset (num_proc=48):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 546/1000 [00:05<00:03, 130.49 examples/s]Applying chat template to eval dataset (num_proc=48):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 567/1000 [00:06<00:04, 102.60 examples/s]Applying chat template to eval dataset (num_proc=48):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 609/1000 [00:06<00:03, 128.80 examples/s]Applying chat template to eval dataset (num_proc=48):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 630/1000 [00:06<00:02, 125.14 examples/s]Applying chat template to eval dataset (num_proc=48):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 651/1000 [00:06<00:02, 118.65 examples/s]Applying chat template to eval dataset (num_proc=48):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 672/1000 [00:06<00:02, 117.72 examples/s]Applying chat template to eval dataset (num_proc=48):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 693/1000 [00:07<00:02, 116.78 examples/s]Applying chat template to eval dataset (num_proc=48):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 714/1000 [00:07<00:02, 117.69 examples/s]Applying chat template to eval dataset (num_proc=48):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 735/1000 [00:07<00:02, 118.17 examples/s]Applying chat template to eval dataset (num_proc=48):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 756/1000 [00:07<00:02, 115.56 examples/s]Applying chat template to eval dataset (num_proc=48):  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 777/1000 [00:07<00:01, 115.77 examples/s]Applying chat template to eval dataset (num_proc=48):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 798/1000 [00:07<00:01, 112.97 examples/s]Applying chat template to eval dataset (num_proc=48):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 819/1000 [00:08<00:01, 115.49 examples/s]Applying chat template to eval dataset (num_proc=48):  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 840/1000 [00:08<00:01, 116.88 examples/s]Applying chat template to eval dataset (num_proc=48):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 860/1000 [00:08<00:01, 115.89 examples/s]Applying chat template to eval dataset (num_proc=48):  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 880/1000 [00:08<00:01, 112.21 examples/s]Applying chat template to eval dataset (num_proc=48):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 900/1000 [00:08<00:00, 107.88 examples/s]Applying chat template to eval dataset (num_proc=48):  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 920/1000 [00:09<00:00, 113.49 examples/s]Applying chat template to eval dataset (num_proc=48):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 940/1000 [00:09<00:00, 122.04 examples/s]Applying chat template to eval dataset (num_proc=48):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 960/1000 [00:09<00:00, 137.45 examples/s]Applying chat template to eval dataset (num_proc=48):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 980/1000 [00:09<00:00, 141.22 examples/s]Applying chat template to eval dataset (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:09<00:00, 113.01 examples/s]Applying chat template to eval dataset (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:09<00:00, 102.27 examples/s]
Tokenizing eval dataset (num_proc=48):   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset (num_proc=48):   2%|‚ñè         | 21/1000 [00:01<00:51, 18.99 examples/s]Tokenizing eval dataset (num_proc=48):   4%|‚ñç         | 42/1000 [00:01<00:30, 31.07 examples/s]Tokenizing eval dataset (num_proc=48):   8%|‚ñä         | 84/1000 [00:01<00:16, 56.15 examples/s]Tokenizing eval dataset (num_proc=48):  10%|‚ñà         | 105/1000 [00:02<00:13, 65.28 examples/s]Tokenizing eval dataset (num_proc=48):  15%|‚ñà‚ñç        | 147/1000 [00:02<00:08, 98.18 examples/s]Tokenizing eval dataset (num_proc=48):  17%|‚ñà‚ñã        | 168/1000 [00:02<00:08, 99.78 examples/s]Tokenizing eval dataset (num_proc=48):  21%|‚ñà‚ñà        | 210/1000 [00:02<00:06, 129.29 examples/s]Tokenizing eval dataset (num_proc=48):  23%|‚ñà‚ñà‚ñé       | 231/1000 [00:03<00:07, 98.97 examples/s] Tokenizing eval dataset (num_proc=48):  25%|‚ñà‚ñà‚ñå       | 252/1000 [00:03<00:09, 83.09 examples/s]Tokenizing eval dataset (num_proc=48):  29%|‚ñà‚ñà‚ñâ       | 294/1000 [00:03<00:06, 112.04 examples/s]Tokenizing eval dataset (num_proc=48):  32%|‚ñà‚ñà‚ñà‚ñè      | 315/1000 [00:03<00:07, 91.25 examples/s] Tokenizing eval dataset (num_proc=48):  34%|‚ñà‚ñà‚ñà‚ñé      | 336/1000 [00:04<00:06, 95.58 examples/s]Tokenizing eval dataset (num_proc=48):  38%|‚ñà‚ñà‚ñà‚ñä      | 378/1000 [00:04<00:06, 101.92 examples/s]Tokenizing eval dataset (num_proc=48):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 420/1000 [00:04<00:05, 106.31 examples/s]Tokenizing eval dataset (num_proc=48):  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 441/1000 [00:05<00:05, 107.62 examples/s]Tokenizing eval dataset (num_proc=48):  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 483/1000 [00:05<00:03, 133.66 examples/s]Tokenizing eval dataset (num_proc=48):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 504/1000 [00:05<00:04, 102.47 examples/s]Tokenizing eval dataset (num_proc=48):  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 525/1000 [00:05<00:04, 105.25 examples/s]Tokenizing eval dataset (num_proc=48):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 567/1000 [00:06<00:03, 134.29 examples/s]Tokenizing eval dataset (num_proc=48):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 588/1000 [00:06<00:03, 127.90 examples/s]Tokenizing eval dataset (num_proc=48):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 609/1000 [00:06<00:03, 98.62 examples/s] Tokenizing eval dataset (num_proc=48):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 651/1000 [00:06<00:03, 102.94 examples/s]Tokenizing eval dataset (num_proc=48):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 693/1000 [00:07<00:02, 128.96 examples/s]Tokenizing eval dataset (num_proc=48):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 714/1000 [00:07<00:02, 123.10 examples/s]Tokenizing eval dataset (num_proc=48):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 735/1000 [00:07<00:02, 121.10 examples/s]Tokenizing eval dataset (num_proc=48):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 756/1000 [00:07<00:02, 118.91 examples/s]Tokenizing eval dataset (num_proc=48):  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 777/1000 [00:07<00:01, 117.40 examples/s]Tokenizing eval dataset (num_proc=48):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 798/1000 [00:08<00:02, 89.62 examples/s] Tokenizing eval dataset (num_proc=48):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 819/1000 [00:08<00:01, 93.81 examples/s]Tokenizing eval dataset (num_proc=48):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 860/1000 [00:08<00:01, 121.76 examples/s]Tokenizing eval dataset (num_proc=48):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 900/1000 [00:08<00:00, 143.16 examples/s]Tokenizing eval dataset (num_proc=48):  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 920/1000 [00:09<00:00, 112.85 examples/s]Tokenizing eval dataset (num_proc=48):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 940/1000 [00:09<00:00, 122.20 examples/s]Tokenizing eval dataset (num_proc=48):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 960/1000 [00:09<00:00, 124.09 examples/s]Tokenizing eval dataset (num_proc=48):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 980/1000 [00:09<00:00, 120.79 examples/s]Tokenizing eval dataset (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:09<00:00, 118.12 examples/s]Tokenizing eval dataset (num_proc=48): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:09<00:00, 100.75 examples/s]
2025-03-30 22:56:08,691 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-03-30 22:56:08,700 - INFO - Performing pre-training evaluation on the dev dataset...
  0%|          | 0/250 [00:00<?, ?it/s]  1%|          | 2/250 [00:00<01:45,  2.34it/s]  1%|          | 3/250 [00:02<03:38,  1.13it/s]  2%|‚ñè         | 4/250 [00:03<03:50,  1.07it/s]  2%|‚ñè         | 5/250 [00:04<03:52,  1.05it/s]  2%|‚ñè         | 6/250 [00:06<05:11,  1.28s/it]  3%|‚ñé         | 7/250 [00:07<05:25,  1.34s/it]  3%|‚ñé         | 8/250 [00:08<05:11,  1.29s/it]  4%|‚ñé         | 9/250 [00:10<05:04,  1.26s/it]  4%|‚ñç         | 10/250 [00:11<05:06,  1.28s/it]  4%|‚ñç         | 11/250 [00:12<04:59,  1.25s/it]  5%|‚ñç         | 12/250 [00:13<04:25,  1.11s/it]  5%|‚ñå         | 13/250 [00:14<04:29,  1.14s/it]  6%|‚ñå         | 14/250 [00:15<04:08,  1.05s/it]  6%|‚ñå         | 15/250 [00:16<03:50,  1.02it/s]  6%|‚ñã         | 16/250 [00:17<03:37,  1.08it/s]  7%|‚ñã         | 17/250 [00:18<03:32,  1.10it/s]  7%|‚ñã         | 18/250 [00:19<03:59,  1.03s/it]  8%|‚ñä         | 19/250 [00:20<03:56,  1.02s/it]  8%|‚ñä         | 20/250 [00:21<03:40,  1.04it/s]  8%|‚ñä         | 21/250 [00:22<03:51,  1.01s/it]  9%|‚ñâ         | 22/250 [00:23<04:14,  1.11s/it]  9%|‚ñâ         | 23/250 [00:24<04:19,  1.14s/it] 10%|‚ñâ         | 24/250 [00:26<04:21,  1.16s/it] 10%|‚ñà         | 25/250 [00:26<03:58,  1.06s/it] 10%|‚ñà         | 26/250 [00:27<03:34,  1.05it/s] 11%|‚ñà         | 27/250 [00:28<03:27,  1.07it/s] 11%|‚ñà         | 28/250 [00:29<03:27,  1.07it/s] 12%|‚ñà‚ñè        | 29/250 [00:30<04:06,  1.12s/it] 12%|‚ñà‚ñè        | 30/250 [00:31<03:53,  1.06s/it] 12%|‚ñà‚ñè        | 31/250 [00:32<03:37,  1.01it/s] 13%|‚ñà‚ñé        | 32/250 [00:33<03:36,  1.01it/s] 13%|‚ñà‚ñé        | 33/250 [00:34<03:44,  1.03s/it] 14%|‚ñà‚ñé        | 34/250 [00:35<03:22,  1.07it/s] 14%|‚ñà‚ñç        | 35/250 [00:36<03:34,  1.00it/s] 14%|‚ñà‚ñç        | 36/250 [00:37<03:46,  1.06s/it] 15%|‚ñà‚ñç        | 37/250 [00:39<03:53,  1.10s/it] 15%|‚ñà‚ñå        | 38/250 [00:40<04:39,  1.32s/it] 16%|‚ñà‚ñå        | 39/250 [00:41<04:11,  1.19s/it] 16%|‚ñà‚ñå        | 40/250 [00:42<03:57,  1.13s/it] 16%|‚ñà‚ñã        | 41/250 [00:43<03:57,  1.14s/it] 17%|‚ñà‚ñã        | 42/250 [00:45<03:55,  1.13s/it] 17%|‚ñà‚ñã        | 43/250 [00:45<03:39,  1.06s/it] 18%|‚ñà‚ñä        | 44/250 [00:46<03:29,  1.02s/it] 18%|‚ñà‚ñä        | 45/250 [00:47<03:01,  1.13it/s] 18%|‚ñà‚ñä        | 46/250 [00:48<03:05,  1.10it/s] 19%|‚ñà‚ñâ        | 47/250 [00:49<02:54,  1.17it/s] 19%|‚ñà‚ñâ        | 48/250 [00:50<02:57,  1.14it/s] 20%|‚ñà‚ñâ        | 49/250 [00:51<03:16,  1.02it/s] 20%|‚ñà‚ñà        | 50/250 [00:52<03:16,  1.02it/s] 20%|‚ñà‚ñà        | 51/250 [00:55<05:40,  1.71s/it] 21%|‚ñà‚ñà        | 52/250 [00:57<05:23,  1.64s/it] 21%|‚ñà‚ñà        | 53/250 [00:58<04:49,  1.47s/it] 22%|‚ñà‚ñà‚ñè       | 54/250 [00:59<04:15,  1.31s/it] 22%|‚ñà‚ñà‚ñè       | 55/250 [01:00<04:29,  1.38s/it] 22%|‚ñà‚ñà‚ñè       | 56/250 [01:02<04:25,  1.37s/it] 23%|‚ñà‚ñà‚ñé       | 57/250 [01:03<04:14,  1.32s/it] 23%|‚ñà‚ñà‚ñé       | 58/250 [01:04<04:23,  1.37s/it] 24%|‚ñà‚ñà‚ñé       | 59/250 [01:05<03:58,  1.25s/it] 24%|‚ñà‚ñà‚ñç       | 60/250 [01:06<03:26,  1.09s/it] 24%|‚ñà‚ñà‚ñç       | 61/250 [01:07<03:23,  1.08s/it] 25%|‚ñà‚ñà‚ñç       | 62/250 [01:08<03:20,  1.07s/it] 25%|‚ñà‚ñà‚ñå       | 63/250 [01:09<03:25,  1.10s/it] 26%|‚ñà‚ñà‚ñå       | 64/250 [01:10<03:21,  1.08s/it] 26%|‚ñà‚ñà‚ñå       | 65/250 [01:11<03:07,  1.01s/it] 26%|‚ñà‚ñà‚ñã       | 66/250 [01:12<03:24,  1.11s/it] 27%|‚ñà‚ñà‚ñã       | 67/250 [01:14<03:33,  1.17s/it] 27%|‚ñà‚ñà‚ñã       | 68/250 [01:15<03:36,  1.19s/it] 28%|‚ñà‚ñà‚ñä       | 69/250 [01:16<03:29,  1.15s/it] 28%|‚ñà‚ñà‚ñä       | 70/250 [01:17<03:22,  1.12s/it] 28%|‚ñà‚ñà‚ñä       | 71/250 [01:19<03:40,  1.23s/it] 29%|‚ñà‚ñà‚ñâ       | 72/250 [01:20<03:23,  1.15s/it] 29%|‚ñà‚ñà‚ñâ       | 73/250 [01:21<03:41,  1.25s/it] 30%|‚ñà‚ñà‚ñâ       | 74/250 [01:22<03:29,  1.19s/it] 30%|‚ñà‚ñà‚ñà       | 75/250 [01:24<04:04,  1.40s/it] 30%|‚ñà‚ñà‚ñà       | 76/250 [01:25<03:44,  1.29s/it] 31%|‚ñà‚ñà‚ñà       | 77/250 [01:26<03:47,  1.31s/it] 31%|‚ñà‚ñà‚ñà       | 78/250 [01:27<03:29,  1.22s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 79/250 [01:28<03:11,  1.12s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 80/250 [01:29<03:00,  1.06s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 81/250 [01:31<03:21,  1.19s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 82/250 [01:32<03:17,  1.17s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 83/250 [01:33<03:21,  1.21s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 84/250 [01:34<03:01,  1.09s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 85/250 [01:35<02:58,  1.08s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 86/250 [01:36<02:50,  1.04s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 87/250 [01:37<02:45,  1.02s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 88/250 [01:38<02:50,  1.05s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 89/250 [01:39<02:46,  1.04s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 90/250 [01:40<02:43,  1.02s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 91/250 [01:41<02:44,  1.03s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 92/250 [01:42<02:35,  1.01it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 93/250 [01:43<02:51,  1.09s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 94/250 [01:45<03:02,  1.17s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 95/250 [01:46<03:12,  1.24s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 96/250 [01:47<03:09,  1.23s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 97/250 [01:48<02:59,  1.17s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 98/250 [01:49<02:50,  1.12s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 99/250 [01:50<02:30,  1.00it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 100/250 [01:51<02:24,  1.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 101/250 [01:52<02:33,  1.03s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 102/250 [01:53<02:39,  1.08s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 103/250 [01:54<02:23,  1.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 104/250 [01:55<02:20,  1.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 105/250 [01:56<02:27,  1.02s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 106/250 [01:57<02:25,  1.01s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 107/250 [01:58<02:32,  1.07s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 108/250 [02:00<02:57,  1.25s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 109/250 [02:01<02:38,  1.13s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 110/250 [02:02<02:31,  1.08s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 111/250 [02:03<02:22,  1.02s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 112/250 [02:04<02:30,  1.09s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 113/250 [02:05<02:32,  1.11s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 114/250 [02:06<02:25,  1.07s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 115/250 [02:07<02:23,  1.07s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 116/250 [02:08<02:03,  1.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 117/250 [02:09<02:40,  1.20s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 118/250 [02:10<02:28,  1.12s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 119/250 [02:11<02:24,  1.10s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 120/250 [02:12<02:08,  1.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 121/250 [02:13<02:07,  1.01it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 122/250 [02:14<01:59,  1.07it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 123/250 [02:15<01:54,  1.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 124/250 [02:16<01:54,  1.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 125/250 [02:17<01:57,  1.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 126/250 [02:18<01:52,  1.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 127/250 [02:18<01:50,  1.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 128/250 [02:19<01:50,  1.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 129/250 [02:20<01:55,  1.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 130/250 [02:21<01:42,  1.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 131/250 [02:22<01:48,  1.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 132/250 [02:23<01:50,  1.07it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 133/250 [02:24<01:49,  1.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 134/250 [02:25<01:38,  1.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 135/250 [02:26<01:59,  1.04s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 136/250 [02:27<01:53,  1.01it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 137/250 [02:28<01:52,  1.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 138/250 [02:29<01:53,  1.01s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 139/250 [02:30<01:47,  1.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 140/250 [02:31<01:51,  1.02s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 141/250 [02:32<01:50,  1.01s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 142/250 [02:33<01:44,  1.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 143/250 [02:34<01:40,  1.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 144/250 [02:35<01:42,  1.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 145/250 [02:36<01:31,  1.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 146/250 [02:37<01:36,  1.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 147/250 [02:38<01:37,  1.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 148/250 [02:39<01:41,  1.00it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 149/250 [02:40<01:35,  1.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 150/250 [02:41<01:45,  1.05s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 151/250 [02:42<01:48,  1.10s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 152/250 [02:43<01:52,  1.15s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 153/250 [02:44<01:43,  1.07s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 154/250 [02:45<01:36,  1.01s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 155/250 [02:46<01:41,  1.07s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 156/250 [02:47<01:42,  1.09s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 157/250 [02:49<01:46,  1.14s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 158/250 [02:50<01:54,  1.24s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 159/250 [02:51<01:42,  1.12s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 160/250 [02:53<01:51,  1.24s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 161/250 [02:54<01:44,  1.17s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 162/250 [02:54<01:30,  1.03s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 163/250 [02:56<01:45,  1.21s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 164/250 [02:57<01:37,  1.13s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 165/250 [02:58<01:32,  1.09s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 166/250 [02:59<01:25,  1.02s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 167/250 [03:00<01:22,  1.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 168/250 [03:01<01:25,  1.04s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 169/250 [03:01<01:17,  1.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 170/250 [03:02<01:16,  1.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 171/250 [03:04<01:22,  1.05s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 172/250 [03:05<01:20,  1.03s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 173/250 [03:06<01:33,  1.21s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 174/250 [03:07<01:20,  1.06s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 175/250 [03:08<01:13,  1.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 176/250 [03:09<01:21,  1.10s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 177/250 [03:11<01:25,  1.17s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 178/250 [03:12<01:30,  1.26s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 179/250 [03:13<01:27,  1.23s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 180/250 [03:14<01:20,  1.14s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 181/250 [03:15<01:10,  1.02s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 182/250 [03:16<01:07,  1.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 183/250 [03:17<01:09,  1.04s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 184/250 [03:18<01:06,  1.01s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 185/250 [03:19<01:06,  1.03s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 186/250 [03:20<01:02,  1.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 187/250 [03:21<01:03,  1.00s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 188/250 [03:22<01:10,  1.14s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 189/250 [03:23<01:04,  1.06s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 190/250 [03:25<01:13,  1.23s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 191/250 [03:26<01:03,  1.08s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 192/250 [03:26<00:59,  1.03s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 193/250 [03:27<00:55,  1.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 194/250 [03:28<00:51,  1.09it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 195/250 [03:29<00:49,  1.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 196/250 [03:30<00:58,  1.09s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 197/250 [03:31<00:54,  1.03s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 198/250 [03:32<00:50,  1.02it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 199/250 [03:33<00:50,  1.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 200/250 [03:35<00:59,  1.18s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 201/250 [03:36<01:00,  1.23s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 202/250 [03:37<00:57,  1.20s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 203/250 [03:39<00:56,  1.20s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 204/250 [03:39<00:48,  1.05s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 205/250 [03:41<00:55,  1.24s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 206/250 [03:42<00:57,  1.31s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 207/250 [03:43<00:51,  1.20s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 208/250 [03:44<00:45,  1.08s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 209/250 [03:45<00:45,  1.12s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 210/250 [03:46<00:39,  1.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 211/250 [03:47<00:36,  1.08it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 212/250 [03:48<00:36,  1.04it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 213/250 [03:49<00:35,  1.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 214/250 [03:50<00:33,  1.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 215/250 [03:50<00:30,  1.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 216/250 [03:51<00:30,  1.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 217/250 [03:52<00:30,  1.09it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 218/250 [03:54<00:32,  1.01s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 219/250 [03:55<00:34,  1.11s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 220/250 [03:56<00:35,  1.17s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 221/250 [03:57<00:31,  1.08s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 222/250 [03:58<00:31,  1.11s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 223/250 [03:59<00:29,  1.09s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 224/250 [04:00<00:27,  1.04s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 225/250 [04:01<00:27,  1.09s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 226/250 [04:02<00:25,  1.04s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 227/250 [04:05<00:32,  1.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 228/250 [04:06<00:30,  1.37s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 229/250 [04:07<00:27,  1.32s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 230/250 [04:08<00:26,  1.33s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 231/250 [04:10<00:24,  1.31s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 232/250 [04:11<00:23,  1.32s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 233/250 [04:12<00:20,  1.23s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 234/250 [04:13<00:19,  1.21s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 235/250 [04:14<00:17,  1.13s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 236/250 [04:15<00:15,  1.09s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 237/250 [04:16<00:13,  1.04s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 238/250 [04:17<00:12,  1.04s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 239/250 [04:18<00:11,  1.04s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 240/250 [04:19<00:09,  1.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 241/250 [04:20<00:08,  1.09it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 242/250 [04:21<00:07,  1.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 243/250 [04:22<00:07,  1.03s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 244/250 [04:23<00:05,  1.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 245/250 [04:24<00:04,  1.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 246/250 [04:25<00:03,  1.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 247/250 [04:26<00:02,  1.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 248/250 [04:27<00:02,  1.07s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 249/250 [04:28<00:01,  1.16s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [04:30<00:00,  1.20s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [04:30<00:00,  1.08s/it]
2025-03-30 23:00:44,643 - INFO - Initial evaluation results: {'eval_loss': 0.6931473612785339, 'eval_model_preparation_time': 0.0096, 'eval_runtime': 275.8968, 'eval_samples_per_second': 3.625, 'eval_steps_per_second': 0.906, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -179.7901153564453, 'eval_logps/rejected': -207.07675170898438, 'eval_logits/chosen': -0.7567641139030457, 'eval_logits/rejected': -0.7174069285392761}
2025-03-30 23:00:44,644 - INFO - Starting training...
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 5,192 | Num Epochs = 6 | Total steps = 1,944
O^O/ \_/ \    Batch size per device = 8 | Gradient accumulation steps = 2
\        /    Data Parallel GPUs = 1 | Total batch size (8 x 2 x 1) = 16
 "-____-"     Trainable parameters = 167,772,160/8,000,000,000 (2.10% trained)
  0%|          | 0/1944 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/scripts/dpo/dpotrain.py", line 161, in <module>
    train_dpo(args)
  File "/sorgin1/users/jbarrutia006/viper/scripts/dpo/dpotrain.py", line 148, in train_dpo
    trainer.train()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/trainer.py", line 2171, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 394, in _fast_inner_training_loop
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/accelerate/accelerator.py", line 2396, in clip_grad_norm_
    self.unscale_gradients()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/accelerate/accelerator.py", line 2340, in unscale_gradients
    self.scaler.unscale_(opt)
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 338, in unscale_
    optimizer_state["found_inf_per_device"] = self._unscale_grads_(
                                              ^^^^^^^^^^^^^^^^^^^^^
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 260, in _unscale_grads_
    raise ValueError("Attempting to unscale FP16 gradients.")
ValueError: Attempting to unscale FP16 gradients.
Traceback (most recent call last):
  File "/sorgin1/users/jbarrutia006/viper/scripts/dpo/dpotrain.py", line 161, in <module>
    train_dpo(args)
  File "/sorgin1/users/jbarrutia006/viper/scripts/dpo/dpotrain.py", line 148, in train_dpo
    trainer.train()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/transformers/trainer.py", line 2171, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 394, in _fast_inner_training_loop
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/accelerate/accelerator.py", line 2396, in clip_grad_norm_
    self.unscale_gradients()
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/accelerate/accelerator.py", line 2340, in unscale_gradients
    self.scaler.unscale_(opt)
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 338, in unscale_
    optimizer_state["found_inf_per_device"] = self._unscale_grads_(
                                              ^^^^^^^^^^^^^^^^^^^^^
  File "/sorgin1/users/jbarrutia006/venvs/viper_tximista/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 260, in _unscale_grads_
    raise ValueError("Attempting to unscale FP16 gradients.")
ValueError: Attempting to unscale FP16 gradients.
srun: error: localhost: task 0: Exited with exit code 1
